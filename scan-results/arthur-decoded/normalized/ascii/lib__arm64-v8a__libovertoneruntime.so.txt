000002a8 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
00001884 v	*ANc
00001f00 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
0015bc28  !"#0123
0015bc38 ()*+89:;
0015c2d8 ,-./<=>?Q
0015c368 $%&'4567
0015c5b8 &TpxAD
0015c7ac UseCooIndices
0015c7ba RegisterCustomOpsUsingFunction: Registration function name must be specified.
0015c808 Input is not of one of the supported map types.
0015c838 OrtStatus *OrtCreateValueImplMapHelper(const onnxruntime::Tensor &, const onnxruntime::Tensor &, OrtValue **) [KeyType = std::basic_string<char>]
0015c8ca At least one element in the sequence is of a type different from others.
0015c913 IsSameDataType(tensor.Get<Tensor>())
0015c938 ConstructorCommon
0015c94a session.inter_op.allow_spinning
0015c96a Serialized version info is null. Invalid ORT format model.
0015c9a5 The session already has a PrePackedWeightsContainer instance
0015c9e2 At least one output should be requested.
0015ca0b The registered allocator for device-id 
0015ca33  are '0' and '1'. 
0015ca46  has already been registered.
0015ca64 OrtMemoryInfo:[
0015ca74  bytes were able to be read.
0015ca91 session.use_ort_model_bytes_directly
0015cab6 Unsupported value for inter_op_num_threads: 
0015cae3 invalid string: control character U+0001 (SOH) must be escaped to \u0001
0015cb2c No allocator for this device has been registered for sharing.
0015cb6a tensor(complex128)
0015cb7d /onnxruntime_src/include/onnxruntime/core/framework/op_kernel_context.h
0015cbc5 delimiter must not be empty
0015cbe1 Inconsistent input sizes
0015cbfa ashmem_create_region
0015cc0f ANEURALNETWORKS_INCOMPLETE
0015cc2a DequantizeLinear
0015cc3b GetType
0015cc43 initializer tensor: 
0015cc58 AddOperandFromPersistMemoryBuffer
0015cc7a AddNnapiTranspose
0015cc8c ComputeConvPads
0015cc9c ] has no channelQuant
0015ccb2 AddSqueezeOp
0015ccbf Reshape/Flatten can only be skipped when input_rank >= 2 and output_rank == 2
0015cd0d  has no quant_param
0015cd21  index  [
0015cd2b HasRequiredScaleAndZeroPoint
0015cd48 IsNodeUnitTypeSupported
0015cd60 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/quantizelinear_op_builder.cc
0015cdcb Resize unsupported input mode, 
0015cdeb Unknown AutoPadType String
0015ce06 has_bias == false || info.TryGetConstantInput(8, &B_)
0015ce3c  kernel_shape: 
0015ce4c  returned 
0015ce57 QCINT8
0015ce5e inferred_output_shape[1] == output_dims_[1] && inferred_output_shape[2] == output_dims_[2] && inferred_output_shape[3] == output_dims_[3]
0015cee8 xnn_create_softmax_nc_
0015ceff unsupported op in Resize, we have FLOAT|UINT8|INT8, but get 
0015cf3c `tf_half_pixel_for_nn` is deprecated since opset 13, 
0015cf72 InlinedVector<std::unique_ptr<GraphTransformer>> onnxruntime::optimizer_utils::GenerateTransformersForMinimalBuild(onnxruntime::TransformerLevel, const onnxruntime::SessionOptions &, const onnxruntime::SatApplyContextVariant &, const onnxruntime::IExecutionProvider &, const InlinedHashSet<std::string> &)
0015d0a4 CastElimination
0015d0b4 ClipQuantRewrite
0015d0c5 ConvMulFusion_Mul_B_
0015d0da ConvBnFusion_BN_B_
0015d0ed index < nodes_.size() && ((node = nodes_[index]) != nullptr || !required)
0015d137 Output edge count not expected for nodes in gemm path
0015d16d Pass MatchInputMaskSubgraphDistilBert
0015d193 Using transpose optimized pattern
0015d1b5 opt_k_transpose perm attribute not matched
0015d1e0 Total fused Attention node count: 
0015d203 Invalid other(scalers) size
0015d21f Fused MatMul and Scale
0015d236 shape
0015d23c onnxruntime::OptimizerExecutionFrame::Info::Info(const std::vector<const Node *> &, const onnxruntime::InitializedTensorSet &, const onnxruntime::Path &, const onnxruntime::IExecutionProvider &, const std::function<bool (const std::string &)> &)
0015d332 Cleaning up back-to-back nodes: 
0015d353 node_output_def_idx >= 0 && static_cast<size_t>(node_output_def_idx) < node_outputs.size()
0015d3ae auto onnxruntime::TransformerMemcpyImpl::ProcessInitializers(const onnxruntime::KernelRegistryManager &, const onnxruntime::InitializedTensorSet &)::(anonymous class)::operator()(const onnxruntime::NodeArg &, size_t) const
0015d48d Permutation length 
0015d4a1 /onnxruntime_src/onnxruntime/core/providers/cpu/cpu_execution_provider.cc
0015d4eb virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Elu<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Elu<float>]
0015d5a8  dimensions or more but input had shape of 
0015d5d4 typename std::enable_if<!std::is_const<reference>::value, reference>::type onnxruntime::OrtValueTensorSlicer<OrtValue>::Iterator::operator*() [T = OrtValue]
0015d671 Outputs from Scan are not optional and should never be null.
0015d6ae num_classes is < 1
0015d6c1 info.GetAttrs("shape", shape).IsOK()
0015d6e6 min->Shape().IsScalar()
0015d6fe void onnxruntime::WritableSliceIterator<int>::Init(gsl::span<const int64_t>, gsl::span<const int64_t>, gsl::span<const int64_t>) [T = int]
0015d789 void onnxruntime::WritableSliceIterator<long>::Init(gsl::span<const int64_t>, gsl::span<const int64_t>, gsl::span<const int64_t>) [T = long]
0015d816 Rank of the input must match number of subscript labels corresponding to the input
0015d869  Right shape: 
0015d878 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Ceil<double>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Ceil<double>]
0015d939 virtual onnxruntime::common::Status onnxruntime::Sum_6<double>::Compute(onnxruntime::OpKernelContext *) const [T = double]
0015d9b4 onnxruntime::BitShift<unsigned long>::BitShift(const onnxruntime::OpKernelInfo &) [T = unsigned long]
0015da1a onnxruntime::common::Status onnxruntime::ml::CastMap::ComputeImpl(onnxruntime::OpKernelContext &, TTo) const [TFrom = std::basic_string<char>, TTo = std::basic_string<char>]
0015dac8 int64_vocabulary
0015dad9 Empty input dimensions.
0015daf1 keys_strings
0015dafe onnxruntime::ml::LabelEncoder_2<float, std::basic_string<char>>::LabelEncoder_2(const onnxruntime::OpKernelInfo &) [TKey = float, TValue = std::basic_string<char>]
0015dba2 info.GetAttr<int64_t>("targets", &num_targets_).IsOK()
0015dbd9 onnxruntime::ml::NORMALIZE onnxruntime::ml::MakeNormalize(const std::string &)
0015dc28 virtual onnxruntime::common::Status onnxruntime::ml::SVMRegressor<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
0015dcac virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommonClassifier<float, float, float>::Init(const onnxruntime::OpKernelInfo &) [InputType = float, ThresholdType = float, OutputType = float]
0015dd83 class_weights_as_tensor
0015dd9b void onnxruntime::ml::detail::TreeAggregatorMin<double, double, float>::MergePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = double, ThresholdType = double, OutputType = float]
0015de98 void onnxruntime::ml::detail::TreeEnsembleCommon<int, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = int, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorClassifier<int, float, float>]
0015dfea T *OrtValue::GetMutable() [T = std::vector<std::map<long, float>>]
0015e02d Shape must be 1 dimensional as it's tensor data of a shape
0015e068 Invalid input mean: 0th dimension != 
0015e08e gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = bool]
0015e0cf /onnxruntime_src/onnxruntime/core/providers/cpu/nn/flatten.h
0015e10c Invalid input data: number of dimensions is less than 3: 
0015e146 LpPool
0015e14d attribute case_change_action has invalid value
0015e17c stopwords
0015e186 Stopword contains invalid utf8 chars
0015e1ab Failed to construct locale with name:
0015e1d1 impl_->max_gram_length_ >= impl_->min_gram_length_
0015e204 sampling_ratio
0015e213 /onnxruntime_src/onnxruntime/core/providers/cpu/quantization/conv_integer.cc
0015e260 virtual onnxruntime::common::Status onnxruntime::ConvInteger::Compute(onnxruntime::OpKernelContext *) const
0015e2cc zero_point_ptr == nullptr || IsScalarOr1ElementVector(zero_point_ptr)
0015e312 virtual onnxruntime::common::Status onnxruntime::DequantizeLinear<int>::Compute(onnxruntime::OpKernelContext *) const [T = int]
0015e392 void onnxruntime::ValidateFastReduceKRK(const gsl::span<const int64_t> &, const onnxruntime::Tensor &)
0015e3f9 /onnxruntime_src/onnxruntime/core/providers/cpu/rnn/deep_cpu_lstm.cc
0015e43e RNN op: Invalid activation attribute - 
0015e466 softplus
0015e46f onnxruntime::rnn::detail::deepcpu::GruOutputGateFuncPtr onnxruntime::rnn::detail::deepcpu::GruOutputGateFuncByName(const std::string &)
0015e4f7 /onnxruntime_src/onnxruntime/core/providers/cpu/sequence/concat_from_sequence.cc
0015e548 frame_length == window_length
0015e566 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/col2im.cc
0015e5a7 detect_positive
0015e5b7 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/mean_variance_normalization.h
0015e60c virtual onnxruntime::common::Status onnxruntime::NonZero<int>::Compute(onnxruntime::OpKernelContext *) const [T = int]
0015e683 sequence_lens shape must be {batch_size}. Got:
0015e6b2 Invalid time_axis of 
0015e6c8 gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = short]
0015e70a gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = unsigned long]
0015e754 CPU execution provider: MLFloat16 data type is not supported with ScatterND opset 18 when reduction is 'max'.
0015e7c2 Starts and axes shape mismatch
0015e7e1  Num entries in 'split' (must equal number of outputs) was 
0015e81d onnxruntime::common::Status onnxruntime::UnsqueezeBase::PrepareCompute(onnxruntime::OpKernelContext *, onnxruntime::UnsqueezeBase::Prepare &) const
0015e8b1 Upsample: unexpected mode
0015e8cb Resize: input/output value's dimension mismatch
0015e8fb /onnxruntime_src/onnxruntime/contrib_ops/cpu/bert/attention.cc
0015e93a Input 1 dimension 0 should have same length as dimension 2 of input 0
0015e980 Inputs 'past' dimension 2 shall have length of num_heads
0015e9b9 Inputs 'mask_index' with 4D data shall have is_unidirectional set to false
0015ea04 Input 0 and 1 shall have same shape
0015ea28 word_embedding and position_embedding shall have same dimension 1
0015ea6a Attention mechanism memory shape error! Expected: {
0015ea9e onnxruntime::contrib::NGramRepeatBlock::NGramRepeatBlock(const onnxruntime::OpKernelInfo &)
0015eafa ) + scale_[0] (
0015eb0a X_rank == 4
0015eb16 /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/dynamic_quantize_matmul.cc
0015eb6b Wrong input type encountered for zero point input def @
0015eba3 IsScalarOr1ElementVector(tensor_x_scale)
0015ebcc b_scale_shape.NumDimensions() == 0 || (b_scale_shape.NumDimensions() == 1 && (b_scale_shape[0] == 1 || b_scale_shape[0] == helper.N()))
0015ec54 SampleOp
0015ec5d beta is expected to have 1 dimension, got 
0015ec88 !char_tokenezation_ || mincharnum_ < 2
0015ecaf /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/beam_search.cc
0015ecf8 Input 'prefix_vocab_mask' shape[1] shall be vocab_size, got 
0015ed35 min_tokens_to_keep
0015ed48 session_state_ != nullptr
0015ed62 cpu_allocator shouldn't be nullptr
0015ed85 void onnxruntime::BFCArena::DeallocateRawInternal(void *)
0015edbf bin->free_chunks.count(h) == 1
0015edde onnxruntime::BFCArena::AllocationRegion::AllocationRegion(void *, size_t, int64_t)
0015ee31 There's no data transfer registered for copying tensors from 
0015ee6f uint8
0015ee75 int64
0015ee7b GetDeleteFunc
0015ee89 elem_proto != nullptr
0015ee9f stream_idx < num_streams_
0015eeb9 shape && sp_tensor.DenseShape() == *shape
0015eee3 buffers_.find(location) == buffers_.end()
0015ef0d , block in memory pattern size is: 
0015ef31 TraceFree
0015ef3b  did not return correct number of compiled functions
0015ef70 provider_type must be specified.
0015ef91 The node is not placed on any Execution Provider. 
0015efc4 '. If type constraint names are available, ensure that they are used in the kernel def type constraints instead of op input or output names. Not doing so will result in this error.
0015f079 RegisterOpSchema
0015f08a /onnxruntime_src/onnxruntime/core/framework/kernel_type_str_resolver_utils.cc
0015f0d8 . Num args is 
0015f0e7 ) and node 
0015f0f3 Caught exception during saving DeviceBasedPartitioner config: 
0015f132 <discarded>
0015f13e Format() == SparseFormat::kCoo
0015f15d MakeCooStrings
0015f16c  dst_size: 
0015f178 void onnxruntime::StreamExecutionContext::CountDownBarrier::Set(int32_t)
0015f1c3 const onnxruntime::Tensor &(anonymous namespace)::GetIndicesTensor(const OrtValue &, OrtSparseIndicesFormat)
0015f230 common::Status onnxruntime::utils::ConstantNodeProtoToTensorProto(const onnx::NodeProto &, const onnxruntime::Path &, onnx::TensorProto &, const std::string &)
0015f2d0 , external_data.length: 
0015f2e9 bool onnxruntime::utils::FinalizeCopyInfoForFeeds(gsl::span<const OrtDevice>, std::vector<MLValueCopyInfo> &)
0015f357 mask
0015f35c Attention mask with shape (batch_size, sequence_length)
0015f394 2D input tensor with shape (batch_size, total_sequence_length)
0015f3d3 Constrain mean and inv_std_var to float tensors.
0015f404 Failed to parse num_return_sequences or it is not positive integer scalar
0015f44e Constrain to any tensor type. If the dtype attribute is not provided this must be a valid output type.
0015f4b5 Constrain input and output types to any tensor type.
0015f4ea Constrain mean and inv_std_var to be float tensors.
0015f51e Max detections to output.
0015f538 snpe_version
0015f545 last dimension of indices must not be larger and rank of data tensor
0015f58e scales
0015f595 Output data tensor from average or max pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes. Floor value of the dimension is used
0015f647 Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis.
0015f6a9 ) + scale[0] (
0015f6b8 The axis along which same quantization parameters are applied. It's optional.If it's not specified, it means per-tensor quantization and input 'x_scale' and 'x_zero_point' must be scalars.If it's specified, it means per 'axis' quantization and input 'x_scale' and 'x_zero_point' must be 1-D tensors.
0015f7e4 Attention mask index with shape (batch_size)
0015f811 input_zero_point
0015f822 3-dimensional matrix A
0015f839 scale of the gemm - scalar (per-tensor quantization)
0015f86e scale_Q_weight
0015f87d N-dimensional input A
0015f893 The shape of the output can be explicitly set which will cause pads values to be auto generated. If output_shape is specified pads values are ignored. See doc for details for equations to generate pads
0015f95d position_embedding should have 2 dimensions, dimension size known, and same hidden size as word_embedding.
0015f9c8 Duplicate sparse_tensor_initializer: '
0015f9ef ) output arg (
0015f9fe ) of output arg (
0015fa10 ) is required but not specified.
0015fa31 ForThisAndAllSubgraphs
0015fa48 node->GetOutputEdgesCount() == 0
0015fa69 ALLOW_RELEASED_ONNX_OPSET_ONLY
0015fa88 void onnxruntime::function_utils::Inliner::bind(google::protobuf::RepeatedPtrField<string> &, const google::protobuf::RepeatedPtrField<string> &) [isOutput = false]
0015fb2d Null strings attribute. Invalid ORT format model.
0015fb5f onnxruntime::NodeArg &onnxruntime::graph_utils::AddInitializer(onnxruntime::Graph &, const onnx::TensorProto &)
0015fbcf itr != node_args.end()
0015fbe6 Node must only have one used output
0015fc0a AttributeProto must have a name.
0015fc2b void onnxruntime::math::Gemm(CBLAS_TRANSPOSE, CBLAS_TRANSPOSE, ptrdiff_t, ptrdiff_t, ptrdiff_t, double, const double *, const double *, double, double *, onnxruntime::concurrency::ThreadPool *)
0015fced virtual void onnxruntime::concurrency::ThreadPoolTempl<onnxruntime::Env>::RunInParallel(std::function<void (unsigned int)>, unsigned int, std::ptrdiff_t) [Environment = onnxruntime::Env]
0015fda8  - error code: 
0015fdb8 MapFileIntoMemory
0015fdca remove() failed. Error code: 
0015fde8 int32_data
0015fdf3 , but the '
0015fdff ) should be stored in 
0015fe16 ) must have a dense-rank > 0
0015fe33 ) has zero input and zero output.
0015fe55 Graph must be in single static assignment (SSA) form, however '
0015fe95  outputs. Expected 
0015fea9  was not
0015feb2 A maximum trip-count for the loop specified at runtime. Optional. Pass empty string to skip.
0015ff0f optional(seq(tensor(double)))
0015ff2d Input tensor to copy shape and optionally type information from.
0015ff6e A 1-D tensor with same type as the inputs containing generated range of values.
0015ffbe Second input operand for the logical operator.
0015ffed /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/math/defs.cc
0016003a First operand, base of the exponent.
0016005f Value of beta.
0016006e sorted
00160075 Constrain input and output types to floating-point tensors.
001600b1 loss = ReduceMean <keepdims = 0> (loss_Ndd)
001600dd const_zero_float
001600ee loss
001600f3 The Fourier Transform of the input vector.If onesided is 0, the following shape is expected: [batch_idx][signal_dim1][signal_dim2]...[signal_dimN][2]. If axis=0 and onesided is 1, the following shape is expected: [batch_idx][floor(signal_dim1/2)+1][signal_dim2]...[signal_dimN][2]. If axis=1 and onesided is 1, the following shape is expected: [batch_idx][signal_dim1][floor(signal_dim2/2)+1]...[signal_dimN][2]. If axis=N-1 and onesided is 1, the following shape is expected: [batch_idx][signal_dim1][signal_dim2]...[floor(signal_dimN/2)+1][2]. The signal_dim at the specified axis is equal to the dft_length.
00160356 Hamming
0016035e num_mel_bins input must be scalar.
00160381 transform_targets
00160393 List of tensors for Sum.
001603ac Constrain mean and variance types to float tensors.
001603e0 GroupNormalization
001603f3 XReshaped = Reshape (X, NewShape)
00160415 Saved mean used during training to speed up gradient computation.
00160457 If spatial is true, the dimension of bias is (C). If spatial is false, the dimensions of bias are (C x D1 x ... x Dn)
001604cd Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.
00160507 A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. It is optional if `output_sequence` is 0.
001605bf ' is expected to have field 'g'
001605df Constrain position to integral tensor. It must be a scalar(tensor of empty shape).
00160632 Element type of inputs are expected to be the same.
00160666 ], Value=
00160670 target map type missing key type.
00160692 Output tensor with the same shape as input with type specified by the 'to' argument
001606e6 Tensor of rank r >=1 (same rank and shape as indices)
0016071c Tensor of rank q + r - indices_shape[-1] - 1.
0016074a Tensors with at least max(dims) dimensions.
00160776 The number of batch dimensions. The gather of indexing starts from dimension of data[batch_dims:]
001607d9 This attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>
00160859 The coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.
001608c9 Denote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, `length_original` as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input "roi", `scale = length_resized / length_original`, <br/>
00160a36 if coordinate_transformation_mode is `"half_pixel"`, <br/>
00160a71 `x_original = (x_resized + 0.5) / scale - 0.5` <br/>
00160aa7 if coordinate_transformation_mode is `"pytorch_half_pixel"`, <br/>
00160aea `x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0` <br/>
00160b39 if coordinate_transformation_mode is `"align_corners"`, <br/>
00160b77 `x_original = x_resized * (length_original - 1) / (length_resized - 1)` <br/>
00160bc6 if coordinate_transformation_mode is `"asymmetric"`, <br/>
00160c01 `x_original = x_resized / scale` <br/>
00160c29 if coordinate_transformation_mode is `"tf_crop_and_resize"`, <br/>
00160c6c `x_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)`
00160d33 Attribute perm for Transpose has repeated value: 
00160d65 x_shape = Shape (input_data)
00160d82 length of each output
00160d98 Output data. If strings are input, the output values are integers, and vice versa.
00160deb The output will be a tensor of the value type of the input map. It's shape will be [1,C], where C is the length of the input dictionary.
00160e74 Encoded output data, having one more dimension than X.
00160eab type case unsupported for symbolic shape inference. inferred=
00160ee9 onnx.TypeProto.Tensor
00160eff This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
00160f7a /build/intermediates/arm64-v8a/Release/_deps/protobuf-src/src/google/protobuf/message_lite.cc
00160fd8 " because it is missing required fields: 
00161002 FATAL
00161008 [:punct:]
00161012 unhandled opcode: 
00161025 job_.size() = 
00161034 /build/intermediates/arm64-v8a/Release/_deps/re2-src/re2/simplify.cc
00161079 {%d,%d}
00161081 (?-m:^)
00161089 (?-m:$)
00161091 Old_Sogdian
0016109d cores_count
001610a9 failed to allocate %zu bytes for descriptions of %u L3 caches
001610e7 darcy
001610ed Texas Instruments
001610ff Tegra AP
00161108 %.0Lf
00161115 covariant return thunk to 
00161135 operator^=
00161140 operator<=
0016114b __cxa_guard_release
0016115f unknown pointer encoding
00161178 unsupported restore location for float register
001611b2 size overflow
001611c0 OrtStatusPtr OrtApis::FillSparseTensorCoo(OrtValue *, const OrtMemoryInfo *, const int64_t *, size_t, const void *, const int64_t *, size_t)
0016124d offsets buffer is not equal to tensor size
00161278 /onnxruntime_src/include/onnxruntime/core/framework/ort_value.h
001612b8 OrtStatus *OrtCreateMapMLValue(const onnxruntime::Tensor &, const onnxruntime::Tensor &, OrtValue **) [KeyType = std::basic_string<char>, ValueType = double]
00161356 onnxruntime::InferenceSession::InferenceSession(const onnxruntime::SessionOptions &, const onnxruntime::Environment &, const void *, int)
001613e0  is not expected to be of type tensor.
00161407 Encountered unknown exception in Run()
0016142e run_options.run_log_severity_level >= 0 && run_options.run_log_severity_level <= static_cast<int>(logging::Severity::kFATAL)
001614ab session.save_model_format
001614c5 The Model Proto hasn't been checked for the ORT config json.
00161502 Setting intra_op_num_threads to 
00161523 number
0016152a Setting enable_profiling to 
00161547 invalid string: missing closing quote
0016156d invalid string: control character U+0003 (ETX) must be escaped to \u0003
001615b6 invalid string: control character U+001B (ESC) must be escaped to \u001B
00161603 ' in custom op '
00161614 seq(tensor(complex64))
0016162b forgot to update the version range in DomainToVersionRange 
00161667 T *onnxruntime::Tensor::MutableData() [T = short]
00161699 T *onnxruntime::Tensor::MutableData() [T = int]
001616c9 const T *onnxruntime::Tensor::Data() const [T = short]
00161700 const void *onnxruntime::Tensor::DataRaw(onnxruntime::MLDataType) const
00161748 Unknown provider name. Currently supported values are 'SNPE', 'XNNPACK', and 'AZURE'
0016179d Attribute type not supported yet.
001617bf Create_State_
001617cd /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/nnapi_execution_provider.cc
00161829  number of nodes in the graph: 
00161849 ANeuralNetworksCompilation_finish
0016186b ANeuralNetworksExecution_getOutputOperandDimensions
0016189f ANeuralNetworksMemoryDesc_addOutputRole
001618c7 ANEURALNETWORKS_NO_ERROR
001618e0 QLinearMul
001618eb Resize
001618f2 Transpose
001618fc The output of graph is not registered [
00161924 operand name: 
00161933 Added NNAPI Operation Type [
00161950 A shape: 
0016195a Failed to get A's shape.
00161973 bool onnxruntime::nnapi::op_builder_helpers::IsQuantizedIOSupported(const onnxruntime::InitializedTensorSet &, const onnxruntime::NodeUnit &, const std::vector<size_t> &, const onnxruntime::nnapi::OpSupportCheckParams &, onnxruntime::ArgType)
00161a66 NodeUnit [
00161a71 axis >= -tensor_rank && axis <= tensor_rank - 1
00161aa1 Operator name: [
00161ab2 NNAPI requires scale to be > 0.
00161ad2 ]'s zero_point: 
00161ae3 Gather only supports up to 1-4d shape, input is 
00161b14 gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = int]
00161b59 NCHW format is not supported on android api level 28
00161b8e Data type for starts and ends inputs' is not supported in this build. Got 
00161bd9 ]'s output 0 
00161be7 ] has different input_scale: 
00161c05  than the output_scale: 
00161c1e A must be 2D
00161c2f mismatching number of scale 
00161c4c strides.size() == kernel_shape.size()
00161c72 (UpsampleMode::LINEAR == mode_ || UpsampleMode::CUBIC == mode_)
00161cb2 xnn_setup_fully_connected_nc_f32 returned 
00161cdd right operand cannot broadcast on dim 
00161d04 Apply
00161d0a Unsupported optimization level: 
00161d2b session.disable_quant_qdq
00161d45 ConvBNFusion
00161d52 LayerNormFusion
00161d62 AttentionFusion
00161d72 virtual onnxruntime::common::Status onnxruntime::GemmSumFusion::Apply(onnxruntime::Graph &, onnxruntime::Node &, onnxruntime::RewriteRule::RewriteRuleEffect &, const logging::Logger &) const
00161e31 FusedConv
00161e3b Expected activation node.
00161e55 ConvAddRelu
00161e61 void onnxruntime::utils::mltype_dispatcher_internal::UnsupportedTypeDefaultPolicy<unsigned long>::operator()(int32_t, Ret &) const [Ret = unsigned long]
00161efa MatchGemmSubgraph
00161f0c Output edge count not expected for nodes in path 1 of unidirectional mask
00161f56 Output edge count not expected for unsqueeze3 of unidirectional mask
00161f9b Start CheckNodesInPathV
00161fb3 Start CheckNodesInPathQ
00161fcb CheckNodesInPathK returns false
00161feb shape of layer norm bias tensor not expected
00162018 Second input of Gather should be a constant with value 1. 
00162053 Failed to get initializer tensor.
00162075 onnxruntime::Initializer &onnxruntime::Initializer::add(const onnxruntime::Initializer &)
001620cf gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = long]
00162110 input_node.InputDefs().size() == 2 && scale_and_index->second < 2
00162152 Tried to allocate without valid type information, ort_value index=
00162195 bool onnxruntime::GetQConstantLowerUpper(const onnxruntime::Graph &, const onnxruntime::Node &, float &, float &)
00162207 _pre_q
0016220e Op version is not supported for
0016222e Failed to find initializer to reshape with name 
0016225f Equal
00162265 com.microsoft.QLinearMul
0016227e virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Selu<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Selu<float>]
0016233d  did not match batch size of 
0016235b  inputs but Scan was only given 
0016237c AllocateFinalOutput
00162390 is_concrete_shape_
001623a5 void onnxruntime::Clip::ComputeImpl<double>::operator()(const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, onnxruntime::Tensor *) const [T = double]
0016245e steps.size()=
0016246c Einsum op: There must be atleast one input
00162497 /onnxruntime_src/onnxruntime/core/providers/cpu/math/einsum.cc
001624d6 std::unique_ptr<Tensor> onnxruntime::EinsumTypedComputeProcessor<long>::PairwiseOperandProcess(const onnxruntime::Tensor &, const onnxruntime::TensorShape &, const onnxruntime::Tensor &, const onnxruntime::TensorShape &, const gsl::span<const int64_t> &, bool) [T = long]
001625e6 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Abs<unsigned char>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Abs<unsigned char>]
001626b3 fmod must have value either 0 or 1
001626d6 onnxruntime::TensorAllocator::TensorAllocator(onnxruntime::OpKernelContext &)
00162724 onnxruntime::GemmHelper::GemmHelper(const onnxruntime::TensorShape &, bool, const onnxruntime::TensorShape &, bool, const onnxruntime::TensorShape &)
001627ba /onnxruntime_src/onnxruntime/core/providers/cpu/math/matmul.cc
001627f9 TopK
001627fe input count mismatch, expected 2 inputs - the tensor to be processed and a tensor containing k value
00162863 status.IsOK() && !input_dimensions_.empty()
0016288f onnxruntime::ml::LabelEncoder_2<float, long>::LabelEncoder_2(const onnxruntime::OpKernelInfo &) [TKey = float, TValue = long]
0016290d void onnxruntime::ml::CastInputToFloat(const onnxruntime::Tensor &, gsl::span<float> &) [SrcType = long]
00162976 ) != (
0016297d info.GetAttrs<std::string>("classlabels_strings", classlabels_strings_).IsOK() || info.GetAttrs<int64_t>("classlabels_ints", classlabels_ints_).IsOK()
00162a14 onnxruntime::ml::SVMCommon::SVMCommon(const onnxruntime::OpKernelInfo &)
00162a5d nodes_falsenodeids.size() == nodes_modes.size()
00162a8d void onnxruntime::ml::detail::TreeAggregatorSum<long, float, float>::ProcessTreeNodePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const TreeNodeElement<ThresholdType> &) const [InputType = long, ThresholdType = float, OutputType = float]
00162b84 virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommonClassifier<long, float, float>::Init(const onnxruntime::OpKernelInfo &) [InputType = long, ThresholdType = float, OutputType = float]
00162c59 Zipmap only supports 1D or 2D input tensors
00162c85 . Size of scale and bias (if provided) must match this. Got scale size of 
00162cd0 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/lrn.cc
00162d0a pool_strings
00162d1b virtual onnxruntime::common::Status onnxruntime::QLinearConv<unsigned char>::UseSharedPrePackedBuffers(std::vector<BufferUniquePtr> &, int, bool &) [ActType = unsigned char]
00162dc9 IsBQuantParamSupported(b_offset->Shape(), b ? b->Shape() : b_shape_)
00162e0e last_loop_size > 0
00162e21 info.GetAttr("hidden_size", &int64_value).IsOK() && int64_value > 0
00162e65 '. Must be one of 'forward', 'reverse', or 'bidirectional'.
00162ea1 Unsupported input signal shape. The signal's first dimenstion must be the batch dimension and its second dimension must be the signal length dimension. It may optionally include a 3rd dimension of size 2 for complex inputs.
00162f81 discrete_fourier_transform
00162f9c short_time_fourier_transform
00162fb9 T onnxruntime::signal::get_scalar_value_from_tensor(const onnxruntime::Tensor *) [T = float]
00163016 Data type mismatch
00163029 last >= first
00163037 Gather Tind type not supported in this build.
00163065 GatherElements op: 'indices' shape should have values within bounds of 'data' shape. Invalid value in indices shape is: 
001630de bilinear
001630e7 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/nonzero_op.cc
0016312c OneHot
00163133 ReverseSequence
00163143  vs 
00163148  at pos=
00163151 CPU execution provider: MLFloat16 data type is not supported with ScatterElements opset 16 when reduction is 'add'.
001631c5 CPU execution provider: string data type is not supported with ScatterND opset 18 when reduction is 'max'.
00163230 beta is expected to have 1 dimensions, got 
0016325c onnxruntime::contrib::CDist<double>::CDist(const onnxruntime::OpKernelInfo &) [T = double]
001632b7  input dimensions instead
001632d1 GetFusedActivationAttr(info, activation_).IsOK()
00163302  is out of bounds of out_left: 
00163322 /onnxruntime_src/onnxruntime/contrib_ops/cpu/maxpool_with_mask.h
00163363 virtual onnxruntime::common::Status onnxruntime::contrib::MurmurHash3::Compute(onnxruntime::OpKernelContext *) const
001633d8 virtual onnxruntime::common::Status onnxruntime::contrib::NhwcMaxPool<unsigned char>::Compute(onnxruntime::OpKernelContext *) const [T8Bits = unsigned char]
00163475 input_def_count >= 5 && (input_def_count - 2) % 3 == 0
001634ac tensor_x_scale->IsDataType<float>()
001634d0 input y_zero_point must be a scalar or 1D tensor of size 1 if given
00163514 Last dimension of bias and input does not match
00163544 beam_idx == num_beams_
0016355b output_sequences != nullptr
00163577 onnxruntime::common::Status onnxruntime::contrib::GenerationCpuDeviceHelper::ExpandBuffer(onnxruntime::Stream *, const OrtValue &, int, onnxruntime::AllocatorPtr, OrtValue &, bool) [T = onnxruntime::MLFloat16]
00163649 encoder subgraph input 0 (encoder_input_ids) shall have int32 type
0016368c BinFromIndex(c->bin_num)->free_chunks.erase(h) > 0
001636c2 int onnxruntime::BFCArena::AllocationRegion::IndexFor(const void *) const
0016370c virtual common::Status onnxruntime::CPUDataTransfer::CopyTensor(const onnxruntime::Tensor &, onnxruntime::Tensor &) const
00163786 Only ONNX MLDataType can be registered
001637ad Allocation of memory pattern buffer for 
001637d6 AllocateReusedOrtValueIfNotAllocatedHelper
00163801 TraceAllocate
0016380f TraceFree for ort_value_idx=
0016382c static_cast<size_t>(first_arg_idx) < actual_inputs.size()
00163866 ', but the existing argument with that formal parameter name has a different formal parameter type string.
001638d1 virtual OrtValue *onnxruntime::OpKernelContext::OutputMLValue(int, const onnxruntime::TensorShape &)
00163936 int onnxruntime::NodeIndexInfo::GetNodeOffset(onnxruntime::NodeIndex) const
00163982 Allocator already registered for 
001639a4  is used by node 
001639b6 Only one node should produce an output. Existing entry for 
001639f2 buffers_.size() == buffer_sizes_.size()
00163a1a found_in_outer_scope_location_map
00163a3c onnxruntime::AllocPlanPerValue &onnxruntime::PlannerImpl::AllocPlan(onnxruntime::OrtValueIndex)
00163a9c  as an input
00163aa9 WaitOnEPStep: wait on notification with id: 
00163ad6 onnxruntime::Status onnxruntime::ExecuteKernel(onnxruntime::StreamExecutionContext &, onnxruntime::NodeIndex, size_t, const bool &, onnxruntime::SessionScope &)
00163b77 entry != nullptr
00163b88 ort_value_name_idx_map.MaxIdx() > -1
00163bad [Memory] SessionStateInitializer statically allocates 
00163be4 Outer index count must be rows + 1 or zero. Got: 
00163c16 ValidateBlockSparseShapes
00163c30 SparseTensor::BlockSparseMutator onnxruntime::SparseTensor::MakeBlockSparseData(const onnxruntime::TensorShape &, const onnxruntime::TensorShape &)
00163cc4 Must have the same shape
00163cdd SparseCsrToDenseTensor
00163cf4 Trace
00163cfa OrtStatusPtr OrtApis::GetTensorTypeAndShape(const OrtValue *, OrtTensorTypeAndShapeInfo **)
00163d56  size to read: 
00163d66  data_type: 
00163d73 Tensor does not have external data to read from.
00163da4 GetFileContent
00163db3 scale
00163db9 value
00163dbf query_length
00163dcc (Optional) Seed to the random generator, if not specified we will auto generate one.
00163e21 ratio
00163e27 Constrain output types to float tensors.
00163e50 The subgraph for initialization of encoder and decoder. It will be called once before decoder subgraph.
00163eb8 Tokenized strings
00163eca N-dimensional dense matrix B
00163ee7 sparse_tensor(uint64)
00163efd Sequence
00163f06 A 1-D input tensor that is to be processed.
00163f32 A 1-D tensor of the same type as 'x' containing all the unique values in 'x' sorted in the same order that they occur in the input 'x'
00163fb9 The scores input tensor.
00163fd2 Encoding type for the boxes or anchors inputs.
00164001 (Optional) Some notes for the model
00164025 Specify if the RNN is forward, reverse, or bidirectional. Must be one of forward (default), reverse, or bidirectional.
0016409c Zero point tensor for input 'X'. It must be a scalar.
001640d2 Constrain input and output types to signed/unsigned int8 tensors.
00164114 Value of beta
00164122 Output data after scaling
0016413c The previous GRU hidden state.
0016415b hidden
00164162 Constrain weights types to 8 bit tensors.
0016418c word_embedding_quant
001641a1 order_Y
001641a9 scale of the input A.
001641bf Output of the Gelu
001641d2 Additional elements added to the side with higher coordinate indices in the output. Each padding value in "output_padding" must be less than the corresponding stride/dilation dimension. By default, this attribute is a zero vector. Note that this attribute doesn't directly affect the computed output values. It only controls the selection of the computed values, so changing this attribute only adds or removes output elements. If "output_shape" is explicitly provided, "output_padding" does not contribute additional size to "output_shape" but participates in the computation of the needed padding amount. This is also called adjs or adjustment in some frameworks.
0016446c This is an invalid model. Subgraph output (
00164498 ) does not match expected type (
001644b9 Type Error: Data in initializer '
001644db  but different TensorProto.
001644f7 graph_proto_ is not in sync with name_to_initial_tensor_.
00164531 bool onnxruntime::model_load_utils::IsAllowReleasedONNXOpsetsOnlySet()
00164578 const std::string &onnxruntime::graph_utils::GetNodeInputName(const onnxruntime::Node &, int)
001645d6 Invalid ExecutionOrder
001645ed SaveRuntimeOptimizationRecordToOrtFormat
00164616 "thread_pool_name": "
0016462c ", "block_size": [
0016463f " failed: 
0016464a read
00164653 ] for now
0016465d ) is 0-element but contains data!
0016467f ) should not be stored in raw_data field
001646a8 Scan 'body' subgraph outputs should all be tensors but output 
001646e7 All Tensor, Sequence(Tensor), Optional(Tensor), and Optional(Sequence(Tensor)) types
0016473c The data type for the elements of the output tensor. If not specified, default is TensorProto::FLOAT.
001647a2 Input tensor must be 2-dimensional
001647c5 Divisor tensor
001647d5           {
001647e1             Alpha = Constant <value_float: float = @alpha>()
0016481e             AlphaCast = CastLike (Alpha, X)
0016484a             Zero = Constant <value = float {0.0}>()
0016487e             ZeroCast = CastLike(Zero, X)
001648a7             XLessThanZero = Less(X, ZeroCast)
001648d5             AlphaMulX = Mul (AlphaCast, X)
00164900             Y = Where (XLessThanZero, AlphaMulX, X)
00164934           }
00164940         
00164949 Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape).
001649ad         {
001649b7           exp_x = Exp (X)
001649d1           one = Constant <value = float {1.0}>()
00164a02           exp_x_add_one = Add (exp_x, one)
00164a2d           Y = Log (exp_x_add_one)
00164a4f         }
00164a59         
00164a62 The hyperbolic arctangent values of the input tensor computed element-wise
00164aad Constrain output y and its zero point data type to 8-bit integer tensor.
00164af6 const_one
00164b00 The number of samples to step between successive DFTs.
00164b37 Invalid rank for 
00164b49 List of tensors for Mean.
00164b63 First operand, should share the type with the second operand.
00164ba1 Constrain input x and its zero point data type to 8-bit integer tensor.
00164be9 The bias value added to output. Default is 0.
00164c17 The exponent.
00164c25 list of floats. This attribute stores the weight of each n-gram in pool. The i-th element in weights is the weight of the i-th n-gram in pool. Its length equals to the size of ngram_indexes. By default, weights is an all-one tensor.This attribute is used when mode is "IDF" or "TFIDF" to scale the associated word counts.
00164d67 Environment dependent string that denotes the locale according to which output strings needs to be upper/lowercased.Default en_US or platform specific equivalent as decided by the implementation.
00164e2b RoIs (Regions of Interest) to pool over. Should be a 2-D tensor of shape (num_rois, 5) given as [[batch_id, x1, y1, x2, y2], ...].
00164eae Mean = ReduceMean (X3D, Axes2)
00164ecd Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimension are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
00165002 A scalar boolean tensor. If true, it indicates that optional-type input contains an element. Otherwise, it is empty.
00165077 opset_import
00165084 producer_name
00165092 metadata_props
001650a1 Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified.
00165141 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/rnn/old.cc
0016518d Computes an one-layer LSTM. This operator is usually supported via some
001651d5 custom implementation such as CuDNN.
001651fb Notations:
00165207 `X` - input tensor
0016521b `i` - input gate
0016522d `o` - output gate
00165240 `f` - forget gate
00165253 `c` - cell gate
00165264 `t` - time step (t-1 means previous time step)
00165294 `W[iofc]` - W parameter weight matrix for input, output, forget, and cell gates
001652e5 `R[iofc]` - R recurrence weight matrix for input, output, forget, and cell gates
00165337 `Wb[iofc]` - W bias vectors for input, output, forget, and cell gates
0016537e `Rb[iofc]` - R bias vectors for input, output, forget, and cell gates
001653c5 `P[iof]`  - P peephole weight vector for input, output, and forget gates
0016540f `WB[iofc]` - W parameter weight matrix for backward input, output, forget, and cell gates
0016546a `RB[iofc]` - R recurrence weight matrix for backward input, output, forget, and cell gates
001654c6 `WBb[iofc]` - W bias vectors for backward input, output, forget, and cell gates
00165517 `RBb[iofc]` - R bias vectors for backward input, output, forget, and cell gates
00165568 `PB[iof]`  - P peephole weight vector for backward input, output, and forget gates
001655bc `H` - Hidden state
001655d0 `num_directions` - 2 if direction == bidirectional else 1
0016560b Activation functions:
00165622   Relu(x)                - max(0, x)
00165648   Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
00165680   Sigmoid(x)             - 1/(1 + e^{-x})
001656ab   (NOTE: Below are optional)
001656c9   Affine(x)              - alpha*x + beta
001656f4   LeakyRelu(x)           - x if x >= 0 else alpha * x
0016572b   ThresholdedRelu(x)     - x if x >= alpha else 0
0016575e   ScaledTanh(x)          - alpha*Tanh(beta*x)
0016578d   HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
001657c8   Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
00165805   Softsign(x)            - x/(1 + |x|)
0016582d   Softplus(x)            - log(1 + e^x)
00165856 Equations (Default: f=Sigmoid, g=Tanh, h=Tanh):
00165887   - it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)
001658c6   - ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)
00165905   - ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)
00165936   - Ct = ft (.) Ct-1 + it (.) ct
00165958   - ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)
00165995   - Ht = ot (.) h(Ct)
001659ac  has inconsistent type 
001659c4  expected but not provided
001659df Value type of map input 
001659f8 (Optional) Starting axis for slicing the shape. Default value is 0.Negative value means counting dimensions from the back.
00165a73 Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs)..
00165afb List of integers indicating the dimensions to be inserted. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(expanded).
00165ba4 N-D tensor after resizing
00165bbe If provided, it specifies a subset of axes that 'roi', 'scales' and 'sizes' refer to. If not provided, all axes are assumed [0, 1, ..., r-1], where r = rank(data). Non-specified dimensions are interpreted as non-resizable. Negative value means counting dimensions from the back. Accepted range is [-r, r-1], where r = rank(data). Behavior is undefined if an axis is repeated.
00165d36 A 1-D INT64 tensor containing the count of each element of 'Y' in input 'X'
00165d82 1-D tensor representing the cropping window dimensions.
00165dba  expected to have tensor or sparse tensor type
00165de9 The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. May only be set if 'scales' is set to an empty tensor.
00165e8e Which axis to split on
00165ea5 height_scale
00165eb2 Input tensor containing indices. The values must be non-negative integers. Any entries in the 'indices' input tensor with values outside the range [0, depth) will result in one-hot representation with all 'off_value' values in the output tensor.In case 'indices' is of non-integer type, the values will be casted to int64 before use.
00166000 Target shape may not have multiple -1 dimensions
00166031 Invalid position of 0
00166047 ) must be same as rank of input 'X' (
0016606d ParseData type mismatch for tensor: 
00166092 An integer to use when an input string value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
0016611b An integer vocabulary array.<br>One and only one of the vocabularies must be defined.
00166171 Data to be processed.
00166187 norm
0016618c Class scores (one per class per example), if prob_a and prob_b are provided they are probabilities for each class, otherwise they are raw scores.
0016621e List of 3 elements containing gamma, coef0, and degree, in that order. Zero if unused for the kernel.
00166284 Second set of probability coefficients. This array must be same size as prob_a.<br>If these are provided then output Z are probability estimates, otherwise they are raw scores.
00166335 The output type will be a tensor of strings or integers, depending on which of the classlabels_* attributes is used.
001663aa Only one of the attributes 'nodes_values', 'nodes_values_as_tensor' should be specified.
00166403 type case mismatch. existing=
00166421  does not contain a graph.
0016643c /build/intermediates/arm64-v8a/Release/_deps/re2-src/re2/bitstate.cc
00166481 Mongolian
0016648b Old_Hungarian
00166499 Osage
001664a2 Tangsa
001664a9 Warang_Citi
001664b5 Actions
001664bd %a %b %d %H:%M:%S %Y
001664d2 time_put_byname failed to construct for 
001664fb decltype(
00166508 typeid (
00166511 operator>>=
0016651d operator<=>
00166529 long
0016652e char32_t
00166537 libunwind: malformed DW_CFA_register DWARF unwind, reg2 too big
00166578 libunwind: malformed DW_CFA_val_offset_sf DWARF unwind, reg too big
001665bd lengths allocation failed
001665d7 index is out of bounds
001665ee ORT_LOAD_CONFIG_FROM_MODEL
00166609 /onnxruntime_src/include/onnxruntime/core/framework/tensor.h
00166646 out of index
00166653 Invalid index requested for map type.
00166679 const T &OrtValue::Get() const [T = std::map<std::basic_string<char>, long>]
001666c6 ] is not supported in this build 
001666ef invalid string: control character U+0011 (DC1) must be escaped to \u0011
00166738 invalid string: control character U+0016 (SYN) must be escaped to \u0016
00166781 invalid number; expected digit after exponent sign
001667b4 object key
001667c2 /onnxruntime_src/onnxruntime/core/session/environment.cc
001667fb AZURE
00166801 AddOutput
0016680b ANeuralNetworksMemoryDesc_finish
0016682c ANeuralNetworksExecution_enableInputAndOutputPadding
00166861 SL_ANeuralNetworksDiagnosticExecutionInfo_isControlFlowUsed
0016689d Your onnx model may be in training mode, please export it in test mode.
001668e5 on getSupportedOperationsForDevices
00166909 Reshape/Flatten can only be skipped when the output is input 0 of Gemm/Matmul
00166957  index,  
00166961 ComputePad: pad type not supported.
00166985 ] has no shape
00166994 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/clip_op_builder.cc
001669f5 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/depthtospace_op_builder.cc
00166a5e nearest_mode
00166a6b Slice doesn't support dynamic input shape
00166a95 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/pool_op_builder.cc
00166af6 ceil_mode
00166b00 actual API level: 
00166b13 _bias_squeezed
00166b22  c_shape: 
00166b2d /onnxruntime_src/onnxruntime/core/providers/shared/node_unit/node_unit.cc
00166b77  of scale quantization parameters for UINT8 tensorper-channel uint8 quantization isn't supported
00166bd8 only support 0 as zero point for per-channel quantization, 
00166c14  model uses the deprecated attribute
00166c39 onnxruntime::ResizeCoordinateTransformationMode onnxruntime::UpsampleBase::StringToCoordinateTransformationMode(const std::string &)
00166cbe Input dim is zero but required output dim is non-zero. 
00166cf6 returned 
00166d00 /onnxruntime_src/onnxruntime/core/providers/xnnpack/nn/conv_transpose.cc
00166d49 CommonSubexpressionElimination
00166d68 BiasSoftmaxFusion
00166d7a FastGeluFusion
00166d89  Max:
00166d8f sum_output_edge.src_arg_index == 0
00166db2 virtual onnxruntime::common::Status onnxruntime::ConvMulFusion::Apply(onnxruntime::Graph &, onnxruntime::Node &, onnxruntime::RewriteRule::RewriteRuleEffect &, const logging::Logger &) const
00166e71 DoubleQDQRemoved_
00166e83 /onnxruntime_src/onnxruntime/core/optimizer/constant_sharing.cc
00166ec3 bool onnxruntime::AttentionFusionHelper::CheckSliceParameters(const onnxruntime::Graph &, const onnxruntime::Node &, const std::vector<int> &, const std::vector<int64_t> &, const logging::Logger &)
00166f89 ValidateGemmInitializer
00166fa1 Start ValidateGemmInitializer
00166fbf Div and Shape1 does not have edge
00166fe1 Div and Shape does not have edge
00167002 Failed to find path for present_v and past_v
0016702f past_k_gather indices != 0
0016704a k_transpose has not perm attribute
0016706d q_matmul and q_add shape not matched
00167092 FuseSubGraphQKDistilBert
001670ab BiasGelu
001670b4 fused Add and Gelu
001670c7 channels_last
001670d5 node ("
001670dd void onnxruntime::QDQ::SelectorManager::InitializeSelectorsMap()
0016711e RunForSave
00167129  for transformer 
0016713b node_arg_ != nullptr
00167150 Transpose optimizer is expected to add only onnx domain ops. Domain: 
00167196 Shrink
0016719d ReduceL2
001671a6 keepdims
001671af RandomNormalLike
001671c0 RegisterCPUKernels
001671d3 input_size < std::numeric_limits<std::ptrdiff_t>::max()
0016720b num_scan_inputs
0016721b directions
00167226 Scan inputs have inconsistent sequence lengths. Previous value was 
0016726a Number of entries in '
00167281 Inconsistent shape in loop output for output. 
001672b0  Got:
001672b6 Unsupported type
001672c7 scan_output_axes
001672d8 start in Range operator should be scalar like tensor, yet got shape:
0016731d Einsum op: Could not copy the intermediate output's buffer into the op's output buffer. Error: 
0016737d virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Abs<long>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Abs<long>]
00167438 ) are not at boundary of span with size:
00167461 /onnxruntime_src/onnxruntime/core/providers/cpu/math/top_k.cc
0016749f map_form_ != PACK_MAP::SPARSE || max_map_ > 0
001674cd Negative index values are not permitted. First entry in map has index value of 
0016751d void onnxruntime::ml::batched_update_scores_inplace(gsl::span<T>, int64_t, int64_t, onnxruntime::ml::POST_EVAL_TRANSFORM, int, bool, concurrency::ThreadPool *) [T = float]
001675c9 info.GetAttr<std::string>("norm", &norm).IsOK()
001675f9 onnxruntime::ml::OneHotEncoderOp<long>::OneHotEncoderOp(const onnxruntime::OpKernelInfo &) [T = long]
0016765f num_categories_ > 0
00167673 info.GetAttrs<float>("rho", rho_).IsOK()
0016769c info.GetAttrs<float>("kernel_params", kernel_params).IsOK()
001676d8 Node 
001676e2 void onnxruntime::ml::detail::TreeAggregatorClassifier<float, float, float>::FinalizeScores(InlinedVector<ScoreValue<ThresholdType>> &, OutputType *, int, int64_t *) const [InputType = float, ThresholdType = float, OutputType = float]
001677cd void onnxruntime::ml::detail::TreeAggregatorClassifier<long, float, float>::FinalizeScores(InlinedVector<ScoreValue<ThresholdType>> &, OutputType *, int, int64_t *) const [InputType = long, ThresholdType = float, OutputType = float]
001678b6 onnxruntime::common::Status onnxruntime::ml::GetVectorAttrsOrDefault(const onnxruntime::OpKernelInfo &, const std::string &, onnx::TensorProto_DataType, std::vector<TH> &) [TH = double]
00167970 Unsupported pooling size.
0016798a X num_dims does not match W num_dims.
001679b0 onnxruntime::LayerNormImpl::LayerNormImpl(const onnxruntime::OpKernelInfo &, bool, bool)
00167a09 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/pool_base.h
00167a48 boxes and scores should have same spatial_dimension.
00167a7d MatmulInteger : B zero point is not valid
00167aa7 QLinearConv : result zero point must be a scalar or 1D tensor of size 1
00167aef QLinearConv : filter scale shape invalid
00167b18 activations
00167b24 activation_func_names.size() == static_cast<size_t>(num_directions_) * 2
00167b6d const T *onnxruntime::rnn::detail::SafeRawConstPointer(typename gsl::span<const T>::iterator, typename gsl::span<const T>::iterator, size_t) [T = float]
00167c06 cur + size <= end
00167c18 Invalid activation function of 
00167c3a ConcatFromSequence
00167c4d onnxruntime::common::Status onnxruntime::CreateMelWeightMatrix<unsigned char>::operator()(onnxruntime::OpKernelContext *, int64_t, int64_t, int64_t, float, float) [T = unsigned char]
00167d04 onnxruntime::common::Status onnxruntime::CreateMelWeightMatrix<unsigned short>::operator()(onnxruntime::OpKernelContext *, int64_t, int64_t, int64_t, float, float) [T = unsigned short]
00167dbd typename std::enable_if<std::is_floating_point<SrcType>::value, void>::type onnxruntime::(anonymous namespace)::CastToString(const SrcType &, std::string &) [SrcType = float]
00167e6c input_rank == reference_rank
00167e89 Ranks of input data are different, cannot concatenate them. expected rank: 
00167ed5 counter.current_offset == last
00167ef4 GatherElements
00167f03 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/reshape.h
00167f44 Attribute shape is not set.
00167f60 CPU execution provider: MLFloat16 data type is not supported with ScatterND opset 16 when reduction is 'mul'.
00167fce /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/tile.cc
0016800d virtual onnxruntime::common::Status onnxruntime::Tile::Compute(onnxruntime::OpKernelContext *) const
00168072 void onnxruntime::DoTransposeImpl(int64_t, gsl::span<const int64_t>, size_t, size_t, const gsl::span<const size_t> &, const uint8_t *, uint8_t *, size_t)
0016810c /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/trilu.h
0016814b Unsupported tensor type of 
00168167 RegisterCpuContribKernels
00168181 max_sequence_length not matching from mask and past when past_present_share_buffer_ is set
001681dc Input 0 and 7 (mask) shall have same shape
00168207 virtual onnxruntime::common::Status onnxruntime::contrib::BiasGelu<float, false>::Compute(onnxruntime::OpKernelContext *) const [T = float, use_approximation = false]
001682ae use_approximation
001682c0 Input 0 is expected to have 1 or more dimensions, got 
001682f7 Number of dimensions for crop size should be exactly 1
0016832e sizeof(uint32_t) == output_element_bytes
00168357 MatMulInteger16
00168367 Position embedding zero point must be a scalar or 1D tensor of size 1
001683ad tensor_x_zero_point->GetElementType() == tensor_y_zero_point->GetElementType()
001683ff Expecting a non-empty tokenexp
0016841e BeamSearch
00168429 ProcessLogits
00168437  is smaller than requested bytes of 
0016845c  of size 
00168466 entry != regions_.end()
0016847e bfloat16
00168487 shape && tensor.Shape() == *shape
001684a9 onnxruntime::ExecutionFrame::ExecutionFrame(gsl::span<const int>, gsl::span<const OrtValue>, gsl::span<const int>, gsl::span<const OrtValue>, const std::unordered_map<size_t, IExecutor::CustomAllocator> &, const onnxruntime::SessionState &, gsl::span<Stream *>)
001685af The Function Style fusion is deprecated.
001685d8  cannot be used with this model due to its ONNX opset not being supported by the layout transformer.
0016863d /onnxruntime_src/onnxruntime/core/framework/func_kernel.h
00168677  Encountered following errors: (
00168698 MatchKernelDefTypes
001686ac auto onnxruntime::NodeIndexInfo::Init(const onnxruntime::ValidNodes<const std::vector<const onnxruntime::Node *>> &, onnxruntime::NodeIndex, const onnxruntime::OrtValueNameIdxMap &)::(anonymous class)::operator()(const onnxruntime::NodeArg &, bool) const
001687ab node_offsets_index < node_offsets_size_
001687d3 dim0_offset < dim0_size
001687eb Using an input in multiple nodes on different devices is not supported currently. Input:
00168844 void onnxruntime::SessionState::AddOutputNameToNodeInfoMapping(const std::string &, const onnxruntime::SessionState::NodeInfo &)
001688c5 VerifyEachNodeIsAssignedToAnEpImpl
001688e8 Can not find the node 
001688ff auto onnxruntime::PlannerImpl::ComputeValueLocation()::(anonymous class)::operator()(const onnxruntime::NodeArg &, size_t) const
00168980 onnxruntime::common::Status onnxruntime::PlannerImpl::BuildExecutionPlan(const onnxruntime::ExecutionProviders &, const onnxruntime::IStreamCommandHandleRegistry &)
00168a25 trigger_point_it != node_to_trigger_points.end()
00168a56  reused by 
00168a62 \u%04x
00168a69 Set a barrier with id: 
00168a81 thread_scheduling_stats
00168a99 Support 2-D matrices only
00168ab3 void onnxruntime::RunSince(size_t, onnxruntime::StreamExecutionContext &, onnxruntime::SessionScope &, const bool &, size_t, bool)
00168b36 onnxruntime::Tensor::Tensor(onnxruntime::MLDataType, const onnxruntime::TensorShape &, void *, const OrtMemoryInfo &, ptrdiff_t, gsl::span<const int64_t>)
00168bd1 FinalizePlan
00168bde Unsupported attribute value type of 
00168c03 length
00168c0a Custom scale will be used if specified. Default value is 1/sqrt(head_size)
00168c55 past state for key and value with shape (2, batch_size, num_heads, total_sequence_length, head_size). If past_present_share_buffer is set, its shape is (2, batch_size, num_heads, max_sequence_length, head_size), while effective_seq_length = (past_sequence_length + kv_sequence_length).
00168d73 2D attention mask with shape (batch_size, sequence_length)
00168dae bias_table
00168db9 2D input tensor with shape (batch_size, vocab_size)
00168ded Decoder input ids after merging predicted tokens
00168e1e Cumulated sequence lengths. Its shape is (batch_size + 1)
00168e58 max_seq_len
00168e64 The output.
00168e70 Custom attention mask. Shape is (batch_size, sequence_length)
00168eae custom
00168eb5 Scalar multiplier for input tensor C.
00168edb rois input tensor has wrong dimension
00168f01 1D gamma tensor for normalization with shape (C), where C is number of channels
00168f51 Input data tensor from the previous operator; According to channels_last, dimensions for image case are (N x C x H x W), or (N x H x W x C) where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), or (N x D1 X D2 ... Dn x C) where N is the batch size.
001690d2 Works on NHWC layout or not? Default not.
001690fc Output zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
00169175 Tensor of data to extract slices from.
0016919c The new GRU hidden state calculated by this op.
001691cc 'Border' attribute must be present and must contain exactly 4 values - (left_border, top_border, right_border, bottom_border)
0016924a DequantizeBFP
00169258 a_scale
00169260 Y_scale
00169268 Output Y's scale. It's a scalar, which means a per-tensor/layer quantization.
001692b6 Mask
001692bb LayerNorm Output
001692cc scale_input
001692d8 Q_bias
001692df Scale tensor, i.e., gamma vector.
00169301 cublasLt order of matrix Y, must be same as order_X if specified together. Optional.
00169356 order_global_weight
0016936a scale_qkv_gemm
00169379 This is an invalid model. The sum of input arg count is not equal to size of input defs in node (
001693db Constant
001693e4 This is an invalid model. Tensor does not have type information.
00169425 by either re-generating the model with latest exporter/converter 
00169467 or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.
001694b3 void onnxruntime::Graph::InitializeStateFromModelFileGraphProto()
001694f5 Node:
001694fb index < data_.size()
00169510 Missing dims for sparse initializer: 
00169536 GRAPH
0016953c bool onnxruntime::graph_utils::RemoveNodeWithSingleNodeInSingleUsedOutput(onnxruntime::Graph &, onnxruntime::Node &)
001695b1 dims[d_i] < d_max
001695c3 Received null affinity_string
001695e1 processor_from > 0 && processor_to > 0
00169608 processor_from <= processor_to
00169627 onnxruntime::logging::LoggingManager::LoggingManager(std::unique_ptr<ISink>, onnxruntime::logging::Severity, bool, const onnxruntime::logging::LoggingManager::InstanceType, const std::string *, int)
001696ee default_logger_id must be provided if instance_type is InstanceType::Default
0016973b EndTimeAndRecordEvent
00169751 "args" : {
0016975c std::string onnxruntime::concurrency::ThreadPoolProfiler::Stop()
001697a1 Null tensor type info. Invalid ORT format model.
001697d2 No opset import for domain '
001697ef ' has been used as graph input names multiple times.
00169824 optional(seq(tensor(uint8)))
00169841 value_floats
0016984e The values for the elements for the 1D, float32, output tensor.
0016988e Output tensor of shape specified by 'input'.If attribute 'value' is specified, the value and datatype of the output tensor is taken from 'value'.If attribute 'value' is not specified, the value in the output defaults to 0, and the datatype defaults to float32.
00169993 All values in input have to be in the range:[0, 1].
001699c7 The softsign (x/(1+|x|)) values of the input tensor computed element-wise
00169a11 Indices
00169a19 Tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] containing the corresponding input tensor indices for the top K values.
00169aa5 Constrain input and output types to all tensors.
00169ad6 The hyperbolic cosine values of the input tensor computed element-wise
00169b1d loss_NCdd = Neg (input_gather_element_transform)
00169b4e Target tensor of shape (N) or (N, d1, d2, ..., dk). Target element value shall be in range of [0, C). If ignore_index is specified, it may have a value outside [0, C) and the target values should either be in the range [0, C) or have the value ignore_index.
00169c50 output = NegativeLogLikelihoodLoss <reduction : string = @reduction, ignore_index : int = @ignore_index> (X_Log, labels)
00169cc9 Whether to perform the inverse discrete fourier transform. By default this value is set to 0, which corresponds to false.
00169d43 The desired top edge of the highest frequency band.
00169d77 Constrain to float tensors
00169d92 Input and target dimension value mismatch.
00169dbd weight_gather_temp
00169dd0 consumed_inputs
00169de0 Coefficient of leakage default to 0.01.
00169e08 1-D input tensor
00169e19 The output values with the same shape as input tensor (the original size without coercion).
00169e75 momentum
00169e7e input_var
00169e88 A tensor of rank >= axis.
00169ea2 Constrain input and output  types to float tensors.
00169ed6 Axes_1 = Constant()
00169eea MeanOfSquare = ReduceMean (Square, Axes2)
00169f14 If true, compute the mean and variance across all spatial elements If false, compute the mean and variance across per feature.Default is 1.
00169fa0 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/object_detection/old.cc
00169ff8 producer_version
0016a00a Computes the indices of the {name} elements of the input tensor's element along the
0016a05e provided axis. The resulting tensor has the same rank as the input if keepdims equals 1.
0016a0b7 If keepdims equal 0, then the resulting tensor has the reduced dimension pruned.
0016a108 The type of the output tensor is integer.
0016a132 The sequence output for the hidden is optional if 0. Default 0.
0016a172 ' appeared multiple times.
0016a18d ' is expected to have field 't'
0016a1ad Required attribute '
0016a1c2 !(it.GetName().empty())
0016a1da Output sequence(s)
0016a1ed SequenceMap
0016a1f9 Input Sequence and Tensor are expected to have the same elem type. Sequence=
0016a246 source map type missing key type.
0016a268 The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto
0016a2ee (Optional) Ending axis for slicing the shape. Negative value means counting dimensions from the back. If omitted, sizes of all axes upto (including) the last one will be included.
0016a3a2 Input and output types can be of any tensor type.
0016a3d4 expanded
0016a3dd (Optional) Axis along which to take slices. If not specified, input is flattened before elements being selected. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
0016a4b9 (Optional) Axis along which one-hot representation in added. Default: axis=-1. axis=-1 means that the additional dimension will be inserted as the innermost/last dimension in the output tensor. Negative value means counting dimensions from the back. Accepted range is [-r-1, r] where r = rank(indices).
0016a5e8 (Optional) The dimension to apply unique. If not specified, the unique elements of the flattened input are returned. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
0016a6c8 Mismatch between number of splits (
0016a6ec 'step' cannot be 0 for Slice
0016a709 'pads' input must be a 1D (shape: [2 * num_axes]) tensor of type int64
0016a750 axes_input = Constant <value_ints : ints = @axes>()
0016a784 x_shape_alldims = Shape (input_data)
0016a7a9 padded_sh = Max(x_shape, shape)
0016a7c9 Incorrect or missing attribute value for starts and ends
0016a802 The input must be a tensor of strings or integers, either [N,C] or [C].
0016a84a An integer.
0016a856 Indicates the transform to apply to the regression output vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
0016a8dd One of 'MAX,' 'L1,' 'L2'
0016a8f6 node id that this weight is for.
0016a917 For each node, define what to do in the presence of a NaN: use the 'true' (if the attribute value is 1) or 'false' (if the attribute value is 0) branch based on the value in this array.<br>This attribute may be left undefined and the defalt value is false (0) for all nodes.
0016aa2a Non of classlabels_int64s or classlabels_strings is set.
0016aa63 The output type will be a tensor of strings or integers, and will have the same shape as the input.
0016aac7 Graph initializer names must appear after the actual inputs: 
0016ab05 sparse_tensor_type
0016ab18 GraphProto attribute inferencing is not enabled in this InferenceContextImpl instance.
0016ab6f  type is missing.
0016ab81 onnx.TypeProto.Sequence
0016ab99 (cannot determine missing fields for lite message)
0016abcc libprotobuf-native
0016abdf Unknown encoding 
0016abf1 pattern too large - compile failed
0016ac17 trailing \
0016ac22 Ahom
0016ac27 Katakana
0016ac30 Lycian
0016ac37 Palmyrene
0016ac41 Tangut
0016ac48 attempt to nsync_mu_runlock() an nsync_mu not held in read mode
0016ac89 cpuinfo_get_%s called before cpuinfo is initialized
0016acbd %s %s%u%.*s
0016acc9 tegra210_dragon
0016acd9 Qualcomm
0016ace2 MediaTek
0016aceb collate_byname<char>::collate_byname failed to construct for 
0016ad38 throw
0016ad3e wchar_t
0016ad46 operator~
0016ad50 operator"" 
0016ad5c std::basic_string
0016ad6e decltype(auto)
0016ad7d std::exception
0016ad8c FillSparseTensorCsr
0016ada0 RegisterCustomOps
0016adb2 output name cannot be empty
0016adce static void SafeIntExceptionHandler<onnxruntime::OnnxRuntimeException>::SafeIntOnOverflow()
0016ae2a static bool onnxruntime::utils::ContainerChecker::IsContainerOfType<std::vector<std::map<long, float>>>::check(const onnxruntime::utils::ContainerChecker::Cont &, size_t) [T = std::vector<std::map<long, float>>]
0016aefe len >= 0 && static_cast<uint64_t>(len) < std::numeric_limits<size_t>::max()
0016af4a in[idx]->IsTensor()
0016af5e /onnxruntime_src/onnxruntime/core/session/inference_session.cc
0016af9d Given model could not be parsed while creating inference session. Error message: 
0016afef Execution providers must be registered before the session is initialized. 
0016b03a ORT model verification failed.
0016b059 Session has already been initialized.
0016b07f Replaying the captured 
0016b097 Invalid run log severity level. Not a valid onnxruntime::logging::Severity value: 
0016b0ea onnxruntime::common::Status onnxruntime::FinalizeSessionOptions(const onnxruntime::SessionOptions &, const onnx::ModelProto &, bool, onnxruntime::SessionOptions &)
0016b18e null
0016b193 invalid string: control character U+0014 (DC4) must be escaped to \u0014
0016b1e0 Result buffer is not large enough
0016b202 seq(tensor(double))
0016b216 [ShapeInferenceError] 
0016b22d SessionOptionsAppendExecutionProvider_Tensorrt: Failed to load shared library
0016b27b void onnxruntime::TensorSeq::Add(OrtValue &&)
0016b2a9  execution provider is not supported in this build. 
0016b2de ANeuralNetworksModel_setOperandSymmPerChannelQuantParams
0016b317 ANeuralNetworksModel_setOperandValueFromMemory
0016b346 ANeuralNetworksCompilation_setPriority
0016b36d ANeuralNetworksMemoryDesc_setDimensions
0016b395 SL_ANeuralNetworksDiagnosticCompilationInfo_areDynamicTensorsUsed
0016b3d7 SL_ANeuralNetworksDiagnosticExecutionInfo_getInputDataClass
0016b413 libcutils.so
0016b422 DepthToSpace
0016b42f GlobalAveragePool
0016b441 Mean of BN must be known
0016b45a value: 
0016b462 ], Type [
0016b46c The input of graph doesn't have elem_type: 
0016b498 AddNewNNAPIOperand
0016b4ab SetOperandValue
0016b4bb count [
0016b4c3 io_def.quant_param.has_value()
0016b4e2 DepthToSpace only supports 4d shape, input is 
0016b511 Resize bilinear only support half_pixel/align_corners on API level 30+, current API level is 
0016b56f round_prefer_floor
0016b582 'step' value cannot be 0
0016b59b /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/binary_op_builder.cc
0016b5fe com.microsoft.QLinearConv is not supported
0016b629 alpha
0016b62f ] has input 0 type: 
0016b644 unsupported number 
0016b658 Could not read constant values from idx 
0016b681 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/pool_attributes.h
0016b6c6 info.GetAttr<int64_t>("count_include_pad", &temp).IsOK()
0016b6ff Dilations dimensions should match kernel shape
0016b72e Unsupported AutoPad Type.
0016b748 xstatus == xnn_status_success
0016b766 mode attribute is 
0016b779 ScalesValidation
0016b78a /onnxruntime_src/onnxruntime/core/optimizer/constant_folding.cc
0016b7ca input_indices.size() == expected_values.size() && input_indices.size() > 0
0016b815 Gather
0016b81c Faild to match path 1 for unidirectional mask
0016b84a CheckSliceParameters returns false for slice1
0016b878 Softmax attribute axis is expected to be 3
0016b8a3 where const not matched.
0016b8bc FuseGptAttention
0016b8cd Start FuseGptAttention
0016b8e4 Failed to load Q, K and V weights, or data type is not float or float16.
0016b92d Mask shape is unknown or not 2D, or data type unknown
0016b963 Input id is not valid. 
0016b97b /onnxruntime_src/onnxruntime/core/optimizer/bias_dropout_fusion.cc
0016b9be Total Gelu Approximation (FastGelu) node count: 
0016b9ef size() == other.size()
0016ba06 InsertedCast_
0016ba14 Unexpected data type for QuantizeLinear input y_zero_point of 
0016ba53 /onnxruntime_src/onnxruntime/core/optimizer/qdq_transformer/qdq_util.cc
0016ba9b  out of bounds for shape 
0016bab5 No NodeArg found for name 
0016bad0 Optimization after layout transformation failed: 
0016bb02 Celu
0016bb07 RegisterOnnxMLOperatorKernels
0016bb25 onnxruntime::ElementWiseKernel<onnxruntime::functors::Elu<float>>::ElementWiseKernel(const onnxruntime::OpKernelInfo &) [F = onnxruntime::functors::Elu<float>]
0016bbc5 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Relu<double>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Relu<double>]
0016bc86 cur_iteration_ < num_iterations_
0016bca7  outputs.
0016bcb1 feeds_fetches_manager_
0016bcc8 /onnxruntime_src/onnxruntime/core/providers/cpu/controlflow/scan_utils.h
0016bd11 Attempt to retrieve final output before it was set.
0016bd45 ONNX_NAMESPACE::TensorProto::DataType_IsValid(output_dtype_) && output_dtype_ != ONNX_NAMESPACE::TensorProto::UNDEFINED
0016bdbd max should be a scalar.
0016bdd5 void onnxruntime::WritableSliceIterator<float>::Init(gsl::span<const int64_t>, gsl::span<const int64_t>, gsl::span<const int64_t>) [T = float]
0016be64 Cannot parse the diagonal elements along dims 
0016be93 void onnxruntime::EinsumTypedComputeProcessor<float>::FinalizeOutput(const onnxruntime::Tensor &, const gsl::span<const int64_t> &) [T = float]
0016bf23 BitwiseAnd
0016bf2e All inputs must have the same shape
0016bf52 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Floor<double>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Floor<double>]
0016c015 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Reciprocal<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Reciprocal<float>]
0016c0e0 info.GetAttrs<int64_t>("cats_int64s", int_categories).IsOK()
0016c11d num_keys == num_values
0016c134 onnxruntime::ml::LabelEncoder_2<long, std::basic_string<char>>::LabelEncoder_2(const onnxruntime::OpKernelInfo &) [TKey = long, TValue = std::basic_string<char>]
0016c1d6 info.GetAttrs<float>("coefficients", coefficients_).IsOK()
0016c211 onnxruntime::ml::OneHotEncoderOp<float>::OneHotEncoderOp(const onnxruntime::OpKernelInfo &) [T = float]
0016c279 SVMRegressor
0016c286 class_weights
0016c294 classlabels_int64s
0016c2a7 virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommon<double, double, float>::Init(const onnxruntime::OpKernelInfo &) [InputType = double, ThresholdType = double, OutputType = float]
0016c378 void onnxruntime::ml::detail::TreeEnsembleCommon<double, double, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = double, ThresholdType = double, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorSum<double, double, float>]
0016c4cf void onnxruntime::ml::detail::TreeAggregator<double, double, float>::FinalizeScores(InlinedVector<ScoreValue<ThresholdType>> &, OutputType *, int, int64_t *) const [InputType = double, ThresholdType = double, OutputType = float]
0016c5b4 void onnxruntime::ml::detail::TreeEnsembleCommon<long, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = long, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorAverage<long, float, float>]
0016c706 void onnxruntime::ml::detail::TreeAggregatorMin<int, float, float>::MergePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = int, ThresholdType = float, OutputType = float]
0016c7fb /onnxruntime_src/onnxruntime/core/providers/cpu/nn/Unpool.cc
0016c838 gsl::narrow_cast<int64_t>(X_shape.NumDimensions()) >= axis
0016c873 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/pool.cc
0016c8ae spatial_scale
0016c8bc attribute case_change_action is not set
0016c8e4 LOWER
0016c8ea Input dimensions are either[C > 0] or [1][C > 0] allowed
0016c923 mode is required
0016c934 impl_->min_gram_length_ > 0
0016c950 impl_->max_skip_count_ >= 0
0016c96c Duplicate ngram detected, size: 
0016c98d void onnxruntime::PrepareForQDQ(const onnxruntime::TensorShape &, const onnxruntime::Tensor &, const onnxruntime::Tensor *, int64_t, int64_t &, int64_t &, int64_t &)
0016ca33 IsScalarOr1ElementVector(a_scale)
0016ca55 clip_ > 0.f
0016ca61 Can not get unpacked span from prepacked weights
0016ca92 onnxruntime::LSTMBase::LSTMBase(const onnxruntime::OpKernelInfo &)
0016cad5 allowed_activations.find(activations_[direction]) != allowed_activations.end()
0016cb28 Expecting activation to be one of Affine, Relu, LeakyRelu, ThresholdedRelu, Tanh, ScaledTanh, Sigmoid, HardSigmoid, Elu, Softsign, Softplus. Got 
0016cbba Invalid GRU reset gate activation function: 
0016cbe7 Violation of the requirment that all input tensors must have the same data type.
0016cc38 std::all_of(split_sizes.cbegin(), split_sizes.cend(), [](int64_t value) { return value >= 0; })
0016cc98 dft_length must be greater than zero.
0016ccbe onnxruntime::common::Status onnxruntime::CreateMelWeightMatrix<unsigned int>::operator()(onnxruntime::OpKernelContext *, int64_t, int64_t, int64_t, float, float) [T = unsigned int]
0016cd73  got: 
0016cd7a Tind
0016cd7f /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/isinf.cc
0016cdbf failed to get first output!
0016cddb size != 0 && (input_shape.Size() % size) == 0
0016ce09 CPU execution provider: string data type is not supported with ScatterElements opset 16 when reduction is 'mul'.
0016ce7a CPU execution provider: string data type is not supported with ScatterElements opset 18 when reduction is 'max'.
0016ceeb CPU execution provider: MLFloat16 data type is not supported with ScatterND opset 18 when reduction is 'min'.
0016cf59 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/space_depth_ops.cc
0016cfa3 Invalid value in 'split' attribute. All values must be > 0
0016cfde perm: 
0016cfe5 (local_source >= source) && (local_source < source + sizeof(T) * num_blocks)
0016d032 'axes' has an out of range axis
0016d052 UpsampleNearest
0016d062 /onnxruntime_src/onnxruntime/contrib_ops/cpu/cpu_contrib_kernels.cc
0016d0a6 Inputs 'past' dimension 1 shall have same length as dimension 0 of input 0
0016d0f1 Attention query layer weight shape error! Expected:{
0016d126 /onnxruntime_src/onnxruntime/contrib_ops/cpu/attnlstm/deep_cpu_attn_lstm.h
0016d171 mem_steps <= max_memory_steps_ && mem_steps > 0
0016d1a1  row[
0016d1a7 NGramRepeatBlock
0016d1b8 max_ngram_size_ > 0
0016d1cc COO indices must be 2-D, got: 
0016d1eb info.GetAttr<int64_t>("normalize_variance", &normalize_variance_).IsOK()
0016d234 virtual onnxruntime::common::Status onnxruntime::contrib::NchwcConv::Compute(onnxruntime::OpKernelContext *) const
0016d2a7 onnxruntime::contrib::NchwcConv::NchwcConv(const onnxruntime::OpKernelInfo &)
0016d2f5 onnxruntime::contrib::NchwcUpsample::NchwcUpsample(const onnxruntime::OpKernelInfo &)
0016d34b /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/dynamic_quantize_lstm.cc
0016d39e QlinearBuildLookupTable : input X_zero_point must be a scalar or 1D tensor of size 1
0016d3f3 QGemm : scale of y must be null or a scalar or 1D tensor of size 1
0016d436 attribute mincharnum is not set
0016d456 Encoder subgraph shall have 2 inputs when decoder_start_token_id attribute is empty
0016d4aa decoder_session_state
0016d4c0 encoder_session_state
0016d4d6 Input 'vocab_mask' is expected to have 1 dimension, got 
0016d50f Input 'vocab_mask'  dimension 0 does not match with vocab_size's, got 
0016d556 num_beams
0016d560 top_k <= Size()
0016d570 subgraph past state dimension 0 shall have length of 2
0016d5a7 AllocateRawInternal
0016d5bb c->bin_num == bin_num
0016d5d1 NumArenaExtensions:       
0016d5ec Config with key [
0016d5fe ]. It will be overwritten
0016d618 /onnxruntime_src/onnxruntime/core/framework/data_transfer_manager.cc
0016d65d thisProto->value_case() == TypeProto::ValueCase::kTensorType
0016d69a utils::HasElemType(thisProto->sequence_type())
0016d6c9 MLDataType for: 
0016d6da onnxruntime::Stream *onnxruntime::DeviceStreamCollectionImpl::GetStream(size_t) const
0016d730 /onnxruntime_src/onnxruntime/core/framework/ex_lib_loader.cc
0016d76d /onnxruntime_src/onnxruntime/core/framework/node_index_info.h
0016d7ab virtual int onnxruntime::IExecutionProvider::GenerateMetaDefId(const onnxruntime::GraphViewer &, onnxruntime::HashValue &) const
0016d82c PartitionOnnxFormatModelImpl
0016d849 TempSpace allocator not found
0016d867 AddExternalInitializers
0016d87f Missing session state for subgraph. Node:'
0016d8aa  Node(s) placed on [
0016d8bf reused != reused_for
0016d8d7 parameter_size
0016d8e6  must be equal to or twice the values size: 
0016d913 dense shape must 2-D. Got: 
0016d92f Expecting indices to have 2-D shape . Got: 
0016d95b Expecting index blocks: 
0016d974 X-device copy of strings not supported
0016d99b Input must be of CSR format
0016d9b7 idx < device_stream_map_->NumStreams()
0016d9de GetExtDataFromTensorProto
0016d9f8 ReadExternalDataForTensor
0016da12 Whether every token can only attend to previous tokens. Default value is 0.
0016da5e Bias tensor with shape (hidden_size + hidden_size + v_hidden_size) from input projection
0016dab7 segment_ids
0016dac3 gamma
0016dac9 input tensor
0016dad6 scores
0016dadd Input tensors of wrong rank (0).
0016dafe Incompatible dimensions for matrix multiplication
0016db30 IsAllFinite
0016db3c Whether A should be transposed
0016db5b Scalar multiplier for the product of input tensors A * B.
0016db95 N-dimensional matrix B
0016dbac image_size
0016dbb7 The bit-packed output mask.
0016dbd4                 CX = Mul (Alpha, X)
0016dbf8                 SIGMOIDCX = Sigmoid (CX)
0016dc21                 Y = Mul (X, SIGMOIDCX)
0016dc48             
0016dc55 NormalizedV = Cast (Normalized)
0016dc75 Biased = Add (Scaled, B2D)
0016dc90 Couple the input and forget gates if 1, default 0.
0016dcc3 Scale of quantized output 'Y'. It must be a scalar.
0016dcf7 w_zero_point
0016dd04 The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G.
0016e06f Scale and Zero-point must be a scalar
0016e095 Scale for doing quantization to get 'y'. It could be a scalar or a 1-D tensor,which means a per-tensor or per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
0016e18c Constrain 'y', 'x_scale' to float tensors.
0016e1b7 The type of BFP - must match with the BFPType enum
0016e1ea Zero point tensor for input 'X'.It must be a scalar.
0016e222 scale of the global_weight
0016e23d Unsupported type:
0016e24f ) input arg (
0016e25d  does not match. 
0016e26f initializer_node_arg != nullptr
0016e28f Removing initializer '
0016e2a6 Source and target must both be tensors
0016e2cd The given function name: 
0016e2eb index >= 0 && static_cast<size_t>(index) < outputs.size()
0016e325 Invalid input index for node 
0016e343 . Index:
0016e34c Can only add a new input at the end of the current ones.
0016e385  Implicit input name 
0016e39b Load model 
0016e3a7 LoadFromString
0016e3b6 Size of affinity string must be between 1 and 
0016e3e5 Quant GEMM format: AIsSigned(
0016e403 ) is not supported on this device
0016e425 "ts" :
0016e42c n >= 0
0016e433 Got null library handle
0016e44b LoadTensorShapeOrtFormat
0016e464 ] not in sorted order.
0016e47b Sparse tensor values (
0016e492  axis value 
0016e49f Condition for the if
0016e4b4 The graph run each iteration. It has 2+N inputs: (iteration_num, condition, loop carried dependencies...). It has 1+N+K outputs: (condition, loop carried dependencies..., scan_outputs...). Each scan_output is created by concatenating the value of the specified output value at the end of each iteration of the loop. It is an error if the dimensions or data type of these scan_outputs change across loop iterations.
0016e653  then=
0016e65a tensor(
0016e662 Input tensor must have rank 2
0016e680 X_greater = Greater (X_random, input)
0016e6a6 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/generator/old.cc
0016e6f7 Right input tensor for the logical operator.
0016e724 Slope tensor. The shape of slope can be smaller then first input X; if so, its shape must be unidirectional broadcastable to X
0016e7a3 zero point of quantized input a
0016e7c3 Constrain input b and its zero point data type to 8-bit integer tensor.
0016e80b If set to 1 will perform the sums in reverse direction.
0016e843 axis tensor can be int32 or int64 only
0016e86a Hann
0016e86f lower_edge_hertz
0016e880 Target rank must be 1 less than the input rank.
0016e8b0 If 1, returns a window to be used as periodic function. If 0, return a symmetric window. When 'periodic' is specified, hann computes a window of length size + 1 and returns the first size points. The default value is 1. 
0016e98d If STFT has both a window input and frame_length specified, the dimension of the window must match the frame_length specified!
0016ea0c Coefficient of ELU default to 1.0.
0016ea2f Output tensor. Same dimension as inputs.
0016ea58 The shape of the output can be explicitly set which will cause pads values to be auto generated. If 'output_shape' is specified, 'pads' values are ignored.
0016eaf4 If set to true, it indicates BatchNormalization is being used for training, and outputs 1, 2, 3, and 4 would be populated.
0016eb6f running (training) or estimated (testing) mean tensor of shape (C).
0016ebb3 Matrix after normalization
0016ebce Constrain input to only numeric types.
0016ebf5 image_shape
0016ec01 NormalizedT = Cast (Normalized)
0016ec21 The number of groups of channels. It should be a divisor of the number of channels `C`.
0016ec79 Ratio of Dropout must be a scalar.
0016ec9c If set to nonzero, run spatial batch normalization in test mode, default is 0.
0016eceb Optional is expected to have an output.
0016ed13 OptionalHasElement is expected to have 0 or 1 input.
0016ed48 Input must be an optional-type value containing an element with type information.
0016ed9a type_proto
0016eda5 (Optional) The axis of the dequantizing dimension of the input tensor. Ignored for per-tensor quantization. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
0016ee7c Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.
0016eebd A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor. Accepted range is [-r, r-1] where r = rank(data).
0016ef60 (Optional) The data type of the tensors in the output sequence. The default type is 'float'.
0016efbd Constrain output types to all tensor types.
0016efe9 _seqempty
0016eff3 Input Sequence and Tensor are expected to have type info. Current type is null.
0016f043 target_type
0016f04f Constrain input `X` and output `Y` types to all tensor types.
0016f08d Tensor of rank one greater than input tensor 'indices', i.e. rank(output) = rank(indices) + 1. The data type for the elements of the output tensor is the same as the type of input 'values' is used.
0016f153 'Repeats' input must be 1D tensor of type int64
0016f183 1-D tensor of slice step of corresponding axis in `axes`. Default to 1. 
0016f1cc List of non-negative integers, indicate the dimensions to squeeze.
0016f20f A string indicating the desired element type of the output tensor, one of 'TO_FLOAT', 'TO_STRING', 'TO_INT64'.
0016f27e Classification scores ([N,E] - one score for each class and example
0016f2c2 Data to be scaled.
0016f2d5 Input type is not float tensor but keys_floats is set
0016f30b WARNING
0016f313 invalid escape sequence
0016f32b bad repetition operator
0016f343 Malayalam
0016f350 Myanmar
0016f358 Ogham
0016f35e Rejang
0016f368 Tamil
0016f36e Toto
0016f377 Samsung
0016f37f Nvidia
0016f386 Rockchip
0016f38f /sys/devices/system/cpu/cpu%u/topology/core_siblings_list
0016f3c9 condition_variable::timed wait: mutex not locked
0016f3fe const_cast
0016f40c unsigned __int128
0016f41e operator delete
0016f42e operator>=
0016f439 terminating with %s exception of type %s
0016f462 unwind_phase2
0016f470 unsupported arm64 register
0016f48b libunwind: malformed DW_CFA_def_cfa DWARF unwind, reg too big
0016f4ca getSLEB128
0016f4d5 getSavedRegister
0016f4ee OrtStatusPtr OrtApis::UseCooIndices(OrtValue *, int64_t *, size_t)
0016f531 the ort_value must contain a constructed tensor
0016f561 Input is not of type sequence or map.
0016f587 static bool onnxruntime::utils::ContainerChecker::IsContainerOfType<std::map<long, long>>::check(const onnxruntime::utils::ContainerChecker::Cont &, size_t) [T = std::map<long, long>]
0016f63f Unsupported input type
0016f656 custom join thread function not set for inter op thread pool
0016f693 ~InferenceSession
0016f6a5 RegisterExecutionProvider
0016f6bf ModelProto corresponding to the model to be loaded has already been parsed. Invoke Load().
0016f71a  as the model has control flow nodes which can't be supported by CUDA Graphs.
0016f768 This session cannot use the CUDA Graph feature as requested by the user  as the model has control flow nodes which can't be supported by CUDA Graphs.
0016f7fe Got invalid dimensions for input: 
0016f821 Could not write a profile because no model was loaded.
0016f858 Invalid session log severity level. Not a valid onnxruntime::logging::Severity value: 
0016f8af  value of 'save' is only valid when saving an ORT format model.
0016f8ef IsOptionalSeqTensor(type)
0016f909 Device:[
0016f912 DeviceType:
0016f927 ORT config json from the model: 
0016f948 boolean
0016f950 Setting graph_optimization_level to ORT_ENABLE_ALL
0016f983 invalid string: control character U+0006 (ACK) must be escaped to \u0006
0016f9cc invalid string: control character U+0012 (DC2) must be escaped to \u0012
0016fa17 graph_optimization_level is not valid
0016fa3d intra-op
0016fa46 inter-op
0016fa4f tensor(int64)
0016fa5d tensor(bfloat16)
0016fa6e Please fetch output tensor with specified shape.
0016fa9f T *onnxruntime::Tensor::MutableData() [T = onnxruntime::BFloat16]
0016fae1 onnxruntime::nnapi::Model::NNMemory::NNMemory(const NnApi *, const char *, size_t)
0016fb34 ANeuralNetworksBurst_create
0016fb50 Reshape
0016fb58 th device's type
0016fb69 [Name: [
0016fb72 size_t android::nn::wrapper::OperandType::GetElementByteSize() const
0016fbb7 , B shape: 
0016fbc3 AddInitializerInNewLayout
0016fbdd ] NNAPI input scale: 
0016fbf3 ] has mismatch scales between onnx and NNAPI
0016fc20 AddQuantizationScaleAndZeroPointToSkip
0016fc47 CanSkipReshape
0016fc56 Reshape/Flatten can only be skipped when the output is Gemm/Matmul
0016fc99 IsQuantizationScaleSupported
0016fcb6  >= size, 
0016fcc1 /reshaped
0016fccb Pad input with zero elements is not supported
0016fcf9 Reshape doesn't support 0 reshape dimension when allowzero is enabled
0016fd3f , input_size_n, 
0016fd50 SAME_UPPER
0016fd5b B of MatMul must be known
0016fd75 index < q_nodes_.size()
0016fd8d RegisterKernels
0016fd9d std::unique_ptr<KernelRegistry> onnxruntime::xnnpack::RegisterKernels()
0016fde5 GetConvCompType
0016fdf5 Scale value should be greater than 0.
0016fe1b ApplyTransformers
0016fe2d _RuleBasedTransformer
0016fe43 /onnxruntime_src/onnxruntime/core/optimizer/graph_transformer_utils.cc
0016fe8a InlinedVector<std::unique_ptr<RewriteRule>> onnxruntime::optimizer_utils::GenerateRewriteRules(onnxruntime::TransformerLevel, const InlinedHashSet<std::string> &)
0016ff2d std::unique_ptr<RuleBasedGraphTransformer> onnxruntime::optimizer_utils::GenerateRuleBasedGraphTransformer(onnxruntime::TransformerLevel, const InlinedHashSet<std::string> &, const InlinedHashSet<std::string_view> &)
00170006 conv.GetOutputEdgesCount() == 1 && conv.OutputNodesBegin()->OpType() == "Add"
00170054 with a fixed dimension size 
00170071 activation != nullptr
00170087 Total shared scalar initializer count: 
001700af fused Gemm 
001700bb MatMulIntegerToFloat
001700d0 q_reshape const not matched
001700ec k_transpose perm attribute not matched
00170113 q and v are not from same Split node
00170138 /onnxruntime_src/onnxruntime/core/optimizer/attention_fusion.cc
00170178 Output edge count not expected for nodes in path 1 of position shape.
001701be BiasDropout
001701ca gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = onnxruntime::BFloat16]
0017021c InsertCastTransformer works on the assumption that `dtype` attribute holds an integer.
00170273 SimplifiedLayerNormalization
00170290 _FusedMatMulAndScale
001702a5 GetScalarConstantInitializer
001702c2 transBatchA
001702ce !node_consumers.empty()
001702e6 bn_B
001702eb ReorderOutput
001702f9 mode
001702fe static std::optional<ExtendedGraphEdge> onnxruntime::graph_utils::ExtendedGraphEdge::TryCreateFromNodeToOutput(const onnxruntime::Graph &, const onnxruntime::Node &, int)
001703a9 perm.size() == gsl::narrow_cast<size_t>(shape_proto->dim_size())
001703ea Cannot reshape initializer 
00170406 is_node_supported_fn
0017041b virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Relu<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Relu<float>]
001704da p_mlvalue
001704e4 CreateFeedsFetchesManager
001704fe 'Loop' input 'cond' should be a scalar tensor. Got shape of 
0017053b Loop subgraph input 1 has unknown shape: 
00170565 output_mlvalue
00170574 TransposeOutput
00170584 Einsum op: Exception during MatMul operation: 
001705b3 rank >= 2 && dim_1 != dim_2 && input_dims[onnxruntime::narrow<size_t>(dim_1)] == input_dims[onnxruntime::narrow<size_t>(dim_2)]
00170633 std::unique_ptr<Tensor> onnxruntime::EinsumTypedComputeProcessor<double>::PairwiseOperandProcess(const onnxruntime::Tensor &, const onnxruntime::TensorShape &, const onnxruntime::Tensor &, const onnxruntime::TensorShape &, const gsl::span<const int64_t> &, bool) [T = double]
00170747 void onnxruntime::EinsumTypedComputeProcessor<long>::FinalizeOutput(const onnxruntime::Tensor &, const gsl::span<const int64_t> &) [T = long]
001707d5 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Abs<double>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Abs<double>]
00170894 RIGHT
0017089a void onnxruntime::UntypedExpand(onnxruntime::OpKernelContext &, const onnxruntime::ProcessBroadcastSpanFuncs &)
0017090a SoftmaxCPU inputs N, D and N * D must be < 
00170936 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/cast_map.h
00170974 max_map must be > 0 if map_form is SPARSE
0017099e Expected 'replaced_value_float' attribute since 'imputed_value_floats' is specified
001709f2 scores_output_data.size() >= scores_output_size
00170a22 Unsupported data type of 
00170a3c void onnxruntime::ml::detail::TreeAggregatorSum<double, double, float>::MergePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = double, ThresholdType = double, OutputType = float]
00170b39 void onnxruntime::ml::detail::TreeEnsembleCommon<long, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = long, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorClassifier<long, float, float>]
00170c8e training_mode
00170c9c /onnxruntime_src/onnxruntime/core/providers/cpu/nn/batch_norm.h
00170cdc Invalid input var: 0th dimension != 
00170d01 beta_ > 0.0f
00170d0e max_gram_length must be inbounds of ngram_counts: 
00170d41 scores_tensor
00170d4f onnxruntime::RoiAlignBase::RoiAlignBase(const onnxruntime::OpKernelInfo &)
00170d9a PropagateInputOrtValueToFirstOutput
00170dbe virtual onnxruntime::common::Status onnxruntime::QLinearConv<signed char>::UseSharedPrePackedBuffers(std::vector<BufferUniquePtr> &, int, bool &) [ActType = signed char]
00170e68 projected_index.size() > 0
00170e83 LSTM
00170e88 onnxruntime::common::Status onnxruntime::SplitToSequence::ComputeImpl(onnxruntime::OpKernelContext &, const onnxruntime::Tensor &, const onnxruntime::Tensor *) const [T = double]
00170f3b signal_components == 1 || signal_components == 2
00170f6c MelWeightMatrix
00170f7c typename std::enable_if<std::is_floating_point<SrcType>::value, void>::type onnxruntime::(anonymous namespace)::CastToString(const SrcType &, std::string &) [SrcType = double]
0017102c size of 'dilations' attribute, if provided, should equal to the number of image dimmensions.
00171089 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/gather.cc
001710ca onnxruntime::GatherElements::GatherElements(const onnxruntime::OpKernelInfo &)
00171119 " not supported, expect bilinear, nearest or bicubic
0017114e Last dimension of grid: 
00171167 virtual onnxruntime::common::Status onnxruntime::NonZero<unsigned char>::Compute(onnxruntime::OpKernelContext *) const [T = unsigned char]
001711f2 pads_size == 2 * data_rank
0017120d onnxruntime::PadBase::PadBase(const onnxruntime::OpKernelInfo &)
0017124e void onnxruntime::IncrementIndexAndComputeOffsetSetup(onnxruntime::MultiIndex &, size_t, gsl::span<const int64_t>, const gsl::span<const size_t> &, size_t)
001712ea Resize: input tensor's dimension does not match the scales.
00171326 Inputs 'mask_index' with 4D data shall have shape batch_size x 1 x max_sequence_length x max_sequence_length)
00171394  rows[
0017139b BifurcationDetector
001713af /onnxruntime_src/onnxruntime/contrib_ops/cpu/fused_gemm.cc
001713ea (channels % 4) == 0
001713fe MatmulInteger : input1 C_scale must be a scalar or 1D tensor of size 1
00171445 info.GetAttr<ONNX_NAMESPACE::GraphProto>("encoder", &proto).IsOK()
00171488 Encoder subgraph shall have 3 inputs when decoder_start_token_id attribute is available
001714e0 virtual void onnxruntime::contrib::transformers::BeamSearchScorer::Initialize(onnxruntime::AllocatorPtr &, int)
00171550 next_scores.size() == next_tokens.size()
00171579 onnxruntime::common::Status onnxruntime::contrib::GenerationCpuDeviceHelper::ExpandBuffer(onnxruntime::Stream *, const OrtValue &, int, onnxruntime::AllocatorPtr, OrtValue &, bool) [T = float]
0017163a Sample
00171641 /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/sampling_parameters.cc
00171692 Setup must be called before CreateInitialFeeds
001716c1 subgraph input 3 shall be named as past_0, got: 
001716f2 encoder subgraph input 2 shall be named as decoder_input_ids, got: 
0017173a BFCArena::Chunk *onnxruntime::BFCArena::ChunkFromHandle(onnxruntime::BFCArena::ChunkHandle)
00171796 Total allocated bytes: 
001717ae h != kInvalidChunkHandle
001717c7 BFCArena::Chunk *onnxruntime::BFCArena::FindChunkPtr(onnxruntime::BFCArena::BinNum, size_t, size_t, onnxruntime::Stream *, bool, onnxruntime::WaitNotificationFn)
00171869 Allocator:
00171874 void onnxruntime::BFCArena::DumpMemoryLog(size_t)
001718a6 Bin for 
001718af   Free 
001718b7 single_node_compute_func should have 1 element.
001718e7 Failed to find kernel for 
00171902 Invalid ORT format model.
0017191c type_proto is not of type map!
0017193b not implemented
0017194b const onnxruntime::KernelCreateInfo &onnxruntime::SessionState::GetNodeKernelCreateInfo(onnxruntime::NodeIndex) const
001719c1 FinalizeSessionStateImpl
001719da weights_to_be_filled_in.buffers_.size() > 0
00171a06 OrtMemoryInfo onnxruntime::PlannerImpl::GetLocationForNodeInput(size_t, const onnxruntime::Node &, const onnxruntime::KernelCreateInfoMap &)
00171a93 ExecuteThePlan
00171aa2 op_name
00171aad DeserializeTensorProto
00171ac4 common::Status onnxruntime::session_state_utils::ExtDataTensorProtoToTensor(const onnxruntime::Env &, const std::basic_string<PATH_CHAR_TYPE> &, const onnx::TensorProto &, onnxruntime::Tensor &, onnxruntime::OrtCallback &)
00171ba3 this tensor already has populated sparse_indices
00171bd4 SparseTensor Allocation failed for size: 
00171bfe Use MakeBlockSparseStrings
00171c19 v >= 0
00171c20 CopySparseData
00171c2f checksum
00171c38 has_layer_state
00171c48 Constrain sequence_length to int tensors.
00171c72 2D output tensor with shape (batch_size, vocab_size)
00171ca7 Constrain sequence_token_count and token_offset to integer types
00171ce8 TorchEmbedding
00171cf7 If true, check only for NaN.
00171d14 The output scalar. Its value is true if all input tensors are finite. Otherwise, the output value would be false.
00171d86 Size of the vocabulary. If not provided, it will be inferred from the decoder subgraph's output shape
00171dec sequences
00171df6 Constrain input0 and output types to float tensors
00171e29 input_0
00171e31 Constrain input A data types as 16-bit integer tensor
00171e67 Seed for the hashing algorithm, unsigned 32-bit integer, default to 0.
00171eae A 1-D INT64 tensor of the same size as 'x' containing the indices for each value in 'x' in the output 'uniques'
00171f1e Input data tensor from the previous operator; 4-D feature map of shape (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
00171fe1 content-to-position attention tensor, QcKr^T.
0017200f List of tensors for SNPE DLC input
00172032 Attribute 'max_output_boxes' must be >= 1.
0017205d Constrain input X and output Y types to float tensors.
00172094 GroupNorm
0017209e Zero point tensor for output 'Y'. It must be a scalar.
001720d5 Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
0017228b Threshold value
0017229b Scale for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
0017237e ReduceSumInteger
0017238f Constrain input A data type to 8-bit integer tensor.
001723c4 condition
001723ce  When True (nonzero), yield x, otherwise yield y
001723ff past state for key and value with shape (2, batch_size, num_heads, past_sequence_length, head_size).
00172464 layernorm_out
00172472 scale_B
0017247a Shape of quantized tensor must be 1D.
001724a0  or UNDEFINED. Got: 
001724b5 graph_inputs_excluding_initializers_.empty() && graph_inputs_including_initializers_.empty() && value_info_.empty() && graph_outputs_.empty()
00172543 This is an invalid model. Error: Duplicate definition of name (
00172583 Argument type mismatch when adding edge.
001725ac Some nodes are not included in the topological sort, graph have a cycle.
001725f5 ) in node (
00172601 VerifyNodeAndOpMatch
00172616 Replacement tensor's data type does not match.
0017264b . Falling back to lenient merge.
0017266c , Error 
00172675 , domain: 
00172680 for node: 
0017268b CanUpdateImplicitInputNameInSubgraphs
001726b1 void onnxruntime::graph_utils::UpdateImplicitInputNameInSubgraph(onnxruntime::Node &, const std::string &, const std::string &)
00172731 std::count_if(subgraph_node.InputEdgesBegin(), subgraph_node.InputEdgesEnd(), [input_slot_index](const Node::EdgeEnd& entry) { return entry.GetDstArgIndex() == input_slot_index; }) == 0
001727eb Attempting to load runtime optimization records for a previously loaded optimizer: 
0017283f CblasNoTrans Unexpected CBLAS_TRANSPOSE for TransB of 
00172876 QLinearGlobalAveragePool parameter out of computation range!
001728b3 !points_.empty()
001728c4 std::string onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::Reset()
00172916 Received negative size from stat call
0017293c DeleteFolder(): nftw() failed with error: 
00172967 /onnxruntime_src/onnxruntime/core/flatbuffers/flatbuffers_utils.cc
001729aa ) should contain one and only one value field.
001729d9 Scan input 
001729e5 Loop 'body' subgraph outputs should all be tensors or sequences or optionals, but output 
00172a3f optional(tensor(float))
00172a57 optional(tensor(complex128))
00172a74 The value for the sole element for the scalar, int64, output tensor.
00172ab9 The value for the sole element for the scalar, float32, output tensor.
00172b00 Output tensor containing the same value of the provided tensor.
00172b40 Only one of the attributes 'value' or 'sparse_value' must be specified for a Constant node.
00172b9c input_less_than_min = Less (input, min)
00172bc4 Constrain input, weight, and output types to floating-point tensors.
00172c09 Constrain target to integer types
00172c2c         X_NCD = Reshape (scores, Shape3D)
00172c56         X_NDC = Transpose <perm = [0, 2, 1]> (X_NCD)
00172c8b         X_LogSM = LogSoftmax <axis = 2> (X_NDC)
00172cbb         X_LogSM_NCD = Transpose <perm = [0, 2, 1]> (X_LogSM)
00172cf8         X_shape = Shape (scores)
00172d19         X_Log = Reshape (X_LogSM_NCD, X_shape)
00172d48       
00172d4f The ground truth output tensor, with shape [batch_size], or [batch_size, D1, D2, ..., Dk], where K is the number of dimensions. Labels element value shall be in range of [0, C). If ignore_index is specified, it may have a value outside [0, C) and the label values should either be in the range [0, C) or have the value ignore_index.
00172e9c Weighted loss float Tensor. If reduction is 'none', this has the shape of [batch_size], or [batch_size, D1, D2, ..., Dk] in case of K-dimensional loss. Otherwise, it is a scalar.
00172f4f SoftmaxCrossEntropyLoss
00172f67 If onesided is 1, only values for w in [0, 1, 2, ..., floor(n_fft/2) + 1] are returned because the real-to-complex Fourier transform satisfies the conjugate symmetry, i.e., X[m, w] = X[m,w]=X[m,n_fft-w]*. Note if the input or window tensors are complex, then onesided output is not possible. Enabling onesided with real inputs performs a Real-valued fast Fourier transform (RFFT). When invoked with real or complex valued input, the default value is 0. Values can be 0 or 1.
00173142 The length of the signal.If greater than the axis dimension, the signal will be zero-padded up to dft_length. If less than the axis dimension, only the first dft_length values will be used as the signal. It's an optional value. 
00173227 Constrain signal and output to float tensors.
00173255 const_zero_casted
00173267 If set, defines the broadcast dimensions. See doc for details.
001732a6 Input tensor C
001732b6 Pow takes input data (Tensor<T>) and exponent Tensor, and
001732f0 produces one output data (Tensor<T>) where the function `f(x) = x^exponent`,
0017333d is applied to the data tensor elementwise.
00173369 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/nn/defs.cc
001733b4 The running mean after the BatchNormalization operator.
001733ec The shape of the block to apply on the input.This is a 1-dimensional tensor of size of at least 2, containing the value [H_block, W_block]  for a 2-D image or [dim_b1, dim_b2, ..., dim_bN] for a N-D block.This is the block-shape before dilation is applied to it.
001734f3 MeanOfSquare = ReduceMean (Square, Axes_1)
0017351e Output data tensor from pooling across the input tensor. Dimensions will be N x C x 1 x 1
00173578 default 1; Pooled output Y's height.
0017359d Input type is null. Input must have Type information.
001735d3 Optional-type input must contain an element with type information.
00173616 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/reduction/defs.cc
00173668 Empty sequence.
00173678 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/sequence/defs.cc
001736c9 Constrain to any tensor type.
001736e7 _cond_out
001736f1 Only supports `int32_t` or `int64_t` inputs for split
00173727  expected to have type but instead is null
00173752 Output tensor of [N, C/(blocksize * blocksize), H * blocksize, W * blocksize].
001737a1 Constrain repeat's type to int64 tensors.
001737cb Constrain grid types to float tensors.
001737f2 (Optional) A scalar value to be used if the mode chosen is `constant` (by default it is 0, empty string or False).
00173865 Invalid Target shape product of 0. Product cannot be 0 in combination with -1
001738b3 Input 'values' must have exactly two elements.
001738e2 `shape` only supports `int32_t` or `int64_t` inputs
00173916 Optional list of output lengths (see also arg 'split')
0017394d Constrain output types to bool, int32, int64, float16, float, double tensors.
0017399c This attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>
00173a1c The coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.
00173a8c Denote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input "roi", scale = length_resized / length_original, <br/>
00173bf5 if coordinate_transformation_mode is "half_pixel", <br/>
00173c2e x_original = (x_resized + 0.5) / scale - 0.5, <br/>
00173c63 if coordinate_transformation_mode is "pytorch_half_pixel", <br/>
00173ca4 x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>
00173cf2 if coordinate_transformation_mode is "align_corners", <br/>
00173d2e x_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>
00173d7c if coordinate_transformation_mode is "asymmetric", <br/>
00173db5 x_original = x_resized / scale, <br/>
00173ddc if coordinate_transformation_mode is "tf_crop_and_resize", <br/>
00173e1d x_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1).
00173ee1 Attribute 'scales' is required.
00173f01 Number of elements of input 'scales' (
00173f28 The strings of the map. This sequence must be the same length as the 'cats_int64s' sequence
00173f84 map(string, int64)
00173f97 The input type must be a tensor of a numeric type, either [N,C] or [C]. The output type will be of the same tensor type and shape.
0017401a onnx.TypeProto.Map
0017402d close() failed: 
0017403e  details: 
00174049 SearchDFA inconsistency
00174061  in AddToThreadq
00174072 Unexpected op in Regexp::Equal: 
00174093 Bhaiksuki
0017409d Elbasan
001740a5 Modi
001740aa failed to allocate %zu bytes for %u uarch index mapping entries
001740ea hi6250
001740f1 Marvell
001740f9 Tuesday
00174105 March
0017410b typeinfo name for 
0017411e operator new
0017412b  [enable_if:
00174138 std::nullptr_t
00174147 objc_object
00174153 std::bad_alloc
00174162 getEncodedP
00174175 , got 
0017417c OrtStatusPtr OrtApis::UseCsrIndices(OrtValue *, int64_t *, size_t, int64_t *, size_t)
001741d2 NULL input supplied for input 
001741f1 non_tensor_base != nullptr
0017420c OrtStatusPtr OrtApis::GetOpaqueValue(const char *, const char *, const OrtValue *, void *, size_t)
0017426f Strings can only reside in CPU memory
00174297 Input is not of one of the supported sequence types.
001742cc onnxruntime::DataTypeImpl::GetType<T>() == type_
001742fd Load model from 
0017430e Encountered unknown exception in Initialize()
00174340 onnxruntime::common::Status onnxruntime::InferenceSession::CachedExecutionProviderForGraphReplay::ReplayGraph()
001743b4 graph_optimization_level option in the model file must be an integer
001743fc Setting graph_optimization_level to ORT_DISABLE_ALL
00174430 invalid string: control character U+0000 (NUL) must be escaped to \u0000
00174479 invalid string: control character U+0007 (BEL) must be escaped to \u0007
001744c2 unexpected 
001744ce common::Status onnxruntime::IOBinding::BindInput(const std::string &, const OrtValue &)
00174526 common::Status onnxruntime::IOBinding::BindOutputImpl(const std::string &, const OrtValue &, OrtDevice)
0017458e execution_mode is not valid
001745aa Session config entry '
001745c1 Output buffer is not large enough for session config entry
001745fc seq(tensor(uint32))
00174610 seq(tensor(int16))
00174623 com.ms.internal.nhwc
00174638 org.pytorch.aten
00174649 libonnxruntime_providers_openvino.so
0017466e GetProvider
0017467a T *onnxruntime::Tensor::MutableData() [T = unsigned int]
001746b3 const T *onnxruntime::Tensor::Data() const [T = int]
001746e8 Provider options key/value cannot be empty
00174713 arg_num < static_cast<size_t>(input_count_)
0017473f ResultCode: 
0017474c Predict
00174754 ANeuralNetworksExecution_burstCompute
0017477a ANeuralNetworksExecution_setReusable
0017479f SL_ANeuralNetworksDiagnosticExecutionInfo_getNnApiVersion
001747dd  is not quantized
001747ef uint32_t onnxruntime::nnapi::ShapeSize(const onnxruntime::nnapi::Shape &, size_t, size_t)
00174849 AddOperandFromScalar
0017485e shape_proto cannot be null for input: 
00174885 op = 
0017488b on setPreference
0017489c _token_
001748a4 Failed to get B's shape.
001748bd IsValidConvWeightQuantizedType
001748dc  must be an initializer tensor
001748fb  only supports per-channel quantization on Android API 29+, 
00174938 zero_points[
00174945 /onnxruntime_src/onnxruntime/core/providers/common.h
0017497a Scales of N/C channel should be 1
0017499c , scale_c, 
001749a8  input axis: 
001749b6 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/unsqueeze_op_builder.cc
00174a1c The weight of convolution must be known
00174a44 and beta == 1.0 is supported.
00174a62  transB 
00174a6b C of Gemm must be a vector of b_shape[
00174a92 Bias of QDQ Gemm must be known
00174ab1  shape of C, 
00174abf GetClipMinMax
00174acd GetClipMinMax() only support Clip node with float inputs for now. 
00174b10 bytes aligned. But it's not satisfied
00174b36 unknown QDQ ops
00174b46 gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = unsigned char]
00174b95 xnn_run_operator returned 
00174bb0 onnxruntime::PoolAttributes::PoolAttributes(const OpNodeProtoHelper<onnxruntime::ProtoHelperNodeContext> &, const std::string &, int)
00174c36  failed. Status:
00174c47 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/upsamplebase.h
00174c8d session.enable_quant_qdq_cleanup
00174cae ConvAddFusion
00174cbc MatmulTransposeFusion
00174cd2 new_gemm_output_defs.size() == 1
00174cf3 virtual onnxruntime::common::Status onnxruntime::CommonSubexpressionElimination::ApplyImpl(onnxruntime::Graph &, bool &, int, const logging::Logger &) const
00174d90  of node 
00174d9a CheckSliceParameters
00174daf concat first input value is not -1
00174dd2 Failed to find reshape shape path 1
00174df6 Pass MatchPastSubgraph
00174e0d reshape initializer value is not expected
00174e37 Failed to find path for q
00174e51 Fused Attention subgraphs 
00174e6c Failed in match input mask subgraph
00174e90 Failed to load Q, K and V bias tensors, or data type is not float or float16.
00174ede CheckInput
00174ee9 /onnxruntime_src/onnxruntime/core/optimizer/gather_fusion.cc
00174f26 virtual onnxruntime::common::Status onnxruntime::GatherToSliceFusion::ApplyImpl(onnxruntime::Graph &, bool &, int, const logging::Logger &) const
00174fb8 is_inner_broadcast
00174fcb onnxruntime::Initializer &onnxruntime::Initializer::mul(const onnxruntime::Initializer &)
00175025 Created a new Cast node to interchange Cast and Transpose nodes
00175065 Info
0017506a GetQDQSelections
0017507b /onnxruntime_src/onnxruntime/core/optimizer/selectors_actions/actions.cc
001750c4 Failed to remove node.
001750db Missing action 
001750eb com.microsoft.QLinearAdd
00175104 onnxruntime::ElementWiseKernel<onnxruntime::functors::HardSigmoid<float>>::ElementWiseKernel(const onnxruntime::OpKernelInfo &) [F = onnxruntime::functors::HardSigmoid<float>]
001751b4  was not found. Defaulting to a rank 1 shape of {0}.
001751e9 Number of entries in 'scan_output_axes' was 
00175216 t_proto_p->dims()[0] == 1
00175230 Tensor proto with external data for value attribute is not supported.
00175276 Invalid data type of 
0017528c onnxruntime::Multinomial::Multinomial(const onnxruntime::OpKernelInfo &)
001752d5 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/utils.h
00175314 The rank of the input must match permutation size for Transpose
00175354 std::unique_ptr<Tensor> onnxruntime::EinsumOp::DeviceHelpers::CpuDeviceHelpers::DiagonalInnermostDims(const onnxruntime::Tensor &, bool, onnxruntime::AllocatorPtr)
001753f8 Left shape: 
00175405 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Log<double>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Log<double>]
001754c4 input_count >= 1
001754d5 !helper.HaveTwoTensorInputs()
001754f3 k argument [
00175500 ai.onnx.ml
0017550b onnxruntime::common::Status onnxruntime::ml::CastMap::ComputeImpl(onnxruntime::OpKernelContext &, TTo) const [TFrom = float, TTo = float]
00175595 info.GetAttrs<TValue>(_value_field_name, values).IsOK()
001755cd multi_class
001755d9 num_features == feature_count_
001755f8 nodes_hitrates_as_tensor
00175611 X dims is empty.
00175622 Attribute:'
0017562e GetVectorAttrsOrDefault
00175646 onnxruntime::ml::ZipMapOp::ZipMapOp(const onnxruntime::OpKernelInfo &)
0017568d Invalid number of outputs for BN training
001756b7  dimension != 
001756c6 Unsupported kernel dimension : 
001756e6 Null input X ptr
001756f7 IsBQuantParamSupported(b_zero_point->Shape(), b ? b->Shape() : b_shape_)
00175740 /onnxruntime_src/onnxruntime/core/providers/cpu/reduction/reduction_ops.h
0017578a fast_shape[1] == output.Shape().Size()
001757b1 Invalid data type for GRU operator of 
001757d8 forward
001757e0 virtual onnxruntime::common::Status onnxruntime::DeepCpuLstmOp::Compute(onnxruntime::OpKernelContext *) const
0017584e const T *onnxruntime::rnn::detail::SafeRawConstPointer(gsl::span<const T>, size_t, size_t) [T = const float]
001758bb Must have valid 'axis' attribute
001758dc Unsupported 'dtype' value: 
001758f8 ), input tensor data type (
00175914 onnxruntime::common::Status onnxruntime::SplitToSequence::ComputeImpl(onnxruntime::OpKernelContext &, const onnxruntime::Tensor &, const onnxruntime::Tensor *) const [T = std::basic_string<char>]
001759d8 STFT
001759dd onnxruntime::common::Status onnxruntime::CreateMelWeightMatrix<int>::operator()(onnxruntime::OpKernelContext *, int64_t, int64_t, int64_t, float, float) [T = int]
00175a80 onnxruntime::(anonymous namespace)::Cast::Cast(const onnxruntime::OpKernelInfo &)
00175ad2 auto onnxruntime::StridedCopy(concurrency::ThreadPool *, unsigned long *, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShape &, const unsigned long *, const onnxruntime::TensorShapeVector &)::(anonymous class)::operator()(std::ptrdiff_t, std::ptrdiff_t) const
00175bea GatherElements op: Rank of input 'data' needs to be equal to rank of input 'indices'
00175c3f void onnxruntime::core_impl(const onnxruntime::Tensor *, const onnxruntime::Tensor *, onnxruntime::Tensor *, int64_t, concurrency::ThreadPool *) [Tin = long]
00175cdd padding_mode_str == "zeros" || padding_mode_str == "border" || padding_mode_str == "reflection"
00175d3d NonZero
00175d45 Depth is negative.
00175d58 reduction
00175d62 CPU execution provider: BFloat16 data type is not supported with ScatterElements opset 18 when reduction is 'max'.
00175dd5 input shape: 
00175de3 CPU execution provider: bool data type is not supported with ScatterND opset 18 when reduction is 'max'.
00175e4c Starts and steps shape mismatch
00175e6c output == output_end
00175e81  NumOutputs=
00175e8e Trilu
00175e94 k should be a 1-D or 0-D tensor.
00175eb5 euclidean
00175ebf ngram_size_ > 0
00175ecf max_ngram_size_ >= min_ngram_size_
00175ef2 COO m index: 
00175f00 Unsupported convolution size.
00175f1e /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/attention_quant.cc
00175f6b tensor_b_zero_point == nullptr || IsScalarOr1ElementVector(tensor_b_zero_point)
00175fbb void onnxruntime::BroadcastLooper(TBroadcastHelper &, const onnxruntime::ProcessBroadcastSpanFuncs &) [TBroadcastHelper = onnxruntime::contrib::(anonymous namespace)::QLinearBroadcastHelper]
0017607a tensor_x_scale == nullptr || IsScalarOr1ElementVector(tensor_x_scale)
001760c0 input_def_count == kExpected_input_count
001760ed QGemm : scale of input b must be a scalar or 1D tensor of size 1 or N
00176133 Last dimension of gamma and input does not match
00176164 Either one of the separators OR tokenexp attributes required but none is set
001761b1 eos_token_id
001761be num_beams >= 1 && num_beams <= kMaxNumBeams
001761ea ) shall be be no more than num_beams (
00176211 void onnxruntime::contrib::transformers::GreedySearchParameters::ParseFromInputs(onnxruntime::OpKernelContext *)
00176282 void onnxruntime::contrib::transformers::SamplingParameters::ParseFromInputs(onnxruntime::OpKernelContext *)
001762ef subgraph input 0 shall be named as input_ids, got: 
00176323 subgraph output 0 shall be named as logits, got: 
00176355 subgraph input 0 (input_ids) shall have int32 type
00176388 encoder subgraph input 1 (encoder_attention_mask) shall have int32 type
001763d0 . Bytes 
001763d9 CopyTensor
001763e4 utils::HasElemType(thisProto->tensor_type())
00176411 uint16
00176418 InlineNodes
00176424  but the node in the model has the following type (
00176458 args is null.
00176466 /onnxruntime_src/onnxruntime/core/framework/mldata_type_utils.cc
001764a7 Requested attribute: 
001764bd  expected to be of type: 
001764d7 Received OrtValue is not a tensor. Only tensors are supported.
00176516 UnloadLibraries
00176526 p_op_kernel
00176532 entry != kernel_create_info_map.cend()
00176559 specific_subgraph_kernel_create_info_map != subgraphs_kernel_create_info_maps_.end()
001765ae GenerateDeallocationPlan
001765c7 incomplete UTF-8 string; last byte: 0x
001765ee Non-zero status code returned while running 
0017661b onnxruntime::OpKernelContextInternal::OpKernelContextInternal(const onnxruntime::SessionState &, onnxruntime::IExecutionFrame &, const onnxruntime::OpKernel &, const logging::Logger &, const bool &, onnxruntime::Stream *)
001766f9 output_size
00176705 format_data_.size() == 1U
0017671f Invalid index: 
0017672f onnxruntime::TensorShape onnxruntime::TensorShape::Slice(size_t, size_t) const
0017677e Unsupported indices_format passed
001767a0  offset: 
001767aa void onnxruntime::utils::UpdateWithParentStream(onnxruntime::DeviceStreamCollection &, onnxruntime::Stream *)
00176818 weight
0017681f embedding_sum
0017682d Constrain scores input and output types to float tensors.
00176867 src_tokens
00176872 Offset of non-padding tokens, and those of padding tokens. Its shape is (batch_size, sequence_length)
001768d8 Constrain token_offset to integer types
00176900 The normal input data.
00176919 If true, check only for Inf, -Inf.
0017693e 2D matrix with shape (M,N)
00176959 Scaling factor applied to attention values, 1/sqrt(3d). d is hidden size per head = H/N. H is hidden size, N is number of heads.
001769da  expected to have tensor or sparse tensor type: 
00176a0b XShape = Shape (X)
00176a1e NumReducedAxes = Neg (Axis1D)
00176a3c Cell clip threshold. Clipping bounds the elements of a tensor in the range of [-threshold, +threshold] and is applied to the input of activations. No clip if not specified.
00176ae9 Optional initial value of the cell. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.
00176b6b The sequence of the memory (input) for attention mechanism. Should be of `[batch_size, max_memory_step, memory_depth]` 
00176be3 bias shall be 1 dimension
00176bfd Tensor must have at least 3 dimensions to convert between channels first and channels last.
00176c59 Input tensor
00176c66 Bool to determine if hidden state is zeroes or passed along for timesteps past the given sequence_length.
00176cd0 If 0, normalize the mean only.  Default is 1.
00176cfe  should specify a shape
00176d16 N-D full precision Input tensor to be quantized.
00176d47 Constrain 'x', 'y_scale' to float tensors.
00176d72 N-D full precision output tensor. It has same shape as input 'x'.
00176db4 Reduced output tensor.
00176dcb Second operand.
00176ddb Constrain input A, b_scale and output Y data type as float tensor.
00176e1e Input X's scale. It's a scalar, which means a per-tensor/layer quantization.
00176e6b Sequence of (Tensor, Scale, ZeroPoint) tuples. The type is sequence of (T8, TF, T8).
00176ec0 Constrain input and output types to int8 tensors.
00176ef2 cublasLt order of output matrix
00176f12 V_weight
00176f1b scale_output
00176f28 {additionalDocumentation}
00176f42 limit
00176f48 ] op_type [
00176f54 Node::LoadFromOrtFormat, input_arg_counts is missing
00176f89 nullptr != func_meta_def
00176fa2 SPARSE_TENSORS
00176fb1 Attempting to get an input that does not exist.
00176fe1 utils::HasName(attribute)
00176ffb Received invalid value for allow_spinning. Valid values are 0 or 1
0017703e ArmLinuxInit
0017704b SystemError
00177057 GENERAL ERROR
00177065 !current_parallel_section.has_value()
0017708e onnxruntime::(anonymous namespace)::PosixThread::PosixThread(const char *, int, unsigned int (*)(int, Eigen::ThreadPoolInterface *), Eigen::ThreadPoolInterface *, const onnxruntime::ThreadOptions &)
00177155 mmap
0017715a Unrecognized type value case (value_info name: 
0017718a ) first dimension size does not equal NNZ.
001771b5 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/controlflow/defs.cc
00177209 optional(tensor(int32))
00177221 value_float
0017722d One of the attributes 'value' or 'sparse_value' must be specified for a Constant node.
00177284 Constrain input to boolean tensor.
001772a7 loss = Mul (loss_unweighted, weight_gather)
001772d3 Number of input tensors does not match the operands in the equation.
00177318 The predicted outputs with shape [batch_size, class_size], or [batch_size, class_size, D1, D2 , ..., Dk], where K is the number of dimensions.
001773a7 labels
001773ae The size of the original DFT. The size of the original DFT is used to infer the size of the onesided DFT, which is understood to be floor(dft_length/2) + 1, i.e. the spectrogram only contains the nonredundant DFT bins.
00177489 Whether C should be broadcasted
001774a9 This operator has **optional** inputs/outputs. See [the doc](IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.
00177601 This number of op outputs should be 1 when Training_mode = False, but it is not.
00177652 Input tensor must have rank 1 or 2
00177675 NumGroups
0017767f InstanceShape = Shape <start = 2> (X)
001776a5 ScaleT = Cast (scale)
001776bb Padding for the beginning and ending along each axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute.
001778a4 The input 4-dimensional tensor of shape NCHW.
001778d2 The output mask. If is_test is nonzero, this output is not filled.
00177915 If spatial is true, the dimension of the running mean (training) or the estimated mean (testing) is (C). If spatial is false, the dimensions of the running mean (training) or the estimated mean (testing) are (C x D1 x ... x Dn).
001779fa RoI pooled output, 4-D tensor of shape (num_rois, C, output_height, output_width). The r-th batch element Y[r-1] is a pooled feature map corresponding to the r-th RoI X[r-1].
00177aa9 sum square
00177ab9     reduced_sum = ReduceSum<keepdims: int = @keepdims>(data, axes)
00177afc     reduced = Log (reduced_sum)
00177b23 Optional input list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor if 'noop_with_empty_axes' is false, else act as an Identity op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1] where r = rank(data).
00177c36 ' is expected to have field 'graphs'
00177c5b  has unknown expected type
00177c76 Attribute specification type mismatch.
00177c9d Expected 1 or more outputs.
00177cb9  is null. Type info is expected.
00177cda Input 'split' can not be empty.
00177cfa  source=
00177d03 Value type of map input was unknown
00177d27 List of tensors for concatenation
00177d49 1D int64 tensor of the same length as input's dimension number, includes numbers of repeated copies along input's dimensions.
00177dc7 Tensor of shape equal to the broadcasted shape of condition, X, and Y.
00177e0e Input rank for starts and ends should be the same: (
00177e43 'sequence_lens' must have rank of 1
00177e67 CenterCropPad op must have 2 inputs.
00177e8c x_shape2 = Gather (x_shape_alldims2, axes_input)
00177ebd paddings
00177ec6 Number of repeated copies to make of the input tensor.
00177efd The output is a tensor of strings or integers. Its shape will be the same as the input shape.
00177f5b The output will be a tensor of strings or integers.
00177f8f Class labels when using integer labels. One and only one 'classlabels' attribute must be defined.
00177ff1 Weights of the intercepts, if used.
00178015 If true and category is not present, will return all zeros; if false and a category if not found, the operator will fail.
0017808f The node kind, that is, the comparison to make at the node. There is no comparison to make at a leaf node.<br>One of 'BRANCH_LEQ', 'BRANCH_LT', 'BRANCH_GTE', 'BRANCH_GT', 'BRANCH_EQ', 'BRANCH_NEQ', 'LEAF'
0017815c The input values
0017816d Input's shape should be 1D or 2D
0017818e key type mismatch from MapProto. existing=
001781b9 onnx.TensorProto.Segment
001781d2 /build/intermediates/arm64-v8a/Release/_deps/protobuf-src/src/google/protobuf/io/zero_copy_stream_impl.cc
00178242 [:^cntrl:]
0017824d NULL state in RunStateOnByte
0017826a SimplifyWalker::ShortVisit called
0017828c Grantha
00178294 Lisu
0017829c Old_North_Arabian
001782ae Old_Permic
001782b9 Pahawh_Hmong
001782cc attempt to nsync_mu_unlock() an nsync_mu held in read mode
00178308 Broadcom
00178311 NovaThor
0017831a Exynos 
00178326 0123456789
00178331 numpunct_byname<char>::numpunct_byname failed to construct for 
00178371 typeinfo for 
0017837f reference temporary for 
00178398 unsigned char
001783a6 operator&=
001783b1 operator*=
001783bc std::basic_string<char, std::char_traits<char>, std::allocator<char> >
00178403 __cxa_guard_abort
00178415 getSavedFloatRegister
0017842f FillSparseTensorBlockSparse
0017844b buffer size is too small for string element
00178477 Trying to get a SparseTensor, but got: 
0017849f OrtStatus *OrtCreateMapMLValue(const onnxruntime::Tensor &, const onnxruntime::Tensor &, OrtValue **) [KeyType = std::basic_string<char>, ValueType = std::basic_string<char>]
0017854e const T *onnxruntime::Tensor::Data() const [T = std::basic_string<char>]
00178597 OrtStatus *OrtCreateValueImplMapHelper(const onnxruntime::Tensor &, const onnxruntime::Tensor &, OrtValue **) [KeyType = long]
00178616 Sequences must have tensors of the same data type. There was at least one tensor in the input that was different.
00178688 void onnxruntime::TensorSeq::Add(const OrtValue &)
001786bb TensorSeq: tensor to be added has a different data type.
001786f8 ) has saved runtime optimizations. They will be ignored.
00178731 NchwcTransformer
00178742  Got: 
00178749  for the following indices
00178765 ShrinkMemoryArenas
00178778 The environment variable contained the value: 
001787a7  MemoryType:
001787ba  failed. Only 
001787c9 execution_mode
001787d8 Ignoring unsupported session option in ORT config: 
0017880c Parallel mode
0017881a syntax error 
00178828 ; last read: '
00178837 SynchronizeInputs
0017884f T *onnxruntime::Tensor::MutableData() [T = bool]
00178880 void onnxruntime::TensorSeq::Add(onnxruntime::Tensor &&)
001788b9 ] is lower than minimal supported NNAPI API feature level [
001788f8 /onnxruntime_src/onnxruntime/core/common/string_utils.h
00178930 ] index: [
0017893b We do not support dynamic output shape or empty output for now
0017897a TENSOR_FLOAT16
00178989 ANeuralNetworksExecution_setInputFromMemory
001789b5 ANeuralNetworksExecution_startCompute
001789db SL_ANeuralNetworksDiagnosticExecutionInfo_isCachingEnabled
00178a16 ANEURALNETWORKS_OP_FAILED
00178a30 Concat
00178a37 begin_idx <= end_idx && begin_idx <= shape.size()
00178a69 Scale of BN must be known
00178a83 Relu
00178a88 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/nnapi_lib/NeuralNetworksWrapper.cc
00178aeb Invalid shape is given!
00178b03 Unsupported element data type: 
00178b23 Reshape/Flatten can not be skipped when the output is a graph output
00178b68  scale dimension 
00178b7a /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/op_builder_helpers.h
00178bd8 ] Input type: [
00178be8 Clip only supports [min, max] = [0, 6] or [-1, 1], the input is [
00178c2a NCHW layout is not supported for android feature level: 
00178c63  only support up to 4d shape, input1 is 
00178c8c QLinearReduceMean
00178c9e xnn_reallocate is not implemented
00178cc0 output_shape
00178ccd void onnxruntime::ConvTransposeAttributes::ComputePadsAndOutputShape(onnxruntime::TensorShape, int64_t, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShapeVector &, const int64_t, onnxruntime::ConvAttributes::ConvPadVector *, onnxruntime::TensorShapeVector *) const
00178e3a onnxruntime::xnnpack::MaxPool::MaxPool(const onnxruntime::OpKernelInfo &)
00178e84 Shape mismatch between inferred value and calculated value.
00178ec0 unsupported Conv in maxpool, we have FLOAT|UINT8, but got 
00178efb /onnxruntime_src/onnxruntime/core/providers/xnnpack/nn/resize.cc
00178f3c when anti-aliasing is set, Resize only supports mode `LINEAR` and `CUBIC`.
00178f87 Two inputs should have same rank and rank >= 3 if transBatchA or transBatchB is true
00178fdc EliminateSlice
00178feb Could not find a CPU kernel and hence 
00179012 Start MatchGemmSubgraph
0017902a Squeeze
00179032 mask_unsqueeze_2 axes not matched. Expect: 2
0017905f past_k_transpose perm attribute not matched
0017908b Range
00179091 mask_index
0017909c Unsqueeze_
001790a7 gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = double]
001790ea std::vector<ScaleMergeInfo> onnxruntime::(anonymous namespace)::GetOutputNodeMerges(onnxruntime::Graph &, onnxruntime::Node &, const InlinedHashSet<std::string> &)
0017918e Fuse_Subgraph
0017919c bool onnxruntime::TransformerMemcpyImpl::ProcessInitializers(const onnxruntime::KernelRegistryManager &, const onnxruntime::InitializedTensorSet &)
00179230 UnsqueezeElimination_
00179246 UnsqueezeElimination cannot remove node 
0017926f Node support test is required.
0017928e virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Relu<signed char>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Relu<signed char>]
00179359 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Softplus<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Softplus<float>]
00179420 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Tanh<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Tanh<float>]
001794df SetupSubgraphExecutionInfo should only be called once for each subgraph.
00179528 Subgraph SessionState was not found for 'body' attribute.
00179562  but 
00179568 IterateSequence
00179578 virtual common::Status onnxruntime::If::SetupSubgraphExecutionInfo(const onnxruntime::SessionState &, const std::string &, const onnxruntime::SessionState &)
00179616 Failed to create output tensor for 
0017963a info.GetAttr<float>("low", &low_).IsOK()
00179663 extents.size()=
00179673 Data types of the inputs must match for MatMul
001796a2 std::unique_ptr<Tensor> onnxruntime::EinsumOp::MatMul(const onnxruntime::Tensor &, const gsl::span<const int64_t> &, const onnxruntime::Tensor &, const gsl::span<const int64_t> &, onnxruntime::AllocatorPtr, concurrency::ThreadPool *, void *, const DeviceHelpers::MatMul<T> &) [T = int]
001797c0 Ellipsis must indicate a fixed number of dimensions across all inputs
00179806 Einsum op: The candidate output cannot be reshaped into the op's output
0017984e output count mismatch, expected 2 outputs to be present for TopK operator
00179898 ) >=
0017989d Input of int64 must have output of string 
001798c8 onnxruntime::ml::DictVectorizerOp<std::basic_string<char>, long>::DictVectorizerOp(const onnxruntime::OpKernelInfo &) [AttrType = std::basic_string<char>, TargetType = long]
00179976 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/imputer.cc
001799b4 post_transform
001799c3 Scaler
001799ca support_vectors
001799da target_weights_as_tensor
001799f3 nodes_missing_value_tracks_true
00179a13 target_treeids
00179a22 target_weights
00179a31 target_class_ids.size() == target_class_nodeids.size()
00179a68 this->base_values_.size() == predictions.size()
00179a98 predictions.size() == (size_t)n_targets_or_classes_
00179acc onnxruntime::ml::TreeEnsembleClassifier<int>::TreeEnsembleClassifier(const onnxruntime::OpKernelInfo &) [T = int]
00179b3e void onnxruntime::ml::detail::TreeAggregatorClassifier<int, float, float>::FinalizeScores(InlinedVector<ScoreValue<ThresholdType>> &, OutputType *, int, int64_t *) const [InputType = int, ThresholdType = float, OutputType = float]
00179c25 Attribute '
00179c31 n_elements > 0
00179c40 TreeEnsembleRegressor
00179c56 0.0f <= ratio_value && ratio_value < 1.0f
00179c80 The rank of input tensor must be >= axis
00179ca9 op_kernel_info.GetAttr<int64_t>("p", &p_).IsOK()
00179cda /onnxruntime_src/onnxruntime/core/providers/cpu/nn/lrn.h
00179d13 Conversion Error
00179d24 case_change_action
00179d37  specified. It should be either avg or max
00179d62 sampling_ratio_ >= 0
00179d77 IsScalarOr1ElementVector(Y_scale)
00179d99 static void onnxruntime::QLinearConv<signed char>::ComputeOffset(onnxruntime::OpKernelContext *, int64_t, ActType &, ActType &, uint8_t &) [ActType = signed char]
00179e3c Quantized GEMM only support alpha equal to 1.0f and beta equal to 0.0f or 1.0f
00179e8b split_scalar > 0
00179e9c GatherElements op: Out of range value in index tensor
00179ed2 grid_dims[0] == N
00179ee4 virtual onnxruntime::common::Status onnxruntime::NonZero<long>::Compute(onnxruntime::OpKernelContext *) const [T = long]
00179f5d . batch_size=
00179f6b none
00179f70 CPU execution provider: BFloat16 data type is not supported with ScatterElements opset 16 when reduction is 'add'.
00179fe3 Invalid axes attribute, axes attribute (if present) should have the same size as starts/ends attributes
0017a04b onnxruntime::TransposeBase::TransposeBase(const onnxruntime::OpKernelInfo &)
0017a098 : 'Linear' mode only support 2-D inputs or 3-D inputs ('Bilinear', 'Trilinear') or 4-D inputs or 5-D inputs with the corresponding outermost 2 scale values being 1.
0017a13d Input 'relative_position_bias' dimension 0 should be same as batch_size, got 
0017a18b epsilon_ >= 0
0017a199 , am_attn_size}, Got:
0017a1af virtual onnxruntime::common::Status onnxruntime::contrib::NGramRepeatBlock::Compute(onnxruntime::OpKernelContext *) const
0017a229 Attribute border needs to be specified with four border elements, got 
0017a270 onnxruntime::contrib::FusedConvFloat::FusedConvFloat(const onnxruntime::OpKernelInfo &)
0017a2c8 channels_ > 0
0017a2d6 onnxruntime::contrib::NchwcPoolBase::NchwcPoolBase(const onnxruntime::OpKernelInfo &)
0017a32c MatMulIntegerToFloat : input a zero point must be a scalar or 1D tensor of size 1. Per-Channel is not supported yet.
0017a3a1 Position embedding scale must be a scalar or 1D tensor of size 1
0017a3e2 Gamma zero point must be a scalar or 1D tensor of size 1
0017a41b Input scale is not float for quantized input @
0017a44a Wrong input type encountered for zero point of quantized input @
0017a48b There must be 
0017a49a skip is expected to have same shape as input
0017a4c7 init_decoder
0017a4d4 encoder_feeds_fetches_manager_
0017a4f3 Input 'presence_mask' shape[1] shall be vocab_size, got 
0017a52c context != nullptr
0017a53f sequences != nullptr
0017a554 virtual onnxruntime::common::Status onnxruntime::contrib::transformers::GreedySearch::Compute(onnxruntime::OpKernelContext *) const
0017a5d8 embedding_size
0017a5e7  device:
0017a5f0  (requested) num_bytes: 
0017a609  (actual) rounded_bytes:
0017a622 0 == memory_size % kMinAllocationSize
0017a648 TotalAllocated:           
0017a663 bool onnxruntime::data_types_internal::IsCompatible(const onnx::TypeProto_Map &, const onnx::TypeProto_Map &)
0017a6d1 Caught exception while loading custom ops with message: 
0017a70a ort_value_idx >= 0 && static_cast<size_t>(ort_value_idx) < alloc_plan.size()
0017a757 MapNamesToMLValueIdxs
0017a76d GetCapabilityForEP
0017a780  kernel_end_version: 
0017a796 kernel def can't be NULL
0017a7af Expecting same size spans
0017a7c9 iter != node_stream_map.end()
0017a7e7 streams
0017a7ef node_names_by_stream_.size() == device_types_.size()
0017a824 id >= 0 && static_cast<size_t>(id) < ort_value_info_.size()
0017a860  activate notification with index 
0017a883 input_type_shape
0017a894 static onnxruntime::SparseTensor &onnxruntime::SparseTensor::GetSparseTensorFromOrtValue(OrtValue &)
0017a8f9 Format() == SparseFormat::kBlockSparse
0017a920 Copy
0017a925 Outer indices must be M + 1. Got: 
0017a948 tensor size overflow
0017a95d SparseTensorProtoToDenseTensorProto
0017a981 Sparse indices int64 data size does not match expected
0017a9b8 CalculateStaticCopyInfoForFeed
0017a9d7 Unsupported OrtValue type.
0017a9f2 weights
0017a9fe LongformerAttention
0017aa12 If static_kv = true, cross-attention; else self-attention
0017aa4c 2D with shape (, hidden_size)
0017aa6a 2D position ids with shape (batch_size, sequence_length) or (1, sequence_length)
0017aabb is_bidirectional
0017aacc 2D input tensor with shape (num_buckets, num_heads), COL-major(See UT for example)
0017ab1f RelativePositionBias
0017ab34 eco_a
0017ab3a GatedRelativePositionBias
0017ab54 The bias input, a vector with the same shape as last dim of data OR same shape with data
0017abad Constrain input 'training_mode' types to boolean tensors.
0017abe7 Grid
0017abec The maximum length of the sequence to be generated. Shape is (1)
0017ac2d The parameter for repetition penalty. Default value 1.0 means no penalty. Accepts value > 0.0. Shape is (1)
0017ac99 Model type: 0 for decoder only like GPT-2; 1 for encoder decoder like Bart
0017ace6 tokenexp
0017acef Matrix multiply results from A * B
0017ad12 Tensor of rank q >= 1.
0017ad29 Integer representing the embedding vector size for each word.If not provide, use the filter size of conv weight
0017ad99 Specify bias of conv
0017adae The distance metric to use. If a string, the distance function can be "braycurtis", "canberra", "chebyshev", "cityblock", "correlation", "cosine", "dice", "euclidean", "hamming", "jaccard", "jensenshannon", "kulsinski", "mahalanobis", "matching", "minkowski", "rogerstanimoto", "russellrao", "seuclidean", "sokalmichener", "sokalsneath", "sqeuclidean", "wminkowski", "yule".
0017af25 Constrain types to float tensors.
0017af47 box_coding
0017af52 feature_map_2
0017af60 p2c_attention
0017af6e Snpe
0017af77 Biased = Identity (Scaled)
0017af92 1D beta tensor for normalization  with shape (C), where C is number of channels
0017afe2 The output tensor with dimensions (N, S, D/2)
0017b010 invalid scales dimension
0017b029 seq_lengths
0017b035 ) + scale[1] (
0017b044 Constrain 'x' and 'x_zero_point' to 8-bit integer tensors.
0017b07f N-D full precision input tensor to be quantized.
0017b0b0 C = ((A - A_zero_point) * (B - B_zero_point)) * (A_scale * B_scale)/C_scale + C_zero_point
0017b10b opset version of corresponding SoftMax.
0017b133 Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. 
0017b19f The weight tensor for the gates. Concatenation of `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The tensor has shape `[num_directions, input_size, 4*hidden_size]`.
0017b254 The recurrence weight tensor. Concatenation of `R[iofc]` and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, hidden_size, 4*hidden_size]`.
0017b308 W's zero point. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
0017b3b0 R's zero point. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
0017b458 position_embedding_quant
0017b471 word_embedding_scale
0017b486 mask_index_out
0017b495 scale_K_gemm
0017b4a2 2D input tensor with shape (input_hidden_size, hidden_size), where hidden_size = num_heads * head_size
0017b509 QOrderedLayerNormalization
0017b524 C_scale
0017b52c beta should have 1 dimension, dimension size known, and same hidden size as word_embedding.
0017b588 Tensor element type mismatch. 
0017b5a7 Invalid node indexes specified when adding edge.
0017b5d8 void onnxruntime::Graph::RemoveEdge(onnxruntime::NodeIndex, onnxruntime::NodeIndex, int, int)
0017b636 void onnxruntime::Graph::KahnsTopologicalSort(const std::function<void (const Node *)> &, const std::function<bool (const Node *, const Node *)> &) const
0017b6d0 Subgraph input missing type.
0017b6ed Type Error: Type parameter (
0017b70a existing->second == &tensor
0017b726 ReplaceInitializedTensorImpl
0017b743 CleanUnusedInitializersAndNodeArgs
0017b766 outer_scope_node_arg != nullptr
0017b786 Node has no function body and cannot be inlined.
0017b7b7 all_tensor_types_with_bfloat
0017b7d4 actuals.size() <= formals.size()
0017b7f5 void onnxruntime::graph_utils::ReplaceNodeInput(onnxruntime::Node &, int, onnxruntime::NodeArg &)
0017b857 than the operator set version 
0017b876 onnxruntime::common::Status::Status(onnxruntime::common::StatusCategory, int, const char *)
0017b8d2 Profiler not started yet
0017b8eb ], "core": 
0017b8f7 Nested parallelism not supported
0017b918 length > buffer.size()
0017b92f close
0017b935  with error: 
0017b943 LoadOpsetImportOrtFormat
0017b95c value_info
0017b967 double_data
0017b973 optional(seq(tensor(bool)))
0017b98f Loop 'body' subgraph outputs should all be tensors or sequences but output 
0017b9db /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/generator/defs.cc
0017ba2d Number of times to sample.
0017ba48 Output tensor with shape [batch_size, sample_size], where sample_size is the number of times to sample. Each value along the axis zero represents the outcome of the corresponding sample in a batch.
0017bb0e First operand, input to be shifted.
0017bb32 Remainder tensor
0017bb44           {
0017bb50             Zero = Constant <value = float {0.0}>()
0017bb84             ZeroCast = CastLike (Zero, X)
0017bbae             Y = Max (X, ZeroCast)
0017bbd0           }
0017bbdc         
0017bbe5 The hyperbolic arcsine values of the input tensor computed element-wise
0017bc2d scale of quantized output y
0017bc4a             loss_sum = ReduceSum <keepdims = 0> (loss_Ndd)
0017bc85             weight_gather_sum = ReduceSum <keepdims = 0> (weight_gather)
0017bcce             loss = Div (loss_sum, weight_gather_sum)
0017bd03           
0017bd0e Rank of input 
0017bd1d  does not match the equation indices.
0017bd43 Output tensor.
0017bd52 List of tensors for Max.
0017bd6b Describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size
0017bdea Attribute dilations has incorrect size
0017be11 Indices tensor from max pooling across the input tensor. The dimensions of indices are the same as output tensor. The values in indices of are the indices of the selected values during pooling. The indices are computed as flatten 1-D tensor, and the indices do not consider padding. So the values in indices are in [0, N x C x D1 x ... x Dn).
0017bf68 Constrain input w and its zero point data type to 8-bit integer tensor.
0017bfb0 Constrain output y data type to 32-bit integer tensor.
0017bfe7 1-dimensional tensor with dilation value along each spatial axis of the image. If not present, the dilation defaults to 1 along each spatial axis of the image.
0017c087 p value of the Lp norm used to pool over the input data, default is 2.0.
0017c0d0 Unexpected literal type.
0017c0e9 Quantized output tensor
0017c101  not in range [min=
0017c115 )'s input 
0017c120 ' is expected to have field 'sparse_tensor'
0017c14c ' is expected to have field 'ints'
0017c16f Error parsing function body:
0017c18c Output tensor at the specified position in the input sequence.
0017c1cb Constrain output types. Casting to complex is not supported.
0017c208 The (first) input tensor will be cast to produce a tensor of the same type as this (second input) tensor.
0017c272 A list of integers. By default, reverse the dimensions, otherwise permute the axes according to the values given.
0017c2e4 values selected at indices where condition is True
0017c317 output_data
0017c323 Output data.
0017c330 output = Cast (input)
0017c346  does not match type of output: 
0017c367 Last dimension of `indices` input tensor in GatherND op must not be larger than the rank of `data` tensor
0017c3d1 Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * input_rank]. `pads` format should be: [x1_begin, x2_begin,...,x1_end, x2_end,...], where xi_begin is the number of pad values added at the beginning of axis `i` and xi_end, the number of pad values added at the end of axis `i`.
0017c594 Data size mismatch. Tensor: 
0017c5b1 Data to be encoded, a tensor of shape [N,C] or [C]
0017c5e4 Thresholds to do the splitting on for each node.
0017c615 Data for input  
0017c626 CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - SerialArena::kBlockHeaderSize): 
0017c68a AddFoldedRange recurses too much.
0017c6b0 [:^upper:]
0017c6bb invalid perl operator
0017c6d1 Chakma
0017c6dc Latin
0017c6e2 Manichaean
0017c6ed Tagbanwa
0017c6f6 Tai_Viet
0017c702 Telechips
0017c70f /sys/devices/system/cpu/kernel_max
0017c732 Unknown error %d
0017c74d operator delete[]
0017c75f std::string
0017c775 /onnxruntime_src/onnxruntime/core/framework/TensorSeq.h
0017c7ad graph_transformation_mgr_.SetSteps(session_options_.max_num_graph_transformation_steps).IsOK()
0017c80e !to.affinity_str.empty()
0017c827 CPUExecutionProvider
0017c83c Invalid rank for input: 
0017c855 GetModelMetadata
0017c866  combination in the memory arena shrink list: 
0017c895 Provider 
0017c89f /onnxruntime_src/onnxruntime/core/session/inference_session.h
0017c8dd session.strict_shape_type_inference
0017c901 %Y-%m-%d_%H-%M-%S
0017c913 SetInterOpNumThreads
0017c928 Unsupported value for enable_profiling option: 
0017c958 false
0017c95e invalid comment; expecting '/' or '*' after '/'
0017c98e invalid string: control character U+000C (FF) must be escaped to \u000C or \f
0017c9dc '[', '{', or a literal
0017c9f3 i == output_count - 1
0017ca09 Only the last output to a custom op may be marked variadic.
0017ca45 tensor(double)
0017ca54 /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc
0017ca95 Unknown type
0017caa2 ANeuralNetworksEvent_wait
0017cabc ANeuralNetworks_getDevice
0017cad6 ANeuralNetworksDevice_getExtensionSupport
0017cb00 ANeuralNetworks_getRuntimeFeatureLevel
0017cb2a BatchNormalization
0017cb3d BN only support up to 4d shape, input is 
0017cb67 th device's name
0017cb78  output nodes
0017cb86 The initializer is not 4D: 
0017cba2 Reshape only supports up to 1-4d shape, input is 
0017cbd4 nearest
0017cbdc Resize does not support exclude_outside for now
0017cc0c Resize bilinear, unsupported coord_trans_mode, 
0017cc3c Only conv 2d is supported.
0017cc57 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/gemm_op_builder.cc
0017ccb8 Floor
0017ccc2 (int64_t(ptr) & (alignment - 1)) == 0
0017cce8 auto_pad == AutoPadType::NOTSET
0017cd08  W: 
0017cd0d convolution2d
0017cd1b  with 
0017cd22  and anti-aliasing is set to 
0017cd40 optimization.enable_gelu_approximation
0017cd67 onnxruntime::Node *onnxruntime::Graph::NodeAtIndexImpl(onnxruntime::NodeIndex) const
0017cdbc !sum_input_moved
0017cdcd /onnxruntime_src/onnxruntime/core/optimizer/conv_add_fusion.cc
0017ce0c gather input 1 value is not expected
0017ce31 k root is not layer norm
0017ce4a std::vector<ScaleMergeInfo> onnxruntime::(anonymous namespace)::GetInputNodeMerges(onnxruntime::Graph &, onnxruntime::Node &, const InlinedHashSet<std::string> &)
0017ceed onnxruntime::Node *onnxruntime::ReorderCastAndTranspose(onnxruntime::Graph &, onnxruntime::Node *, InlinedHashMap<onnxruntime::NodeArg *, size_t> &, std::deque<onnxruntime::NodeIndex> &, bool &, bool &)
0017cfb8 void onnxruntime::NchwcTransformerImpl::TransformConv(onnxruntime::Node &)
0017d003 onnxruntime::common::Status onnxruntime::(anonymous namespace)::InsertQDQPair(onnxruntime::Graph &, const onnxruntime::graph_utils::ExtendedGraphEdge &, onnxruntime::NodeArg &, onnxruntime::NodeArg *, const logging::Logger &)
0017d0e5 /onnxruntime_src/onnxruntime/core/optimizer/relu_clip_fusion.cc
0017d125 /onnxruntime_src/onnxruntime/core/optimizer/reshape_fusion.cc
0017d163 ApplyRulesOnNode
0017d174 target_node != NodesToOptimizeIndices::kEmptyNodeIndex
0017d1ab ) does not match produced node op in runtime optimization record (
0017d1ee Execution type '
0017d1ff new_num_elts == old_num_elts
0017d21c const_transpose_optimizer
0017d236 opset_import_iter != domain_to_version_map.end()
0017d267 /onnxruntime_src/onnxruntime/core/optimizer/transpose_optimizer/ort_transpose_optimizer.cc
0017d2c2 Ceil
0017d2c7 ReduceLogSum
0017d2d4 com.microsoft.QLinearConcat
0017d2f0 TvmExecutionProvider
0017d305 ElementWiseKernel
0017d317 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::HardSigmoid<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::HardSigmoid<float>]
0017d3e4 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Softsign<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Softsign<float>]
0017d4ab  outputs but Scan expects 
0017d4c6  outputs which doesn't match the subgraph's 
0017d4f3 void onnxruntime::If::Init(const onnxruntime::OpKernelInfo &)
0017d531 Failed to create output tensor for If output 
0017d55f onnxruntime::Loop::Info::Info(const onnxruntime::Node &, const onnxruntime::GraphViewer &)
0017d5ba ONNX_NAMESPACE::TensorProto::DataType_IsValid(t_proto.data_type())
0017d5fd /onnxruntime_src/onnxruntime/core/providers/cpu/math/clip.h
0017d639 CumSum
0017d640 DeviceCompute
0017d64e Einsum subscripts string contains too many subscript labels when compared to the rank of the input 
0017d6b2 num_broadcasted_indices < num_of_ellipsis_dims_
0017d6e2 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Log<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Log<float>]
0017d79f onnxruntime::Broadcaster::Broadcaster(gsl::span<const int64_t>, gsl::span<const int64_t>)
0017d7f9 helper.HaveTwoTensorInputs()
0017d816 left.NumDimensions() == 2 || left.NumDimensions() == 1
0017d84d Binarizer
0017d857  is NaN
0017d85f Unexpected CAST_TO value of 
0017d87c onnxruntime::ml::DictVectorizerOp<long, float>::DictVectorizerOp(const onnxruntime::OpKernelInfo &) [AttrType = long, TargetType = float]
0017d906  and the number of 
0017d91a Input shape had more than 2 dimension. Dims=
0017d947 onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommon<float, float, float>::Init(int, int, int, const std::string &, const std::vector<float> &, const std::vector<ThresholdType> &, int64_t, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<float> &, const std::vector<ThresholdType> &, const std::vector<int64_t> &, const std::vector<std::string> &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<float> &, const std::vector<ThresholdType> &, const std::string &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<float> &, const std::vector<ThresholdType> &) [InputType = float, ThresholdType = float, OutputType = float]
0017dc5b target_class_ids.size() == target_class_treeids.size()
0017dc92 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/tree_ensemble_aggregator.h
0017dce0 classes.size() == 2 || classes.size() == 1
0017dd0b onnxruntime::ml::TreeEnsembleClassifier<double>::TreeEnsembleClassifier(const onnxruntime::OpKernelInfo &) [T = double]
0017dd83 virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommon<long, float, float>::compute(onnxruntime::OpKernelContext *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *) const [InputType = long, ThresholdType = float, OutputType = float]
0017de9f ' must be a vector.
0017deb3 is_spatial_
0017debf float onnxruntime::(anonymous namespace)::GetRatioOrDefault(const onnxruntime::Tensor *) [T2 = double]
0017df26 virtual onnxruntime::common::Status onnxruntime::Dropout<double, float>::Compute(onnxruntime::OpKernelContext *) const [T1 = double, T2 = float]
0017dfb7 virtual onnxruntime::common::Status onnxruntime::Dropout<double, double>::Compute(onnxruntime::OpKernelContext *) const [T1 = double, T2 = double]
0017e04a /onnxruntime_src/onnxruntime/core/providers/cpu/nn/instance_norm.cc
0017e08e info.GetAttr<float>("spatial_scale", &spatial_scale_).IsOK()
0017e0cb onnxruntime::Shrink::Shrink(const onnxruntime::OpKernelInfo &)
0017e10a Duplicate stopwords not allowed
0017e12a :Please, install necessary language-pack-XX and configure locales
0017e16c min_gram_length >= max_gram_length required: 
0017e19a pool_strings must not be empty if specified
0017e1c6 QLinearMatmul : result zero point must be a scalar or 1D tensor of size 1
0017e210 void onnxruntime::ResultsNoTransposePrepareForReduce::ValidateNotEmpty()
0017e259 sigmoid
0017e261 affine
0017e268 onnxruntime::common::Status onnxruntime::CreateMelWeightMatrix<short>::operator()(onnxruntime::OpKernelContext *, int64_t, int64_t, int64_t, float, float) [T = short]
0017e30f Attribute to is not set.
0017e328 onnxruntime::common::Status onnxruntime::ConcatBase::PrepareForCompute(onnxruntime::OpKernelContext *, const onnxruntime::ConcatBase::InlinedTensorsVector &, onnxruntime::Prepare &) const
0017e3e4 virtual onnxruntime::common::Status onnxruntime::Pad::Compute(onnxruntime::OpKernelContext *) const
0017e448 axes_tensor_dims.size() == 1
0017e465 The input tensor cannot be reshaped to the requested shape. Input shape:
0017e4ae time_axis
0017e4b8 gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = short]
0017e4ff CPU execution provider: string data type is not supported with ScatterElements opset 18 when reduction is 'min'.
0017e570 CPU execution provider: BFloat16 data type is not supported with ScatterND opset 18 when reduction is 'max'.
0017e5dd Size
0017e5e2  Sum of sizes in 'split' (must equal size of selected axis) was 
0017e623 Inputs 'mask_index' with 1D data shall have length of batch_size or 2 * batch_size
0017e676 Inputs 'mask_index' with 2D data shall have shape batch_size x total_sequence_length
0017e6cb /onnxruntime_src/onnxruntime/contrib_ops/cpu/bert/attention_base.cc
0017e70f ConvTransposeWithDynamicPads
0017e72c info.GetAttr("scale", &scale_).IsOK()
0017e752 activation_params count mismatch
0017e773 Expecting 2xValues == indices
0017e791 onnxruntime::contrib::ReorderOutput::ReorderOutput(const onnxruntime::OpKernelInfo &)
0017e7e7 pool_attrs_.kernel_shape.size() == 2
0017e80c W_zero_point
0017e819 virtual onnxruntime::common::Status onnxruntime::contrib::NhwcMaxPool<signed char>::Compute(onnxruntime::OpKernelContext *) const [T8Bits = signed char]
0017e8b2 Word embedding zero point must be a scalar or 1D tensor of size 1
0017e8f4 /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/qlinear_lookup_table.cc
0017e946 onnxruntime::common::Status onnxruntime::contrib::QLinearAveragePool::ComputeImpl(onnxruntime::OpKernelContext *) const [T8Bits = signed char]
0017e9d5 mincharnum
0017e9e0 'num_return_sequences' has to be smaller or equal to 'num_beams'.
0017ea22 next_beam_scores_.empty()
0017ea3c beam_hyp.Size() >= gsl::narrow_cast<int>(num_beams_)
0017ea71 Batch can only be done if all beams have been generated
0017eaa9 Sampling
0017eab2 temperature
0017eabe subgraph past state dimension 2 shall have a positive value for number of heads
0017eb0e subgraph past state dimension 2 shall have a positive value for vocabulary size
0017eb5e past_0
0017eb65 /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/subgraph_t5_decoder.cc
0017ebb6 encoder subgraph output 2 shall be named as present_key_self_0, got: 
0017ebfc /onnxruntime_src/onnxruntime/contrib_ops/cpu/word_conv_embedding.cc
0017ec40 char_embedding_size
0017ec54 /onnxruntime_src/onnxruntime/core/framework/allocator.cc
0017ec8d Duplicate allocator for OrtMemType:
0017ecb1  arena_extend_strategy: 
0017ecca Failed to allocate memory for requested buffer of size 
0017ed02 Bin size: Chunks in_use/total (if not zero). Allocated bytes in_use/total. Requested bytes.
0017ed5e CopySparseTensors
0017ed70 virtual bool onnxruntime::SparseTensorTypeBase::IsCompatible(const onnx::TypeProto &) const
0017edcc GetElementType
0017eddb  entries which doesn't match the number of fetches the frame was initialized with of 
0017ee31 Allocation of tensor types requires a shape.
0017ee5e  does not match actual shape of 
0017ee7f offset >= 0 && static_cast<size_t>(offset) < node_values_size_
0017eebe ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < all_values_size_
0017ef0e ORT optimization- Force fallback to CPU execution for node: 
0017ef4b Kernel not found
0017ef5c Received nullptr for name
0017ef76 "bytes": [
0017ef81 {"bytes":[
0017ef8c Number of streams: 
0017efa3 OrtValue indexes should have been populated.
0017efd0 Src and Dst must be of the same type
0017eff5 DenseTensorToSparseCoo
0017f00c External data type cannot be UNDEFINED or STRING.
0017f03e past
0017f043 key_padding_mask
0017f054 Global attention flags with shape (batch_size, sequence_length)
0017f094 input tensor with shape (batch_size, num_heads, sequence_length or total_sequence_length, head_size)
0017f0f9 1D mask_index tensor with shape (batch_size)
0017f126 1D bias tensor with shape (hidden_size
0017f14f query_layer
0017f15d Mask of vocabulary for first step. Words that masked with 0 are not allowed to be generated, and 1 is allowed. Shape is (batch_size, vocab_size)
0017f1ee Output tensor of shape (M, N).
0017f20d Value used for extrapolation, when applicable. Default is 0.0f. 
0017f24e The boxes input tensor.
0017f266 feature_map_1
0017f274 pooled_size
0017f280 InvStdDev = Reshape (InvStdDev2D, ReducedShape)
0017f2b0 Number of neurons in the hidden layer.
0017f2d7 initial_h
0017f2e1 input and zero_point pair is expected to have be same type.
0017f31d number of groups input channels and output channels are divided into.
0017f363 Bias applied to each channel, same size as C.
0017f391 The scaled hyperbolic tangent values of the input tensor computed element-wise
0017f3e0 Negative values are not allowed in a shape specification
0017f419 'Scale' must contain exactly 2 values - (height, width)
0017f451 QuantizeBFP
0017f45d Constrain input type to 8-bit integer tensor.
0017f48b Constrain output to 32 bit tensor
0017f4ad Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). Its type is int32_t and must be quantized with zero_point = 0 and scale = alpha / beta * a_scale * b_scale.
0017f5b4 K_bias
0017f5bb scale of the gemm - scalar (per-tensor quantization). Also this is the output scale for the operator.
0017f621 quantization scale must be float tensors.
0017f64b Constrain bias type to 32-bit integer tensor.
0017f679 1-D Tensor of the range.
0017f692 input_ids shall be 2 dimensions
0017f6b2 gamma should have 2 dimension, dimension size known, and same hidden size as word_embedding.
0017f70f UpdateTypeAndShape
0017f722 void onnxruntime::Graph::CleanUnusedInitializersAndNodeArgs(const std::unordered_set<std::string> *)
0017f787 This is an invalid model. In Node, 
0017f7ab No opset registered for domain 
0017f7cb  in function opset imports.
0017f7e7 GRAPHS
0017f7ee Attempting to get index by a name which does not exist:
0017f826  in one of the subgraphs.
0017f840 Mismatch between Graph and IndexedSubGraph. Output not found:
0017f87e <p_fd> less than 0.
0017f892 , but it its version is higher
0017f8b1 void onnxruntime::math::Gemv(CBLAS_TRANSPOSE, int, int, float, const T *, const T *, float, T *, Provider *) [T = double, Provider = onnxruntime::CPUMathUtil]
0017f950 /onnxruntime_src/onnxruntime/core/util/thread_utils.cc
0017f987 onnxruntime
0017f993 INVALID_PROTOBUF
0017f9a4 "core": 
0017f9ad realpath
0017f9b6 LoadValueInfoOrtFormat
0017f9cd raw_data
0017f9d6  but subgraphs produce 
0017f9ee optional(seq(tensor(float)))
0017fa0b Attribute 'value_string' expect a string.
0017fa35 Constrain input/output to boolean tensors.
0017fa60 output_large_than_max = Less (max, tmp)
0017fa88 The tangent of the input tensor computed element-wise
0017fabe Constrain input a and its zero point data type to 8-bit integer tensor.
0017fb06 weight_gather_temp = Gather (weight, transform_targets)
0017fb3e Constrain input and output types to all numerical tensor types.
0017fb7e The Mel Weight Matrix. The output has the shape: [floor(dft_length/2) + 1][num_mel_bins].
0017fbd8 The Short-time Fourier Transform of the signals.If onesided is 1, the output has the shape: [batch_size][frames][dft_unique_bins][2], where dft_unique_bins is frame_length // 2 + 1 (the unique components of the DFT) If onesided is 0, the output has the shape: [batch_size][frames][frame_length][2], where frame_length is the length of the DFT.
0017fd30 Input data tensor containing the indices corresponding to elements in the first input tensor X.This tensor is typically the second output of the MaxPool op.Dimensions must be the same as input tensor X. The indices are linear, i.e. computed considering the tensor as flattened 1-D tensor, assuming row-major storage. Also, the linear indices should not consider padding. So the values in indices are in the range [0, N x C x D1 x ... x Dn).
0017fee9 The output mask.
0017fefa Output tensor, which has the shape and type as input tensor
0017ff36 N = Shape <start = 0, end = 1> (X)
0017ff59 If true, compute the mean and variance across per activation. If false, compute the mean and variance across per feature over each mini-batch.
0017ffe8 Optional is expected to have either an input or the type attribute set.
00180030 Error parsing TensorProto (expected a tensor shape).
00180065 The bias tensor for input gate. Concatenation of `[Wbi, Rbi]` and `[WBbi, RBbi]` (if bidirectional). The tensor has shape `[num_directions, 2*hidden_size]`. Optional: If not specified - assumed to be 0.
00180130 A list of 2 (or 4 if bidirectional) activation functions for update, reset, and hidden gates. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
0018021a  not in allowed input sizes.
00180237  is marked single but has an empty string in the graph
0018026e )'s output 
0018027a ' is expected to have field 'type_proto'
001802a4 This attribute describes how to interpret the `sizes` input with regard to keeping the original aspect ratio of the input, and it is not applicable when
0018033d the `scales` input is used. <br/>
00180360 Given a set of `sizes`, associated with a subset of `axes` (explicitly provided or default), and assuming `d = axes[i]`, with `i` being the index of the provided `sizes`. <br/>
00180412 If `keep_aspect_ratio_policy` is `"stretch"`, the original aspect ratio is disregarded, and the input is resized to the specified size: <br/>
001804a0 `out_size[d] = sizes[i]` <br/>
001804c0 If `keep_aspect_ratio_policy` is `"not_larger"`, the sizes are adjusted so that no extent of the output is larger than the specified size, while keeping the original aspect ratio: <br/>
0018057a `scale = Min(sizes[i] / in_size[d])` <br/>
001805a5 `out_size[d] = round_int(scale * in_size[i])` <br/>
001805da If `keep_aspect_ratio_policy` is `"not_smaller"`, the sizes are adjusted so that no extent of the output is smaller than the specified size, while keeping the original aspect ratio: <br/>
00180696 `scale = Max(sizes[i] / in_size[d])` <br/>
001806c1 `out_size[d] = round_int(scale * in_size[i])` <br/>
001806f6 For non-resizable axes (those not specified in `axes`), the output size will be equal to the input size.
00180760 Note: `round_int` stands for computing the nearest integer value, rounding halfway cases up.
001807bd }, input shape = {
001807d0 padded_input = Pad (input_data, pads, , axes_input)
00180804 Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get "nearest" pixel in input tensor from x_original, so this attribute is valid only if "mode" is "nearest".
0018092c The input is not evenly splittable
0018094f Ranks inferred (
00180960 Number of elements of attribute 'scales' must be same as rank of input 'X'
001809ab Providing `scales` is incompatible with a `keep_aspect_ratio_policy` other than "stretch".
00180a06 The output array, elements ordered as the inputs.
00180a38 Value(s) to change to.
00180a4f Chosen support vectors
00180a66 Flag indicating whether the regression is a one-class SVM or not.
00180aa8 Node id for each node. Node ids must restart at zero for each tree and increase sequentially.
00180b06 The id of the tree that each node is in.
00180b2f The input type must be a tensor of integers or strings, of any shape.
00180b75 Cannot find missing input: 
00180b91 onnx.TensorShapeProto
00180ba7  Can't back up over more bytes than were returned by the last call to Next().
00180bf5 INFO
00180bfa RE2: invalid startpos, endpos pair. [
00180c20 RepetitionWalker::ShortVisit called
00180c44 Concat of 
00180c4f [:^punct:]
00180c5a missing ]
00180c64 Canadian_Aboriginal
00180c78 Hiragana
00180c81 Limbu
00180c87 Miao
00180c8e Phoenician
00180c99 Shavian
00180ca1 Tai_Tham
00180caa panic: 
00180cb2 money_get error
00180cc2 auto
00180cc7 unsigned short
00180cd6 %LaL
00180cdb operator/
00180ce5 operator|
00180cef exynos9810
00180cfa libunwind: malformed DW_CFA_val_offset DWARF unwind, reg (%lu) out of range
00180d4c FDE has zero length
00180d60 FDE is really a CIE
00180d74 location dimensions do not match shape size
00180da0 Training APIs are not supported with this build. Please build onnxruntime from source with the build flags enable_training_apis to retrieve the training APIs.
00180e40 The given version [%u] is not supported, only version 1 to %u is supported in this build.
00180e9b allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
00180edf const onnxruntime::SparseTensor &OrtValue::Get() const
00180f16 Trying to get a Tensor, but got: 
00180f3b /onnxruntime_src/onnxruntime/core/common/safeint.h
00180f6e Number of values should be at least 1.
00180f95 Expecting all elements to be tensors. Got: 
00180fc1 Received nullptr for exec provider
00180fe4 Unable to serialize model as it contains compiled nodes. Please disable any execution providers which generate compiled nodes.
00181063 elements, but feeds has 
0018107c EndProfiling
00181089 Error during EndProfiling(): 
001810a7 PartitionOrtFormatModel
001810bf Flush-to-zero and denormal-as-zero are 
001810e7 enable_profiling
001810f8 SetExecutionMode
00181109 Unsupported graph_optimization_level value in ORT config: 
00181144 invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
00181188 <uninitialized>
00181198 Output buffer is not large enough for ::OrtKernelInfo output name
001811da Output
001811e1 mapped_feed_names_.size() == feed_names_.size()
00181211 Size mismatch
0018121f RegisterCustomOpsLibrary
00181238 static void OrtEnv::Release(OrtEnv *)
0018125e libonnxruntime_providers_dnnl.so
0018127f CANN execution provider is not enabled in this build.
001812b5 GetPartitioningStopOps
001812cc !delimiter.empty()
001812df SetOutputBuffers
001812f0 ANeuralNetworksModel_relaxComputationFloat32toFloat16
00181326 ANeuralNetworksExecution_compute
00181347 SL_ANeuralNetworksDiagnosticCompilationInfo_getSessionId
00181380 ] B Input type: [
00181392 ], end [
0018139b _imm_mul
001813a4 AddOperation
001813b1 The input/initializer of graph doesn't have valid type, name: 
001813f0  for now, only u8s8 QlinearConv supports per-channel quantization on API 29+
0018143d  mismatch int8 per-channel quantization weight,
0018146d IsQuantizationZeroPointSupported
0018148e  scale can only be [
001814a3 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/flatten_op_builder.cc
00181507 pads must be a constant
0018151f coordinate_transformation_mode
0018153e ends
00181543 , Input type 2: 
00181554 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/minmax_op_builder.cc
001815b7 invalid output node index
001815d1 Input min of Clip must be known
001815f1 QLinearConvTranspose
00181606 Invalid input shape: 
0018161c Invalid input shape. Only N can be zero. Got:
0018164a onnxruntime::xnnpack::AveragePool::AveragePool(const onnxruntime::OpKernelInfo &)
0018169c exclude_outside can be set to 1 when (1 mode is CUBIC. 
001816d4 (2 mode is CUBIC or LINEAR when anti-aliasing is on. Current mode is set to 
00181721 EliminateDropout
00181732 MatMulScaleFusion
00181744 conv_W_tensor_proto
00181758 /onnxruntime_src/onnxruntime/core/optimizer/selectors_actions/helpers.h
001817a0 Input of reshape_before_gemm is not the input of subgraph
001817da MatchInputMaskSubgraph
001817f1 Start CheckNodesInPathK
00181809 /onnxruntime_src/onnxruntime/core/optimizer/embed_layer_norm_fusion.cc
00181850 EmbedLayerNormalization
00181868 /onnxruntime_src/onnxruntime/core/optimizer/gelu_approximation.cc
001818aa /onnxruntime_src/onnxruntime/core/optimizer/layer_norm_fusion.cc
001818eb Failed to get allocator for optimizer
00181911 QuickGelu
0018191b /onnxruntime_src/onnxruntime/core/optimizer/rule_based_graph_transformer.cc
00181967 MoveInputOutput
00181977 0 <= p && p_int < shape_proto->dim_size()
001819a1 An entry for this node should be added in kLayoutTransformationPotentiallyAddedOps.
001819f5 Transpose optimizer failed: 
00181a12 SpaceToDepth
00181a1f Unexpected data type for Clip input of 
00181a47 Invalid scan input:
00181a5b /onnxruntime_src/onnxruntime/core/framework/ort_value_tensor_slicer.h
00181aa1 SetupInputs
00181aad onnxruntime::common::Status onnxruntime::ScanImpl::CreateLoopStateVariables(std::vector<LoopStateVariable> &)
00181b1b Output type not supported in this build: 
00181b45 void onnxruntime::Clip::ComputeImpl<signed char>::operator()(const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, onnxruntime::Tensor *) const [T = signed char]
00181c08 onnxruntime::Einsum::Einsum(const onnxruntime::OpKernelInfo &)
00181c47 input_shape_1_override[0] == input_shape_2_override[0]
00181c7e Found '.' not part of an ellipsis in input: 
00181cab  Left shape override: 
00181cc2 void onnxruntime::BroadcastIterator::Init(ptrdiff_t, ptrdiff_t)
00181d02 Invalid Y argument: num_indices = 0
00181d26 info.GetAttr<std::string>("cast_to", &attr).IsOK()
00181d59 SPARSE
00181d60 info.GetAttr<int64_t>("default_int64", &default_int_).IsOK()
00181d9d LEAF
00181da2 void onnxruntime::ml::detail::TreeAggregatorAverage<int, float, float>::FinalizeScores(InlinedVector<ScoreValue<ThresholdType>> &, OutputType *, int, int64_t *) const [InputType = int, ThresholdType = float, OutputType = float]
00181e86 (std::is_same<float, TH>::value)
00181ea7 info.GetAttrs<int64_t>("kernel_shape", kernel_shape_).IsOK()
00181ee4  vs. 
00181eea ComputeImpl
00181ef6 wstr != wconv_error
00181f0a Invalid mode of value 
00181f21 Sampling ratio should be >=0, but it was 
00181f4f void onnxruntime::rnn::detail::ComputeGemm(const int, const int, const int, const float, const float *, const float *, const GemmWeights<uint8_t> &, const float, float *, float *, const int, uint8_t *, int32_t *, concurrency::ThreadPool *)
0018203f weights.quant_para_
00182053 /onnxruntime_src/onnxruntime/core/providers/cpu/signal/utils.h
00182092 -INF
00182097 dst_strides.size() == src_strides.size() && src_strides.size() == copy_shape.size() && !copy_shape.empty()
00182102 Missing/Invalid 'axis' attribute value
00182129 . Value must be in range [0,
00182146 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/space_depth_ops.h
0018218f /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/split.h
001821ce Mismatched data types between input and output Tensors. 
00182207 (local_source >= source) && (local_source < source + num_blocks * num_elts_in_block)
0018225c BaseCompute
00182268 Attention cannot have both past and relative_position_bias
001822a3 qkv_hidden_sizes attribute should have 3 elements
001822d5  q_hidden_size=
001822e5 Input 'past' expect k_hidden_size == v_hidden_size
00182318 position_ids's first dimension shall be 1 or batch_size
00182350 gamma is expected to have size of 
00182373 , aw_attn_size}. Got:
00182389 info.GetAttr<std::string>("metric", &metric).IsOK()
001823bd Scale
001823c3 Currently supporting only 2-D matrices
001823ea /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/qembed_layer_norm.cc
00182439 void onnxruntime::contrib::(anonymous namespace)::QLinearImpl(onnxruntime::OpKernelContext &, double, const onnxruntime::ProcessBroadcastSpanFuncs &) [T = signed char]
001824e1 input_count_x3 >= 3 && input_count_x3 % 3 == 0
00182510 onnxruntime::contrib::SkipLayerNorm<float>::SkipLayerNorm(const onnxruntime::OpKernelInfo &) [T = float]
00182579 void onnxruntime::contrib::transformers::BeamSearch::Init(const onnxruntime::OpKernelInfo &)
001825d6  should be a scalar. Got shape of 
001825f9 onnxruntime::common::Status onnxruntime::contrib::GenerationCpuDeviceHelper::CreateEncoderInputs(const onnxruntime::Tensor *, const OrtValue *, int, int, onnxruntime::AllocatorPtr, OrtValue &, OrtValue &, OrtValue &)
001826d2 void onnxruntime::contrib::transformers::Sampling::Init(const onnxruntime::OpKernelInfo &)
0018272d decoder subgraph input 0 (input_ids) shall have int32 type
00182768 onnxruntime::BFCArena::BFCArena(std::unique_ptr<IAllocator>, size_t, onnxruntime::ArenaExtendStrategy, int, int, int)
001827de BinForSize(bin_size * 2) != BinFromIndex(b)
0018280a  BFC Arena shrunk by 
00182820 , next: 
00182829 MaxAllocSize:             
00182844 /onnxruntime_src/onnxruntime/core/framework/data_types.cc
0018287e ~ExLibLoader
0018288b Unloading DSO 
0018289a void onnxruntime::IExecutionFrame::Init(gsl::span<const int>, gsl::span<const OrtValue>, const std::unordered_map<int, OrtValue> &, const std::function<bool (const std::string &)> &, gsl::span<const OrtValue>)
0018296c  size=
00182973 void onnxruntime::IExecutionProvider::InsertAllocator(onnxruntime::AllocatorPtr)
001829c4 !provider_type_.empty()
001829dc  Version mismatch.
001829ef cannot find allocator
00182a05 Received nullptr for OrtValue
00182a23 /onnxruntime_src/onnxruntime/core/framework/library_handles.cc
00182a62 session.node_partition_config_file
00182a85 const onnxruntime::KernelCreateInfo &onnxruntime::GetKernelCreateInfo(const onnxruntime::KernelCreateInfoMap &, onnxruntime::NodeIndex)
00182b0d nullptr != tensor_type_base
00182b29 onnxruntime::OrtValueIndex &onnxruntime::PlannerImpl::Buffer(onnxruntime::OrtValueIndex)
00182b82 type must be string, but is 
00182b9f Async Kernel Support is not implemented yet.
00182bcc _fence_after
00182bd9 SaveInitializedTensors
00182bf0  bytes for 
00182bfc This method should follow a call to constructor that supplies the allocator
00182c48 ValidateCsrIndices
00182c5b  to device type: 
00182c6d /onnxruntime_src/onnxruntime/core/framework/stream_execution_context.cc
00182cb5 ' failed
00182cbe TensorProtoToMLValue() must take a pre-allocated MemBuffer!
00182cfa Sparse indices int32 data size does not match expected
00182d31 Invalid SparseTensor indices. Should one of the following types: int8, int16, int32 or int64
00182d8e model format error! Need a value for the external data info
00182dca CalculateStaticCopyInfoForFeeds
00182dea The value to be filled in the attention mask. Default value is -10000.0f
00182e33 Input tensor with shape (batch_size, sequence_length, input_hidden_size)
00182e7c Constrain mask index to integer types
00182ea2 segment_embedding
00182eb4 Saved mean used during training to speed up gradient computation
00182ef5 Encoder input ids.
00182f08 Number of non-padding tokens in each sequence with shape (batch_size).
00182f4f RemovePadding
00182f5d tensor of shape (1, num_heads, 1, 1)
00182f82 Output tensor of the same type and shape as the input tensor.
00182fc0 The ratio of random dropout, with value in [0, 1). If this input was not set, or if it was set to 0, the output would be a simple copy of the input. If it's non-zero, output will be a random dropout of the scaled input, which is typically the case during training. It is an optional value, if not specified it will default to 0.5.
0018310b If align_corners=1, the extrema (-1 and 1) are considered as referring to the center points of the input's corner pixels. If align_corners=0, they are instead considered as referring to the corner points of the input's corner pixels, making the sampling more resolution agnostic.
00183223 Constrain input and output types to float tensors
00183255 Constrain input and output types to float/int tensors.
0018328c Constrain input B data types as 16-bit integer tensor
001832c2 This operator applies convolution to word from left to right with window equal to conv_window_size and stride to 1.Take word 'example' for example, with conv_window_size equal to 2, conv is applied to [ex],[xa], [am], [mp]...If not provide, use the first dimension of conv kernel shape.
001833e1 Bias tensor.
001833ee anchors
001833f6 score_activation
00183407 The cropped patches output tensor.
0018342a  expected to have rank 
00183442 VarPlusEpsilon = Add (Var, Epsilon)
00183466 StdDev = Sqrt (VarPlusEpsilon)
00183485 The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`
00183506 Optional initial value of the hidden. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.
0018358d Input data to be scaled
001835a5 Array of sequence lengths.  len(seq_lengths) should equal batch size N.
001835ed Input data type does not match the expected data type
00183623 N-D quantized Input tensor to be de-quantized.
00183652 Each bounding box spans this dimension.Typically, the block dimension corresponds to the reduction dimension of the matrix multipication that consumes the output of this operator.For example, for a 2D matrix multiplication A@W, QuantizeBFP(A) would use block_dim 1 and QuantizeBFP(W) would use block_dim 0.The default is the last dimension.
001837a7 dtype
001837ad Constrain output types to 32 bit tensors.
001837d7 apply softmax to elements for dimensions axis,or all dims along with axis according to op-version
00183839 The input tensor
0018384a Y's scale.
00183855 zero point of quantized input tensor.It's a scalar, which means a per-tensor/layer quantization.
001838b6 position_embedding_scale
001838cf Scale for segment embeddings
001838ec word_embedding_zero_point
00183906 2-dimensional matrix B. Transposed if order_B is ORDER_COL.
00183942 scale of the weight (scalar for per-tensor quantization or 1-D of dims [hidden_size] for per-channel quantization)
001839b5 Constrain filter type to 8-bit integer tensor.
001839e4 Constrain output type to 8-bit integer tensor.
00183a13 Invalid destination node arg slot specified when adding edge.
00183a51 ) : (
00183a57 Duplicate initializer (dense or ConstantNode): '
00183a8c Missing string data for initializer. Invalid ORT format model.
00183acb Missing raw data for initializer. Invalid ORT format model.
00183b07 LoadSparseInitializerOrtFormat
00183b26  ImplicitInputs:
00183b37 ONNX Runtime only *guarantees* support for models stamped with opset version 7 or above for opset domain 'ai.onnx'. Please upgrade your model to opset 7 or higher. For now, this opset 
00183bf0 Protobuf parsing failed.
00183c09 LoadOpIdentifierOrtFormat
00183c23 known by the checker.
00183c3d RUNTIME_EXCEPTION
00183c4f Invalid fd was supplied: 
00183c69 offset < 0
00183c74 File: 
00183c7b Model must have opset imports. Invalid ORT format model.
00183cb4 dim_param value with no name. Invalid ORT format model.
00183cec ] out of range.
00183cfc ) should not contain more than one value field.
00183d2c NodeProto (name: 
00183d3e ai.onnx.training
00183d4f  was 
00183d55 An optional list of K flags. The i-th element of the list specifies the axis for the i-th scan_output. The scan outputs are accumulated along the specified axis. If omitted, 0 will be used as the scan axis for every scan_output. Negative value for an axis means counting dimensions from the back. Accepted range is [-r, r-1].
00183e9b (Optional) The value of the output elements.Should be a one-element tensor. If not specified, it defaults to a tensor of value 0 and datatype float32
00183f31 Constrain output types to be numerics.
00183f58 The shape of the output tensor.
00183f78 The mean of the normal distribution.
00183f9d X_random = RandomUniformLike <low = 0.0, high = 1.0, seed = @seed> (input)
00183fe8 Whether the operator should behave like fmod (default=0 meaning it will do integer mods); Set this to 1 to force fmod treatment
00184068 The exponential of the input tensor computed element-wise
001840a3         {
001840ad           Zero = Constant <value = float {0.0}>()
001840df           ZeroCast = CastLike(Zero, X)    
0018410a           XLessThanZero = Less (X, ZeroCast)
00184137           SlopeMulX = Mul (slope, X)
0018415c           Y = Where(XLessThanZero, SlopeMulX, X)
0018418d         }
00184197         
001841a0 Values
001841a7 Whether to return the top-K largest or smallest elements.
001841e1 Ellipsis represents incompatible dimensions.
0018420e  broadcasting: (
0018421f Axis has less than the requested k elements.
0018424c loss_N1dd
00184256 weight_gather
00184264 Attribute kernel_shape has incorrect size
0018428e 'output_shape' must have same number of elements as the shape of input tensor X.
001842e0         {
001842ea           Exponent = Constant <value = float {2.0}>()
00184320           Epsilon = Constant <value = float {1e-9}>()
00184356           X_RM = ReduceMean <axes : ints = @axes> (X)
0018438c           EX_squared = Pow (X_RM, Exponent)
001843b8           X_squared = Pow (X, Exponent)
001843e0           E_Xsquared = ReduceMean <axes : ints = @axes> (X_squared)
00184424           Variance = Sub (E_Xsquared, EX_squared)
00184456           STD = Sqrt (Variance)
00184476           X_variance = Sub (X, X_RM)
0018449b           Processed_STD = Add (STD, Epsilon)
001844c8           Y = Div (X_variance, Processed_STD)
001844f6         }
00184500         
00184509 block_shape
00184515 Invalid value(
00184524 Input shape must have either [C] or [1,C] dimensions where C > 0
00184565 BiasT = Cast (bias)
00184579 The running variance (training) or the estimated variance (testing) as a 1-dimensional tensor of size C.
001845e2 The output tensor of the same shape as X.
0018460c The input element.
0018461f Constrain output to a boolean tensor.
00184645 Value expected but not found.
00184663 Error parsing TensorProto (expected a tensor type).
00184697 'axis' must be in [-rank(indices), rank(indices)-1]
001846cb , max=
001846d2 Sequence enclosing the input tensors.
001846f8 Constrain output to integral tensor. It must be a scalar(tensor of empty shape).
00184749 new_axis
00184752 Expected 1 or more inputs.
0018476d Input was expected to have sequence type. Got 
0018479c Input was expected to have optional type. Got 
001847cb Which axis to split on. A negative value means counting dimensions from the back. Accepted range is [-rank, rank-1] where r = rank(input).
00184856 transposed
00184861 Constrain input 'X' and output 'Y' to all tensor types.
00184899 Input tensor containing indices. Any entries in the 'indices' input tensor with values outside the range [-depth, depth-1] will result in one-hot representation with all 'off_value' values in the output tensor.In case 'indices' is of non-integer type, the values will be casted to int64 before use.
001849c4 data tensor must have rank >= 1
001849e4 padded_input = Pad (input_data, pads)
00184a0a 1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
00184aaa Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1]
00184b17 The output is a 1-D tensor of string, float, or integer.
00184b50 map(string, float)
00184b63 Indicates whether to do OvR or multinomial (0=OvR is the default).
00184ba6 First, offset by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.
00184c43 Tree id for each node.
00184c5a The index of the class list that each weight is for.
00184c8f Base values for classification, added to final class score; the size must be the same as the classes or can be left unassigned (assumed 0)
00184d1a Label encoder has only one output.
00184d3d Only one of keys_*'s can be set in label encoder.
00184d6f  were provided.
00184d7f Can't happen
00184d8c SearchOnePass inconsistency
00184da8 [:alnum:]
00184db2 Missing case in Compiler: 
00184dcd Failed to analyze start state.
00184dec GrowStack() failed: 
00184e04 Avestan
00184e0c Devanagari
00184e17 Lepcha
00184e21 Samaritan
00184e2b Sora_Sompeng
00184e38 failed to allocate %zu bytes for %u logical processor mapping entries
00184e7e hi6210sft
00184e88 WonderMedia
00184e94 Tegra T
00184e9c %m/%d/%y
00184eb1 operator&
00184ebb operator%
00184ec5 operator>>
00184ed4 libunwind: malformed DW_CFA_same_value DWARF unwind, reg too big
00184f16 DW_EH_PE_aligned pointer encoding not supported
00184f46 truncated sleb128 expression
00184f66 tried creating tensor with negative value in shape
00184f99 initial_growth_chunk_size_bytes
00184fb9 static bool onnxruntime::utils::ContainerChecker::IsContainerOfType<std::map<std::basic_string<char>, std::basic_string<char>>>::check(const onnxruntime::utils::ContainerChecker::Cont &, size_t) [T = std::map<std::basic_string<char>, std::basic_string<char>>]
001850bd OrtStatus *OrtCreateMapMLValue(const onnxruntime::Tensor &, const onnxruntime::Tensor &, OrtValue **) [KeyType = long, ValueType = long]
00185146 OrtMemoryInfo is null
0018515c to.custom_join_thread_fn
00185175 The ORT format model version [
00185194 The provided PrePackedWeightsContainer instance to be added to the session is null
001851e7 CUDAExecutionProvider
001851fd Output vector incorrectly sized: output_names.size(): 
00185234  combination is not an arena based allocator: 
00185263 /onnxruntime_src/onnxruntime/core/framework/execution_providers.h
001852a5 Invalid value for 
001852b8 LoadOrtModelBytes
001852ca ort_config
001852d5 /onnxruntime_src/onnxruntime/core/session/inference_session_utils.cc
0018531a inter_op_num_threads option in the model file must be an integer
0018535b invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
001853a9 invalid string: control character U+0019 (EM) must be escaped to \u0019
001853f1 iterator does not fit current value
00185415 ; expected 
00185425 cannot use at() with 
0018543b Failed to load dynamic library 
0018545b tensor(uint64)
0018546a seq(tensor(uint8))
0018547d unordered_map::at: key not found
0018549e ] has 
001854a5 SL_ANeuralNetworksDiagnosticCompilationInfo_getErrorCode
001854de ANEURALNETWORKS_OUTPUT_INSUFFICIENT_SIZE
00185507 Node does not have corresponding NodeUnit.
00185532 RegisterModelInputs
00185546 RegisterModelOutputs
0018555b  system NNAPI feature level: 
00185579 ], fused the output [
0018558f GetInputDataType
001855a0 NNAPI does not support 0 reshape dimension
001855cb IsSupportedBatchMatMul
001855e2  of NodeUnit: 
001855f1 axis 
001855f7 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/elu_op_builder.cc
00185657 Gather doesn't support dynamic input shape
00185682 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/LRN_op_builder.cc
001856e2 asymmetric
001856ed , output_size_c, 
001856ff /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/slice_op_builder.cc
00185761 model_builder.UseNCHW()
00185779 NOTSET
00185780 Bias of QLinearConv must be known
001857a2  alpha 
001857aa  beta 
001857b5 XNNPACK initialization failed with status 
001857e0  channels_last: 
001857f1 dim_size > 0
001857fe Failed to create xnnpack kernel. xnn_create_
0018582b GetTensorQuantType
0018583e Resize: input tensor's rank does not match the output tensor's rank.
00185883  Input dim value: 
00185896 DoubleQDQPairsRemover
001858ac /onnxruntime_src/include/onnxruntime/core/graph/graph.h
001858e4 LeakyRelu
001858ee optimizer_utils::GetClipConstantMinMax(state.graph, *activation, min, max)
00185939 axis
0018593e Gemm bias is not constant initializer
00185964 hidden_size != num_heads * head_size
00185989 FuseSubGraphQK
00185998 qkv_bias
001859a1 Gamma should be of shape (hidden_size). 
001859ca SqueezeAxesInitializer
001859e1 UnsqueezeAxesInitializer
001859fa void onnxruntime::Initializer::scale_by_axis(const onnxruntime::Initializer &, int)
00185a4e RemoveDuplicateCastTransformer
00185a6d MatMulInteger
00185a7b FusedMatMul
00185a87 MIGraphXExecutionProvider
00185aa1  provided for op: 
00185ab4 ArgMax
00185abb Hardmax
00185ac3 Scan
00185acb 'Loop' input 'M' should be a scalar tensor. Got shape of 
00185b05 gsl::narrow_cast<int64_t>(output_axes_.size()) == num_scan_outputs
00185b48 Invalid value in scan_input_axes for input 
00185b74 delta in Range operator can not be zero!
00185b9d There was a problem acquiring temporary memory allocator in Einsum op
00185be3 Einsum op: Unsupported data type for Diagonal 
00185c12 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Abs<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Abs<float>]
00185ccf virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Sqrt<double>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Sqrt<double>]
00185d90 cur_out == end_out
00185da3 /onnxruntime_src/onnxruntime/core/providers/cpu/math/gemm_helper.h
00185de6 right.NumDimensions() == 2
00185e01 void onnxruntime::TopkOpset10ConstructorCommon(const onnxruntime::OpKernelInfo &, int &)
00185e5a CastMap
00185e62 Invalid input type of value: 
00185e80  Expected TO_FLOAT, TO_STRING or TO_INT64
00185eaa (name: 
00185eb2 scores.size() == static_cast<size_t>(expected_num_scores)
00185eec LinearRegressor
00185efc Invalid argument: input has empty dimensions.
00185f2a kernel_params
00185f38 nodes_falsenodeids.size() == nodes_truenodeids.size()
00185f6e base_values.empty() || base_values_as_tensor.empty()
00185fa3 onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommon<int, float, float>::Init(int, int, int, const std::string &, const std::vector<float> &, const std::vector<ThresholdType> &, int64_t, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<float> &, const std::vector<ThresholdType> &, const std::vector<int64_t> &, const std::vector<std::string> &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<float> &, const std::vector<ThresholdType> &, const std::string &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<float> &, const std::vector<ThresholdType> &) [InputType = int, ThresholdType = float, OutputType = float]
001862b3 GetVectorAttrsOrDefault not implemented for type 
001862e5 Invalid input B: 0th dimension != 
00186308 output and sum shape must match
00186328 Invalid input scale: number of dimensions is not 1: 
0018635d StringNormalizer
0018636e wstring_convert: from_bytes error
00186390 min_gram_length
001863a0 onnxruntime::NonMaxSuppressionBase::NonMaxSuppressionBase(const onnxruntime::OpKernelInfo &)
001863fd and will be fixed in the next ORT 1.13 release. Thus the results of RoiAlign 
0018644b virtual onnxruntime::common::Status onnxruntime::DynamicQuantizeLinear<unsigned char>::Compute(onnxruntime::OpKernelContext *) const [T = unsigned char]
001864e4 x_zero_point must be null or 1D tensor with size 
00186516 IsScalarOr1ElementVector(a_offset)
00186539 IsBQuantParamSupported(b_scale->Shape(), b ? b->Shape() : b_shape_)
00186581 info.GetAttr("linear_before_reset", &int64_value).IsOK()
001865ba reverse
001865c2 bidirectional
001865d0 lda >= K && ldb >= K && ldc >= N
001865f1 LSTM operator does not support double yet
0018661d snprintf_result > 0 && gsl::narrow_cast<size_t>(snprintf_result) == buffer_span.size() - 1
00186678 EyeLike : Input tensor dimension is not 2
001866a2 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/gather_elements.cc
001866ec int64_t onnxruntime::GetIndex(size_t, const T *, int64_t) [T = int]
00186730 padding_mode "
0018673f virtual onnxruntime::common::Status onnxruntime::IdentityOp<true>::Compute(onnxruntime::OpKernelContext *) const [is_dropout = true]
001867c4 PadInputWithDimValueOfZero
001867df info.GetAttr<int64_t>("batch_axis", &batch_axis).IsOK()
00186817 onnxruntime::Scatter<onnxruntime::TypeList<float, double, long, unsigned long, int, unsigned int, short, unsigned short, signed char, unsigned char, onnxruntime::MLFloat16, onnxruntime::BFloat16, bool, std::basic_string<char>>>::Scatter(const onnxruntime::OpKernelInfo &) [EnabledDataTypes = onnxruntime::TypeList<float, double, long, unsigned long, int, unsigned int, short, unsigned short, signed char, unsigned char, onnxruntime::MLFloat16, onnxruntime::BFloat16, bool, std::basic_string<char>>]
00186a0a Indices type is not supported.
00186a29 updates shape: 
00186a39 CPU execution provider: MLFloat16 data type is not supported with ScatterND opset 16 when reduction is 'add'.
00186aa7 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/slice.cc
00186ae7 auto onnxruntime::SliceImpl(onnxruntime::OpKernelContext *, const onnxruntime::Tensor &, SliceOp::PrepareForComputeMetadata &)::(anonymous class)::operator()(SliceIterator<T> &) const
00186b9f void *onnxruntime::SliceIteratorBase::CopyInnermostAxisNonSolitaryInnerStep(void *)
00186bf3 std::all_of(split_sizes_.cbegin(), split_sizes_.cend(), [](int64_t value) { return value >= 0; })
00186c55 Input count of Tile OP mismatch, the second one is empty
00186c8e /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/trilu.cc
00186cce Either scales or sizes MUST be provided as input.
00186d00 Input 'bias' is expected to have 1 dimension, got 
00186d33 bias_dims[0]=
00186d41 Inputs 'past' dimension 2 shall have length of 
00186d71 /onnxruntime_src/onnxruntime/contrib_ops/cpu/bert/embed_layer_norm.cc
00186db7  is not in (0, 
00186dc7 max_ngram_size
00186dd6 Can not multiply A and B as inner dimension does not match. inner_A: 
00186e1c virtual onnxruntime::common::Status onnxruntime::contrib::QLinearConcat::Compute(onnxruntime::OpKernelContext *) const
00186e96 QGemm : scale of input a must be a scalar or 1D tensor of size 1
00186ed7 Input 'prefix_vocab_mask' is expected to be 2 dimensions, got 
00186f16 Input 'presence_mask' is expected to have 2 dimensions, got 
00186f53 max_length > sequence_length
00186f70 element_type == DataTypeImpl::GetType<T>()
00186f9b BeamSearch op: An implementation for the input type 
00186fd0  New allocator: 
00186fe1 BFCArena
00186fea  with following configs: initial_chunk_size_bytes: 
0018701e  max_dead_bytes_per_chunk: 
0018703a Extending BFCArena for 
00187052 BFC Arena ran out of memory trying to allocate 
00187082 void onnxruntime::BFCArena::FreeAndMaybeCoalesce(BFCArena::ChunkHandle)
001870ca : Chunks 
001870d4 Sum Total of in-use chunks: 
001870f1 CopyTensors
001870fd thisProto->value_case() == TypeProto::ValueCase::kSparseTensorType
00187140 virtual void onnxruntime::NonTensorTypeBase::ToDataContainer(const OrtValue &, size_t, void *) const
001871a5 /onnxruntime_src/include/onnxruntime/core/framework/data_types.h
001871e6 static void onnxruntime::data_types_internal::OptionalTypeHelper::Set(const onnx::TypeProto *, onnx::TypeProto &)
00187258 Failed to unload DSO: 
0018726f /onnxruntime_src/onnxruntime/core/framework/execution_frame.cc
001872ae !is_strided_tensor
001872c1 /onnxruntime_src/onnxruntime/core/framework/graph_partitioner.cc
00187302 This op has been implemented only for the following types (
0018733e Attribute: 
0018734a ort_value.IsTensor()
0018735f Insufficient dimensions to slice on 
00187384 static OrtValueTensorSlicer<T> onnxruntime::OrtValueTensorSlicer<const OrtValue>::Create(T &, int64_t, int64_t) [T = const OrtValue]
00187409 onnxruntime::OrtValueTensorSlicer<const OrtValue>::Iterator::Iterator(T &, size_t, size_t, int64_t, onnxruntime::OrtValueTensorSlicer::Iterator::Direction) [T = const OrtValue]
001874ba An OrtValue for this name has already been added: 
001874ed const onnxruntime::NodeIndexInfo &onnxruntime::SessionState::GetNodeIndexInfo() const
00187543 CreateSubgraphSessionState
0018755e  which is of op type: 
00187575 /onnxruntime_src/onnxruntime/core/framework/prepacked_weights.cc
001875b6  against size 
001875c5 void onnxruntime::PlannerImpl::Reuse(onnxruntime::OrtValueIndex, onnxruntime::OrtValueIndex, onnxruntime::AllocKind)
0018763a  launch kernel with idx 
00187653 SequentialExecutor::Execute
0018766f , Got 
00187676 SparseTensor::CooView onnxruntime::SparseTensor::AsCoo() const
001876b5 Index size: 
001876c2 This method does not expect allocator to be set
001876f2 Use MakeCsrStrings
00187705 MakeCsrStrings
00187714  to be equal to values blocks: 
00187734 void onnxruntime::Tensor::Init(onnxruntime::MLDataType, const onnxruntime::TensorShape &, void *, onnxruntime::AllocatorPtr, ptrdiff_t, gsl::span<const int64_t>)
001877d6 Mem pattern for initializer 
001877f3 string tensor can not use pre-allocated buffer
00187822 Failed to find allocator for device 
00187847 Attention mask with shape (batch_size, 1, max_sequence_length, max_sequence_length), (batch_size, total_sequence_length) or (batch_size, sequence_length, total_sequence_length), or index with shape (batch_size) or (2 * batch_size)
0018792e past_sequence_length
00187943 Constrain input and output types to float tensors.
00187976 1D input tensor with shape (3 * hidden_size)
001879a3 key_length
001879ae prev_suffix_match_idx
001879c4 Inputs 0 shall be 2 dimensions
001879e3 The output mask of dropout.
001879ff Constrain the output to a boolean tensor.
00187a29 model type: 0 for GPT-2; 1 for encoder decoder like T5
00187a60 Presence penalty for custom sampling
00187a85 normalized
00187a90 mark
00187a95 N-dimensional matrix A
00187aac counts
00187ab3 2D matrix with shape (K,N)
00187ace feature_map_3
00187adc Pooled size.
00187ae9  is null
00187af2 Deviation = Sub (XU, Mean2D)
00187b0f /onnxruntime_src/onnxruntime/core/graph/contrib_ops/onnx_deprecated_operators.cc
00187b60 1-D tensor of axes that `starts` and `ends` apply to.
00187b96 Shape of x
00187ba1 Constrain output data type to 32-bit integer tensor.T2 must be tensor(uint32) when T1 is tensor(uint8),or must be tensor(int32) when T1 is tensor(int8).
00187c3a X_scale
00187c42 z_zero_point
00187c4f gamma_quant
00187c5e scale of the input, scalar value (per tensor) currently.
00187c97 scale_Q_gemm
00187ca4 scale_V_weight
00187cb3 scale_weight
00187cc0 Zero point tensor for output 'y'. It's a scalar, which means a per-tensor/layer quantization.
00187d1e Input B's scale. It's a scalar, which means a per-tensor/layer quantization.
00187d6b ) is an outer scope value being returned directly. Please update the model to add an Identity node between the outer scope value and the subgraph output.
00187e05 Invalid node indexes specified when removing edge.
00187e38 This is an invalid model. Error: the graph is not acyclic.
00187e73 ) type inference failed
00187e8b graph_proto_ is not in sync with name_to_initial_tensor_
00187ec4 const onnx::TensorShapeProto &onnxruntime::utils::GetShape(const onnx::TypeProto &)
00187f18 void onnxruntime::model_load_utils::ValidateOpsetForDomain(const std::unordered_map<std::string, int> &, const logging::Logger &, bool, const std::string &, int)
00187fba Null ints attribute. Invalid ORT format model.
00187fe9 Mismatch between Graph and IndexedSubGraph. Input not found:
00188026 LoadRuntimeOptimizationRecordFromOrtFormat
00188051 std::vector<LogicalProcessors> onnxruntime::concurrency::ReadThreadAffinityConfig(const std::string &)
001880b8 ElementSize must be power of 2 and less or equal than 16!
001880f2 void onnxruntime::logging::LoggingManager::CreateDefaultLogger(const std::string &)
00188146 INVALID_GRAPH
00188154 Negative thread index is not allowed
00188179 Failed to load library 
00188191 ) second dimension size does not match rank of tensor.
001881c8  in initializer but not in graph input
001881ef ConstantFill
001881fc ) is not equal to number of scan outputs (
00188227 v_final_and_scan_outputs
00188240 optional(seq(tensor(uint64)))
0018825e optional(seq(tensor(complex128)))
00188280 Scalar. Value to step by.
0018829a Constrain input to float tensors.
001882bc Input tensor whose elements to be clipped
001882e6 Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape).
00188349 N-dimensional quantized matrix b
0018836a loss_N1dd = Slice (loss_NCdd, const_zero, const_one, const_one)
001883ab         {
001883b5           A0 = Constant <value = float {0.54347826087}>()
001883ef           A1 = Constant <value = float {0.45652173913}>()
00188429           A2 = Constant <value = float {0.0}>()
00188459           Zero = Constant <value = float {0.0}>()
0018848b           One = Constant <value = float {1.0}>()
001884bc           Two = Constant <value = float {2.0}>()
001884ed           Tau = Constant <value = float {6.2831853}>()
00188524           Periodic_Size_FP = Cast <to = 1> (size)
00188556           Symmetric_Size_FP = Sub(Periodic_Size_FP, One)
0018858f           IsPeriodic = Constant <value_int : int = @periodic>()
001885cf           IsPeriodic_FP = Cast <to = 1> (IsPeriodic)
00188604           IsSymmetric_FP = Sub(One, IsPeriodic_FP)
00188637           Periodic_Component = Mul(Periodic_Size_FP, IsPeriodic_FP)
0018867b           Symmetric_Component = Mul(Symmetric_Size_FP, IsSymmetric_FP)
001886c2           Size_FP = Add(Periodic_Component, Symmetric_Component)
00188703           AngularIncrement = Div (Tau, Size_FP)
00188733           Range = Range (Zero, Periodic_Size_FP, One)
00188769           RangeAngular = Mul (Range, AngularIncrement)
001887a0           TwoRangeAngular = Mul (RangeAngular, Two)
001887d4           CosTwoRangeAngular = Cos (TwoRangeAngular)
00188809           A2_Component = Mul (A2, CosTwoRangeAngular)
0018883f           CosRangeAngular = Cos (RangeAngular)
0018886e           A1_Component = Mul (A1, CosRangeAngular)
001888a1           Temp0 = Sub (A0, A1_Component)
001888ca           Temp1 = Add (Temp0, A2_Component)
001888f6           output = Cast <to : int = @output_datatype> (Temp1)
00188934         }
0018893e         
00188947 Value of beta default to 0.5
00188964 Input tensor A
00188973 Scalar multiplier for the product of input tensors A * B, the default value is 1.0.
001889c7 The input tensor of rank >= axis.
001889e9 Attribute pooled_shape must be specified
00188a12 Bias tensor of shape (C).
00188a2c running (training) or estimated (testing) variance tensor of shape (C).
00188a74 Input is ether string UTF-8 or int32/int64
00188a9f The starting indexes of 1-grams, 2-grams, and so on in pool. It is useful when determining the boundary between two consecutive collections of n-grams. For example, if ngram_counts is [0, 17, 36], the first index (zero-based) of 1-gram/2-gram/3-gram in pool are 0/17/36. This format is essentially identical to CSR (or CSC) sparse matrix format, and we choose to use this due to its popularity.
00188c2a A list of integers, along which to reduce. The default is to caculate along axes [0,2,3] for calculating mean and variance along each channel. Two variables with the same C-coordinate are associated with the same mean and variance.
00188d12 Epsilon = Cast (FloatEpsilon)
00188d30 ROI pool output shape (height, width).
00188d57 Constrain input type to all tensor and sequence types.
00188d8e /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/optional/defs.cc
00188ddf /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/quantization/defs.cc
00188e34  unknown
00188e3d Mismatched sparse tensor element type:
00188e64 Input was expected to have either tensor, sequence, optional or map type. Got 
00188eb3 Input tensor can be of arbitrary type.
00188eda Optional length of each output. Values should be >= 0.Sum of the values must be equal to the dim value at 'axis' specified.
00188f56 Tensor of rank r >= 1 (same rank as input).
00188f82 Type of reduction to apply: none (default), add, mul, max, min. 'none': no reduction applied. 'add':  reduction using the addition operation. 'mul': reduction using the multiplication operation.'max': reduction using the maximum operation.'min': reduction using the minimum operation.
0018909f Output tensor of the same dimensions and type as tensor input. output_dim[i] = input_dim[i] * repeats[i]
00189108 A 1-D INT64 tensor containing indices of 'Y' elements' first occurance in 'X'. When 'axis' is provided, it contains indices to subtensors in input 'X' on the 'axis'. When 'axis' is not provided, it contains indices to values in the flattened input tensor. 
00189209 A 0-D tensor containing a single value corresponding to the number diagonals above or below the main diagonal to exclude or include. Default value is 0 if it's not specified.
001892b8 Repeated axis: 
001892c8 Three modes: constant(default), reflect, edge
001892f6 List of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D it is the number of pixels. `pads` rank should be double of the input's rank. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
0018949f 'step' cannot be 0
001894b2 Input 'scales' must have float element type.
001894df The type of tensor: 
001894f4 The input must be a map from strings or integers to either strings or a numeric type. The key and value types cannot be the same.
00189576 Scaled output data.
0018958a Class labels if using string labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
001895f6 seq(map(string, float))
0018960e Only one of values_*'s can be set in label encoder.
00189642 Inferred elem type differs from existing elem type: (
00189678 onnx.TypeProto.SparseTensor
00189694  Parameter to BackUp() can't be negative.
001896be DFA out of memory: 
001896d5 [:^space:]
001896e5 Glagolitic
001896f0 Khmer
001896f6 Khojki
001896fd Marchen
00189705 Oriya
00189711 Sogdian
00189719 Thai
0018971e failed to allocate %zu bytes for descriptions of %u L2 caches
0018975c Unknown
0018976b failed to parse file %s: file is empty
00189792 clock_gettime(CLOCK_REALTIME) failed
001897b7 condition_variable::wait: mutex not locked
001897e2 collate_byname<wchar_t>::collate_byname(size_t refs) failed to construct for 
00189833 Saturday
0018983c April
00189842 August
00189849 signed char
00189855 sizeof...(
00189860 basic_ostream
0018986e std::ostream
0018987b std::iostream
00189889 long long
00189893 noexcept(
0018989d terminate_handler unexpectedly returned
001898c5 unsupported restore location for register
001898fc Unknown Exception
00189910 this API does not support strings
00189932 /onnxruntime_src/include/onnxruntime/core/common/logging/logging.h
00189975 static void onnxruntime::logging::LoggingManager::SetDefaultLoggerSeverity(onnxruntime::logging::Severity)
001899e0 onnxruntime::SparseTensor &(anonymous namespace)::ValidateFillInputArgs(OrtValue *, const onnxruntime::TensorShape &, const OrtMemoryInfo *)
00189a6d gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = std::basic_string<char>]
00189ac6 Affinity string must not be empty
00189ae8 optimization.minimal_build_optimizations
00189b11  index: 
00189b1e Found session/run/environment configuration in the model file to be used while running the model
00189b7f type must be number, but is 
00189b9c discarded
00189ba6 cannot compare iterators of different containers
00189bd7 parse_error
00189be3 while parsing 
00189bf2 number literal
00189c01 unknown token
00189c0f /onnxruntime_src/onnxruntime/core/session/IOBinding.cc
00189c46  contains null pointers
00189c5e tensor(uint16)
00189c6d seq(tensor(int32))
00189c80 seq(tensor(int64))
00189c93 Unsupported Source/Target type=
00189cb3 TryGetProviderInfo_CUDA
00189ccb onnxruntime::Provider &onnxruntime::ProviderLibrary::Get()
00189d06  is not present.
00189d17 onnxruntime::Tensor *onnxruntime::OpKernelContext::Output(int)
00189d56 const T *onnxruntime::Tensor::Data() const [T = signed char]
00189d93 Node supported: [
00189da5 ] name: [
00189daf ANeuralNetworksMemory_free
00189dca ANeuralNetworksModel_finish
00189de6 ANeuralNetworksDevice_getVersion
00189e07 ANeuralNetworksDevice_getType
00189e25 ANeuralNetworksModel_getSupportedOperationsForDevices
00189e5b ANeuralNetworksMemoryDesc_addInputRole
00189e82 SL_ANeuralNetworksDiagnosticCompilationInfo_getDeviceIds
00189ebb ANEURALNETWORKS_OUT_OF_MEMORY
00189ed9 ], shape size [
00189ee9 FindActivation
00189ef8 TENSOR_INT32
00189f05 AddNnapiBatchNormalization
00189f20 /transposed
00189f2c  is used by 
00189f39 Skipping Reshape/Flatten node [
00189f59 /split_
00189f61 Initializer [
00189f6f ]'s scale: 
00189f7b Op [
00189f80 starts
00189f8b Weight input was not constant initializer. XNNPACK EP should not have asked for the node. Node name:
00189ff0 kernel_shape num_dims is not compatible with W num_dims.
0018a029 xnn_create_resize_bilinear2d_nhwc_
0018a04c onnxruntime::UpsampleBase::UpsampleBase(const onnxruntime::OpKernelInfo &)
0018a097 left_num_dims and right_num_dims must be >= 1
0018a0c5 GemmTransposeFusion
0018a0d9 Dropout
0018a0e1 _transformed
0018a0ee ConvAddActivationFusion
0018a106 virtual std::vector<NodeAndMoveInfo> onnxruntime::(anonymous namespace)::actions::FuseConvAddActivation::ValueMoves(const onnxruntime::ReplaceWithNew::RuntimeState &) const
0018a1b3 Invalid free dimension override.
0018a1d4 representative.output_index != kInvalidOutputIndex
0018a207 DynamicQuantizeLinear
0018a21d Gemm bias is not constant
0018a237 Faild to match gemm gather path
0018a257 unidir mask shape not expected
0018a276 This optimizer does not support external data for unidirectional mask right now
0018a2c6 Failed to find Softmax node
0018a2e2 Start MatchInputMaskSubgraphDistilBert
0018a309 Cast mask from int64 to int32
0018a327 Split
0018a32d num_heads
0018a337 Fused an attention node for GPT.
0018a358 qkv_weights
0018a364 Position embedding shape is not expected.
0018a38e Input shape is unknown or not 2D, or data type unknown
0018a3c5 position_embeddings
0018a3d9 SliceAxesInitializer
0018a3ee /onnxruntime_src/onnxruntime/core/optimizer/bias_gelu_fusion.cc
0018a42e  into softmax(input + bias)
0018a44a fused Add-Dropout-(Add) for 
0018a467 utils::HasDataType(tensor_proto)
0018a488 gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = onnxruntime::MLFloat16]
0018a4e0 void onnxruntime::utils::mltype_dispatcher_internal::CallableDispatchableHelper::CheckCalledOnce()
0018a543 virtual onnxruntime::common::Status onnxruntime::InsertCastTransformer::ApplyImpl(onnxruntime::Graph &, bool &, int, const logging::Logger &) const
0018a5d7 ReduceMean
0018a5e2 Buffer overflow
0018a5f2 Invalid node index 
0018a606 virtual size_t onnxruntime::ApiTensor::NumElements() const
0018a641 Atanh
0018a647 Mean
0018a64c onnxruntime::ElementWiseKernel<onnxruntime::functors::ThresholdedRelu<float>>::ElementWiseKernel(const onnxruntime::OpKernelInfo &) [F = onnxruntime::functors::ThresholdedRelu<float>]
0018a704 Init
0018a709 Output OrtValue has not been created for loop state variable output 
0018a74e Misuse of LoopStateVariable. Attempt to move beyond end of sequence
0018a792 else_branch
0018a79e void onnxruntime::Loop::Init(const onnxruntime::OpKernelInfo &)
0018a7de /onnxruntime_src/onnxruntime/core/providers/cpu/controlflow/scan_9.cc
0018a824 info.GetAttr<float>("scale", &scale_).IsOK()
0018a851 onnxruntime::RandomUniform::RandomUniform(const onnxruntime::OpKernelInfo &)
0018a89e sample_size
0018a8aa onnxruntime::SliceSkips::SliceSkips(const onnxruntime::TensorShape &, gsl::span<const int64_t>, gsl::span<const int64_t>)
0018a924 dims.size() == starts.size()
0018a941 The broadcasted dimensions of the inputs are incompatible
0018a97b void onnxruntime::EinsumTypedComputeProcessor<double>::FinalizeOutput(const onnxruntime::Tensor &, const gsl::span<const int64_t> &) [T = double]
0018aa0d virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Neg<long>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Neg<long>]
0018aac8 auto onnxruntime::BitShift<unsigned char>::Compute(onnxruntime::OpKernelContext *)::(anonymous class)::operator()(onnxruntime::BroadcastHelper &) const [T = unsigned char]
0018ab74 Tensor with shape information must be 1 dimensional.
0018aba9 void onnxruntime::TopkOpset9ConstructorCommon(const onnxruntime::OpKernelInfo &, int &, unsigned int &)
0018ac11 onnxruntime::ml::LabelEncoder_2<std::basic_string<char>, float>::LabelEncoder_2(const onnxruntime::OpKernelInfo &) [TKey = std::basic_string<char>, TValue = float]
0018acb5 intercepts
0018acc0 SOFTMAX_ZERO
0018accd /onnxruntime_src/onnxruntime/core/providers/cpu/ml/onehotencoder.cc
0018ad11 tmp_cats_int64s.empty() || tmp_cats_strings.empty()
0018ad45 n_supports
0018ad50 n_targets_or_classes > 0
0018ad69 BRANCH_LEQ
0018ad74 predictions.size() == predictions2.size()
0018ad9e void onnxruntime::ml::detail::TreeEnsembleCommon<float, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = float, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorMax<float, float, float>]
0018aeef predictions.size() == 2
0018af07 void onnxruntime::ml::detail::TreeAggregatorMax<double, double, float>::MergePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = double, ThresholdType = double, OutputType = float]
0018b004 void onnxruntime::ml::detail::TreeAggregatorAverage<long, float, float>::FinalizeScores(InlinedVector<ScoreValue<ThresholdType>> &, OutputType *, int, int64_t *) const [InputType = long, ThresholdType = float, OutputType = float]
0018b0ea Unexpected type (
0018b0fc ' has one dimension but is empty.
0018b11e Index tensor shape should be same as that of the input data tensor to unpool.
0018b16c pads_[dim] < kernel_shape_[dim] && pads_[dim + kernel_shape_.size()] < kernel_shape_[dim]
0018b1c8 onnxruntime::BatchNorm<double>::BatchNorm(const onnxruntime::OpKernelInfo &) [T = double]
0018b222 PrepareForCompute
0018b234 info.GetAttr<int64_t>("axis", &axis_).IsOK()
0018b261 op_kernel_info.GetAttr<float>("epsilon", &epsilon_).IsOK()
0018b29c onnxruntime::LpNorm<float>::LpNorm(const onnxruntime::OpKernelInfo &) [T = float]
0018b2ee void onnxruntime::PoolProcessContext::init(const onnxruntime::OpKernelInfo &)
0018b33c max_gram_length
0018b34c (items % ngram_size == 0)
0018b366 size_t onnxruntime::ngram_details::PopulateGrams(ForwardIter, size_t, size_t, size_t, Map &) [K = long, ForwardIter = gsl::details::span_iterator<const long>, Map = std::unordered_map<long, std::unique_ptr<onnxruntime::ngram_details::NgramPart<int64_t>>>]
0018b466 boxes and scores should have same num_batches.
0018b495 iou_threshold must be in range [0, 1].
0018b4bc Null batch_indices_ptr
0018b4d3 RoiAlignBase
0018b4e0 Optional op must have a TypeProto in the 'type' attribute if the attribute is present
0018b536 select_last_index
0018b548 hidden_size
0018b554 /onnxruntime_src/onnxruntime/core/providers/cpu/rnn/rnn_helpers.cc
0018b597 dft_length must be a scalar value.
0018b5ba  has mismatched dimensions of 
0018b5d9 auto onnxruntime::StridedCopy(concurrency::ThreadPool *, unsigned int *, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShape &, const unsigned int *, const onnxruntime::TensorShapeVector &)::(anonymous class)::operator()(std::ptrdiff_t, std::ptrdiff_t) const
0018b6ef  must be within the inclusive range [
0018b715 last dimension of indices must not be larger than rank of input tensor
0018b75c virtual onnxruntime::common::Status onnxruntime::GridSample<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
0018b7da value_tensor->DataType() == data_type && value_tensor->Shape().Size() == 1
0018b825 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/padbase.h
0018b866 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/reverse_sequence.h
0018b8b0 Scatter
0018b8b8 onnxruntime::SliceBase::SliceBase(const onnxruntime::OpKernelInfo &, bool)
0018b903 virtual onnxruntime::common::Status onnxruntime::Squeeze::Compute(onnxruntime::OpKernelContext *) const
0018b96b Attribute perm of Transpose has an invalid value. Value 
0018b9a4 bool onnxruntime::TypedDoTransposeEltWise(int64_t, gsl::span<const int64_t>, size_t, const gsl::span<const size_t> &, const uint8_t *, uint8_t *) [T = unsigned char]
0018ba4a /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/unsqueeze.h
0018ba8d ApplyAttention
0018ba9c Attention v weight shape error! Expected:{
0018bac7 ) + rightBorder (
0018bad9 An axis tensor must be a scalar tensor.
0018bb01 unimplemented activation: 
0018bb1c COO k index: 
0018bb2a normalize_variance
0018bb3d info.GetAttr<int64_t>("channels", &channels_).IsOK()
0018bb72 invalid channel count
0018bb88 Unsupported transformation mode '
0018bbaa Each input must be (tensor, scale, zero_point) tuple!
0018bbe0 IsScalarOr1ElementVector(tensor_y_zero_point)
0018bc0e  inputs! (condition, x, x_scale, x_zero_point, y, y_scale, y_zero_point, z_scale, z_zero_point)
0018bc6e tensor_z_scale->IsDataType<float>()
0018bc92 QLinearWhere
0018bc9f QGemm : zero point of y must be null or a scalar or 1D tensor of size 1
0018bce7 virtual onnxruntime::common::Status onnxruntime::contrib::transformers::BeamSearch::SetupSubgraphExecutionInfo(const onnxruntime::SessionState &, const std::string &, const onnxruntime::SessionState &)
0018bdb1  is required
0018bdbe /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/greedy_search_parameters.cc
0018be14 subgraph input 2 shall be named as attention_mask, got: 
0018be4d present_0
0018be57 /onnxruntime_src/onnxruntime/core/framework/allocatormgr.cc
0018be93  Existing allocator: 
0018bea9 void *onnxruntime::BFCArena::AllocateRawInternal(size_t, bool, onnxruntime::Stream *, bool, onnxruntime::WaitNotificationFn)
0018bf29 NumAllocs:                
0018bf44 Config key is empty or longer than maximum length 128
0018bf7a Tensor size mismatch
0018bf8f virtual bool onnxruntime::OptionalTypeBase::IsCompatible(const onnx::TypeProto &) const
0018bfe7 proto != nullptr
0018bff8 LoadExternalLib
0018c008 node_index_info and ort_value_idx_map are out of sync and cannot be used
0018c051 invalid index 
0018c060  returned nullptr
0018c072 . Validate usage of dim_value (values should be > 0) and dim_param (all values with the same string should equate to the same size) in shapes in the model.
0018c10e /onnxruntime_src/onnxruntime/core/framework/fallback_cpu_capability.cc
0018c155 kernel_info != nullptr
0018c16c input_copy_needed != DeviceCopyCheck::Unknown && output_copy_needed != DeviceCopyCheck::Unknown
0018c1cc  already exist.
0018c1dc GetFuncs
0018c1e5  and type (
0018c1f1 Failed to find op_id: 
0018c208 /onnxruntime_src/onnxruntime/core/framework/op_kernel.cc
0018c241 kernel != nullptr
0018c253 arg_num < arg_counts.size()
0018c26f entry != kernel_create_info_map_.cend()
0018c297  doesn't have an implementation that can consume provided pre-packed weights
0018c2e4 VerifyEachNodeIsAssignedToAnEp
0018c303 OuterScopeNodeArgLocationAccumulator
0018c328 /onnxruntime_src/onnxruntime/core/framework/prepacked_weights_container.cc
0018c373 Number of streams does not equal to number of device types!
0018c3af DeviceBasedPartitioner
0018c3c6  input with name 
0018c3d8 Not expecting an allocator set
0018c3f7 Use MakeCooStrings
0018c40a SparseTensor::CsrView onnxruntime::SparseTensor::AsCsr() const
0018c449 /onnxruntime_src/onnxruntime/core/framework/sparse_utils.cc
0018c485 Expecting inner indices to be same as nnz. Got: 
0018c4b6 */_ORT_MEM_ADDR_/*
0018c4c9  is not supported.
0018c4dc Must have a valid data type
0018c4f8 source and destination buffer size mismatch
0018c524 ExecuteGraph
0018c531 Inputs 2 (value) shall be 3 dimensions
0018c558 relative_position_bias
0018c56f query
0018c575 Value with shape (batch_size, kv_sequence_length, v_hidden_size)
0018c5b6 3D output tensor with shape (batch_size, sequence_length, hidden_size)
0018c5fd 3D input tensor with shape (batch_size, sequence_length, hidden_size)
0018c643 The NGram size.
0018c653 sequence_token_count
0018c668 token_offset
0018c675 Pads has incorrect number of values
0018c699 Processed beam scores for each vocabulary token at each generation step.Beam scores consisting of log softmax scores for each vocabulary token and sum of log softmax of previously generated tokens in this beam.Shape is (max_length - sequence_length, batch_size, num_beams, vocab_size)
0018c7b6 ComplexMul
0018c7c1 sparse_tensor(uint32)
0018c7d7 num_detections
0018c7e6 Constrain input and output types to uint8, uint16, float tensors.
0018c828 PrefixShape = Slice (XShape, Zero1D, Axis1D)
0018c855 The last output value of the cell. It has shape `[num_directions, batch_size, hidden_size]`.
0018c8b2 The number of groups of channels. It should be a divisor of the number of channels C
0018c907 The output tensor of the same shape as X
0018c930 invalid scales value
0018c945 hidden_prev
0018c951 A_zero_point
0018c95e b_scale
0018c966 data_scale
0018c971 beta_quant
0018c97c QuantizeWithOrder
0018c98e Zero point tensor for input 'w'. It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M).
0018ca7b Can't merge shape info. Both source and target dimension have values but they differ. Source=
0018cad9 ) does not exist in the graph.
0018caf8 Argument mismatch when removing edge.
0018cb1e Invalid model. Node input '
0018cb3a  inputs but subgraph has 
0018cb54 ' has element type 
0018cb68 Type Error: Shape of initializer 
0018cb8a ) attribute (
0018cb98 existing_entry != mutable_initializers.pointer_end()
0018cbcd onnxruntime::Node &onnxruntime::Graph::CreateFusedSubGraphNode(const onnxruntime::IndexedSubGraph &, const std::string &)
0018cc47 auto onnxruntime::function_utils::IOTypeConstraintHelper(const onnx::FunctionProto &, std::unique_ptr<onnx::OpSchema> &, const InlinedHashMap<std::string, int> &, const InlinedHashMap<std::string, int> &)::(anonymous class)::operator()(const onnx::NodeProto &) const
0018cd52  is till opset 
0018cd62 SaveAttributeOrtFormat
0018cd79 LoadInitializerOrtFormat
0018cd92 Should be unreachable if CanRemoveNodeAndMergeEdges is in sync with the logic here.
0018cde6 const std::vector<NodeIndex> &onnxruntime::GraphViewer::GetNodesInTopologicalOrder(onnxruntime::ExecutionOrder) const
0018ce5c  model may run depending upon legacy support of some older opset version operators.
0018ceb0 Domain already set in registry
0018cecf RegisterOpSchemaInternal
0018cee8 std::unique_ptr<ThreadPool> onnxruntime::concurrency::CreateThreadPoolHelper(onnxruntime::Env *, OrtThreadPoolParams)
0018cf5e actual_num_affinities == static_cast<size_t>(options.thread_pool_size) - 1
0018cfa9 "dur" :
0018cfb1 code != static_cast<int>(common::OK)
0018cfd6 DistributionEnqueue
0018cfea munmap failed. error code: 
0018d006 . Invalid ORT format model.
0018d022 tensor
0018d029 STRING data (tensor name: 
0018d044 Op registered for 
0018d057 The value for the elements of the output tensor.
0018d088 1D tensor. The shape of the expected output tensor. If empty tensor is given, the output would be a scalar. All values must be >= 0.
0018d10d Constrain input types to float tensors.
0018d135 Constrain input types to common numeric type tensors.
0018d16b Constrain output types to all numeric tensors and bool tensors.
0018d1ab output = Where (input_large_than_max, max, input)
0018d1dd tmp = Where (input_less_than_min, min, input)
0018d20b The arctangent of the input tensor computed element-wise
0018d244 A 1-D tensor indicates the shape you want to expand to, following the broadcast rule
0018d299 Zero point tensor for input 'B'. It's optional and default value is 0. It could be a scalar or a N-D tensor, Scalar refers to per tensor quantization whereas N-D refers to per col quantization. If the input is 2D of shape [K, N] then zero point tensor may be an N element vector [zp_1, zp_2, ..., zp_N]. If the input is N-D tensor with shape [D1, D2, K, N] then zero point tensor may have shape [D1, D2, 1, N]. 
0018d435 Input tensor of shape (N, C) or (N, C, d1, d2, ..., dk).
0018d46e output = NegativeLogLikelihoodLoss <reduction : string = @reduction, ignore_index : int = @ignore_index> (X_Log, labels, weights)
0018d4f0 Constrain the input size to int64_t.
0018d515 Samples per second of the input signal used to create the spectrogram. Used to figure out the frequencies corresponding to each spectrogram bin, which dictates how they are mapped into the mel scale.
0018d5dd If onesided is 1, only values for w in [0, 1, 2, ..., floor(n_fft/2) + 1] are returned because the real-to-complex Fourier transform satisfies the conjugate symmetry, i.e., X[m, w] = X[m,w]=X[m,n_fft-w]*. Note if the input or window tensors are complex, then onesided output is not possible. Enabling onesided with real inputs performs a Real-valued fast Fourier transform (RFFT).When invoked with real or complex valued input, the default value is 1. Values can be 0 or 1.
0018d7b7 Input tensor representing a real or complex valued signal. For real input, the following shape is expected: [batch_size][signal_length][1]. For complex input, the following shape is expected: [batch_size][signal_length][2], where [batch_size][signal_length][0] represents the real component and [batch_size][signal_length][1] represents the imaginary component of the signal.
0018d92f A tensor representing the window that will be slid over the signal.The window must have rank 1 with shape: [window_shape]. It's an optional value. 
0018d9c3 weight_gather_temp_1
0018d9d8 Value of alpha default to 0.2
0018d9f6 Number of top elements to retrieve
0018da19 Attribute pads has incorrect size
0018da3b Input data tensor that has to be unpooled. This tensor is typically the first output of the MaxPool op.Dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non-image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
0018dc6f Zero point tensor for input 'w'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M)
0018dd82 Scale tensor of shape (C).
0018dd9d Input for n-gram extraction
0018ddba Carries out batch normalization as described in the paper
0018ddf4 https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
0018de3d There are five required inputs 'X', 'scale', 'B', 'input_mean' and
0018de80 'input_var'.
0018de8d Note that 'input_mean' and 'input_var' are expected to be the estimated
0018ded5 statistics in inference mode (training_mode=False, default),
0018df12 and the running statistics in training mode (training_mode=True).
0018df54 There are multiple cases for the number of outputs, which we list below:
0018df9e Output case #1: Y, running_mean, running_var (training_mode=True)
0018dfe0 Output case #2: Y (training_mode=False)
0018e009 When training_mode=False, extra outputs are invalid.
0018e03e The outputs are updated as follows when training_mode=True:
0018e07e running_mean = input_mean * momentum + current_mean * (1 - momentum)
0018e0c3 running_var = input_var * momentum + current_var * (1 - momentum)
0018e106 Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B
0018e148 where:
0018e150 current_mean = ReduceMean(X, axis=all_except_channel_index)
0018e18c current_var =  ReduceVar(X, axis=all_except_channel_index)
0018e1c8 Notice that ReduceVar refers to the population variance, and it equals to
0018e212 sum(sqrd(x_i - x_avg)) / N
0018e22d where N is the population size (this formula does not use sample size N - 1).
0018e281 The computation of ReduceMean and ReduceVar uses float to avoid overflow for float16 inputs.
0018e2df When training_mode=False:
0018e2fd Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B
0018e33f For previous (depreciated) non-spatial cases, implementors are suggested
0018e388 to flatten the input shape to (N x C * D1 * D2 * ... * Dn) before a BatchNormalization Op.
0018e3e4 Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1.
0018e4c1 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/nn/old.cc
0018e50b Saved variance used during training to speed up gradient computation. Should not be used for testing.
0018e571 Constrain output mask types to boolean tensors.
0018e5a1 The zero-padding added to one side of the output. This is also called adjs/adjustment in some frameworks.
0018e60b Identifier expected but not found.
0018e62e Zero point for doing quantization to get 'y'. Shape must match y_scale. Default is uint8 with zero point of 0 if it's not specified.
0018e6b3 product
0018e6bb Reduced output tensor with integer data type.
0018e6e9 The bias tensor for the gates. Concatenation of `[Wb[zrh], Rb[zrh]]` and `[WBb[zrh], RBb[zrh]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 6*hidden_size]`. Optional: If not specified - assumed to be 0
0018e7d5  has unsupported type 
0018e7ec ' is expected to have field 'strings'
0018e812 One or more outputs forming a sequence of tensors after splitting
0018e854 Which axis to concat on. Accepted range in `[-r, r - 1]`, where `r` is the rank of input tensors. When `new_axis` is 1, accepted range is `[-r - 1, r]`. 
0018e8ee Input type was null
0018e902  target=
0018e90b Reshaped data.
0018e91a Constrain output to int64 tensor, which should be a scalar though.
0018e95d 1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1s.
0018e9e3 Tensor of int32/int64 indices, of r >= 1 (same rank as input). All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
0018eab1 Tensor of the same shape as indices.
0018ead6 When coordinate_transformation_mode is "tf_crop_and_resize" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f.
0018eb97 Tensor to copy input into.
0018ebb2 output_data = Slice (padded_input, start_dims, end_dims, axes_input)
0018ebf7 List of integers indicate the padding element count at the beginning and end of each axis, for 2D it is the number of pixel. `paddings` rank should be double of the input's rank. `paddings` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
0018ed81 The scale along width dimension. It takes value greater than or equal to 1.
0018edcd Starting indices of corresponding axis in `axes`
0018edfe A string vocabulary array.<br>One and only one of the vocabularies must be defined.
0018ee52 A list of strings. One and only one of 'value_*'s should be set.
0018ee93 Data to be encoded.
0018eea7 First set of probability coefficients.
0018eece Regression outputs (one score per target per example).
0018ef05 Support vector coefficients.
0018ef22 Child node if expression is true.
0018ef44 The weight for the class in class_id.
0018ef6a The keys when using string keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
0018efd2 Only one of the attributes 'class_weights', 'class_weights_as_tensor' should be specified.
0018f02d opaque_type
0018f039  is out of bounds.
0018f04c [:alpha:]
0018f056 [^\x00-\x{10ffff}]
0018f069 Dives_Akuru
0018f075 Ethiopic
0018f07e Gujarati
0018f087 Masaram_Gondi
0018f095 hi3751
0018f09c ro.hardware.chipname
0018f0b7 operator new[]
0018f0c6 operator!
0018f0d0 std::basic_ostream<char, std::char_traits<char> >
0018f102 __float128
0018f10d char16_t
0018f116 __cxa_guard_acquire detected recursive initialization
0018f14c during phase1 personality function said it would stop here, but now in phase2 it did not stop here
0018f1af libunwind: malformed DW_CFA_GNU_negative_offset_extended DWARF unwind, reg too big
0018f212 ml_type != nullptr
0018f225 const T &OrtValue::Get() const [T = std::map<long, float>]
0018f260 Execution providers must be registered before the session is initialized.
0018f2aa  failed:
0018f2b3 operator()
0018f2c2 w+be
0018f2c7 intra_op_num_threads option in the model file must be an integer
0018f308 invalid number; expected digit after '.'
0018f335 key '
0018f33b Only the last input to a custom op may be marked variadic.
0018f376 env_ptr == p_instance_.get()
0018f393 seq(tensor(bfloat16))
0018f3a9 tensor(int32)
0018f3b7 SessionOptionsAppendExecutionProvider_MIGraphX: Failed to load shared library
0018f405 OrtSessionOptionsAppendExecutionProvider_Rocm: Failed to load shared library
0018f452 Tensor type mismatch.
0018f468 void onnxruntime::Tensor::Reshape(const onnxruntime::TensorShape &)
0018f4ac matching node is missing
0018f4c5 ] of this build for NNAPI
0018f4df The actual input [
0018f4f7 ANeuralNetworksModel_setOperandExtensionData
0018f524 ANeuralNetworksCompilation_setTimeout
0018f54a scalar output [
0018f55a ] type [
0018f563 , ONNX input zero point: 
0018f57d , the actual output_rank, 
0018f598 actual zero point type: [
0018f5b2 ], Operator [
0018f5c0 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/dequantizelinear_op_builder.cc
0018f62d half_pixel
0018f638 , scale_n, 
0018f644 virtual onnxruntime::common::Status onnxruntime::nnapi::SoftMaxOpBuilder::AddToModelBuilderImpl(onnxruntime::nnapi::ModelBuilder &, const onnxruntime::NodeUnit &) const
0018f6ed /onnxruntime_src/onnxruntime/core/providers/shared/utils/utils.cc
0018f72f QLinear
0018f737 [bias_datatype]=
0018f748 deconvolution2d
0018f75c error quantized op to be fused, op name is 
0018f788 antialias
0018f792 pytorch_half_pixel
0018f7a5 ] is not supported!
0018f7b9 /onnxruntime_src/onnxruntime/core/providers/xnnpack/math/matmul.cc
0018f7fc /onnxruntime_src/onnxruntime/core/providers/xnnpack/nn/conv.cc
0018f83b ACLExecutionProvider
0018f850 ReshapeFusion
0018f85e GatherToSplitFusion
0018f872 BiasDropoutFusion
0018f884 graph.RemoveNode(sum_node.Index())
0018f8a7 virtual bool onnxruntime::GemmSumFusion::SatisfyCondition(const onnxruntime::Graph &, const onnxruntime::Node &, const logging::Logger &) const
0018f937 conv_B_tensor_proto
0018f94b ScaledTanh
0018f956 Where
0018f95c Faild to match path 3 for unidirectional mask
0018f98a Output edge count not expected for Softmax
0018f9b5 past_v_gather indices != 1
0018f9d0 Failed in match Transpose attribute perm. Expected: 0, 2, 1, 3
0018fa0f q_transpose perm attribute not matched
0018fa36 k and v are not from same Split node
0018fa5b Cast Input from int64 to int32
0018fa7a Split for Fused Gather nodes
0018fa97 virtual std::vector<uint8_t> onnxruntime::ApiTensor::Data() const
0018fad9 success
0018fae1 GetKernelRegistry
0018faf3 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Tanh<double>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Tanh<double>]
0018fbb4 Invalid entries in sequence_lens. Max sequence length was 
0018fbef void onnxruntime::LoopImpl::SaveOutputsAndUpdateFeeds(const std::vector<OrtValue> &, std::vector<OrtValue> &)
0018fc5d num_samples is < 1
0018fc70 starts.size()=
0018fc7f dims_size == starts.size() && dims_size == extents_.size() && dims_size >= steps.size()
0018fcd7 virtual onnxruntime::common::Status onnxruntime::CumSum<int>::Compute(onnxruntime::OpKernelContext *) const [T = int]
0018fd4d bool onnxruntime::EinsumOp::IsTransposeRequired(size_t, const gsl::span<const size_t> &)
0018fda6 dim_iter == rank
0018fdb7 Found '.' not part of an ellipsis in the output subscript provided
0018fdfa '. Valid values are 'LEFT' or 'RIGHT'.
0018fe21 offset % span_size_ == 0
0018fe3a onnxruntime::OutputBroadcaster::OutputBroadcaster(size_t, onnxruntime::Tensor &, ptrdiff_t, ptrdiff_t)
0018fea1 M_ >= 0 && K_ > 0 && N_ >= 0
0018fec2 input_count >= 0 && static_cast<size_t>(input_count) == input_dimensions_.size()
0018ff13 classlabels_ints
0018ff24 void onnxruntime::ml::CastInputToFloat(const onnxruntime::Tensor &, gsl::span<float> &) [SrcType = double]
0018ff92 onnxruntime::ml::OneHotEncoderOp<std::basic_string<char>>::OneHotEncoderOp(const onnxruntime::OpKernelInfo &) [T = std::basic_string<char>]
0019001e SVMClassifier
0019002c /onnxruntime_src/onnxruntime/core/providers/cpu/ml/tree_ensemble_common.h
00190076 nodes_treeids
00190084 AVERAGE
0019008c virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommonClassifier<float, float, float>::compute(onnxruntime::OpKernelContext *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *) const [InputType = float, ThresholdType = float, OutputType = float]
001901b4 void onnxruntime::ml::detail::TreeEnsembleCommon<int, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = int, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorSum<int, float, float>]
001902ff int64_t onnxruntime::ml::detail::TreeAggregatorClassifier<int, float, float>::_set_score_binary(int &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = int, ThresholdType = float, OutputType = float]
001903db /onnxruntime_src/onnxruntime/core/providers/cpu/ml/zipmap.cc
00190418 !is_train_ || ((!saved_mean && !saved_inv_std) || (saved_mean && saved_inv_std))
00190469 InstanceNormalization
0019047f Mismatch between input data and B: size of B != input channel count 
001904c4 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/roi_pool.h
00190502 ConvInteger
0019050e IsScalarOr1ElementVector(y_offset)
00190531 void onnxruntime::ValidateCommonFastReduce(const onnxruntime::Tensor *)
00190579 fast_shape.size() == 3
00190590 layout_ == 0
0019059d onnxruntime::rnn::detail::Direction onnxruntime::rnn::detail::MakeDirection(const std::string &)
001905fe T *onnxruntime::rnn::detail::SafeRawPointer(typename gsl::span<T>::iterator, typename gsl::span<T>::iterator, size_t) [T = float]
00190680 activation_func_names.size() == static_cast<size_t>(num_directions_) * 3
001906c9 softsign
001906d2 SequenceLength
001906e1 strides_.empty()
001906f2 dilations_.size() == image_dim_number
00190718 " not supported, expect zeros, border or reflection
0019074c requested_shape[i] >= -1
00190765 Invalid batch_axis of 
0019077c time_axis and batch_axis must have different values but both are 
001907c2 CPU execution provider: string data type is not supported with ScatterND opset 16 when reduction is 'mul'.
0019082d Starts must be a 1-D array
00190848 Starts and ends shape mismatch
00190867 Attribute blocksize is not set.
00190887 !input_tensor.IsDataType<std::string>()
001908af void onnxruntime::DoTransposeEltWise(int64_t, gsl::span<const int64_t>, size_t, const gsl::span<const size_t> &, const std::string *, std::string *)
00190944 Resize: size of roi array should be 2 * N where N is the rank of input tensor X.
00190995 Resize: input shape needs to be at least a single dimension
001909d1 /onnxruntime_src/onnxruntime/contrib_ops/cpu/bert/attention_cpu_base.h
00190a18 Input 'input' is expected to have 3 dimensions, got 
00190a4d token_id < vocab_size
00190a63 info.GetAttrs("scales", scales_).IsOK()
00190a8b } for per-tensor/layer quantization or shape {
00190aba tensor_c_zero_point == nullptr || IsScalarOr1ElementVector(tensor_c_zero_point)
00190b0a tensor_y_zero_point == nullptr || IsScalarOr1ElementVector(tensor_y_zero_point)
00190b5a onnxruntime::common::Status onnxruntime::contrib::QLinearAveragePool::ComputeImpl(onnxruntime::OpKernelContext *) const [T8Bits = unsigned char]
00190beb onnxruntime::contrib::QLinearSoftmax::QLinearSoftmax(const onnxruntime::OpKernelInfo &)
00190c43 b_scale_shape.NumDimensions() == b_zp_shape.NumDimensions() && (b_scale_shape.NumDimensions() == 0 || (b_scale_shape[0] == b_zp_shape[0]))
00190cce attribute mark is not set
00190ce8 gpt_subgraph_ == nullptr
00190d01 decoder_feeds_fetches_manager_
00190d20 /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/beam_search_impl_base.h
00190d72 Input 'input_ids' is expected to have 2 dimensions, got 
00190dab Not Implemented
00190dbb virtual onnxruntime::common::Status onnxruntime::contrib::transformers::Sampling::Compute(onnxruntime::OpKernelContext *) const
00190e3b input_ids
00190e45 encoder_hidden_states
00190e5b conv_window_size
00190e6c Extended allocation by 
00190e84 tried to allocate 0 bytes
00190e9e !c->in_use() && (c->bin_num == kInvalidBinNum)
00190ecd void onnxruntime::BFCArena::RemoveFreeChunkIterFromBin(BFCArena::Bin::FreeChunkSet *, const BFCArena::Bin::FreeChunkSet::iterator &)
00190f52 Config value is longer than maximum length: 
00190f7f static void onnxruntime::data_types_internal::MapTypeHelper::Set(onnx::TensorProto_DataType, const onnx::TypeProto *, onnx::TypeProto &)
00191008 CleanUp
00191010 AllocateAsPerAllocationPlan
0019102c onnxruntime::SparseTensor *OrtValue::GetMutable()
0019105e Failed to find args for kernel type string '
0019108b nullptr != type_proto
001910a1 OrtValue is TensorSequence type but has no element Tensor DataType.
001910e5 gsl::narrow_cast<int64_t>(tensor_shape.NumDimensions()) >= slice_dimension
00191130 /onnxruntime_src/onnxruntime/core/framework/session_state.cc
0019116d Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.
00191232 Unsupported device allocator in the context of pre-packed weights caching: 
0019127e onnxruntime::HashValue onnxruntime::PrePackedWeights::GetHash() const
001912c4 node_index
001912cf Skipping entry for missing optional value at idx 
00191301 Expecting data type to be set as string
00191329  are out of bounds or can not be read in full.
00191358 CopyOneInputAcrossDevices
00191372 CopyOutputsAcrossDevices
0019138b 2D input tensor with shape (hidden_size, 2 * hidden_size)
001913c5 Constrain input and output types to float and float16 tensors.
00191404 bias tensor
00191410 The length of query. Self Attention requires query_length = key_length
00191457 Saved inverse standard variance used during training to speed up gradient computation.
001914ae input_skip_bias_sum
001914c2 Constrain output 'mask' types to boolean tensors.
001914f4 isnan_only
001914ff The minimum length below which the score of eos_token_id is set to -Inf. Shape is (1)
00191555 Seed for random number generator. Shape is (1)
00191584 boxes
0019158a The third feature map input tensor.
001915ae c2c_attention
001915bc disentangled_attention
001915d5 The weight tensor of the query layer in the attention mechanism. Should be of shape `[num_directions, am_query_depth(hidden_size of lstm), am_attn_size]` 
00191670 BiasSplitGelu
0019167e NhwcConv
00191687 A 1-D values of (leftBorder, topBorder, rightBorder, bottomBorder).
001916cb Constrain input and output types to all tensor types.
00191701 Unactivated gate outputs from forget, update, and output gates, pre-activation.
00191751 ) needs to be greater than or equal to the top_border (
00191789 Input A zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
00191803 reduced_scale
00191811 R_zero_point
0019181e Constrain scale types to any float tensor type.
0019184e scale of quantized input tensor. It's a scalar, which means a per-tensor/layer quantization.
001918ab Scale for 1D beta tensor
001918c4 order_input
001918d0 Constrain Scale to float32 types
001918f1 K_weight
001918fa Attention mask with shape (batch_size, 1, max_sequence_length, max_sequence_length), (batch_size, past_sequence_length + sequence_length)or (batch_size, sequence_length, past_sequence_length + sequence_length), or index with shape (batch_size) or (2 * batch_size).
00191a03 reserved. (not used as add bias need float value in cublasLt for normal order.)
00191a53 Padding for the beginning and ending along each spatial axis
00191a90 {name}
00191a97  expected to have: 
00191aab This is an invalid model. Type Error: Type '
00191ad8 Shouldn't be possible to have NodeArgs that haven't been handled already.
00191b22 onnx::GraphProto onnxruntime::Graph::ToGraphProto() const
00191b5c ) -> (
00191b63 /onnxruntime_src/include/onnxruntime/core/common/const_pointer_container.h
00191bae Null tensor attribute. Invalid ORT format model.
00191bdf /onnxruntime_src/onnxruntime/core/graph/graph_proto_serializer.cc
00191c21 std::all_of(output_edges.cbegin(), output_edges.cend(), [&src_idx](const GraphEdge& edge) { return edge.src_arg_index == src_idx; })
00191ca6 onnxruntime::Model::Model(onnx::ModelProto &&, const onnxruntime::PathString &, const onnxruntime::IOnnxRuntimeOpSchemaRegistryList *, const logging::Logger &, const onnxruntime::ModelOptions &)
00191d69 std::pair<NodeAttributes::iterator, bool> onnxruntime::utils::SetNodeAttribute(onnx::AttributeProto, onnxruntime::NodeAttributes &)
00191ded /onnxruntime_src/onnxruntime/core/graph/op_identifier.h
00191e25 ReadThreadAffinityConfig
00191e3e /onnxruntime_src/onnxruntime/core/common/cpuid_info.cc
00191e75 INVALID_ARGUMENT
00191e86 "thread_id": "
00191e95 SaveValueInfoOrtFormat
00191eac Null value type info in fbs::SequenceType. Invalid ORT format model.
00191ef1 name
00191ef6 elem_type
00191f00 key_type
00191f09 float_data
00191f14 type field and data field mismatch in attribute 
00191f45 Number of scan output axes specified (
00191f6c If node has 
00191f79 final_state_and_scan_outputs
00191f96 optional(seq(tensor(float16)))
00191fb5 optional(seq(tensor(string)))
00191fd3 Int64 tensor
00191fe0 complex64
00191fea The value for the elements of the output tensor in sparse format.
0019202c Constrain input types. Strings and complex are not supported.
0019206a (Optional) The data type for the elements of the output tensor, if not specified, we will use int32.
001920cf Direction of moving bits. It can be either "RIGHT" (for right shift) or "LEFT" (for left shift).
00192130 Constrain input to integer tensors.
00192155           {
00192161             Softplus_X = Softplus (X)
00192187             TanHSoftplusX = Tanh (Softplus_X)
001921b5             Y = Mul (X, TanHSoftplusX)
001921dc            }
001921e9         
001921f2 Mish
001921f7 Constrain index tensor to int64
00192217 NegativeLogLikelihoodLoss
00192231 Einsum expression string.
0019224b Lower bound on the frequencies to be included in the mel spectrum. This corresponds to the lower edge of the lowest triangular band.
001922d0 Constrain to integer tensors.
001922ee Constrain to any numerical types.
00192310 window input must have rank = 1.
00192331 const_one_casted
00192342 running_mean
0019234f The input 1-dimensional bias tensor of size C.
0019237e A 2D tensor with the contents of the input tensor, with input dimensions up to axis flattened to the outer dimension of the output and remaining input dimensions flattened into the inner dimension of the output.
00192452 Scaling parameter.
00192465 ) for attribute 'axis'
0019247c C = Shape <start = 1, end = 2> (X)
001924a3 Constrain mean and variance types to float tensors. It allows all float type for U.
001924f7 The output 4-dimensional tensor of the same shape as input.
00192533 Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [0, R], where R is the rank of the input tensor. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). 
0019267f If spatial is true, the dimension of scale is (C). If spatial is false, the dimensions of scale are (C x D1 x ... x Dn)
001926f7 Scale for input 'x'. It can be a scalar, which means a per-tensor/layer dequantization, or a 1-D tensor for per-axis dequantization.
0019277c Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
001927cd Defines behavior if 'axes' is empty. Default behavior with 'false' is to reduce all axes. When axes is empty and this attribute is set to true, input tensor will not be reduced,and the output tensor would be equivalent to input tensor.
001928b9 ) has input size 
001928cb ) has more outputs (
001928e0 Position in the sequence where the new tensor is inserted. It is optional and default is to insert to the back of the sequence. Negative value means counting positions from the back. Accepted range in `[-n, n]`, where `n` is the number of tensors in 'input_sequence'. It is an error if any of the index values are out of bounds. It must be a scalar(tensor of empty shape).
00192a55 Sequence of tensors for concatenation
00192a7b Input 0 expected but not provided
00192a9d SequenceConstruct is expected to have at least 1 input.
00192ad5 Tensor of rank q + (r - 1).
00192af1 Constrain input and output types to all tensor types (including bfloat).
00192b3a Tensor specifying lengths of the sequences in a batch. It has shape `[batch_size]`.
00192b8e Input: 
00192b96 'Repeats' input has incorrect number of values. The number of values in 'repeats' must be equal to the number of input dimensions.
00192c19 Input 'depth' must be a scalar or rank 1 tensor.
00192c4a Number of elements of input 'shape' (
00192c70 Ending indices (exclusive) of corresponding axis in axes`
00192caa A string to use when an input integer value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
00192d32 A value that needs replacing.
00192d50 The total number of regression targets, 1 if not defined.
00192d8a The input must be a tensor of a numeric type, either [C] or [N,C].
00192dcd The class score for each class, for each point, a tensor of shape [N,E].
00192e16 The output map
00192e25 in initializers. 
00192e37 Unexpected re_anchor value: 
00192e54 pattern length 
00192e64 list count 
00192e73 RunStateOnByteUnlocked failed after ResetCache
00192ea2 Unexpected opcode in short circuit: 
00192ec7 Bad reference count 
00192edc kRegexpCapture cap() == 0
00192ef8 \x{%x}
00192eff Buhid
00192f05 Inherited
00192f0f Kaithi
00192f16 Meetei_Mayek
00192f23 Tai_Le
00192f30 failed to parse the list of possible processors in %s
00192f66 ios_base::clear
00192f7d January
00192f85 October
00192f94 typename 
00192f9e operator>
00192fa8 operator[]
00192fb3 operator->
00192fbe unsigned long
00192fcc std::bad_cast
00192fda setRegister
00192fe6 libunwind: malformed DW_CFA_offset_extended DWARF unwind, reg too big
00193030 Output buffer allocation failed
00193050 Attempt to use DefaultLogger but none has been registered.
0019308b OrtStatus *OrtCreateMapMLValue(const onnxruntime::Tensor &, const onnxruntime::Tensor &, OrtValue **) [KeyType = long, ValueType = float]
00193115 Env is null
00193121  elements.
0019312c ValidateInputs
0019313b  is not expected to be of type tensor sequence.
0019316b Session not initialized.
00193188 void onnxruntime::InferenceSession::InitLogger(logging::LoggingManager *)
001931d2 Provided type is not an optional tensor
001931fc Setting graph_optimization_level to ORT_ENABLE_BASIC
00193233 iterator out of range
00193249 ' not found
00193255 Unsupported version '
0019326b tensor(uint32)
0019327a tensor(int8)
00193287 , but it is already registered from file 
001932b1 Schema error: 
001932c4 const T *onnxruntime::Tensor::Data() const [T = onnxruntime::MLFloat16]
0019330c ) != new size (
0019331c Both NNAPI_FLAG_CPU_DISABLED and NNAPI_FLAG_CPU_ONLY are set
00193359 ANeuralNetworksExecution_setInput
0019337b ANeuralNetworksDevice_getFeatureLevel
001933a1 SL_ANeuralNetworksDiagnosticExecutionInfo_getOutputDataClass
001933de Unknown input: 
001933ee ] does not support using graph input(quantized) as node input
0019342c of type [
00193436 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/model_builder.cc
00193490 Clip
00193495 node_unit_it != node_unit_map_.end()
001934ba AddNewOperand
001934c8 Adding node [
001934d6 The model cannot run using current set of target devices, 
00193511 QDQ 
00193516 ANEURALNETWORKS_DEPTH_TO_SPACE only supports DCR rearrangement mode. Current mode:
00193569 Pad only supports up to 1-4d shape, input is 
00193597 Reshape doesn't support 0 reshape dimension on a dynamic dimension
001935da align_corners
001935e8 Transpose only supports 1-4d shape, input is 
00193616 PRelu
0019361c Pow only supports fp32 inputs, actual input type
0019364d dilations
00193657 Unknown weight type 
0019366c transB
00193673 GemmOpBuilder - Operand [
0019368d B must be 2D
0019369a GetGemmBiasSize
001936aa index == 0
001936b5 A Conv/ConvTranspose node has both 'auto_pad' and 'pads' attributes
001936f9 `InlinedVector::at(size_type)` failed bounds check
0019372c ComputePadAndOutputShape
00193745  quantization parameters for INT8
00193767 info.GetAttr("storage_order", &storage_order).IsOK()
0019379c GlobalLpPool
001937a9 input_dims.size() >= 2
001937c0 void onnxruntime::PoolAttributes::ComputeSizePadDilations(const int64_t, const int64_t, const int64_t, int64_t *, int64_t *, int64_t, int64_t *) const
00193857 . It can only be 
00193869 num_dims_with_pad != num_output_dims
0019388e xnn_setup_convolution2d_nhwc_
001938ac DivMulFusion
001938b9 GemmSumFusion
001938c7 ConvMulFusion
001938d5 QDQS8ToU8Transformer
001938ea SkipLayerNormFusion
001938fe QDQFinalCleanupTransformer
00193919 gemm_input_edge.src_arg_index < 2
0019393b mul_B_tensor_proto
0019394e Unsupported data type: 
00193966 ] because it's the graph's output.
00193989 fused Gelu subgraphs 
0019399f unsqueeze_after_gather axes value not expected
001939ce Pass ValidateGemmInitializer
001939eb Failed to find reshape shape path 2
00193a0f Failed to find path 2 of position shape.
00193a38 /onnxruntime_src/onnxruntime/core/optimizer/initializer.cc
00193a73 _bn_nchwc
00193a7d ForEachWithIndex
00193a8e /onnxruntime_src/onnxruntime/core/optimizer/qdq_transformer/qdq_final_cleanup.cc
00193adf  with name "
00193aee /onnxruntime_src/onnxruntime/core/optimizer/qdq_transformer/qdq_propagation.cc
00193b3d /onnxruntime_src/onnxruntime/core/optimizer/qdq_transformer/qdq_s8_to_u8.cc
00193b89 qdq_s8_to_u8_zp_conversion
00193ba4 Fused reshape node: 
00193bb9 Cannot replace concat node with initializer:
00193be6 Too many produced nodes in the runtime optimization record.
00193c22 VitisAIExecutionProvider
00193c3b domain == kOnnxDomain
00193c51 ReduceSumSquare
00193c61 RegisterOnnxOperatorKernels
00193c7d virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Celu<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Celu<float>]
00193d3c /onnxruntime_src/onnxruntime/contrib_ops/cpu/activations.h
00193d77  has length of 
00193d87  but expected 
00193d96 /onnxruntime_src/onnxruntime/core/providers/cpu/generator/random.cc
00193dda delta in Range operator should be scalar like tensor, yet got shape:
00193e1f /onnxruntime_src/onnxruntime/core/providers/cpu/math/cumsum.cc
00193e5e std::unique_ptr<Tensor> onnxruntime::EinsumOp::MatMul(const onnxruntime::Tensor &, const gsl::span<const int64_t> &, const onnxruntime::Tensor &, const gsl::span<const int64_t> &, onnxruntime::AllocatorPtr, concurrency::ThreadPool *, void *, const DeviceHelpers::MatMul<T> &) [T = long]
00193f7d Another operand has a dim value of 
00193fa1 Inputs have ellipses in them but the provided output subscript does not contain an ellipsis
00193ffd Output subscript contains letters not seen in the inputs
00194036 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Abs<int>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Abs<int>]
001940ef start_offset >= 0 && real_end >= 0 && start_offset <= real_end && real_end <= len
00194141 default_string
00194150 DictVectorizer
0019415f Imputer
00194167 The 
0019416c /onnxruntime_src/onnxruntime/core/providers/cpu/ml/svmregressor.cc
001941af /onnxruntime_src/onnxruntime/core/providers/cpu/ml/tree_ensemble_classifier.cc
001941fe target_ids
00194209 nodes_hitrates.empty() || nodes_hitrates_as_tensor.empty()
00194244  (truenode).
00194251  X: 
00194256 group count is <= 0
0019426a virtual onnxruntime::common::Status onnxruntime::Dropout<float, float>::Compute(onnxruntime::OpKernelContext *) const [T1 = float, T2 = float]
001942f9 LpNormalization
00194309 info.GetAttr<int64_t>("size", &size).IsOK()
00194335 size_ % 2 == 1
00194344 MaxRoiPool
0019434f TFIDF
00194355 status.IsOK() && !impl_->ngram_counts_.empty()
00194388 The existing summation for max mode and sampling ratios besides 1 is incorrect 
001943d8 /onnxruntime_src/onnxruntime/core/providers/cpu/quantization/dynamicquantizelinear.cc
0019442e IsScalarOr1ElementVector(X_zero_point)
00194455 void onnxruntime::ValidateFastReduceKR(const gsl::span<const int64_t> &, const onnxruntime::Tensor &)
001944bb void onnxruntime::rnn::detail::ComputeGemm(const int, const int, const int, const float, TSpanAIter, TSpanAIter, const int, TSpanBIter, TSpanBIter, const int, const float, TSpanCIter, TSpanCIter, const int, concurrency::ThreadPool *) [TSpanAIter = gsl::details::span_iterator<const float>, TSpanBIter = gsl::details::span_iterator<const float>, TSpanCIter = gsl::details::span_iterator<float>]
00194645 onnxruntime::rnn::detail::deepcpu::GruResetGateFuncPtr onnxruntime::rnn::detail::deepcpu::GruResetGateFuncByName(const std::string &)
001946cb /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/cast_op.cc
0019470d indices element out of data bounds, idx=
00194736 input_tensor != nullptr && indices_tensor != nullptr
0019476b Grid batch size 
0019477c Failed to obtain detect_negative
0019479d Input is expected to have four dimensions corresponding to [N,C,H,W]
001947e2 pads_tensor_dims.size() == 1 || (pads_tensor_dims.size() == 2 && pads_tensor_dims[0] == 1)
0019483d Pads tensor size should be equal to twice the input dimension count 
00194882 data_rank * 2 == pads.size()
0019489f The dimension with value zero exceeds the dimension size of the input tensor.
001948ed gsl::narrow_cast<int64_t>(input_shape.Size()) == size
00194923 batch_axis < 2
00194932 data type is different from updates type
0019495b CPU execution provider: BFloat16 data type is not supported with ScatterElements opset 16 when reduction is 'mul'.
001949ce CPU execution provider: BFloat16 data type is not supported with ScatterND opset 16 when reduction is 'mul'.
00194a3b onnxruntime::DepthToSpace::DepthToSpace(const onnxruntime::OpKernelInfo &)
00194a86 Invalid num_outputs value of 
00194aa4 IsScalarOr1ElementVector(k)
00194ac0 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/unsqueeze.cc
00194b04 RegisterNchwcKernels
00194b19 qkv_hidden_sizes
00194b2a Input 'bias' dimension 0 should have same length as dimension 1 of input 'weights'
00194b7d virtual onnxruntime::common::Status onnxruntime::contrib::DeepCpuAttnLstmOp::Compute(onnxruntime::OpKernelContext *) const
00194bf8 sqeuclidean
00194c04 onnxruntime::contrib::BifurcationDetector::BifurcationDetector(const onnxruntime::OpKernelInfo &)
00194c66 ) needs to be greater than or equal to the topBorder (
00194c9d Input's width (
00194cad  Axis is 
00194cb7 /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/qlinear_pool.cc
00194d01 /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/qlinear_softmax.cc
00194d4e Input scale is not float for quantized input x @ 2
00194d84 y_zp == nullptr || IsScalarOr1ElementVector(y_zp)
00194db6 Can not digest tokenexp: 
00194dd0 CheckInputs
00194ddc Node input 
00194de8 /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/beam_search_impl_gpt.h
00194e39 onnxruntime::common::Status onnxruntime::contrib::transformers::BeamSearchT5<float>::Execute(const onnxruntime::FeedsFetchesManager &, const onnxruntime::FeedsFetchesManager &) [T = float]
00194ef6 subgraph input 1 shall be named as present_0, got: 
00194f2a decoder subgraph input 2 shall be named as encoder_hidden_states, got: 
00194f72 decoder subgraph input 1 (encoder_attention_mask) shall have int32 type
00194fba CudaPinned
00194fc5 !c1->in_use() && !c2->in_use() && c1->stream == c2->stream
00195000 void onnxruntime::BFCArena::RemoveFreeChunkFromBin(BFCArena::ChunkHandle)
0019504a !c->in_use()
00195057 Diff between in-use and requested bytes is 
00195083 Limit:                    
0019509e virtual bool onnxruntime::SequenceTensorTypeBase::IsCompatible(const onnx::TypeProto &) const
001950fc fetches.empty() || fetches.size() == fetch_mlvalue_idxs_.size()
0019513c  not found.
00195148 Failed to add kernel for 
00195162 /onnxruntime_src/onnxruntime/core/framework/kernel_type_str_resolver.cc
001951aa RegisterNodeOpSchema
001951bf RegisterGraphNodeOpSchemas
001951da  Attribute:
001951e6 Node placements
001951f6 ]. Number of nodes: 
0019520b subgraphs_kernel_create_info_maps.find(local_subgraph_kernel_create_info_map_key) == subgraphs_kernel_create_info_maps.end()
00195288 BuildExecutionPlan
0019529b cannot use insert() with 
001952b8 \ufffd
001952bf WaitOnEPStep.wait_handle is null
001952e0  wait on Notification with id: 
00195300 All implicit inputs should have OrtValue instances by now. 
0019533c  does not.
00195347 the ort_value must contain a constructed sparse tensor
0019537e  > dense_size: 
0019538e onnxruntime::Tensor::Tensor(onnxruntime::MLDataType, const onnxruntime::TensorShape &, void *, std::shared_ptr<IAllocator>, ptrdiff_t, gsl::span<const int64_t>)
0019542f Weight buffer for initializer '
0019544f ' is not found
0019545e TensorProto type 
00195470 Invalid SparseTensor indices. INT8 indices must be in the raw data of indices tensor
001954c5 SNPEExecutionProvider
001954db input shall be 2 dimensions
001954f7 global_weight
00195505 If has_layer_state = true, layer_state = {} or [a,b]; else layer_state = None
00195553 inv_std_var
0019555f bias for the gated_ur_linear, shape (D)
00195588                 T1 = Mul (X_bias, X_bias)
001955b2                 T2 = Mul (c, T1)
001955d3                 T3 = Add (b, T2)
001955f4                 T4 = Mul (X_bias, T3)
0019561a                 T5 = Tanh (T4)
00195639                 T6 = Add (one, T5)
0019565c                 T7 = Mul (X_bias, T6)
00195682                 Y = Mul (a, T7)
001956a2             
001956af Input tensor. Every matrix in the batch must be invertible.
001956eb Constrain input 'ratio' types to float tensors.
0019571b vocab_mask
00195726 Word IDs of generated sequences. Shape is (batch_size, max_sequence_length)
00195772 top_p
00195778 input_1
00195780 2-dimensional sparse matrix A. Either COO or CSR format
001957b8 A 2D Matrix that represents the distance between each pair of the two collections of inputs.
00195815 The anchors input tensor.
0019582f background_class
00195840 The second feature map input tensor.
00195865 inputs
0019586c Constrain 'training_mode' to boolean tensor.
00195899 ReducedShape = Concat <axis = 0> (PrefixShape, SuffixShape)
001958d5 SquareOfMean = Mul (Mean2D, Mean2D)
001958f9 Normalized = Div (Deviation, StdDev)
0019591e clip
00195923 Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. with the N and C value keep it value, while the otherdimensions are all 1.
001959d9 The size of the kernel along each axis.
00195a01 Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths.
00195a97 The shape of the convolution kernel. If not present, should be inferred from input W.
00195aed Output tensor
00195afb Sliced data tensor.
00195b0f An input tensor.
00195b20 X_zero_point
00195b2d zero point of quantized weight tensor. It's a scalar or a 1D tensor, which means a per-tensor/per-column quantization.Its size should be 3 * hidden_size if it is per-column quantization
00195be7 beta_scale
00195bf2 scale of the softmax result - scalar (per-tensor quantization)
00195c31 scale_X
00195c39 Be compatible with float version.
00195c5b Zero point tensor for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
00195cb8 ]. Its actual value is: 
00195cd1 Constrain input and output types.
00195cf3 Graph ctor should have created NodeArg for initializer. Missing:
00195d34 InferAndVerifySubgraphTypes
00195d50 '. It is no longer used by any node.
00195d75 /onnxruntime_src/onnxruntime/core/graph/function.cc
00195da9 IndexedSubGraph contains values not present in the Graph
00195de2 , max supported IR version: 
00195dff  failed. File doesn't exist
00195e1b Failed to parse since_version from 
00195e3f void onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::LogEndAndStart(onnxruntime::concurrency::ThreadPoolProfiler::ThreadPoolEvent)
00195ed0 VIWEF
00195ed6  file "
00195ede SaveTypeInfoOrtFormat
00195ef4  is not supported currently
00195f10 data_type
00195f1a Unrecognized data_type (tensor name: 
00195f40 Warning: Model contains experimental ops:
00195f6a  is deprecated in domain_version of 
00195f8f  sparse initializer name is not unique across initializers and sparse_initializers
00195fe2 Graph to run if condition is false. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the then_branch.
00196097 optional(seq(tensor(uint16)))
001960b5 optional(seq(tensor(uint32)))
001960d3 optional(seq(tensor(complex64)))
001960f4 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/controlflow/old.cc
00196147 value_ints
00196152 TypeAndShapeInferenceFunction implementation incomplete: this line should never be reached.
001961ae Input to 'Range' op should be scalars (Tensor with only one element and shape empty)
00196203 Second input operand for the bitwise operator.
00196232 Output tensor (same size as X)
00196251 output = Where (input_less_than_min, min, input)
00196282 Tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] containing top K values from the input tensor
001962f4 largest
001962fc The sine of the input tensor computed element-wise
00196330             loss_sum = ReduceSum <keepdims = 0> (loss_Ndd)
0019636b             weight_gather_sum = ReduceSum <keepdims = 0> (weight_gather)
001963b4             loss = Div (loss_sum, weight_gather_sum)
001963e9         
001963f2 Specifies a target value that is ignored and does not contribute to the input gradient. It's an optional value.
00196462 dft_length
0019646d /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/math/old.cc
001964b9 loss_NCdd
001964c3 Attribute pooled_shape has incorrect length
001964ef Input matrix
001964fc UTF-8 Normalized strings
00196515 Attribute pads must have an even size
0019653b Input data tensor to be rearranged from column blocks back into an image. This is a 3-dimensional tensor containing [N, C * n-ary-product(block_shape), L], where N is batch dimension, C is image channel dimension and L is number of blocks.The blocks are enumerated in increasing lexicographic-order of their indices.For example, with an image-size 10*20 and block-size 9*18, there would be 2*3 blocks, enumerated in the order block(0, 0), block(0, 1), block(0, 2), block(1, 0), block(1, 1), block(1, 2).
00196733 sinceVersion == 17 || sinceVersion == 18
0019675c The first normalization dimension. If rank(X) is r, axis' allowed range is [-r, r]. Negative value means counting dimensions from the back.
001967e8 auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding. DEPRECATION NOTE: auto_pad is only intended to support legacy uses, and for framework authors, one is explicitly encouraged to use explicit padding specified in the pads attribute.
001969f9 Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum), default is 0.9f.
00196a87 Unexpected type.
00196a98 Scale for doing quantization to get 'y'. It can be a scalar, which means per-tensor/layer quantization, or a 1-D Tensor for per-axis quantization.
00196b2b The axis in which to compute the arg indices.
00196b59 The shape format of inputs X, initial_h, initial_c and outputs Y, Y_h, Y_c. If 0, the following shapes are expected: X.shape = [seq_length, batch_size, input_size], Y.shape = [seq_length, num_directions, batch_size, hidden_size], initial_h.shape = Y_h.shape = initial_c.shape = Y_c.shape = [num_directions, batch_size, hidden_size]. If 1, the following shapes are expected: X.shape = [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length, num_directions, hidden_size], initial_h.shape = Y_h.shape = initial_c.shape = Y_c.shape = [batch_size, num_directions, hidden_size].
00196da7 The tensor to split
00196dbb _seqlen
00196dc3 Element type of sequence input 
00196de3 target map type missing value type.
00196e07 Input was expected to have tensor or sparse tensor type. Got 
00196e45  does not match existing output type of 
00196e6e Specified shape for output.
00196e8a DCR (default) for depth-column-row order re-arrangement. Use CRD for column-row-depth order.
00196ee7 Constrain input and output types to all tensor, sequence, and optional types.
00196f35 1-D tensor of axes that `pads` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data). Behavior is undefined if an axis is repeated. If not provided, all axes are assumed (`[0, 1, ..., input_rank-1]`).
0019703b Mismatch between the sum of 'split' (
00197061 type: 
00197068 Indices tensor must have rank >= 1
0019708b Input 'values' must be rank 1 tensor.
001970b1 Pads has incorrect number of values. Expected 2 * 
001970e4 Tensor of int32/int64 indices, of any rank q. All index values are expected to be within bounds. It is an error if any of the index values are out of bounds.
00197183 This attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>
00197203 The coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.
00197273 Denote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input "roi", scale = length_resized / length_original, <br/>
001973dc if coordinate_transformation_mode is "half_pixel", <br/>
00197415 x_original = (x_resized + 0.5) / scale - 0.5, <br/>
0019744a if coordinate_transformation_mode is "pytorch_half_pixel", <br/>
0019748b x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>
001974d9 if coordinate_transformation_mode is "align_corners", <br/>
00197515 x_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>
00197563 if coordinate_transformation_mode is "asymmetric", <br/>
0019759c x_original = x_resized / scale, <br/>
001975c3 if coordinate_transformation_mode is "tf_half_pixel_for_nn", <br/>
00197606 x_original = (x_resized + 0.5) / scale, <br/>
00197635 if coordinate_transformation_mode is "tf_crop_and_resize", <br/>
00197676 x_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1).
0019773a Class labels when using string labels. One and only one 'classlabels' attribute must be defined.
0019779b The output will be a sequence of string or integer maps to float.
001977dd Input type is not string tensor but key_strings is set
00197814 Only one of the attributes 'base_values', 'base_values_as_tensor' should be specified.
0019786b Error parsing '
0019787e [:^print:]
00197889 RunStateOnByteUnlocked failed after Reset
001978b3 njob_ = 
001978bc Simplify case not handled: 
001978d8 {%d}
001978e0 Egyptian_Hieroglyphs
001978f5 Elymaic
001978fd Newa
00197902 hi3635
0019790d /sys/devices/system/cpu/possible
0019792e clock_gettime(CLOCK_MONOTONIC) failed
00197954 time_get_byname failed to construct for 
00197981 > typename 
0019798d (anonymous namespace)
001979a3 operator==
001979ae  complex
001979bf CIE start does not match
001979d8 CIE version is not 1 or 3
001979f2 tried Filling sparse tensor with negative value in block sparse indices shape
00197a40 OrtStatusPtr OrtApis::UseBlockSparseIndices(OrtValue *, const int64_t *, size_t, int32_t *)
00197a9c arena_extend_strategy
00197ab2 1.14.1
00197ab9 const T &OrtValue::Get() const [T = std::vector<std::map<std::basic_string<char>, float>>]
00197b14 static bool onnxruntime::utils::ContainerChecker::IsContainerOfType<std::map<long, float>>::check(const onnxruntime::utils::ContainerChecker::Cont &, size_t) [T = std::map<long, float>]
00197bce Key and value tensors have unequal number of elements.
00197c05 elem_type_ != nullptr
00197c1d Session successfully initialized.
00197c3f Did not find an arena based allocator registered for device-id 
00197c7f is_model_proto_parsed
00197c95  id:
00197c9a a+be
00197c9f The Model Proto has already been checked for the ORT config json.
00197ce1 graph_optimization_level
00197cfa invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
00197d46 <parse error>
00197d54 cannot use key() for non-object iterators
00197d7e output
00197d85 seq(tensor(bool))
00197d97 Trying to register schema with name 
00197dbc const T *onnxruntime::OpKernelContext::Input(int) const [T = onnxruntime::TensorSeq]
00197e11 input_ptr
00197e1b onnxruntime::TensorSeq *OrtValue::GetMutable()
00197e4a const T *onnxruntime::Tensor::Data() const [T = unsigned char]
00197e89 const T *onnxruntime::Tensor::Data() const [T = unsigned int]
00197ec7 type == dtype_
00197ed6 nnapi error: requires android sdk version to be at least %d
00197f13 ANeuralNetworksMemory_createFromFd
00197f36 ANeuralNetworksExecution_setOutput
00197f59 ANeuralNetworksExecution_setOutputFromMemory
00197f86 ANeuralNetworksModel_getExtensionOperandType
00197fb3 SL_ANeuralNetworksDiagnosticCompilationInfo_getCompilationTimeNanos
00197ff7 NodeArg: 
00198001 Flatten
00198009 const onnxruntime::NodeUnit &onnxruntime::nnapi::ModelBuilder::GetNodeUnit(const onnxruntime::Node *) const
00198075 on compilation finish
0019808b AddNnapiSplit
00198099 HandleAutoPad
001980a7 Expected layout and operator layout do not match. Possible bug in layout optimizer.
001980ff AddMinMaxOperator
00198111  opset [
0019811a ] Input [
00198124  is different than input[0]'s zero_point: 
0019814f Indices of Gather must be known.
00198170 constant_value must be a constant
00198192 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/reshape_op_builder.cc
001981f6 Input sizes of Resize must be known
0019821a SoftMax only support 2d/4d shape, input is 
00198246 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/transpose_op_builder.cc
001982ac _bias
001982b2 bias of QLinearConv should be int32, actual type: 
001982e5 Supported batch matmul: [
001982ff C of Gemm cannot be a scalar
0019831c [input_datatype]=
0019832e /onnxruntime_src/onnxruntime/core/providers/cpu/nn/conv_transpose_attributes.h
0019837d FP32
00198382 /onnxruntime_src/onnxruntime/core/providers/xnnpack/nn/max_pool.cc
001983c5 failed. Status:
001983d5 pads[dim] < kernel_shape[dim] && pads[dim + kernel_shape.size()] < kernel_shape[dim]
0019842a not_smaller
00198436 coordinate_transform_mode:[
00198452 info.GetAttr<int64_t>("transB", &temp).IsOK()
00198480 /onnxruntime_src/onnxruntime/core/providers/cpu/math/matmul_helper.h
001984c5 NhwcTransformer
001984d5 ConvMulFusion_W_
001984e6  node '
001984ee . Can't constant fold 
00198505 /onnxruntime_src/onnxruntime/core/optimizer/free_dim_override_transformer.cc
00198552 activation_
0019855e Faild to match path 4 for unidirectional mask
0019858c past_v_gather and past_k_gather does not have same past input
001985ca Pass CheckNodesInPathV
001985e1 CheckNodesInPathQ returns false
00198601 Mask data type is not int32 or int64 or float32
00198631 Beta should be of shape (hidden_size). 
00198659 The parent of two shape nodes are expected to be input_ids.
00198695 Input data type is not int32 or int64
001986bb range_input_defs.size() == 3
001986d8 /onnxruntime_src/onnxruntime/core/optimizer/fast_gelu_fusion.cc
00198718 Axis must be non-negative
00198732 channels
0019873b " and 
00198742 src_node || dst_node
00198757 Failed to set op schema for added Q node.
00198781 virtual onnxruntime::common::Status onnxruntime::FuseReluClip::Apply(onnxruntime::Graph &, onnxruntime::Node &, onnxruntime::RewriteRule::RewriteRuleEffect &, const logging::Logger &) const
0019883f MatchAndProcess
0019884f New node op (
0019885d virtual void onnxruntime::ApiValueInfo::PermuteDims(const std::vector<int64_t> &)
001988af Permutation entry 
001988c2 BitShift
001988cb Tile
001988d0 DnnlExecutionProvider
001988e6 ValidateInput
001988f4 CreateLoopStateVariables
0019890d directions.size() == num_entries
0019892e '. 0 == forward. 1 == reverse.
0019894d void onnxruntime::scan::detail::LoopStateVariable::Next()
00198987 OrtValue &onnxruntime::scan::detail::OutputIterator::operator*()
001989c8 then_feeds_fetches_manager_ && else_feeds_fetches_manager_
00198a03 onnxruntime::RandomNormal::RandomNormal(const onnxruntime::OpKernelInfo &)
00198a4e limit in Range operator should be scalar like tensor, yet got shape:
00198a93 Axis tensor should be 0D or 1D
00198ab2 dims.size() == extents_.size()
00198ad1 Missing 'equation' attribute
00198aee Length of permutation must match the rank of the input to be permutated
00198b36 Einsum op: Transpose failed: 
00198b54 Found a '.' not part of an ellipsis in input: 
00198b83 /onnxruntime_src/onnxruntime/core/providers/cpu/math/einsum_utils/einsum_typed_compute_processor.cc
00198be7 left_dim == right_dim
00198bfd /onnxruntime_src/onnxruntime/core/providers/cpu/math/element_wise_ops.cc
00198c46 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Abs<unsigned short>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Abs<unsigned short>]
00198d15 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Neg<int>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Neg<int>]
00198dce virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Exp<double>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Exp<double>]
00198e8d direction
00198e97 void onnxruntime::BroadcastIterator::Append(ptrdiff_t, ptrdiff_t)
00198ed9 onnxruntime::common::Status onnxruntime::ml::CastMap::ComputeImpl(onnxruntime::OpKernelContext &, TTo) const [TFrom = std::basic_string<char>, TTo = float]
00198f75 CategoryMapper
00198f84 default_int64
00198f92 FeatureVectorizer
00198fa4 inputdimensions
00198fb4 However, the number of key is 
00198fd3 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/linearclassifier.cc
0019901a onnxruntime::ml::Normalizer::Normalizer(const onnxruntime::OpKernelInfo &)
00199065 Rank of input to Normalized must be less than 2. Got 
0019909b nodes_values_as_tensor
001990b2 BRANCH_LT
001990bc int64_t onnxruntime::ml::detail::TreeAggregatorClassifier<double, double, float>::_set_score_binary(int &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = double, ThresholdType = double, OutputType = float]
001991a0 virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommonClassifier<long, float, float>::compute(onnxruntime::OpKernelContext *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *) const [InputType = long, ThresholdType = float, OutputType = float]
001992c6 void onnxruntime::ml::detail::TreeEnsembleCommon<int, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = int, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorAverage<int, float, float>]
00199415 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/instance_norm.h
00199458 attribute is_case_sensitive is not set
0019947f virtual onnxruntime::common::Status onnxruntime::NonMaxSuppression::Compute(onnxruntime::OpKernelContext *) const
001994f1 OptionalHasElement
00199504 IsValidQuantParam(W_zero_point, M)
00199527 QLinearConv : result scale must be a scalar or 1D tensor of size 1
0019956a /onnxruntime_src/onnxruntime/core/providers/cpu/quantization/quantize_linear_matmul.cc
001995c1 QLinearMatmul : result scale must be a scalar or 1D tensor of size 1
00199606 onnxruntime::RNN<float>::RNN(const onnxruntime::OpKernelInfo &) [T = float]
00199652 Invalid GRU hidden gate activation function: 
00199680 T onnxruntime::bit_reverse(T, unsigned int) [T = unsigned long]
001996c0 signal shape must end in 1 (real) or 2 (real, imaginary).
001996fa highest_index >= 0 && highest_index < num_spectrogram_bins
00199735 pads_.size() == 2 * image_dim_number
0019975a size of 'pads' attribute, if provided, should equal to twice the number of image dimmensions.
001997b8 static void SafeIntExceptionHandler<onnxruntime::OnnxRuntimeException>::SafeIntOnDivZero()
00199813 bicubic
0019981b /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/identity_op.h
00199860 At most one dimension can be -1.
00199881 , requested shape:
00199894 CPU execution provider: bool data type is not supported with ScatterND opset 18 when reduction is 'min'.
001998fd !has_axes || attr_axes_.size() == attr_starts_.size()
00199933 info.GetAttr("blocksize", &blocksize_).IsOK()
00199961 Cannot split using values in 'split' attribute. Axis=
00199997 split_tensor->Shape().NumDimensions() == 1
001999c2 If 'num_outputs' is specified, the 'split' input should not be provided.
00199a0b /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/transpose.h
00199a4e /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/upsample.cc
00199a91 : 'Cubic' mode only support 2-D inputs ('Bicubic') or 4-D inputs with the corresponding outermost 2 scale values being 1.
00199b0b past_present_share_buffer
00199b25 input_ids and position_ids shall have same sequence_length
00199b60 word_embedding is expected to have 2 dimensions, got 
00199b96 position_embedding is expected to have 2 dimensions, got 
00199bd0 onnxruntime::contrib::DeepCpuAttnLstmOp::DeepCpuAttnLstmOp(const onnxruntime::OpKernelInfo &)
00199c2e CDist
00199c34 Input 1 dimension 0 should have same length as the last dimension of input 0
00199c81 virtual onnxruntime::common::Status onnxruntime::contrib::ExpandDims::Compute(onnxruntime::OpKernelContext *) const
00199cf5 /onnxruntime_src/onnxruntime/contrib_ops/cpu/fused_conv.cc
00199d30 /onnxruntime_src/onnxruntime/contrib_ops/cpu/image_scaler.h
00199d6c (X_shape[1] % MlasNchwcGetBlockSize()) == 0
00199d98 DynamicQuantizeLSTM : 
00199daf Weight point must be constant
00199dcd virtual onnxruntime::common::Status onnxruntime::contrib::MatMulInteger16<short, short, int>::Compute(onnxruntime::OpKernelContext *) const [T1 = short, T2 = short, T3 = int]
00199e7c A != nullptr && B != nullptr
00199e99 Beta zero point must be a scalar or 1D tensor of size 1
00199ed1 MatmulInteger : input1 B_zero_point must be a scalar or 1D tensor of size 1 if given
00199f26 tensor_x_zero_point->GetElementType() == tensor_y_zero_point->GetElementType() && tensor_x_zero_point->GetElementType() == tensor_z_zero_point->GetElementType() && tensor_y_zero_point->GetElementType() == tensor_z_zero_point->GetElementType()
0019a01c Subgraph SessionState was not found for 'decoder' attribute.
0019a059 GenerateNextToken
0019a06b onnxruntime::common::Status onnxruntime::contrib::transformers::BeamSearchT5<onnxruntime::MLFloat16>::Execute(const onnxruntime::FeedsFetchesManager &, const onnxruntime::FeedsFetchesManager &) [T = onnxruntime::MLFloat16]
0019a14a next_scores.size() == next_indices.size()
0019a174 subgraph output 1 (present_0) shall shall have same data type of logits output
0019a1c3 number of outputs expected to be 1 + 2 * layers, got:
0019a1f9 Input tensor to Unique op should be 1D
0019a220 Char embedding size does not match char_embedding_size attribute.
0019a262  Char embedding size: 
0019a279 Allocated memory at 
0019a28e  for output 
0019a29b  with domain:
0019a2a9 Found kernel for Op with name (
0019a2c9 found duplicated provider 
0019a2e4 Op schema must be available.
0019a301 No attribute with name: 
0019a31a Buffer containing the initializer must be owned by the user.
0019a35a auto onnxruntime::SessionState::PrepackConstantInitializedTensors(InlinedHashMap<std::string, size_t> &, const std::unordered_map<std::string, const OrtValue *> &)::(anonymous class)::operator()(bool) const
0019a429  used in the node: 
0019a43d devices
0019a445 Caught exception when reading partition config file: 
0019a47b p_provider
0019a486 execution_plan[node_stream_map_[node_index]]->device_.Type() == node_device_mem_location.device.Type()
0019a4ed invalid value index: 
0019a503 invalid UTF-8 byte at index 
0019a520  ) is different from what is supplied (
0019a548  must be less than total buffer size: 
0019a56f values_count == index_size
0019a58a Format() == SparseFormat::kUndefined
0019a5af allocator_ != nullptr
0019a5c5 MakeBlockSparseStrings
0019a5dc Destination must have a CPU allocator set
0019a606 Currently do not support dims higher than 2 dimensions: 
0019a63f Unable to convert strings tensor to a sparse tensor that not on CPU
0019a683 Unable to convert strings tensor to a sparse tensor that is not on CPU
0019a6ca dtype_ != nullptr
0019a6dc  for SizeFromDimension. Tensor has 
0019a700 Key padding mask with shape (batch_size) or (batch_size, kv_sequence_length)
0019a74d One sided attention windows length W, or half of total window length
0019a792 static_kv
0019a79c Final beam score of the generated sequences. Shape is (batch_size, num_return_sequences)
0019a7f5 All filtered values will be set to this float value.
0019a82a presence_mask
0019a838 Specified axis to insert a dimension
0019a85d Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * input_rank] or a 2D tensor of shape [1, 2 * input_rank]. `pads` format (1D example) should be as follow [x1_begin, x2_begin,...,x1_end, x2_end,...], where xi_begin is the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
0019aa5a A 1-D INT64 tensor containing the the count of each element of 'uniques' in the input 'x'
0019aab4 Activation function to apply to the scores input.
0019aae6 content-to-content attention tensor, QcKc^T.
0019ab15 The weights of attention layer in the attention wrapper. If exists, should be of shape `[num_directions, memory_depth+hidden_size, aw_attn_size]. Please note that attention mechanism context depth is also memory_depth in the attention mechanism.` 
0019ac0d y_scale
0019ac15 Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.
0019ae5a The shape of filled tensor
0019ae75 input_as_shape
0019ae84 Constrain the input to uint8.
0019aea2 B_zero_point
0019aeaf Scale of quantized input 'B'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.
0019af8c C = (A_scale * (A - A_zero_point) + B_scale * (B - B_zero_point))/C_scale + C_zero_point
0019afe5 Constrain input A and its zero point types to 8 bit tensors.
0019b022 Scale for word embeddings
0019b03c position_embedding_zero_point
0019b05a scale of the input
0019b06d order_B
0019b075 order_weight
0019b082 cublasLt order of input X. Default is ROW MAJOR. See the schema of QuantizeWithOrder for order definition.
0019b0ed scale of the input A
0019b102 scale of the global_qkv_gemm
0019b11f QOrderedLongformerAttention
0019b13b  not specified
0019b14a segment_embedding should have 2 dimensions, dimension size known, and same hidden size as word_embedding.
0019b1b4 Inputs 0 shall be 3 dimensions
0019b1d3  Input=
0019b1db  . Got: 
0019b1e4 ) of operator (
0019b1f4 sparse_tensor_names_.count(tensor_name) == 0
0019b221 void onnxruntime::Graph::SetInputs(gsl::span<const NodeArg *const>)
0019b265  , or sparse tensors
0019b27a fbs_node_arg_names cannot be null
0019b29c Null graph attribute. Invalid ORT format model.
0019b2ce Found out-of-range processor id in affinity string: 
0019b303 , skip affinity setting
0019b31b void onnxruntime::profiling::Profiler::Initialize(const logging::Logger *)
0019b366 Kernel
0019b36d Null sequence type info. Invalid ORT format model.
0019b3a0 Type:
0019b3a6 ' is required to be non-empty.
0019b3c5 ) should be file inside the 
0019b3e2 Nodes in a graph must be topologically sorted, however input '
0019b421  was not a tensor.
0019b434 Initial values of the loop's N state variables followed by M scan_inputs
0019b47d optional(tensor(int64))
0019b495 Constrain output types. Strings and complex are not supported.
0019b4d4 Output tensor of random values drawn from normal distribution
0019b512 (Optional) The data type for the elements of the output tensor, if not specified, we will use the data type of the input tensor.
0019b593 Attribute 'value_floats' expect a list of floats.
0019b5c5 The arccosine of the input tensor computed element-wise
0019b5fd Constrain output Y data type as 32-bit integer tensor.
0019b634 An input tensor that is to be processed.
0019b65d squeeze_mask = Squeeze (mask, axes)
0019b681 The data type of the output tensor. Strictly must be one of the values from DataType enum in TensorProto whose values correspond to T3. The default value is 1 = FLOAT. 
0019b72a The number of bands in the mel spectrum.
0019b753 expanded_target_int64
0019b769 Input tensor of any shape, base of the exponent.
0019b79a Attribute kernel_shape must be specified
0019b7c3 Ngram results
0019b7d1 Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
0019b89c The running variance after the BatchNormalization operator.
0019b8d8 An input tensor with shape [num_batches, spatial_dimension, 4]. The single box data format is indicated by center_point_box.
0019b955 Constrain output type to all optional tensor or optional sequence types.
0019b99e Unexpected type in sparse-tensor element type.
0019b9cd Unexpected attribute type.
0019b9e8 Expected character 
0019b9fc log sum exponent
0019ba0d L2 norm
0019ba15 The recurrence weight tensor. Concatenation of `Ri` and `RBi` (if bidirectional). The tensor has shape `[num_directions, hidden_size, hidden_size]`.
0019baaa position
0019bab3 Length of each output. It can be either a scalar(tensor of empty shape), or a 1-D tensor. All values must be >= 0. 
0019bb27 Constrain split size to integral tensor.
0019bb50 _itercount
0019bb5b Element type of input 
0019bb72 Key type of map input was unknown
0019bb94 Shape of the input tensor
0019bbae (Optional) Specify which axis is time axis. Must be one of 0 (default), or 1.
0019bbfc Attribute `num_outputs` value cannot be lower than 1
0019bc31 Input 'depth' must have exactly one element.
0019bc5e sh_diff = Sub (x_shape2, shape)
0019bc7e New shape
0019bc88 Class labels if using integer labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
0019bcf5 The weight for each target
0019bd10 The total number of targets.
0019bd2d A list of labels.
0019bd43 [libprotobuf 
0019bd54 Compiler::Copy called!
0019bd71 Cypro_Minoan
0019bd7e Duployan
0019bd8b Syriac
0019bd92 %s %s
0019bd98 Spreadtrum
0019bda3 /sys/devices/system/cpu/cpu%u/topology/physical_package_id
0019bdde bad_variant_access
0019bdf1 vtable for 
0019bdfd VTT for 
0019be06 alignof (
0019be12 noexcept (
0019be1d char
0019be24 operator<
0019be2e operator->*
0019be3a unsigned int
0019be47 %s failed to broadcast
0019be5e DW_EH_PE_funcrel pointer encoding not supported
0019be8e libunwind: Unsupported .eh_frame_hdr version
0019bec0 Stacktrace:
0019becd const T &OrtValue::Get() const [T = std::map<std::basic_string<char>, std::basic_string<char>>]
0019bf2d const T *onnxruntime::Tensor::Data() const [T = float]
0019bf64 status.IsOK()
0019bf72 session.dynamic_block_base
0019bf8d session.load_model_format
0019bfa7 Serializing optimized model with Graph Optimization level greater than ORT_ENABLE_EXTENDED and the NchwcTransformer enabled. The generated model may contain hardware specific optimizations, and should only be used in the same environment the model was optimized in.
0019c0b1 Cached EP instance for graph replay is not set yet before calling ReplayGraph()
0019c105 array
0019c10b string
0019c112 Setting graph_optimization_level to ORT_ENABLE_EXTENDED
0019c14a There must be one (and only one) dynamic typed input to the custom op. Its type info at runtime will be used to infer the type info of this dynamic typed output which is required for the success of the model loading step. More than one dynamic typed inputs are currently not supported as differing types at runtime means the output type cannot be inferred without which model loading cannot proceed.
0019c2da  it.second=
0019c2e6 Input index: 
0019c2f4 Provider_SetHost
0019c305 T *onnxruntime::Tensor::MutableData() [T = double]
0019c338 ep.nnapi.partitioning_stop_ops
0019c357 ANeuralNetworksModel_setOperandValue
0019c37c SL_ANeuralNetworksDiagnosticCompilationInfo_getInputDataClass
0019c3ba ro.build.version.sdk
0019c3cf QLinearAveragePool
0019c3e2 Gemm
0019c3e7 ] must have {1} shape, 
0019c3ff Per-channel quantization is only supported on Android API level 29+,
0019c444 FindActivation does not support, NodeUnit [
0019c470 Minimum NNAPI feature level required: 
0019c497  actual dim 
0019c4a8  weight dimension[0] 
0019c4be , output_size_n, 
0019c4d0 For Android API Level < 29 input for softmax needs to be NCHW.
0019c50f /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/squeeze_op_builder.cc
0019c573 MaxPool
0019c57b VALID
0019c581 /onnxruntime_src/onnxruntime/core/providers/xnnpack/xnnpack_execution_provider.cc
0019c5d3 The XNNPACK EP utilizes an internal pthread-based thread pool for multi-threading.If ORT's thread pool size is > 1 and spinning is enabled, there will be contention between the two thread pools, and performance will suffer.Please set either intra_op_param.allow_spinning to 0 in the SessionOption config params,or the ORT intra-op threadpool size to 1.
0019c734  xnnpack wants to allocate a space with 
0019c75d QCINT32
0019c765 info.GetAttrs("kernel_shape", kernel_shape).IsOK()
0019c79b  or 
0019c7a0 tf_crop_and_resize
0019c7b3 nearest_mode:[
0019c7c2 M_ == 1 && N_ == 1 was false
0019c7e2 Validating no unexpected access using an invalid node_index. Got:
0019c824 Fused Gemm with Transpose
0019c83e virtual onnxruntime::common::Status onnxruntime::ConvAddFusion::Apply(onnxruntime::Graph &, onnxruntime::Node &, onnxruntime::RewriteRule::RewriteRuleEffect &, const logging::Logger &) const
0019c8fd virtual onnxruntime::common::Status onnxruntime::ConvBNFusion::Apply(onnxruntime::Graph &, onnxruntime::Node &, onnxruntime::RewriteRule::RewriteRuleEffect &, const logging::Logger &) const
0019c9bb HardSigmoid
0019c9c7 Not eliminating output 
0019c9df CheckSliceParameters returns false for last_slice
0019ca11 Output edge count not expected for nodes in path v
0019ca44 Word embedding shape not expected.
0019ca67 Failed to get position embedding weights.
0019ca91 The parent of shape nodes are expected to be input_ids.
0019cac9 Optional position subgraph nodes number of outputs unexpected.
0019cb08 MatchInputToConcatSubgraph
0019cb23 gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = double]
0019cb6b gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = onnxruntime::BFloat16]
0019cbc2 gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = onnxruntime::MLFloat16]
0019cc15 /onnxruntime_src/onnxruntime/core/optimizer/matmul_add_fusion.cc
0019cc56 fused MatMul and Transpose 
0019cc72 Created a new Transpose node to interchange Cast and Transpose nodes
0019ccb7 Unexpected data type for Clip 'min' input of 
0019cce5 node_idx <= NodesToOptimizeIndices::kEmptyNodeIndex
0019cd19 Nodes to optimize are not valid, skipping action.
0019cd4b SetOpSinceVersionForProducedNodes
0019cd6d SkipLayerNormalization
0019cd84 virtual void onnxruntime::ApiGraph::TransposeInitializer(std::string_view, const std::vector<int64_t> &)
0019cded since_version.has_value()
0019ce07 Asin
0019ce0c Atan
0019ce15 /onnxruntime_src/onnxruntime/core/optimizer/unsqueeze_elimination.cc
0019ce5a AzureExecutionProvider
0019ce71 std::vector<std::vector<const Node *>> onnxruntime::utils::(anonymous namespace)::CreateSupportedPartitionNodeGroups(const onnxruntime::GraphViewer &, const onnxruntime::utils::IsNodeSupportedFn &, const onnxruntime::utils::OnGroupClosedFn &, const std::string &, bool)
0019cf7f Subgraph in 'body' produces 
0019cf9c Scan<8> spec does not support transpose of output. This should never be called.
0019cfec num_variadic_inputs == num_subgraph_inputs
0019d017 Failed to create output tensor for output #
0019d043 Expected AllocateFinalOutput to have been called to before we read the OrtValue from the iterator.
0019d0a6 onnxruntime::scan::detail::OutputIterator &onnxruntime::scan::detail::OutputIterator::operator++()
0019d109 info.GetAttr<ONNX_NAMESPACE::GraphProto>("else_branch", &proto).IsOK()
0019d150 Number of entries in 'scan_input_axes' was 
0019d17c void onnxruntime::ConstantOfShapeBase<onnxruntime::TypeList<long, onnxruntime::MLFloat16, float, double, signed char, short, int, unsigned char, unsigned short, unsigned int, unsigned long, bool>>::SetValueFromTensorProto(const onnx::TensorProto &) [EnabledOutputTypeList = onnxruntime::TypeList<long, onnxruntime::MLFloat16, float, double, signed char, short, int, unsigned char, unsigned short, unsigned int, unsigned long, bool>]
0019d32d Invalid dtype of 
0019d33f dims.size()=
0019d34c Only 1 batch dimension is allowed for MatMul
0019d379 /onnxruntime_src/onnxruntime/core/providers/cpu/math/einsum_utils/einsum_compute_preprocessor.cc
0019d3da data_n.Shape() == shape
0019d3f2 axis == 1 || axis == largest
0019d40f ] should not be greater than specified axis dim value [
0019d447 op_kernel_info.GetAttr<int64_t>("largest", &largest_temp).IsOK()
0019d488 value of k must not be negative
0019d4a8 Empty value of imputed values.
0019d4c7 LabelEncoder
0019d4d4 values_int64s
0019d4e2 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/label_encoder.h
0019d525 info.GetAttrs<TKey>(_key_field_name, keys).IsOK()
0019d557 NONE
0019d55c Empty scale in attributes
0019d576 Either both scale and offset can be of feature size (
0019d5ac base_values
0019d5b8 void onnxruntime::ml::detail::TreeAggregatorMax<float, float, float>::MergePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = float, ThresholdType = float, OutputType = float]
0019d6b1 onnxruntime::ml::TreeEnsembleClassifier<long>::TreeEnsembleClassifier(const onnxruntime::OpKernelInfo &) [T = long]
0019d725 Training mode only supports spatial BN
0019d74c virtual onnxruntime::common::Status onnxruntime::Flatten::Compute(onnxruntime::OpKernelContext *) const
0019d7b4 size_ > 0
0019d7be pooled_height_ > 0
0019d7d4 std::all_of(impl_->ngram_indexes_.begin(), impl_->ngram_indexes_.end(), [](int64_t i) { return i >= 0; })
0019d83e n-gram counts out of bounds for 
0019d85f center_point_box only support 0 or 1
0019d884 Null rois_ptr
0019d892 Number of dimensions for rois should be exactly 
0019d8c3 Second dimension for rois should be exactly 
0019d8f0 x_zero_point must be null or a scalar or 1D tensor or size 1.
0019d92e count == 1
0019d939 An axes tensor must be a vector tensor.
0019d961 info.GetAttr("keepdims", &keepdims).IsOK()
0019d98c Only works on matrices with two dimensions.
0019d9b8 Input X must have 3 dimensions only. Actual:
0019d9e5 }. Actual:
0019d9f0 info.GetAttr("hidden_size", &hidden_size_).IsOK()
0019da22 activations_.size() == static_cast<size_t>(num_directions)
0019da5d onnxruntime::common::Status onnxruntime::SplitToSequence::ComputeImpl(onnxruntime::OpKernelContext &, const onnxruntime::Tensor &, const onnxruntime::Tensor *) const [T = long]
0019db0e output_datatype
0019db1e snprintf() failed with return value: 
0019db44 dilations_.empty()
0019db57 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/concat.cc
0019db98 Non concat axis dimensions must match: Axis 
0019dbc5 auto onnxruntime::StridedCopy(concurrency::ThreadPool *, std::basic_string<char> *, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShape &, const std::basic_string<char> *, const onnxruntime::TensorShapeVector &)::(anonymous class)::operator()(std::ptrdiff_t, std::ptrdiff_t) const
0019dcf1 X input is required!
0019dd06 virtual onnxruntime::common::Status onnxruntime::ReverseSequenceOp::Compute(onnxruntime::OpKernelContext *) const
0019dd78 . Input rank=
0019dd86 , indices shape: 
0019dd98 Cannot slice scalars
0019ddad 'repeat' input tensor must have the same length as the 'input' tensor
0019ddf3 virtual onnxruntime::common::Status onnxruntime::Trilu::Compute(onnxruntime::OpKernelContext *) const
0019de59 info.GetAttr<int64_t>("upper", &temp).IsOK()
0019de86 onnxruntime::Tensor *onnxruntime::contrib::AttentionBase::GetPresent(onnxruntime::OpKernelContext *, const onnxruntime::Tensor *, int, int, int, int &) const
0019df24 Input 1 is expected to have 1 dimensions, got 
0019df53 /onnxruntime_src/onnxruntime/contrib_ops/cpu/bert/bifurcation_detector.h
0019df9c info.GetAttr<int64_t>("max_ngram_size", &max_ngram_size_).IsOK()
0019dfdd src_tokens_len >= prev_suffix_match_idx_data
0019e00a ) + bottomBorder (
0019e01d ) does not match the number of channels (
0019e047 /onnxruntime_src/onnxruntime/contrib_ops/cpu/math/sparse_dense_matmul.cc
0019e090 MurmurHash3
0019e09c scales_[0] == 1 && scales_[1] == 1 && scales_[2] >= 1 && scales_[3] >= 1
0019e0e5 info.GetAttr<std::string>("coordinate_transformation_mode", &transformation_mode).IsOK()
0019e13e transformation_mode_ == TransformationMode::ASYMMETRIC
0019e175 Recurrent
0019e17f ComputeCommon
0019e18d MatmulInteger : input1 C_zero_point must be a scalar or 1D tensor of size 1 if given
0019e1e2 QlinearBuildLookupTable : input Y_scale must be a scalar or 1D tensor of size 1
0019e232 Match contains invalid utf8 chars: 
0019e256 /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/beam_search_impl_t5.h
0019e2a6 max_length <= kMaxSequenceLength
0019e2c7 num_return_sequences (
0019e2de /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/generation_device_helper.cc
0019e334 void onnxruntime::contrib::GenerationCpuDeviceHelper::ExpandInputs(const OrtValue &, int, onnxruntime::AllocatorPtr, OrtValue &) [T = int]
0019e3bf CreateAllocator
0019e3cf . bin_num:
0019e3da Failed to find a free memory block despite calling Extend. rounded_bytes=
0019e424 , Chunk State: 
0019e434 /onnxruntime_src/onnxruntime/core/framework/data_transfer.cc
0019e471 virtual bool onnxruntime::TensorTypeBase::IsCompatible(const onnx::TypeProto &) const
0019e4c7  has already been loaded.
0019e4e1 No provider specified.
0019e4f8  kernel is not supported in 
0019e515  in KernelRegistryManager
0019e52f Kernel type string already exists for formal parameter name '
0019e56d onnxruntime::OpKernelContext::OpKernelContext(onnxruntime::IExecutionFrame *, const onnxruntime::OpKernel *, onnxruntime::Stream *, concurrency::ThreadPool *, const logging::Logger &)
0019e625 Failed to find input name in the mapping: 
0019e650 !op_type.empty()
0019e661 CreatePlan
0019e66c Partitioner type is not DeviceBasedPartitioner
0019e69b SessionState should have saved the KernelCreateInfo prior to this running. NodeIndex:
0019e6f1 wait_handle_
0019e6fe static const onnxruntime::SparseTensor &onnxruntime::SparseTensor::GetSparseTensorFromOrtValue(const OrtValue &)
0019e76f void onnxruntime::StreamExecutionContext::RecycleNodeInputs(onnxruntime::NodeIndex)
0019e7c5 Unsupported type: 
0019e7d8 /onnxruntime_src/onnxruntime/core/framework/endian_utils.cc
0019e814 relative position bias: addition to QxK' with shape (batch_size, num_heads, sequence_length, total_sequence_length) or (1, num_heads, sequence_length, total_sequence_length)
0019e8c2 3D input tensor with shape (total_sequence_length, batch_size, hidden_size)
0019e90e use_past
0019e917 The epsilon value to use to avoid division by zero.
0019e94b max_distance
0019e958 output tensor with shape (batch_size, num_heads, seq_len, seq_len)
0019e99b scale_grad_by_freq
0019e9ae A 0-D tensor containing a single value corresponding to the number diagonals above or the main diagonal to exclude or include.Default value is 0 if it's not specified.
0019ea56 Constrain output 'mask' types to uint32 tensors.
0019ea87 no repeat ngrams size
0019ea9d The subgraph for the first decoding run. It will be called once before `decoder` subgraph. This is relevant only for the GPT2 model. If this attribute is missing, the `decoder` subgraph will be used for all decoding runs
0019eb7a The sequence used as a prompt for the generation. Shape is (batch_size, sequence_length)
0019ebd3 Minimumber of tokens we keep per batch example in the output.
0019ec11 Filtered logits as input to the mutinomial function for debug purpose. Shape is (batch_size, vocab_size)
0019ec7a Tensor of rank r >= 1.
0019ec91 iou_threshold
0019ec9f max_output_boxes
0019ecb0 span
0019ecb5  but has rank 
0019ecc4 Zero1D = Constant()
0019ecd8 Mean = Reshape (Mean2D, ReducedShape)
0019ed02 x_zero_point
0019ed11 Zero point for doing quantization to get 'y'. It could be a scalar or a 1-D tensor, which means a per-tensoror per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
0019ee0d bfp_type
0019ee18 1d bias, not scaled with scale_Y.
0019ee3a scale_QKT_softmax
0019ee4c scale_values_gemm
0019ee5e scale of the quantized X
0019ee77 1D input tensor with shape (3 * hidden_size), fp32 only currently.
0019eeba Scale tensor for input 'w'. It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M).
0019efa2 auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET
0019f001 Input A's scale. It's a scalar, which means a per-tensor/layer quantization.
0019f04e Value of attribute 
0019f062 qkv_hidden_sizes should have 3 elements
0019f08a Serialization of fused function body is not currently supported, 
0019f0cc UpdateTypeShapeInference is not intended to be used with control flow nodes containing subgraphs
0019f12d  but usage of initializer in graph expects 
0019f159 Outer scope node arg name '
0019f175 ' source:
0019f17f Null floats attribute. Invalid ORT format model.
0019f1b0 FLOATS
0019f1b7 graph_->GetNode(idx) != nullptr
0019f1d7 node
0019f1dc /onnxruntime_src/onnxruntime/core/graph/runtime_optimization_record_container.cc
0019f22d CblasTrans Unexpected CBLAS_TRANSPOSE for TransB of 
0019f26c ENGINE_ERROR
0019f279 More work items than threads
0019f296 LoadSequenceTypeOrtFormat
0019f2b0 ' instead of '
0019f2bf Sparse tensor initializers must have a non-empty name
0019f2f5 tensor of bool, which should be a scalar.
0019f31f Attribute 'value_strings' expect a list of strings.
0019f353 Dividend tensor
0019f364           {
0019f370             HS_X = HardSigmoid<alpha = 0.16666667163372, beta = 0.5>(X)
0019f3b8             Y = Mul (X, HS_X)
0019f3d6           }
0019f3e2         
0019f3eb Softmax(input, axis) = Exp(input) / ReduceSum(Exp(input), axis=axis, keepdims=1) 
0019f43d Whether to return the elements in sorted order.
0019f46d The cosine of the input tensor computed element-wise
0019f4a2 loss = Squeeze (loss_N1dd, axes)
0019f4c3 Type of reduction to apply to loss: none, sum, mean(default). 'none': no reduction will be applied, 'sum': the output will be summed. 'mean': the sum of the output will be divided by the number of elements in the output.
0019f5a0 sample_rate
0019f5ac signal
0019f5b3 List of tensors for 
0019f5c8 The data type of the output tensor. Strictly must be one of the values from DataType enum in TensorProto whose values correspond to T2. The default value is 1 = FLOAT. 
0019f671 size
0019f676 legacy optimization attribute.
0019f695 The output values with the same shape as the input tensor.
0019f6d0 Input tensor X must have at least 2 dimensions.
0019f700 Stride along each spatial axis. If not present, the stride defaults to 1 along each axis.
0019f75a BuildContextDependentFunctionBodyLayerNormalization
0019f78e The weight tensor that will be used in the convolutions; has size (C x M/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the weight shape will be (C x M/group x k1 x k2 x ... x kn), where (k1 x k2 x ... x kn) is the dimension of the kernel. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)
0019f977 Shape3D = Constant <value_ints = [0, 0, -1]> ()
0019f9a7 Biased = Add (Scaled, BiasReshaped)
0019f9cb Dilation value along each spatial axis of filter.
0019f9fd The running mean after the BatchNormalization operator. Must be in-place with the input mean. Should not be used for testing.
0019fa7b Allowed values are 'half_pixel' and 'output_half_pixel'. Use the value 'half_pixel' to pixel shift the input coordinates by -0.5 (the recommended behavior). Use the value 'output_half_pixel' to omit the pixel shift for the input (use this for a backward-compatible behavior).
0019fb8f RoIs (Regions of Interest) to pool over; rois is 2-D input of shape (num_rois, 4) given as [[x1, y1, x2, y2], ...]. The RoIs' coordinates are in the coordinate system of the input image. Each coordinate set has a 1:1 correspondence with the 'batch_indices' input.
0019fc97 The shape format of inputs X, initial_h and outputs Y, Y_h. If 0, the following shapes are expected: X.shape = [seq_length, batch_size, input_size], Y.shape = [seq_length, num_directions, batch_size, hidden_size], initial_h.shape = Y_h.shape = [num_directions, batch_size, hidden_size]. If 1, the following shapes are expected: X.shape = [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length, num_directions, hidden_size], initial_h.shape = Y_h.shape = [batch_size, num_directions, hidden_size].
0019fe99 ) than declared (
0019feab ' is expected to have field 'floats'
0019fed0 ' is expected to have field 'tensors'
0019fef6 additional_inputs
0019ff08 Constrain input types to any sequence type.
0019ff34 target sequence type missing element type.
0019ff5f Input tensor of [N,C,H,W], where N is the batch axis, C is the channel or depth, H is the height and W is the width.
0019ffd4 Four modes: "round_prefer_floor" (default, as known as round half down), "round_prefer_ceil" (as known as round half up), "floor", "ceil". Only used by nearest interpolation. It indicates how to get "nearest" pixel in input tensor from x_original, so this attribute is valid only if "mode" is "nearest".
001a0104 If set to 1, "linear" and "cubic" interpolation modes will use an antialiasing filter when downscaling. Antialiasing is achieved by stretching the resampling filter by a factor max(1, 1 / scale), which means that when downsampling, more input pixels contribute to an output pixel.
001a021d 4-D tensor of shape (N, C, H_out, W_out) of sampled values. For integer input types, intermediate values are computed as floating point and cast to integer at the end.
001a02c5 A 1-D INT64 tensor containing, for elements of 'X', its corresponding indices in 'Y'. When 'axis' is provided, it contains indices to subtensors in output 'Y' on the 'axis'. When 'axis' is not provided, it contains indices to values in output 'Y'. 
001a03be Both 'split' input and 'num_outputs' attribute were given
001a03f8 'axes' attribute must not contain any duplicates
001a0429  values. Got 
001a0437 Rank 1 tensor of booleans to indicate which slices or data elements to be selected. Its length can be less than the input length alone the axis or the flattened input size if axis is not specified. In such cases data slices or elements exceeding the condition length are discarded.
001a0551 Attribute value for pads is required
001a0576 ) is not equal to the existing dim value (
001a05a1 The input type is a tensor of any shape.
001a05ca The index of the target that each weight is for
001a05fa seq(map(int64, float))
001a0611 optional_type
001a061f Invalid RE2: 
001a0630 missing )
001a063f Cherokee
001a0648 Hanifi_Rohingya
001a0658 Hatran
001a065f Javanese
001a0670 moneypunct_byname failed to construct for 
001a069b Friday
001a06a2 : out of range
001a06b1 dynamic_cast
001a06c4 short
001a06ca ostream
001a06d2 long double
001a06de __cxa_guard_acquire
001a06f2 libc++abi
001a0703 IsTensor()
001a070e value_type != nullptr
001a0724 Encountered unknown exception in LoadWithLoader()
001a0756 Invalid Output Name:
001a076b ModelProto needs to be parsed to check for ORT config within it
001a07ab Unexpected input data type. Actual: (
001a07d1 ParseSessionOptionsFromModelProto
001a07f3 Unsupported value for intra_op_num_threads: 
001a0820 Unsupported execution_mode value in ORT config: 
001a0851 true
001a0856 invalid string: control character U+001F (US) must be escaped to \u001F
001a08a2 ::OrtKernelInfo output does not have a type
001a08ce BindInput
001a08d8 mapped_output_names_.size() == output_names_.size()
001a090c tensor(float)
001a091a , but its version is not 
001a0934 SessionOptionsAppendExecutionProvider_CANN: Failed to load shared library
001a097e const T &onnxruntime::OpKernelContext::RequiredInput(int) const [T = onnxruntime::Tensor]
001a09d8 onnxruntime::Tensor &onnxruntime::OpKernelContext::RequiredOutput(int, const onnxruntime::TensorShape &)
001a0a41 T *onnxruntime::Tensor::MutableData() [T = unsigned short]
001a0a7c ] as part of the NodeUnit type: [
001a0a9e ANeuralNetworksExecution_free
001a0abc ANeuralNetworksExecution_startComputeWithDependencies
001a0af2 nnapi error: unable to open function %s
001a0b1b libandroid.so
001a0b29 AveragePool
001a0b35 CheckIsInitializer
001a0b48 GlobalMaxPool
001a0b56 on create
001a0b60 AddNnapiReshape
001a0b70  zero point dimension 
001a0b87 quant_op_type != QuantizedOpType::Unknown
001a0bb1 ] name [
001a0bba blocksize
001a0bc4 New shape of reshape must be known
001a0be7 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/resize_op_builder.cc
001a0c4a . input_size_c, 
001a0c5b SoftMax only support axis 1 on Android API level: 
001a0c8e Squeeze only supports 1-4d shape, input is 
001a0cba perm
001a0cbf ceil_mode == 1 is not supported for pooling
001a0ceb  than the output_zp: 
001a0d01 ConvBase
001a0d0a unsupported Conv in/out data type:
001a0d2d QUINT8
001a0d34 ret.IsOK()
001a0d3f xnn_setup_average_pooling2d_nhwc_
001a0d61 xnn_setup_deconvolution2d_nhwc_
001a0d81 GeluFusion
001a0d8c GeluApproximation
001a0d9e node_index < nodes_.size()
001a0db9 Fused Gemm with Sum
001a0dcd other_sum_input != nullptr
001a0de8 Could not find OrtValue with name '
001a0e0c MatchUnidirMaskSubgraph
001a0e24 mask_mul const input not matched
001a0e45 gather indices not matched.
001a0e61 Failed to convert mask to int32
001a0e81 ConstantOfShape
001a0e91 Segment id is not valid. 
001a0eab Squeeze for Fused Gather nodes
001a0eca BiasSoftmax
001a0ed6 /onnxruntime_src/onnxruntime/core/optimizer/insert_cast_transformer.cc
001a0f1d fused Matmul and Add 
001a0f37 /onnxruntime_src/onnxruntime/core/graph/extended_graph_edge.h
001a0f75 onnxruntime::Node *onnxruntime::graph_utils::ExtendedGraphEdge::GetMutableNodeAtEnd(onnxruntime::Graph &, onnxruntime::graph_utils::ExtendedGraphEdge::End) const
001a1017 generated at runtime
001a102c /onnxruntime_src/onnxruntime/core/optimizer/quick_gelu_fusion.cc
001a106d /onnxruntime_src/onnxruntime/core/optimizer/rocm_blas_alt_impl.cc
001a10af size >= 0
001a10b9  domain not found in opset imports.
001a10dd Transpose Optimizer is adding an unexpected node: 
001a1110 Acos
001a1115 auto onnxruntime::optimizer_utils::GetClipConstantMinMax(const onnxruntime::Graph &, const onnxruntime::Node &, float &, float &)::(anonymous class)::operator()(const onnxruntime::Node &, size_t, float &) const
001a11e8 /onnxruntime_src/onnxruntime/core/providers/cpu/controlflow/scan_8.cc
001a122e void onnxruntime::scan::detail::ReadDirections(const onnxruntime::OpKernelInfo &, const std::string &, onnxruntime::TensorShapeVector &, size_t)
001a12bf  is not compatible with 
001a12d8  inputs. Found:
001a12e8 gsl::narrow_cast<int64_t>(input_axes_.size()) == num_scan_inputs_
001a132a Could not infer data type from input tensor with data type 
001a1366 info.GetAttr<int64_t>("dtype", &dtype).IsOK()
001a1394 exclusive
001a139e Input tensor should have a rank of at least 2
001a13cc Matrix dimensions are not equal. Square matrix is expected
001a1407 Einsum op: An implementation for the input type 
001a1438 input_shape_1_override.size() == 3 && input_shape_2_override.size() == 3
001a1481 The only subscript labels allowed are lower-cased letters (a-z) and upper-cased letters (A-Z)
001a14df virtual onnxruntime::common::Status onnxruntime::Max_6<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
001a1558 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Neg<double>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Neg<double>]
001a1617 onnxruntime::BitShift<unsigned int>::BitShift(const onnxruntime::OpKernelInfo &) [T = unsigned int]
001a167b Invalid start/ending offset [
001a1699 start_offset % span_size == 0 && real_end % span_size == 0
001a16d4 fmod attribute must be true for floating point types
001a1709 input count mismatch, expected 1 input - the tensor to be processed
001a174d Invalid argument: X input has empty dimensions.
001a177d /onnxruntime_src/onnxruntime/core/providers/cpu/ml/category_mapper.h
001a17c2 onnxruntime::ml::DictVectorizerOp<std::basic_string<char>, double>::DictVectorizerOp(const onnxruntime::OpKernelInfo &) [AttrType = std::basic_string<char>, TargetType = double]
001a1874 keys_int64s
001a1880 values is 
001a188b  Found:
001a1893 Unexpected NORMALIZE value of 
001a18b2 OneHotEncoder
001a18c0 nodes_nodeids
001a18ce base_values.empty()
001a18e2 it->i < (int64_t)predictions.size()
001a1906 compute
001a190e void onnxruntime::ml::detail::TreeEnsembleCommon<double, double, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = double, ThresholdType = double, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorMax<double, double, float>]
001a1a65 (for attribute '
001a1a76 onnxruntime::MaxUnpool::MaxUnpool(const onnxruntime::OpKernelInfo &)
001a1abb kernel_shape_[dim] > 0
001a1ad2 ratio input should have a single value.
001a1afa onnxruntime::LRN<float>::LRN(const onnxruntime::OpKernelInfo &) [T = float]
001a1b46 pooled_shape
001a1b53 onnxruntime::TfIdfVectorizer::TfIdfVectorizer(const onnxruntime::OpKernelInfo &)
001a1ba4  >= 
001a1ba9 !pool_strings.empty()
001a1bbf boxes_tensor
001a1bcc QLinearConv : input zero point must be a scalar or 1D tensor of size 1
001a1c13 void onnxruntime::ValidateFastReduceRK(const gsl::span<const int64_t> &, const onnxruntime::Tensor &)
001a1c79 void onnxruntime::ValidateMustBeOverloaded()
001a1ca6 Input sequence_lens must have shape {
001a1ccc relu
001a1cd1 std::string onnxruntime::rnn::detail::NormalizeActivationArgumentAndGetAlphaBetaCount(const std::string &, std::vector<float>::const_iterator &, const std::vector<float>::const_iterator &, std::vector<float>::const_iterator &, const std::vector<float>::const_iterator &, float &, float &)
001a1df2 const T *onnxruntime::rnn::detail::SafeRawConstPointer(gsl::span<const T>, size_t, size_t) [T = float]
001a1e59 SequenceAt
001a1e64 SequenceInsert
001a1e73 SplitToSequence operator does not support 
001a1e9e int64_t onnxruntime::GetSeqIdx(const onnxruntime::Tensor &)
001a1eda virtual onnxruntime::common::Status onnxruntime::STFT::Compute(onnxruntime::OpKernelContext *) const
001a1f3f onnxruntime::Col2Im<float>::Col2Im(const onnxruntime::OpKernelInfo &) [T = float]
001a1f91 EyeLike
001a1f99 padding_mode
001a1fa6 Unable to get an allocator
001a1fc1 virtual onnxruntime::common::Status onnxruntime::IdentityOp<false>::Compute(onnxruntime::OpKernelContext *) const [is_dropout = false]
001a2048 MeanVarianceNormalization CPU EP only supports NHW and NCHW reduction for axes attribute.
001a20a2 Invalid argument for depth; it's not a scalar.
001a20d1 i < input_shape.NumDimensions()
001a20f1 , data shape: 
001a2100 CPU execution provider: BFloat16 data type is not supported with ScatterND opset 16 when reduction is 'add'.
001a216d input_shape[i] == 1
001a2181 Tile doesn't have an implementation yet for the type: 
001a21b8 naxes > 0
001a21c2 bool onnxruntime::TypedDoTransposeEltWise(int64_t, gsl::span<const int64_t>, size_t, const gsl::span<const size_t> &, const uint8_t *, uint8_t *) [T = unsigned short]
001a2269 gamma is expected to have 1 dimensions, got 
001a2296 AttnLSTM
001a229f  [seqno=
001a22a8 auto onnxruntime::contrib::NGramRepeatBlock::Compute(onnxruntime::OpKernelContext *)::(anonymous class)::operator()(int64_t) const
001a232b /onnxruntime_src/onnxruntime/contrib_ops/cpu/crop.h
001a235f SparseToDenseMatMul
001a2373  vs inner_B: 
001a2381  is out of bounds of lhs_right: 
001a23a2 Unsupported mode '
001a23b5 Beta scale must be a scalar or 1D tensor of size 1
001a23e8 Input scale is not float for input def @
001a2411 void onnxruntime::contrib::(anonymous namespace)::BuildLookupTableIfFixed(const onnxruntime::OpKernelInfo &, std::vector<QLinearSoftmax::EXP_OUT_DTYPE> &, size_t, bool)
001a24ba num_return_sequences
001a24cf parameters->sequence_length == 1
001a24f0 pad_token_id
001a24fd seed >= 0
001a2507 onnxruntime::common::Status onnxruntime::contrib::transformers::GptSubgraph::CreateInitialFeeds(const onnxruntime::Tensor &, const std::vector<const OrtValue *> &, int, int, gsl::span<int32_t> &, OrtValue &, const OrtValue *, std::vector<OrtValue> &, const GenerationDeviceHelper::CreateGptInputsFunc &, const GenerationDeviceHelper::AddToFeedsFunc &, IAllocatorUniquePtr<char> &, onnxruntime::Stream *, int)
001a26a0 number of outputs expected to be kFirstPastInputIndex + 4 * layers, got:
001a26e9 encoder subgraph outputs 1, 2, ... shall have same data type
001a2726 OpenVINO_GPU
001a2733 /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc
001a276c virtual void *onnxruntime::BFCArena::Reserve(size_t)
001a27a1  bytes. 
001a27aa void onnxruntime::BFCArena::InsertFreeChunkIntoBin(BFCArena::ChunkHandle)
001a27f4 Summary of in-use chunks by size: 
001a2817 AddConfigEntry
001a2826 virtual void onnxruntime::NonTensorTypeBase::FromDataContainer(const void *, size_t, OrtValue &) const
001a288d /onnxruntime_src/onnxruntime/core/framework/device_stream_collection.cc
001a28d5 onnxruntime::common::Status onnxruntime::IExecutionFrame::GetOrCreateNodeOutputMLValue(const int, int, const onnxruntime::TensorShape *, OrtValue *&, const onnxruntime::Node &)
001a2986  failed. Error:
001a2996 Candidate for fallback CPU execution: 
001a29bd Error mapping output names: 
001a29da Create state function failed. Return value:
001a2a06  (node_version: 
001a2a17 Failed to verify KernelTypeStrResolver flatbuffers data.
001a2a50  is defined.
001a2a5d  but is of type: 
001a2a6f /onnxruntime_src/onnxruntime/core/framework/session_options.cc
001a2aae allocator_for_caching.get() != nullptr
001a2ad5  All nodes placed on [
001a2aec SaveConfig
001a2af7 int &onnxruntime::PlannerImpl::UseCount(onnxruntime::OrtValueIndex)
001a2b3f ActivateNotificationStep: activate notification with id: 
001a2b79 session.use_device_allocator_for_initializers
001a2ba7  failed.
001a2bb0 Internal error. The preallocated buffer is too small. Requires 
001a2bf0 Must contain Coo format. Got: 
001a2c0f onnxruntime::Tensor::Tensor(onnxruntime::MLDataType, const onnxruntime::TensorShape &, std::shared_ptr<IAllocator>, gsl::span<const int64_t>)
001a2c9d size_t onnxruntime::Tensor::SizeInBytes() const
001a2ccd Invalid dimension of 
001a2ce3 Invalid TensorProto
001a2cf7  in 'Constant' node '
001a2d0d model format error!
001a2d21 const OrtMemoryInfo &onnxruntime::utils::FindMemoryInfoForValue(const onnxruntime::SessionState &, std::string_view)
001a2d96 exec_plan_ptr
001a2da4 FindMemoryInfoForValue
001a2dbb BatchOrCopyMLValue
001a2dce feed_streams.size() == num_feeds
001a2def When past_present_share_buffer is used, it is required to specify past_sequence_length (could be 0).
001a2e54 2D input tensor with shape (hidden_size, 3 * hidden_size)
001a2e8e key_cache
001a2e98 Constrain input and output float tensors types.
001a2ec8 Input tensor with shape (batch_size, sequence_length, hidden_size)
001a2f0b Input tensor with shape (total_tokens, hidden_size)
001a2f3f [TypeInferenceError] 
001a2f55  expected to have tensor type
001a2f73  = Constant()
001a2f81 Error unexpected extra input in node:
001a2fa7 Failed to parse num_beams or it is not positive integer scalar
001a2fe6 seed
001a2feb The number of returned sequences in the batch. Shape is (1)
001a3027 Rfft
001a302c Whether A should be transposed on the last two dimensions before doing multiplication
001a3082 1-D tensor of shape (num_rois,) with each element denoting the index of the corresponding image in the batch.
001a30f0 Input data tensor from the previous layer.
001a311b The detection_classes output tensor.
001a3140 Box IOU threshold value.
001a3159 Image size.
001a3165 notes
001a316b  != mat_h:
001a3176  expected to have rank >
001a318f crop_size shape input tensor has wrong dimension
001a31c0 Scale2D = Flatten <axis = 0> (Scale)
001a31e5 InvStdDev2D = Reciprocal (StdDev)
001a3207 The bias tensor for input gate. Concatenation of `[Wb[iofc], Rb[iofc]]`, and `[WBb[iofc], RBb[iofc]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 8*hidden_size]`. Optional: If not specified - assumed to be 0.
001a32fa memory_seq_lens
001a330a Bias tensor. Dimensions are (D), where D is the same hidden dimension as input tensor
001a3360 Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
001a355b 1D input tensor
001a356b extra_shape
001a3577 GivenTensorFill
001a3587 ) + bottom_border (
001a359b Constrain the input to float and bfloat.
001a35c4 Concatenated tensor
001a35d8 z_scale
001a35e0 Zero point tensor for input 'A'. It is a scalar.
001a3611 Zero point tensor for output 'Y'. It is a scalar, which means a per-tensor quantization. It is optional. The output is full precision(float32) if it is not provided. Or the output is quantized.
001a36d3 scale of the output Y.
001a36ea 3d or 2d matrix C. if 2d expand to 3d first. Shape[0] should be 1 or same as A.shape[0] 
001a3743 Hidden layer sizes of Q, K, V paths in Attention
001a3774 order_X
001a377c  should be of integer type and specify a type.
001a37ab delta
001a37b1 word_embedding should have 2 dimensions and dimension size is known.
001a37f6 utils::HasName(sparse_tensor)
001a3814  appears in graph inputs and will not be treated as constant value/weight. 
001a3860 onnxruntime::common::Status onnxruntime::Graph::Resolve(const onnxruntime::Graph::ResolveOptions &)
001a38c4 void onnxruntime::Graph::AddInitializedTensor(const onnx::TensorProto &)
001a390d  target:
001a3916 SaveSparseInitializerOrtFormat
001a3935 STRINGS
001a393d onnxruntime::GraphViewer::GraphViewer(const onnxruntime::Graph &, const onnxruntime::IndexedSubGraph *)
001a39a5 , but it its domain is not
001a39c0 Found invalid processor id in affinity string: 
001a39f0 Parse
001a39f6 Node
001a39fe file_path == nullptr
001a3a13 value_type
001a3a1e TensorProto ( tensor name: 
001a3a3a values of data_type '
001a3a50 ) must have rank 1.
001a3a64 Attribute (name: 
001a3a76  initializer name is not unique
001a3a96  OpType: 
001a3aa0 optional(tensor(uint8))
001a3ab8 An optional list of M flags. The i-th element of the list specifies the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted, 0 will be used as the scan axis for every scan_input.
001a3b82 (Optional) Index of the diagonal to be populated with ones. Default is 0. If T2 is the output, this op sets T2[i, i+k] = 1. k = 0 populates the main diagonal, k > 0 populates an upper diagonal,  and k < 0 populates a lower diagonal.
001a3c6b Constrain output types to integral tensors.
001a3c97 Constrain input types to all numeric tensors.
001a3cc5 Coefficient of SELU default to 1.05070102214813232421875 (i.e., float32 approximation of 1.0507009873554804934193349852946).
001a3d42 Constrain input X and output types to float tensors.
001a3d77 inverse
001a3d7f Blackman
001a3d88 Invalid value for attribute axis
001a3da9 Input tensor C, can be inplace.
001a3dc9 Second operand. With broadcasting can be of smaller size than A. If broadcasting is disabled it should be of the same size.
001a3e45 Invalid value for attribute k
001a3e63 The order of the normalization, only 1 or 2 are supported.
001a3e9e The weighting criteria. It can be one of "TF" (term frequency), "IDF" (inverse document frequency), and "TFIDF" (the combination of TF and IDF)
001a3f2f         {
001a3f39           Exponent = Constant <value = float {2.0}>()
001a3f6f           Epsilon = Constant <value = float {1e-9}>()
001a3fa5           axes = Constant <value_ints: ints = @axes>()
001a3fdc           X_RM = ReduceMean (X, axes)
001a4002           EX_squared = Pow (X_RM, Exponent)
001a402e           X_squared = Pow (X, Exponent)
001a4056           E_Xsquared = ReduceMean (X_squared, axes)
001a408a           Variance = Sub (E_Xsquared, EX_squared)
001a40bc           STD = Sqrt (Variance)
001a40dc           X_variance = Sub (X, X_RM)
001a4101           Processed_STD = Add (STD, Epsilon)
001a412e           Y = Div (X_variance, Processed_STD)
001a415c         }
001a4166         
001a416f GroupSize = Div (C, NumGroups)
001a418e NewShape = Concat <axis = 0> (N, NumGroups, GroupSize, InstanceShape)
001a41d4 BiasReshaped = Reshape (BiasT, ScaleShape)
001a41ff Scaled = Mul (ScaleReshaped, Normalized)
001a4228 The pooling method. Two modes are supported: 'avg' and 'max'. Default is 'avg'.
001a4278 Float representing the threshold for deciding when to remove boxes based on score. It is a scalar.
001a42db doc_string
001a42e6 Cannot find a function builder that satisfies the requested opset version: op_type = 
001a433c Graph attribute inferencer for "body" not available
001a4370 SequenceMap_loop_body
001a4386 Constrain to any tensor or sequence type.
001a43b0 source map type missing value type.
001a43d4 Target size of the output tensor. Its interpretation depends on the 'keep_aspect_ratio_policy' value.The number of elements of 'sizes' should be the same as the rank of input 'X', or the length of 'axes', if provided. Only one of 'scales' and 'sizes' can be specified. 
001a44e2 ) and outputs (
001a44f2 Both `data` and `indices` input tensors in GatherND op need to have rank larger than 0.
001a454a Too many axes provided
001a4561 The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if "mode" is "cubic".
001a466e Invalid Target shape product of 0
001a4690 Selected output data as an array
001a46b1 The input map that is to be cast to a tensor
001a46de A tensor representing the same data as the input map, ordered by their keys
001a472a If the value of map_form is 'SPARSE,' this attribute indicates the total length of the output tensor.
001a4790 map(int64, double)
001a47a3 A list of floats.
001a47b5 Encoded output data
001a47c9 prob_b
001a47d0 N, Top class for each point
001a47ec onnx.TypeProto.Opaque
001a4802 /build/intermediates/arm64-v8a/Release/_deps/protobuf-src/src/google/protobuf/parse_context.h
001a4860 Unhandled 
001a486b no error
001a4874 DoCoalesce failed: r1->op() is 
001a4894 {%d,}
001a489a (){}[]*+?|.^$\
001a48a9 Arabic
001a48b0 Cham
001a48b5 Deseret
001a48bd Linear_B
001a48c6 Old_Italic
001a48d1 Thaana
001a48d8 attempt to nsync_mu_unlock() an nsync_mu not held in write mode
001a4919 Kirin 
001a4920 ro.board.platform
001a4932 Thursday
001a4943 guard variable for 
001a495a operator?
001a4964 unexpected
001a496f libunwind: %s - %s
001a498a Can not use strings in pre-allocated memory. Use CreateSparseTensorAsOrtValue() to allocate memory inside and copy
001a49fd input name cannot be empty
001a4a18 element index is out of bounds
001a4a37 Specified domain and type names combination does not refer to a registered opaque type
001a4a8e Not able to find appropriate IDataTransfer to copy sparse data
001a4acd utils::IsPrimitiveDataType<T>(dtype_)
001a4af3 OrtStatus *OrtCreateMapMLValue(const onnxruntime::Tensor &, const onnxruntime::Tensor &, OrtValue **) [KeyType = std::basic_string<char>, ValueType = float]
001a4b90 Having memory pattern enabled is not supported while using the DML Execution Provider. 
001a4be8 Failed to save ORT format model to file: 
001a4c12 session.use_env_allocators
001a4c2d MemcpyTransformer
001a4c3f /onnxruntime_src/onnxruntime/core/framework/mldata_type_utils.h
001a4c7f /onnxruntime_src/onnxruntime/core/framework/feeds_fetches_manager.h
001a4cc3 Did not find session options in the model file to be used while running the model
001a4d15 invalid string: control character U+0004 (EOT) must be escaped to \u0004
001a4d5e invalid number; expected digit after '-'
001a4d87 excessive array size: 
001a4d9e MemcpyFromHost
001a4dad  version: 
001a4db8 Exception caught: 
001a4dcb libonnxruntime_providers_cuda.so
001a4dec Required output at index 
001a4e06 T *onnxruntime::Tensor::MutableData() [T = unsigned long]
001a4e40 kernel already mapped to existing node
001a4e67 Using default partitioning stop ops list.
001a4e91 ANeuralNetworksModel_addOperand
001a4eb1 ANeuralNetworksCompilation_create
001a4ed3 ANeuralNetworksMemoryDesc_create
001a4ef4 SL_ANeuralNetworksDiagnosticCompilationInfo_getNnApiVersion
001a4f30 SL_ANeuralNetworksDiagnosticExecutionInfo_getModelArchHash
001a4f6b ANEURALNETWORKS_BAD_DATA
001a4f84 Invalid indices: begin [
001a4f9d d shape
001a4fa5 Prepare
001a4fad shape_proto cannot be null for output: 
001a4fd5 /zero_bias
001a4fe0 _axes
001a4fe6 Dynamic shape is not supported for now, for input:
001a5019 Clip Node [
001a5028 Relu Node [
001a5034 'axes' has duplicates
001a504a ] has different input_zp: 
001a5065 Sigmoid
001a506d Sqrt
001a5072 XnnpackExecutionProvider
001a508b has_bias == false || info.TryGetConstantInput(2, &B_)
001a50c1 *out_size >= 0
001a50d0 opset
001a50d6 void onnxruntime::xnnpack::GetScaleAndZeroPoint(const onnxruntime::OpKernelInfo &, int, std::vector<float> &, int, uint8_t &, int32_t)
001a515d gsl::span<const T> onnxruntime::xnnpack::ReadConstantValues(const onnxruntime::OpKernelInfo &, int) [T = float]
001a51cd xnn_create_average_pooling2d_nhwc_
001a51f0 opset must be existed in attributes of QlinearSoftmax
001a5226 yet this opset 
001a5236 left_num_dims > 2 && left_num_dims == right_num_dims
001a526b InlinedVector<std::unique_ptr<GraphTransformer>> onnxruntime::optimizer_utils::GenerateTransformers(onnxruntime::TransformerLevel, const onnxruntime::SessionOptions &, const onnxruntime::IExecutionProvider &, const InlinedHashSet<std::string> &)
001a5361 EliminateIdentity
001a5373 FuseReluClip
001a5380 new_gemm_input_defs.size() == 3
001a53a0 /onnxruntime_src/onnxruntime/core/optimizer/conv_mul_fusion.cc
001a53df ConvActivationFusion
001a53f4 with activation 
001a5405 DynamicQuantizeMatMul
001a541f Gemm weight shape is not expected
001a5441 Position embedding shape not matched.
001a5467 split
001a546d Unsqueeze for Fused Gather nodes
001a548e stash_type
001a5499 /onnxruntime_src/onnxruntime/core/optimizer/matmul_scale_fusion.cc
001a54dc output_node.OutputDefs().size() == 1
001a5501 allocator_ptr_
001a5510 InsertQDQPair
001a551e _post_dq
001a5527 dst_node != nullptr
001a553b _min_zero_constant
001a554e /onnxruntime_src/onnxruntime/core/optimizer/skip_layer_norm_fusion.cc
001a5594 Failed to get size of TensorProto
001a55b6 Added in transpose optimizer
001a55d3 Softsign
001a55dc Sinh
001a55e1 /onnxruntime_src/onnxruntime/core/providers/partitioning_utils.cc
001a5623 /onnxruntime_src/onnxruntime/core/providers/cpu/activation/activations.h
001a566e valid
001a5674 AllocateFinalBuffer
001a5688 onnxruntime::If::Info::Info(const onnxruntime::Node &, const onnxruntime::GraphViewer &)
001a56e1 num_subgraph_outputs == static_cast<size_t>(num_outputs)
001a571a /onnxruntime_src/onnxruntime/core/providers/cpu/controlflow/loop.cc
001a575e virtual onnxruntime::common::Status onnxruntime::Scan<9>::Compute(onnxruntime::OpKernelContext *) const [OpSet = 9]
001a57d2 onnxruntime::RandomUniformLike::RandomUniformLike(const onnxruntime::OpKernelInfo &)
001a5827 info.GetAttr<int64_t>("sample_size", &num_samples_).IsOK()
001a5862 Einsum
001a5869 Einsum op: The candidate output does not match the actual output's shape
001a58b2  in the same dimension
001a58c9 The override dims are not compatible with given tensor's shape. 
001a590a right.Shape().Size() == right_shape_override.Size()
001a593e virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Abs<signed char>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Abs<signed char>]
001a5a07 Can broadcast 0 by 0 or 1. 
001a5a23 void onnxruntime::TopkOpset11ConstructorCommon(const onnxruntime::OpKernelInfo &, int &, bool &, bool &)
001a5a8c op_kernel_info.GetAttr<int64_t>("sorted", &sorted_temp).IsOK()
001a5acb replaced_value_int64
001a5ae0 info.GetAttrs<std::string>("classes_strings", string_classes).IsOK()
001a5b25 void onnxruntime::ml::CastInputToFloat(const onnxruntime::Tensor &, gsl::span<float> &) [SrcType = int]
001a5b8d One falsenode is pointing either to itself, either to another tree.
001a5bd1 BRANCH_GTE
001a5bdc BRANCH_GT
001a5be6 virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommon<float, float, float>::compute(onnxruntime::OpKernelContext *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *) const [InputType = float, ThresholdType = float, OutputType = float]
001a5d04 void onnxruntime::ml::detail::TreeAggregatorSum<float, float, float>::MergePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = float, ThresholdType = float, OutputType = float]
001a5dfd  C: 
001a5e02 X->Shape().NumDimensions() == 4
001a5e22 virtual onnxruntime::common::Status onnxruntime::RoiPool<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
001a5e9d pooled_shape.size() == 2
001a5eb6 Empty stopwords not allowed
001a5ed2 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/tfidfvectorizer.cc
001a5f18  id: 
001a5f1e IsScalarOr1ElementVector(X_Zero_Point)
001a5f45 Reduction on all axes, output size should be 1.
001a5f75 tanh
001a5f7a /onnxruntime_src/onnxruntime/core/providers/cpu/rnn/lstm_base.h
001a5fba Got nullptr for sequence input.
001a5fda virtual onnxruntime::common::Status onnxruntime::SequenceEmpty::Compute(onnxruntime::OpKernelContext *) const
001a6048 Invalid value in 'split' input. All values must be >= 0
001a6080 BlackmanWindow
001a6093 virtual onnxruntime::common::Status onnxruntime::Compress::Compute(onnxruntime::OpKernelContext *) const
001a60fc onnxruntime::common::Status onnxruntime::DispatchStridedCopy(concurrency::ThreadPool *, onnxruntime::Tensor &, std::ptrdiff_t, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShape &, const onnxruntime::Tensor &, std::ptrdiff_t, const onnxruntime::TensorShapeVector &) [EnabledDataTypes = onnxruntime::TypeList<int, long, float, double, unsigned long, unsigned int, short, unsigned short, signed char, unsigned char, onnxruntime::MLFloat16, onnxruntime::BFloat16, bool, std::basic_string<char>>]
001a62fd src and dst must have same shape and not be rank 0.
001a6331 total_num_elements_to_copy >= 0
001a6351 copy shape must have non-negative size
001a6378 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/gatherbase.h
001a63bc Failed to obtain detect_positive
001a63dd onnxruntime::common::Status onnxruntime::PadImpl(onnxruntime::OpKernelContext *, const onnxruntime::PadsVector &, const onnxruntime::PadsVector &, const onnxruntime::Mode &, T) [T = unsigned char]
001a64a2 gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = unsigned long]
001a64f1 Indices dim=
001a6502 SpaceToDepth requires input height to be a multiple of block_size
001a6544 v >= 0 && static_cast<uint64_t>(v) <= std::numeric_limits<size_t>::max()
001a658d  is repeated.
001a659b Rank of input and output tensor should be same.
001a65cb Upsample: input/output value is nullptr
001a65f3 not support normalize yet.
001a660e Crop
001a6613 Input is expected to have four dimensions corresponding to [N,C,H,W], got 
001a665e MaxpoolWithMask
001a666e QAttention
001a6679 MatmulInteger : b zero point is not valid
001a66a3 Word embedding scale must be a scalar or 1D tensor of size 1
001a66e0 void onnxruntime::contrib::(anonymous namespace)::QLinearImpl(onnxruntime::OpKernelContext &, double, const onnxruntime::ProcessBroadcastSpanFuncs &) [T = unsigned char]
001a678a onnxruntime::contrib::QLinearConcat::QLinearConcat(const onnxruntime::OpKernelInfo &)
001a67e0 onnxruntime::contrib::QLinearWhere::QLinearWhere(const onnxruntime::OpKernelInfo &)
001a6834 !tokenexp.empty()
001a6846 Input 'attention_mask' is expected to have same shape as input_ids
001a6889 max_length
001a6894 num_return_sequences >= 1
001a68ae present_key_self_0
001a68c1 Specified device is not supported.
001a68e4 h < chunks_.size()
001a68f7 DumpMemoryLog
001a6905 /onnxruntime_src/onnxruntime/core/framework/bfc_arena.h
001a693d /onnxruntime_src/onnxruntime/core/framework/execution_frame.h
001a697b /onnxruntime_src/onnxruntime/core/framework/execution_provider.cc
001a69bd std::unordered_set<NodeIndex> onnxruntime::GetCpuPreferredNodes(const onnxruntime::GraphViewer &, const IExecutionProvider::IKernelLookup &, gsl::span<const NodeIndex>)
001a6a66  because the CPU execution path is deemed faster than overhead involved with execution on other EPs 
001a6acb /onnxruntime_src/onnxruntime/core/framework/feeds_fetches_manager.cc
001a6b10 Error mapping feeds: 
001a6b26 , but was not selected
001a6b3d onnxruntime::common::Status onnxruntime::SessionState::FinalizeSessionStateImpl(const std::basic_string<PATH_CHAR_TYPE> &, const onnxruntime::KernelRegistryManager &, const onnxruntime::Node *, const onnxruntime::SessionOptions &, bool, InlinedHashMap<std::string, size_t> &, const InlinedHashMap<onnxruntime::OrtValueName, OrtMemoryInfo> &, bool)
001a6c99 The kernel corresponding to the node 
001a6cbf Rerunning with verbose output on a non-minimal build will show node assignments.
001a6d10 void onnxruntime::AccumulateAllNestedSubgraphsInfo(const onnxruntime::SessionState &, const std::string &, size_t, onnxruntime::SubgraphsKernelCreateInfoMaps &)
001a6db1 virtual onnxruntime::common::Status onnxruntime::DeviceBasedPartitioner::PartitionGraph(const onnxruntime::GraphViewer &, const onnxruntime::ExecutionProviders &, std::vector<InlinedVector<NodeIndex>> &, onnxruntime::ExecutionOrder)
001a6e9a Failed to find node "
001a6eb0 virtual onnxruntime::common::Status onnxruntime::WaitOnEPStep::Execute(onnxruntime::StreamExecutionContext &, size_t, onnxruntime::SessionScope &, const bool &, bool &)
001a6f59 ExecuteKernel
001a6f67 provider
001a6f70 output_type_shape
001a6f82 Done saving initialized tensors
001a6fa2 SparseCooToDenseTensor
001a6fb9 Exiting due to terminate flag being set to true.
001a6fea int64_t onnxruntime::TensorShape::SizeFromDimension(size_t) const
001a702c Unsupported OrtValue type to copy between device.
001a705e , this is not supported yet.
001a707b new_key_cache
001a7089 tokens
001a7090 Error parsing node:
001a70a4 'pads' input must be a 1D (shape: [2 * n_input_dims]) tensor of type int64
001a70ef A 0-D bool tensor. If given, this will scale gradients by the inverse of frequency of the indices (words) in the mini-batch. Default  is ``False``
001a7182 Constrain input types to all tensor types.
001a71ad The id of the padding token
001a71c9 If set to float < 1, only the smallest set of most probable tokens with probabilities that add up to `top_p` or higher are kept for generation.
001a7259 Presence penalty mask. Shape is (batch_size, vocab_size)
001a7292 Scalar multiplier for the product of the input tensors.
001a72ca sparse_tensor(int32)
001a72df Constrain to tensor(float).
001a72fb SuffixShape = ConstantOfShape (NumReducedAxes)
001a732a Scaled = Mul (NormalizedV, Scale2D)
001a734e Y = Reshape (Biased, XShape)
001a736b Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]` 
001a741b The weight tensor for peepholes. Concatenation of `P[iof]` and `PB[iof]` (if bidirectional) along dimension 0. It has shape `[num_directions, 3*hidde_size]`. Optional: If not specified - assumed to be 0.
001a74e7 Activation after group normalization: 0 for None, 1 for Swish
001a7525 y_zero_point
001a7532 Result, has same type as input, with H and W dimensions reduced.
001a7573 Scale of quantized input 'A'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'A'.
001a7650 data_zero_point
001a7660 R_scale
001a7668 X's scale.
001a7673 Constrain input B and its zero point types to 8 bit tensors.
001a76b0 Constrain input C to 32 bit integer tensors.
001a76dd scale of weight scale. It's a scalar or a 1D tensor, which means a per-tensor/per-column quantization.Its size should be 3 * hidden_size if it is per-column quantization
001a7787 Zero Point for 1D gamma tensor
001a77a6 The output data type, only support TensorProto_DataType_FLOAT (1) and TensorProto_DataType_FLOAT16 (10)
001a780e cublasLt order of matrix Y and optional matrix C
001a783f cublasLt order of global bias
001a785d Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn)
001a7951 Required attribute axis is missing
001a7974 LoadFromOrtFormat
001a7986 Duplicate constant node sparse initializer name: '
001a79b9 This is an invalid model. At top level graph without matching NodeArg that subgraph consumes. Name=
001a7a1d node.GetAttributeNameToMutableSubgraphMap().empty()
001a7a51 InlineFunction
001a7a60 input->Exists()
001a7a70 TypeProto must have shape for this to run
001a7a9a  are '0' and '1'. The environment variable contained the value: 
001a7adb SaveModel
001a7ae5 /onnxruntime_src/onnxruntime/core/graph/node_attr_utils.cc
001a7b20 RegisterOpSet
001a7b2e ), BIsSigned(
001a7b3c /onnxruntime_src/onnxruntime/core/common/logging/logging.cc
001a7b78 enabled_
001a7b81 Maximum number of events reached, could not record profile event.
001a7bc3 " : "
001a7bc9 [ONNXRuntimeError]
001a7bdc unnamed_thread_pool
001a7bf0 {"main_thread": {
001a7c02 }, "sub_threads": {
001a7c16 void onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::LogEnd(onnxruntime::concurrency::ThreadPoolProfiler::ThreadPoolEvent)
001a7c9f , offset: 
001a7caa DeleteFolder
001a7cb7 Failed to unload library with error: 
001a7cdd LoadTensorTypeAndShapeOrtFormat
001a7cfd ) should be a relative path, but it is an absolute path: 
001a7d37 , but it is not regular file.
001a7d55 Sparse tensor (
001a7d65 Loop 'body' subgraph scan outputs should all be tensors but output 
001a7da9 Values that are live-out to the enclosing scope. The return values in the `then_branch` and `else_branch` must be of the same data type. The `then_branch` and `else_branch` may produce tensors with the same element type and different shapes. If corresponding outputs from the then-branch and the else-branch have static shapes S1 and S2, then the shape of the corresponding output variable of the if-node (if present) must be compatible with both S1 and S2 as it represents the union of both possible shapes.For example, if in a model file, the first output of `then_branch` is typed float tensor with shape [2] and the first output of `else_branch` is another float tensor with shape [3], If's first output should have (a) no shape set, or (b) a shape of rank 1 with neither `dim_value` nor `dim_param` set, or (c) a shape of rank 1 with a unique `dim_param`. In contrast, the first output cannot have the shape [2] since [2] and [3] are not compatible.
001a8164 optional(seq(tensor(int64)))
001a8181 optional(tensor(uint32))
001a819a value_int
001a81a8 Scalar. First entry for the range of output values.
001a81dc Constrain input and output types to high-precision numeric tensors.
001a8221           {
001a822d             Alpha = Constant <value_float: float = @alpha>()
001a826a             AlphaCast = CastLike (Alpha, X)
001a8296             Beta = Constant <value_float: float = @beta>()
001a82d1             BetaCast = CastLike (Beta, X)
001a82fb             Zero = Constant <value = float {0.0}>()
001a832f             ZeroCast = CastLike (Zero, X)
001a8359             One = Constant <value = float {1.0}>()
001a838c             OneCast = CastLike (One, X)
001a83b4             AlphaMulX = Mul (X, AlphaCast)
001a83df             AlphaMulXAddBeta = Add (AlphaMulX, BetaCast)
001a8418             MinOneOrAlphaMulXAddBeta = Min (AlphaMulXAddBeta, OneCast)
001a845f             Y = Max(MinOneOrAlphaMulXAddBeta, ZeroCast)
001a8497           }
001a84a3         
001a84ad           {
001a84b9             One = Constant <value = float {1.0}>()
001a84ec             OneCast = CastLike (One, input)
001a8518             AbsInput = Abs(input)
001a853a             OneAddAbsInput = Add (OneCast, AbsInput)
001a856f             output = Div(input, OneAddAbsInput)
001a859f           }
001a85ab         
001a85b4 const_ignore_index
001a85c7 size input must be greater than 0.
001a85ea frame_length input must be scalar.
001a860d input_gather_element
001a8622 This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](Broadcasting.md).
001a86aa MaxUnpool op must have either two or three inputs.
001a86dd Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [-r, r], where r is the rank of the input tensor. Negative value means counting dimensions from the back. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). 
001a8862 string enum that cases output to be lowercased/uppercases/unchanged. Valid values are "LOWER", "UPPER", "NONE". Default is "NONE"
001a88e4 spatial
001a88ec max_output_boxes_per_class
001a8907 log sum
001a890f Input tensor to be inserted into the input sequence.
001a8944 _cond
001a894a Element type of tensor or sparse tensor input was unknown
001a8984 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/tensor/defs.cc
001a89d3 Tensor of int32/int64 indices, of any rank q. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
001a8a90 Constrain to boolean tensors.
001a8aae inverse_indices
001a8abe OneHot node must have three inputs.
001a8ae2 4-D tensor, [N,C,H,W]
001a8af8 Cannot parse data from external tensors. Please 
001a8b29 The id of the tree that this node is in.
001a8b52 Cannot infer type and shape for node name 
001a8b7d Container for generated shape data cannot be nullptr when enable_data_propagation option is set.
001a8bde /build/intermediates/arm64-v8a/Release/_deps/protobuf-src/src/google/protobuf/io/zero_copy_stream.cc
001a8c43 CHECK failed: backup_bytes_ == 0 && buffer_.get() != NULL: 
001a8c7f Bad call to ParseState::ParsePerlFlags
001a8ca9 [:cntrl:]
001a8cb3 Unexpected opcode: 
001a8cc7 /build/intermediates/arm64-v8a/Release/_deps/re2-src/re2/regexp.cc
001a8d0a invalid character class range
001a8d28  [truncated]
001a8d35 Buginese
001a8d3e Common
001a8d45 Khitan_Small_Script
001a8d59 Mahajani
001a8d62 Makasar
001a8d6a Old_South_Arabian
001a8d7c Saurashtra
001a8d8a Tifinagh
001a8d93 unique_lock::lock: references null mutex
001a8dbc failed to allocate %zu bytes for descriptions of %u core clusters
001a8dfe song
001a8e03 tegra132
001a8e0f unspecified iostream_category error
001a8e33 generic
001a8e3b virtual thunk to 
001a8e5b operator*
001a8e65 operator||
001a8e70 istream
001a8e78 char8_t
001a8e80 DW_OP_deref_size with bad size
001a8e9f Unknown DWARF encoding for search table.
001a8ed0 string buffer allocation failed
001a8ef0 internal error
001a8eff const OrtValue &onnxruntime::TensorSeq::GetAt(size_t) const
001a8f3b const onnxruntime::Tensor &OrtValue::Get() const
001a8f6c -inter-op
001a8f76 This session already contains a loaded model.
001a8fa4 This session will use the CUDA Graph feature as requested by the user.
001a8feb model_run
001a8ff5 FeedsFetchesInfo
001a9006  OrtMemType:
001a9013 session_options
001a9023 intra_op_num_threads
001a9038 inter_op_num_threads
001a904d invalid literal
001a905d invalid string: control character U+000E (SO) must be escaped to \u000E
001a90a5 invalid string: control character U+0015 (NAK) must be escaped to \u0015
001a90ee string literal
001a90fd type_id_counter == 1
001a9112 Size mismatch:
001a9121 /onnxruntime_src/onnxruntime/core/session/abi_session_options.cc
001a9162 libonnxruntime_providers_cann.so
001a9183 libonnxruntime_providers_tensorrt.so
001a91a8 const T *onnxruntime::Tensor::Data() const [T = unsigned short]
001a91e8 void *onnxruntime::Tensor::MutableDataRaw(onnxruntime::MLDataType)
001a922b shape_.Size() == new_shape.Size()
001a924d SNPE
001a9252 Release_State_
001a9261 ANeuralNetworksModel_getExtensionOperationType
001a9290 SL_ANeuralNetworksDiagnosticExecutionInfo_getDeviceIds
001a92c7 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/helper.cc
001a931a HasValidBinaryOpQuantizedInputTypes
001a933e ] is not a binary qlinear op
001a935b  of 
001a9360 IsOpSupportedImpl
001a9372 newshape
001a937b The zero point of 
001a938e ] has unsupported type [
001a93a7 dim2: 
001a93ae Concat only supports up to 1-4d shape, input is 
001a93df ] = 
001a93e4 constant_value must be known
001a9401 Input scales of Resize must be known
001a9426 transA
001a942d Only transA == 0, alpha == 1.0 
001a944d C of Gemm can only be 1d tensor for API level 
001a947c ] only supports 2 inputs, 
001a9497 virtual std::vector<std::unique_ptr<ComputeCapability>> onnxruntime::XnnpackExecutionProvider::GetCapability(const onnxruntime::GraphViewer &, const onnxruntime::IExecutionProvider::IKernelLookup &) const
001a9564 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/conv_attributes.h
001a95a9 output_padding
001a95b8 void onnxruntime::ConvTransposeAttributes::ComputeTransposePadAndOutputShape(const int64_t, const int64_t, const int64_t, const int64_t, const int64_t, onnxruntime::AutoPadType, int64_t *, int64_t *, int64_t *) const
001a9691 invalid
001a9699 std::unique_ptr<IndexedSubGraph::MetaDef> onnxruntime::xnnpack::FuseQDQGroup(const onnxruntime::NodeUnit &)
001a9705 utils::HasExternalData(value) == false
001a972c kernel_shape[dim] > 0
001a9742 Pad should be smaller than kernel.
001a9765 void onnxruntime::PoolAttributes::InferOutputSize(gsl::span<const int64_t>, onnxruntime::TensorShapeVector *, onnxruntime::TensorShapeVector *) const
001a97fb xnn_setup_resize_bilinear2d_nhwc_
001a981d 'Linear' mode only support:
001a9839   * 2-D inputs or
001a984b   * 3-D inputs ('Bilinear', 'Trilinear') or
001a9877   * 4-D inputs with the corresponding outermost 2 scale values being 1 or the corresponding outermost and innermost scale values being 1 or
001a9903   * 5-D inputs with the corresponding outermost 2 scale values being 1in the 
001a9951 'Cubic' mode only support 2-D inputs ('Bicubic') or 4-D inputs with the corresponding outermost 2 scale values being 1 in the 
001a99d0 DynamicQuantizeMatMulFusion
001a99ec bn_mean_tensor_proto
001a9a01 Unsupported output type of 
001a9a1d Expected value:
001a9a2d CheckSliceParameters returns false for mask_slice
001a9a5f Output edge count not expected for squeeze_2/slices2/shape2 of unidirectional mask
001a9ab2 present_k_unsqueeze axes value not expected
001a9ade FuseSubGraph
001a9aeb Expecting the same data type
001a9b08 transBatchB
001a9b14 At least one graph node must be specified in the propagation edge.
001a9b57 ApplySelectorsAndActions
001a9b70 Failed to find initializer for name: 
001a9b96 TransposeInitializer
001a9baf com.microsoft.QLinearGlobalAveragePool
001a9bd6 static_cast<size_t>(num_subgraph_inputs) == subgraph_inputs.size()
001a9c19 virtual common::Status onnxruntime::Loop::SetupSubgraphExecutionInfo(const onnxruntime::SessionState &, const std::string &, const onnxruntime::SessionState &)
001a9cb9 utils::HasDataType(t_proto)
001a9cd5 !utils::HasExternalData(t_proto)
001a9cfa The innermost dims should have the same dim value to parse the diagonal elements
001a9d4b Einsum operands could not be broadcast together. Please check input shapes/equation provided.Input shape of operand 
001a9dc0 BitwiseOr
001a9dca virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Abs<short>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Abs<short>]
001a9e87 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Neg<signed char>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Neg<signed char>]
001a9f50 , D=
001a9f55 op_kernel_info.GetAttr<int64_t>("k", &k_temp).IsOK()
001a9f8a /onnxruntime_src/onnxruntime/core/providers/cpu/ml/ml_common.h
001a9fc9 info.GetAttrs(std::is_same<AttrType, std::string>::value ? "string_vocabulary" : "int64_vocabulary", vocabulary_).IsOK()
001aa042 virtual onnxruntime::common::Status onnxruntime::ml::FeatureVectorizer::Compute(onnxruntime::OpKernelContext *) const
001aa0b8 LinearClassifier
001aa0c9 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/linearregressor.cc
001aa10f onnxruntime::ml::ScalerOp<long>::ScalerOp(const onnxruntime::OpKernelInfo &) [T = long]
001aa167 vectors_per_class
001aa179 nodes_falsenodeids.size() == nodes_featureids.size()
001aa1ae void onnxruntime::ml::detail::TreeAggregatorSum<float, float, float>::ProcessTreeNodePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const TreeNodeElement<ThresholdType> &) const [InputType = float, ThresholdType = float, OutputType = float]
001aa2a7 void onnxruntime::ml::detail::TreeEnsembleCommon<float, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = float, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorClassifier<float, float, float>]
001aa3ff virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommon<long, float, float>::Init(const onnxruntime::OpKernelInfo &) [InputType = long, ThresholdType = float, OutputType = float]
001aa4ca virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommon<int, float, float>::Init(const onnxruntime::OpKernelInfo &) [InputType = int, ThresholdType = float, OutputType = float]
001aa593 void onnxruntime::ml::detail::TreeAggregatorSum<int, float, float>::MergePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = int, ThresholdType = float, OutputType = float]
001aa688 void onnxruntime::ml::detail::TreeAggregator<int, float, float>::FinalizeScores(InlinedVector<ScoreValue<ThresholdType>> &, OutputType *, int, int64_t *) const [InputType = int, ThresholdType = float, OutputType = float]
001aa765 Must provide classlabels_strings or classlabels_int64s but not both.
001aa7aa  filter_number: 
001aa7bb wstring_convert: to_bytes error
001aa7db max_skip_count must be non-negative: 
001aa801 First dimension (num_rois) of batch_indices and rois don't match
001aa842 scale.Shape().NumDimensions() == 1 && scale.Shape()[0] == broadcast_dim
001aa88a QLinearMatmul : input zero point must be a scalar or 1D tensor of size 1
001aa8d3 linear_before_reset
001aa8e7 Invalid 'direction' argument of '
001aa909 offset + size <= size_t(span.size())
001aa92e alpha == 1.0f && (beta == 0.0f || beta == 1.0f)
001aa95e /onnxruntime_src/onnxruntime/core/providers/cpu/sequence/sequence_ops.cc
001aa9a7 SequenceErase
001aa9b5 Split should be > 0
001aa9c9 onnxruntime::common::Status onnxruntime::short_time_fourier_transform(onnxruntime::OpKernelContext *, bool, bool) [T = double, U = double]
001aaa54 HammingWindow
001aaa62 strides_.size() == image_dim_number
001aaa86 void onnxruntime::StridedCopy(concurrency::ThreadPool *, T *, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShape &, const T *, const onnxruntime::TensorShapeVector &) [T = std::basic_string<char>]
001aab5f int64_t onnxruntime::GetIndex(size_t, const T *, int64_t) [T = long]
001aaba4 invalid index found, index = 
001aabc2 GatherND
001aabcb virtual onnxruntime::common::Status onnxruntime::GatherND::Compute(onnxruntime::OpKernelContext *) const
001aac34 Invalid argument for values; either it's rank is more than 1 or it has more than 2 elements
001aac90 gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = unsigned short]
001aacdb CPU execution provider: MLFloat16 data type is not supported with ScatterElements opset 18 when reduction is 'max'.
001aad4f Unsupported input type in SpaceToDepth op: 
001aad7b The split tensor must be a vector tensor.
001aada5 virtual onnxruntime::common::Status onnxruntime::Transpose::Compute(onnxruntime::OpKernelContext *) const
001aae0f  k_hidden_size=
001aae1f input_ids is expected to have 2 dimensions, got 
001aae50 /onnxruntime_src/onnxruntime/contrib_ops/cpu/bert/bias_gelu.cc
001aae8f virtual onnxruntime::common::Status onnxruntime::contrib::BifurcationDetector::Compute(onnxruntime::OpKernelContext *) const
001aaf0c ) needs to be greater than or equal to the leftBorder (
001aaf44 ImageScaler
001aaf50 virtual onnxruntime::common::Status onnxruntime::contrib::ReorderInput::Compute(onnxruntime::OpKernelContext *) const
001aafc6 X_shape.NumDimensions() == 4
001aafe3 virtual onnxruntime::common::Status onnxruntime::contrib::MatMulIntegerToFloat::Compute(onnxruntime::OpKernelContext *) const
001ab061 IsScalarOr1ElementVector(a_zero_point_tensor)
001ab08f Segment embedding zero point must be a scalar or 1D tensor of size 1
001ab0d4 IsScalarOr1ElementVector(tensor_c_scale)
001ab0fd virtual onnxruntime::common::Status onnxruntime::contrib::QLinearWhere::Compute(onnxruntime::OpKernelContext *) const
001ab173 dims.size() == 2
001ab184 num_beams shall be a positive integer no more than 
001ab1b8 onnxruntime::common::Status onnxruntime::contrib::GenerationCpuDeviceHelper::ProcessLogits(const OrtValue &, transformers::IBeamSearchState<T> *, transformers::IBeamSearchCpuState *, transformers::ISequences *, onnxruntime::AllocatorPtr &, onnxruntime::concurrency::ThreadPool *, transformers::ILogitsProcessorList *, transformers::IBeamScorer *, const transformers::IGenerationParameters *, int, onnxruntime::Stream *, const transformers::IConsoleDumper *) [T = float]
001ab38e /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/greedy_search_impl_gpt.h
001ab3e1 GetParameters
001ab3ef decoder subgraph output 0 shall be named as logits, got: 
001ab429 decoder_input_ids
001ab43b present_value_self_0
001ab450 std::array<BFCArena::BinDebugInfo, BFCArena::kNumBins> onnxruntime::BFCArena::get_bin_debug_info()
001ab4b3 InUse:                    
001ab4ce /onnxruntime_src/onnxruntime/core/framework/config_options.cc
001ab50c src.SizeInBytes() == dst.SizeInBytes()
001ab533 thisProto->value_case() == TypeProto::ValueCase::kOptionalType
001ab572 bool onnxruntime::NonTensorTypeBase::IsSequenceCompatible(const onnx::TypeProto &) const
001ab5cb int16
001ab5d1 int32
001ab5d7  Requested shape:
001ab5e9 Trying to allocate memory for unused optional inputs/outputs
001ab626 VerifyOutputSizes
001ab638 Expected shape from model of 
001ab656  by that EP. This means the graph is now invalid as there will not be an EP able to run the node. This could be a bug in layout transformer, or in the GetCapability implementation of the EP.
001ab715 /onnxruntime_src/onnxruntime/core/framework/kernel_lookup.h
001ab751 onnxruntime::KernelDefBuilder &onnxruntime::KernelDefBuilder::VariadicAlias(int, int)
001ab7a7 op_id is null.
001ab7b6 . Do you have duplicated calls to SessionState::AddInitializedTensor function?
001ab805 output_names_to_nodeinfo.empty()
001ab826 ComputeReuseCount
001ab838 Strided tensor is not supported in non-training build for now.
001ab87a outer_num == (rows + 1)
001ab892 static size_t onnxruntime::Tensor::CalculateTensorStorageSize(onnxruntime::MLDataType, const onnxruntime::TensorShape &, gsl::span<const int64_t>)
001ab925 duplicated location
001ab939 The preallocated buffer is too small. Requires 
001ab969 TensorProto: 
001ab977  failed
001ab97f bool onnxruntime::utils::FinalizeCopyInfoForFetches(gsl::span<const OrtMemoryInfo *const> &, std::vector<MLValueCopyInfo> &)
001ab9fc Hidden dimension of Q, K, V: hidden_size, hidden_size and v_hidden_size
001aba46 Constrain to integer types
001aba61 output tensor with shape (batch_size, num_heads, new sequence_length, head_size)
001abab2 new_value_cache
001abac2 1D gamma tensor for layer normalization with shape (hidden_size)
001abb03 Max distance
001abb10 SkipSimplifiedLayerNormalization
001abb31 Constrain indices to integer types
001abb54 output tensor with shape (batch_size, sequence_length, hidden_size)
001abb98 tensor with shape (batch_size, seq_len, num_heads x head_size)
001abbd7 rel_pos
001abbdf isinf_only
001abbea sparse_tensor(float)
001abbff Constrain output type to unsigned and signed 32-bit integer tensor.
001abc43 Input tensor.
001abc51 1-D tensor of 2 elements: [crop_height, crop_width]. All cropped image patches are resized to this size. Both crop_height and crop_width need to be positive.
001abcef payload of the SNPE DLC file.
001abd0d Square = Mul (XU, XU)
001abd23 The sequence length of the input memory for the attention mechanism. Should be of `[batch_size]` 
001abd85 A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`
001abe12 Output tensor must have at least 3 dimensions
001abe40 ) + right_border (
001abe53 A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor.
001abec4 Zero point tensor for input 'A'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'A'.
001abfcb Coefficient of leakage.
001abfe3 Scale of output 'Y'. It is a scalar, which means a per-tensor quantization. It is optional. The output is full precision(float32) if it is not provided. Or the output is quantized.
001ac098 weight_scale
001ac0a5 TODO: input tensor of (ROWS, COLS). if less than 2d, will broadcast to (1, X). If 3d, it is treated as (B, ROWS, COS)
001ac11b DequantizeWithOrder
001ac12f scale_QKT_gemm
001ac13e additional add to QxK' with shape (batch_size, num_heads, sequence_length, sequence_length).
001ac19b Tensor(scalar, or dims=[1]). Number that increments start. Defaults to 1.
001ac1e5 . Please, fix your model.
001ac1ff ) bound to different types (
001ac21c ) does not have type information.
001ac23e Trying to replace non-external initializer with external data
001ac27c Can't remove node 
001ac28f  must be either specified in graph inputs or graph initializers.
001ac2d0 shape != nullptr
001ac2e1  is under development and support for this is limited. The operator schemas and or other functionality may change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain 
001ac3da /onnxruntime_src/onnxruntime/core/graph/graph_utils.cc
001ac411  ExplicitInputs:
001ac422 Failed to load model with error: 
001ac444 session_logger != nullptr
001ac45e /onnxruntime_src/onnxruntime/core/common/status.cc
001ac491 pthread_create failed, error code: 
001ac4b5 ' of '
001ac4bc ' is required but missing.
001ac4db setting data_type field (tensor name: 
001ac502 ) is not equal to number of scan inputs (
001ac52c tensor of int64, which should be a scalar.
001ac557 initial_state_and_scan_inputs
001ac575 An optional list of K flags, one for each scan_output. The i-th element of the list specifies whether the i-th scan_output should be constructed by appending or prepending a new value in each iteration: 0 indicates appending and 1 indicates prepending. If omitted, all scan_output tensors will be produced by appending a value in each iteration.
001ac6cf  else=
001ac6d6 All Tensor and Sequence types
001ac6f4 opaque(
001ac6fc The values for the elements for the 1D, int64, output tensor.
001ac73a value_strings
001ac748 (Optional) The data type for the elements of the output tensor. If not specified,the data type of the input tensor T1 is used. If input tensor T1 is also notspecified, then type defaults to 'float'.
001ac80f The standard deviation of the normal distribution.
001ac842 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/logical/defs.cc
001ac893           {
001ac89f             Alpha = Constant <value_float: float = @alpha>()
001ac8dc             AlphaCast = CastLike (Alpha, X)
001ac908             Zero = Constant <value = float {0.0}>()
001ac93c             ZeroCast = CastLike (Zero, X)
001ac966             AlphaLessThanX = Less(AlphaCast, X)
001ac996             Y = Where(AlphaLessThanX, X, ZeroCast)
001ac9c9           }
001ac9d5         
001ac9de Constrain input and output types to numeric tensors.
001aca13 weight_gather_temp_1 = Where (mask, const_zero_float, weight_gather_temp)
001aca5d Log probability tensor. If the output of softmax is prob, its value is log(prob).
001acaaf X_ReduceMax = ReduceMax <keepdims = 1> (input, axes)
001acae4 is_onesided and inverse attributes cannot be enabled at the same time
001acb2a Pass 1 to enable broadcasting
001acb48 data_0
001acb4f Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0.The value represent the number of pixels added to the beginning and end part of the corresponding axis.`pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number ofpixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaultsto 0 along start and end of each spatial axis.
001acd8f Tensor to be normalized.
001acda8 is_test
001acdb0 The running mean (training) or the estimated mean (testing) as a 1-dimensional tensor of size C.
001ace11 Saved variance used during training to speed up gradient computation.
001ace57 If spatial is true, the dimension of the running variance(training) or the estimated variance (testing) is (C). If spatial is false, the dimensions of the running variance(training) or the estimated variance (testing) are (C x D1 x ... x Dn).
001acf4a /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/object_detection/defs.cc
001acfa3 Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified.
001ad038 output_sequence
001ad048 (outputs_.size() - 1) == i
001ad063 Position of the tensor in the sequence. Negative value means counting positions from the back. Accepted range in `[-n, n - 1]`, where `n` is the number of tensors in 'input_sequence'. It is an error if any of the index values are out of bounds. It must be a scalar(tensor of empty shape).
001ad184 new_axis must be either 0 or 1
001ad1a3 Input was expected to have map type. Got 
001ad1cd Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
001ad250 Tensor of int32/int64 indices, with the same rank r as the input. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
001ad321 Output tensor of [N, C * blocksize * blocksize, H/blocksize, W/blocksize].
001ad36c (Optional) Whether map negative infinity to true. Default to 1 so that negative infinity induces true. Set this attribute to 0 if negative infinity should be mapped to false.
001ad41b Input axes has incorrect length
001ad43b pad_amount_right = Sub(pad_amount, pad_amount_left)
001ad46f 1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is "tf_crop_and_resize"
001ad568 Dimension value inferred (
001ad583 Number of elements of input 'scales' must be same as rank of input 'X'
001ad5ca map(int64, string)
001ad5dd A dictionary.
001ad5eb Data to be classified.
001ad602 Weights of the model(s).
001ad61b Input of shape [N,F]
001ad630 Feature id for each node.
001ad64a For each node, define what to do in the presence of a missing value: if a value is missing (NaN), use the 'true' or 'false' branch based on the value in this array.<br>This attribute may be left undefined, and the defalt value is false (0) for all nodes.
001ad749 N classes
001ad753  optype 
001ad75c Inferred shape and existing shape differ in rank: (
001ad790 onnx.TrainingInfoProto
001ad7a7 onnx.FunctionProto
001ad7be Error reverse compiling '
001ad7d8 Bad hex digit 
001ad7e7 [:ascii:]
001ad7f1 StateSaver failed to restore state.
001ad819 Brahmi
001ad820 Dogra
001ad82a Runic
001ad830 Vithkuqi
001ad839 mu held in reader and writer mode simultaneously on entry to nsync_cv_wait_with_deadline()
001ad895 foster_e
001ad8a1 Monday
001ad8a8 February
001ad8b1 mutex lock failed
001ad8c3 unspecified system_category error
001ad8e5 construction vtable for 
001ad903 __int128
001ad90c template<
001ad916 operator<<
001ad921 operator+
001ad92b operator+=
001ad936 operator++
001ad941 unsigned long long
001ad954  imaginary
001ad95f unexpected_handler unexpectedly returned
001ad988 libunwind: malformed DW_CFA_expression DWARF unwind, reg too big
001ad9d6 max_mem
001ad9de OrtStatus *OrtCreateValueImplSeqHelper(const OrtValue *const *, size_t, OrtValue **)
001ada33 DmlExecutionProvider
001ada48 So disabling it for this session since it uses the DML Execution Provider.
001ada93 sparse_tensor
001adaa1 p_fetches->size(): 
001adab5  CUDA Graph for this model with tag: 
001adadb Running with tag: 
001adaee GetOverridableInitializers
001adb0c ParseOrtConfigJsonInModelProto
001adb2b Setting execution_mode to 
001adb46 invalid string: control character U+001E (RS) must be escaped to \u001E
001adb8e invalid_iterator
001adb9f cannot use erase() with 
001adbb8 map::at:  key not found
001adbd0  is not implemented
001adbe4  index=
001adbec tensor(uint8)
001adbfa seq(tensor(int8))
001adc0c CUDA execution provider is not enabled in this build.
001adc42 const T *onnxruntime::Tensor::Data() const [T = onnxruntime::BFloat16]
001adc89 Maximum string length for a provider options key/value is 1024.
001adcc9 SetInputBuffer
001adcd8 ANeuralNetworksModel_create
001adcf4 ANeuralNetworksModel_addOperation
001add16 ANeuralNetworksExecution_create
001add36 SL_ANeuralNetworksDiagnosticCompilationInfo_isCachingEnabled
001add73 QLinearAdd
001add7e MatMul
001add85 on model finish
001add95 /new_perm
001add9f GetBinaryOpQuantizationScaleAndZeroPoint
001addc8 GetConvMatMulOpQuantizationScaleAndZeroPoint
001addf5 MinMaxOpBuilder, unknown op: 
001ade13  does not support per-channel quantization, 
001ade40 system NNAPI feature level: 
001ade5d  GetQuantizationScaleAndZeroPoint failed, message: 
001ade91 Input axes of Squeeze must be known
001adeb9 Input max of Clip must be known
001aded9 onnxruntime::ConvAttributes::ConvAttributes(const onnxruntime::OpKernelInfo &)
001adf28 kernel_shape is not compatible with W shape.
001adf55 info.GetAttr<std::string>("mode", &mode).IsOK()
001adf85 (default) or 
001adf93 ceil
001adf98 ParseScalesData
001adfa8 info.GetAttr<float>("alpha", &alpha_).IsOK()
001adfd5 Level
001adfdb MatMulIntegerToFloatFusion
001adff6 ConstantFolding
001ae006 Slice does not have enough number of inputs
001ae032 concat_after_gather input 2 does not have expected value
001ae06b Optional position subgraph nodes Where node is expected to be the parent of Reshape.
001ae0c0 fused EmbedLayerNorm subgraphs 
001ae0e0 bn_scale
001ae0e9 TryCreateKernel
001ae0f9 Failed to set op schema for added DQ node.
001ae124 FuseReluClip_
001ae132 /onnxruntime_src/onnxruntime/core/optimizer/transformer_memcpy.cc
001ae174 virtual void onnxruntime::ApiGraph::CopyValueInfo(std::string_view, std::string_view)
001ae1ca IsInf
001ae1d0 Softplus
001ae1dd ReduceLogSumExp
001ae1ed com.microsoft.QLinearSigmoid
001ae20a GridSample
001ae215 Multinomial
001ae221 onnxruntime::common::Status onnxruntime::Scan8Impl::CreateLoopStateVariables(std::vector<std::vector<LoopStateVariable>> &)
001ae29f Expected AllocateFinalOutput to have been called to before we increment the iterator
001ae2f4 /onnxruntime_src/onnxruntime/core/providers/cpu/controlflow/if.cc
001ae336  Expected:
001ae341 Invalid value in scan_output_axes for output 
001ae36f info.GetAttr<float>("mean", &mean_).IsOK()
001ae39a MultinomialCompute
001ae3ad /onnxruntime_src/onnxruntime/core/providers/cpu/math/clip.cc
001ae3ea void onnxruntime::Clip::ComputeImpl<unsigned char>::operator()(const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, onnxruntime::Tensor *) const [T = unsigned char]
001ae4b1 void onnxruntime::SliceIteratorBase::Init(gsl::span<const int64_t>, gsl::span<const int64_t>, gsl::span<const int64_t>)
001ae529 Right shape: 
001ae537 Expand
001ae53e virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Exp<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Exp<float>]
001ae5fb Gemm: Invalid bias shape for broadcast
001ae622 ComputeImplOpset13
001ae635 op_kernel_info.GetAttr<int64_t>("axis", &axis_temp).IsOK()
001ae670 onnxruntime::ml::CAST_TO onnxruntime::ml::MakeCast(const std::string &)
001ae6b8 onnxruntime::ml::CategoryMapper::CategoryMapper(const onnxruntime::OpKernelInfo &)
001ae70b Invalid input type:
001ae71f ) must have the same length. 
001ae73d onnxruntime::ml::LabelEncoder_2<long, float>::LabelEncoder_2(const onnxruntime::OpKernelInfo &) [TKey = long, TValue = float]
001ae7bb Scale size: (
001ae7c9 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/svmclassifier.cc
001ae80d classlabels_strings_.size() > 0 || classlabels_ints_.size() > 0
001ae84d nodes_featureids
001ae85e nodes_falsenodeids.size() == nodes_treeids.size()
001ae890  is already there.
001ae8a3 class_ids
001ae8ad virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommon<double, double, float>::compute(onnxruntime::OpKernelContext *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *) const [InputType = double, ThresholdType = double, OutputType = float]
001ae9cf void onnxruntime::ml::detail::TreeEnsembleCommon<double, double, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = double, ThresholdType = double, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorAverage<double, double, float>]
001aeb2a Output channels M is not divisible by group.
001aeb57  M: 
001aeb5c op_kernel_info.GetAttr("axis", &axis_).IsOK()
001aeb8a info.GetAttr<float>("beta", &beta_).IsOK()
001aebb5 onnxruntime::RoiPool<float>::RoiPool(const onnxruntime::OpKernelInfo &) [T = float]
001aec09 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/string_normalizer.cc
001aec51 UPPER
001aec57 Non-empty ngram_counts is required
001aec7a output_height
001aec88 QLinearMatmul : weight scale must be a scalar, 1D tensor of size 1, or last to second dimension is 1
001aeced int64_t onnxruntime::GetScalarSplitInput(const onnxruntime::Tensor &)
001aed33 Unsupported input data type of 
001aed53 Unsupported bit size.
001aed69 window_size < signal_size
001aed83 /onnxruntime_src/onnxruntime/core/providers/cpu/signal/window_functions.cc
001aedce input != nullptr
001aeddf /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/gather_nd.cc
001aee23 onnxruntime::GridSample<float>::GridSample(const onnxruntime::OpKernelInfo &) [T = float]
001aee7d invalid indice found, indice = 
001aee9d CPU execution provider: BFloat16 data type is not supported with ScatterND opset 18 when reduction is 'min'.
001aef0a Missing or invalid starts and ends attribute
001aef37 . Size of dimension being split is 
001aef5b hidden_size should be divisible by num_heads:
001aef89 /onnxruntime_src/onnxruntime/contrib_ops/cpu/attnlstm/bahdanau_attention.cc
001aefd5 virtual void onnxruntime::contrib::BahdanauAttention<float>::PrepareMemory(const gsl::span<const T> &, const gsl::span<const int> &) [T = float]
001af066 Input's height (
001af077  specified. It should be either bilinear or nearest
001af0ab onnxruntime::contrib::Scale<float>::Scale(const onnxruntime::OpKernelInfo &) [T = float]
001af104 info.GetAttr<int64_t>("channels_last", &channels_last_).IsOK()
001af143 Input 
001af14a Gamma scale must be a scalar or 1D tensor of size 1
001af17e Input x_scale must be a scalar or 1D tensor of size 1
001af1b4 QlinearBuildLookupTable : input Y_zero_point must be a scalar or 1D tensor of size 1
001af209 attribute mincharnum must have a positive value
001af239 !separators.empty()
001af24d vocab_size
001af258 last_outputs.size() >= static_cast<size_t>(1) + num_present_tensors
001af29c /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/sampling_cpu_helper.h
001af2ec virtual onnxruntime::common::Status onnxruntime::contrib::transformers::GreedySearch::SetupSubgraphExecutionInfo(const onnxruntime::SessionState &, const std::string &, const onnxruntime::SessionState &)
001af3b8 subgraph past state is expected to have 5 dimension, got 
001af3f2 subgraph logits output is expected to have 3 dimension, got 
001af42f subgraph input 1 (position_ids) shall have int32 type
001af465 decoder subgraph output shall have same data type as that of encoder_hidden_states
001af4b8 onnxruntime::common::Status onnxruntime::contrib::transformers::T5DecoderSubgraph::CreateInitialFeeds(gsl::span<const int32_t>, const std::vector<const OrtValue *> &, const std::vector<OrtValue> &, const std::vector<OrtValue> &, std::vector<OrtValue> &, const GenerationDeviceHelper::DeviceCopyFunc<int32_t> &, const GenerationDeviceHelper::ExpandBufferFunc<int32_t> &, const GenerationDeviceHelper::ExpandBufferFunc<float> &, const GenerationDeviceHelper::ExpandBufferFunc<MLFloat16> &, int, onnxruntime::Stream *, bool, int, transformers::Sequences &)
001af6e2 encoder subgraph input 2 (decoder_input_ids) shall have int32 type
001af725 Creating BFCArena for 
001af73c  bins of max chunk size 
001af755 b->free_chunks.size() == bin_info.total_chunks_in_bin - bin_info.total_chunks_in_use
001af7aa  at 
001af7af  | in_use: 
001af7bb bool
001af7c0 static void onnxruntime::data_types_internal::SequenceTypeHelper::Set(const onnx::TypeProto *, onnx::TypeProto &)
001af832 API VERSION 
001af83f /onnxruntime_src/onnxruntime/core/framework/kernel_registry.cc
001af87e type_proto is not of type sequence!
001af8a2 Attribute name and type don't match
001af8c6 void onnxruntime::MemPatternPlanner::TraceAllocation(int, size_t)
001af908 AddInitializer
001af917 Unable to write the provided PrePackedWeights instance into the container
001af963 p_kernel_def
001af970 ComputeReusePlan
001af985  node. Name:'
001af993 Begin execution
001af9a3 common::Status onnxruntime::session_state_utils::SaveInitializedTensors(const onnxruntime::Env &, const std::basic_string<PATH_CHAR_TYPE> &, const onnxruntime::GraphViewer &, const onnxruntime::AllocatorPtr &, const onnxruntime::OrtValueNameIdxMap &, const std::vector<OrtValueIndex> &, onnxruntime::ITensorAllocator &, const onnxruntime::session_state_utils::SaveTensorFunction &, const logging::Logger &, const onnxruntime::DataTransferManager &, const onnxruntime::ExecutionPlanBase &, const onnxruntime::SessionOptions &, const onnxruntime::session_state_utils::MemoryProfileFunction &)
001afbf2 entry != initialized_tensors_to_allocate.end() && entry->second->data_type() != ONNX_NAMESPACE::TensorProto_DataType_STRING
001afc6e Values size 
001afc7b Must contain Csr format. Contains: 
001afc9f Input must be of COO format
001afcbb onnxruntime::common::Status onnxruntime::utils::GetExtDataFromTensorProto(const onnxruntime::Env &, const char *, const onnx::TensorProto &, void *&, SafeInt<size_t> &, onnxruntime::OrtCallback &)
001afd80 Element_size of: 
001afd92  external data size mismatch. Computed size: 
001afdc0 model format error! Need a key for the external data info
001afdfa offset
001afe01 parsing 
001afe0a InitializeFeedFetchCopyInfo
001afe26  while parent graph node running on device: 
001afe53 present
001afe5b value_cache
001afe67 The length of key.
001afe7a Sum of the input and skip inputs (and bias if it exists) with shape (batch_size, sequence_length, hidden_size).
001afeea Decoder input ids.
001afefd A 0-D scalar tensor. If specified, the entries at `padding_idx` do not contribute to the gradient; therefore, the embedding vector at `padding_idx` is not updated during training, i.e. it remains as a fixed pad.
001affd1 If set to true then it indicates dropout is being used for training. It is an optional value hence unless specified explicitly, it is false. If it is false, ratio is ignored and the operation mimics inference mode where nothing will be dropped from the input data and if mask is requested as output it will contain all ones.
001b0116 Support padding modes for outside grid values: `zeros`(default), `border`, `reflection`. zeros: use 0 for out-of-bound grid locations, border: use border values for out-of-bound grid locations, reflection: use values at locations reflected by the border for out-of-bound grid locations.
001b0235 4-D tensor of shape (N, C, H, W), where N is the batch size, C is the numbers of channels, H and W are the height and width of the input data.
001b02c4 Input offset, 4-D tensor of shape (N, H_out, W_out, 2), where H_out and W_out are the height and width of grid and output, Grid specifies the sampling pixel locations normalized by the input spatial dimensions. Therefore, it should have most values in the range of [-1, 1]. If grid has values outside the range of [-1, 1], the corresponding outputs will be handled as defined by padding_mode.
001b044d Exponential penalty to the length. Default value 1.0 means no penalty.Value > 1.0 encourages longer sequences, while values < 1.0 produces shorter sequences.Shape is (1,)
001b04f8 Strings to tokenize
001b050c Boolean whether to mark the beginning/end character with start of text character (0x02)/end of text character (0x03).
001b0582 Constrain output Y data types as 32-bit integer tensor.T3 must be tensor(uint32) when both T1 and T2 are tensor(uint16),or must be tensor(int32) when either T1 or T2 is tensor(int16).
001b063a sparse_tensor(int64)
001b0653 Constrain input X type to float tensors.
001b067c Input axis is invalid: 
001b0694 B2D = Flatten <axis=0> (B)
001b06af Input data type does not match the expected data type. Current data type is 
001b06fc addition
001b0705 multiplication
001b0714 reduced_zero_point
001b0727 Scale for position embeddings
001b0745 order_A
001b074d Constrain input gamma and bias could be float16/float tensors. float may get better precision, float16 runs faster.
001b07c1 Tensor(scalar, or dims=[1]). Upper limit of sequence, exclusive.
001b0802 Invalid source node arg slot specified when adding edge.
001b083b BuildConnections
001b084c ) of Optype (
001b085a Removing NodeArg '
001b086d Graph attribute inferencing failed: 
001b0892 /onnxruntime_src/onnxruntime/core/graph/function_utils.cc
001b08cc  is under development and support for this is limited. The operator schemas and or other functionality could possibly change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain 
001b09d0 Number of actual parameters cannot exceed number of formal parameters
001b0a16 void onnxruntime::graph_utils::AddNodeInput(onnxruntime::Node &, int, onnxruntime::NodeArg &)
001b0a74 <p_fd> is less than 0.
001b0a8b void onnxruntime::concurrency::ThreadPool::ParallelFor(std::ptrdiff_t, const onnxruntime::TensorOpCost &, const std::function<void (std::ptrdiff_t, std::ptrdiff_t)> &)
001b0b33 n <= num_threads_ + 1
001b0b49 /onnxruntime_src/onnxruntime/core/platform/posix/env.cc
001b0b81 Null map type info. Invalid ORT format model.
001b0baf LoadTensorDimensionOrtFormat
001b0bcc ) to UNDEFINED is not allowed
001b0bea ) dimensions are not positive.
001b0c09 name: 
001b0c10 body
001b0c15 optional(
001b0c1f The Alpha value in Celu formula which control the shape of the unit. The default value is 1.0.
001b0c7e scale of quantized input b
001b0c99 loss_Ndd = Squeeze (loss_N1dd, axes)
001b0cbe weight_gather = Gather (weight, target)
001b0ce6 loss_Ndd = Mul (loss_unweighted, weight_gather)
001b0d16 log_prob = Identity (X_Log)
001b0d32 ) vs (
001b0d39 'shape' input must be 1D tensor
001b0d59 Input tensor must have at least 2 dimensions
001b0d86 The storage order of the tensor. 0 is row major, and 1 is column major. This attribute is used only to convert an n-tuple index value into a single integer value for producing the second output. 
001b0e4a Output data tensor that contains the result of the unpooling.
001b0e88 SquareOfMean = Mul (Mean, Mean)
001b0ea8 Deviation = Sub (X3D, Mean)
001b0ec4 The running variance after the BatchNormalization operator. Must be in-place with the input var. Should not be used for testing.
001b0f45 Saved mean used during training to speed up gradient computation. Should not be used for testing.
001b0fa7 Integer representing the maximum number of boxes to be selected per batch per class. It is a scalar. Default to 0, which means no output.
001b1031 The optional output enclosing the input element.
001b1062 model_version
001b1071         {
001b107b            Q_Min = Constant<value = float {0.0}>()
001b10ae            Q_Max = Constant<value = float {255.0}>()
001b10e3            X_Min = ReduceMin <keepdims = 0> (x)
001b1113            X_Min_Adjusted = Min (X_Min, Q_Min)
001b1142            X_Max = ReduceMax <keepdims = 0> (x)
001b1172            X_Max_Adjusted = Max (X_Max, Q_Min)
001b11a1            X_Range = Sub (X_Max_Adjusted, X_Min_Adjusted)
001b11db            Scale = Div (X_Range, Q_Max)
001b1203            Min_Scaled = Div (X_Min_Adjusted, Scale)
001b1237            Initial_ZeroPoint_FP = Sub (Q_Min, Min_Scaled)
001b1271            Clipped_ZeroPoint_FP = Clip (Initial_ZeroPoint_FP, Q_Min, Q_Max)
001b12bd            Rounded_ZeroPoint_FP = Round (Clipped_ZeroPoint_FP)
001b12fc            Zeropoint = Cast <to = 2> (Rounded_ZeroPoint_FP)
001b1338            y_scale = Identity (Scale)
001b135e            y_zero_point = Identity (Zeropoint)
001b138d            y = QuantizeLinear (x, Scale, Zeropoint)
001b13c1         }
001b13cb         
001b13d4  not in allowed output sizes.
001b13f2  for operator 
001b1401 ai.onnx.preview.training
001b141a Element type of optional input was unknown
001b1445 updates
001b144d List of integers indicating the dimensions to squeeze. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
001b14ee Original tensor
001b14fe Scalar specifying the number of classes in one-hot tensor. This is also the size of the one-hot dimension (specified by 'axis' attribute) added on in the output tensor. The values in the 'indices' input tensor are expected to be in the range [-depth, depth-1]. In case 'depth' is of non-integer type, it will be casted to int64 before use.
001b1652 values selected at indices where condition is False
001b1686 Constrain to all tensor types.
001b16a5 input_data
001b16b0 Only supports `int32_t` or `int64_t` inputs for starts/ends/axes/steps
001b16f7 Tensor of int32/int64 indices, of r >= 1 (same rank as input).
001b1736 Scalar specifying the number of classes in one-hot tensor. This is also the size of the one-hot dimension (specified by 'axis' attribute) added on in the output tensor. The values in the 'indices' input tensor are expected to be in the range [0, depth). In case 'depth' is of non-integer type, it will be casted to int64 before use.
001b1883 rank must be greater than axis
001b18a2 map(int64, float)
001b18b4 The integers of the map. This sequence must be the same length as the 'cats_strings' sequence.
001b1913 A 1-D tensor holding values from the input dictionary.
001b194a An ordered collection of tensors, all with the same element type.
001b198c Indicates the transform to apply to the scores vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
001b1a08 Node id for each node. Ids may restart at zero for each tree, but it not required to.
001b1a5e Child node if expression is true
001b1a7f /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/traditionalml/old.cc
001b1ad4  inferred=
001b1adf ERROR
001b1ae5 terminating.
001b1af3 SearchNFA inconsistency
001b1b0b [:^lower:]
001b1b18 Armenian
001b1b21 Balinese
001b1b2a Cypriot
001b1b32 Greek
001b1b38 Hangul
001b1b3f Kharoshthi
001b1b4a Old_Turkic
001b1b55 Siddham
001b1b5d Sinhala
001b1b65 /sys/devices/system/cpu/cpu%u/cpufreq/cpuinfo_min_freq
001b1b9c Sunday
001b1baa : no conversion
001b1bc0 operator=
001b1bca operator/=
001b1bd5 evaluateExpression
001b1bef This API supports Tensors or SparseTensors
001b1c1a /onnxruntime_src/include/onnxruntime/core/framework/data_types_internal.h
001b1c64 Provided OrtMemoryInfo is null
001b1c83 session.force_spinning_stop
001b1c9f custom join thread function not set for intra op thread pool
001b1cdc Could not parse model successfully while constructing the inference session
001b1d28 Missing Model. Invalid ORT format model.
001b1d51 This session cannot use the CUDA Graph feature as requested by the user  as all the graph nodes have not been partitioned to the CUDA EP.
001b1ddb Size mismatch: feed_names has 
001b1dfa Start the second Run() to capture the graph. The first one is for necessary memory allocation;The second one is for capturing the graph.
001b1e87 IsGraphCaptured()
001b1e99 .json
001b1e9f Json stored in the `ort_config` key cannot be parsed. Error message: 
001b1ee5 Setting inter_op_num_threads to 
001b1f06 invalid string: forbidden character after backslash
001b1f3a invalid string: control character U+000D (CR) must be escaped to \u000D or \r
001b1f88 invalid string: control character U+0018 (CAN) must be escaped to \u0018
001b1fd1 invalid string: control character U+001A (SUB) must be escaped to \u001A
001b201a invalid string: control character U+001C (FS) must be escaped to \u001C
001b2062 onnxruntime::CustomOpKernel::CustomOpKernel(const onnxruntime::OpKernelInfo &, const OrtCustomOp &)
001b20c6 ComputeAsync
001b20d3 tensor(int16)
001b20e1 in onnx/defs/schema.h).
001b20f9 const T *onnxruntime::OpKernelContext::Input(int) const [T = onnxruntime::SparseTensor]
001b2151 T *onnxruntime::Tensor::MutableData() [T = signed char]
001b2189 const T *onnxruntime::Tensor::Data() const [T = unsigned long]
001b21c8 TENSOR_BOOL8
001b21d5 SL_ANeuralNetworksDiagnosticExecutionInfo_getErrorCode
001b220c Unknown error code: 
001b2221 Conv
001b2226 ] is not supported for now
001b2241 bool onnxruntime::nnapi::IsInternalQuantizedNodeUnit(const onnxruntime::NodeUnit &)
001b2295 Non-spatial BN is not supported
001b22b5 Target device 
001b22c4 Set fp16
001b22cd on createForDevices
001b22e1 A and B must have at least three dimensions and have the same leading dimensions except for the last two. 
001b234c Dilation not supported for AutoPadType::SAME_UPPER or AutoPadType::SAME_LOWER.
001b239b HasSupportedOpSet
001b23ad Flatten only supports up to 1-4d shape, input is 
001b23df /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/gather_op_builder.cc
001b2442 virtual onnxruntime::common::Status onnxruntime::nnapi::LRNOpBuilder::AddToModelBuilderImpl(onnxruntime::nnapi::ModelBuilder &, const onnxruntime::NodeUnit &) const
001b24e7 Mode is not supported: 
001b24ff /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/softmax_op_builder.cc
001b2563  to 
001b2568  b_shape: 
001b2573 iter != node_to_compute_capability.cend()
001b259d ConvTranspose
001b25ab auto_pad
001b25b4 /onnxruntime_src/onnxruntime/core/providers/xnnpack/nn/conv_base.cc
001b25f8 No kernel shape is set.
001b2610 GetType(*input_defs[0], x_dtype)
001b2631 xnn_setup_softmax_nc_
001b2647 not_larger
001b2652 ParseSizesData
001b2661 num_dims_with_pad - 2 != num_output_dims
001b268a GenerateRuleBasedGraphTransformer
001b26ac TransposeOptimizer
001b26bf /onnxruntime_src/onnxruntime/core/optimizer/conv_add_act_fusion.cc
001b2702 /onnxruntime_src/onnxruntime/core/optimizer/attention_fusion_helper.h
001b2748 Expect mask data type is uint8 or float
001b2770 Start MatchPastSubgraph
001b2788 Output edge count not expected for nodes in past subgraph
001b27c2 q root should be layer normalization
001b27e7 unsqueeze_output_
001b27f9 Gelu approximation
001b280c YieldOp
001b2814 dtype_attribute->second.has_i()
001b2834  at NodeArg "
001b2842 qdq_s8_to_u8_quant
001b2855 bool onnxruntime::QDQ::QOrDQNodeHasConstantScalarScaleAndZeroPoint(const onnxruntime::Node &, const onnxruntime::QDQ::GetConstantInitializerFn &, bool &)
001b28f2 void onnxruntime::TransformerMemcpyImpl::ProcessDefs(onnxruntime::Node &, const onnxruntime::KernelRegistryManager &, onnxruntime::InitializedTensorSet &)
001b298d dup_replacements.find(&arg) == dup_replacements.end()
001b29c3 Selu
001b29c8 Asinh
001b29ce Greater
001b29d6 ReduceMin
001b29e0 ReduceProd
001b29eb CoreMLExecutionProvider
001b2a03 onnxruntime::ElementWiseKernel<onnxruntime::functors::LeakyRelu<float>>::ElementWiseKernel(const onnxruntime::OpKernelInfo &) [F = onnxruntime::functors::LeakyRelu<float>]
001b2aaf virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Relu<int>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Relu<int>]
001b2b6a virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::ThresholdedRelu<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::ThresholdedRelu<float>]
001b2c3f /onnxruntime_src/onnxruntime/core/providers/cpu/controlflow/scan_utils.cc
001b2c89 !is_concrete_shape_
001b2c9d virtual onnxruntime::common::Status onnxruntime::If::Compute(onnxruntime::OpKernelContext *) const
001b2d00 final_output_mlvalue_
001b2d16 /onnxruntime_src/onnxruntime/core/providers/cpu/generator/constant_of_shape_base.h
001b2d69 Must have a single dimension
001b2d86 Must have a valid input shape.
001b2da5 min should be a scalar.
001b2dbd virtual onnxruntime::common::Status onnxruntime::CumSum<double>::Compute(onnxruntime::OpKernelContext *) const [T = double]
001b2e39 /onnxruntime_src/onnxruntime/core/providers/cpu/math/einsum_utils/einsum_auxiliary_ops.cc
001b2e93 output.SizeInBytes() == input.SizeInBytes()
001b2ebf virtual onnxruntime::common::Status onnxruntime::Min_6<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
001b2f3c k_temp > 0
001b2f47 TO_FLOAT
001b2f50 info.GetAttrs<std::string>("cats_strings", string_categories).IsOK()
001b2f95 cats_int64s
001b2fa1 onnxruntime::ml::DictVectorizerOp<std::basic_string<char>, float>::DictVectorizerOp(const onnxruntime::OpKernelInfo &) [AttrType = std::basic_string<char>, TargetType = float]
001b3051 void onnxruntime::ml::LinearClassifier::ComputeImpl(const gsl::span<const float>, int64_t, int64_t, int64_t, const std::vector<float> &, const std::vector<float> &, onnxruntime::Tensor &, onnxruntime::Tensor &, onnxruntime::ml::POST_EVAL_TRANSFORM, bool, concurrency::ThreadPool *) const
001b3171 Input shape needs to be at least a single dimension.
001b31a6 Unsupported input element type of 
001b31c9 onnxruntime::ml::OneHotEncoderOp<double>::OneHotEncoderOp(const onnxruntime::OpKernelInfo &) [T = double]
001b3233 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/scaler.cc
001b3270 aggregate_function
001b3283 BRANCH_EQ
001b328d  features.
001b3298 void onnxruntime::ml::detail::TreeEnsembleCommon<int, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = int, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorMin<int, float, float>]
001b33e3 Input dimension cannot be less than 3.
001b340a /onnxruntime_src/onnxruntime/core/providers/cpu/nn/conv.cc
001b3445 roi_batch_id >= 0
001b3457 op_kernel_info.GetAttr<float>("lambd", &lambd_temp).IsOK()
001b3492 en_US.UTF-8
001b349e is_case_sensitive
001b34b0 p.second
001b34b9 min_gram_length is required
001b34d5 size_t onnxruntime::ngram_details::PopulateGrams(ForwardIter, size_t, size_t, size_t, Map &) [K = std::basic_string<char>, ForwardIter = std::__wrap_iter<std::reference_wrapper<const std::basic_string<char>> *>, Map = std::unordered_map<std::reference_wrapper<const std::basic_string<char>>, std::unique_ptr<onnxruntime::ngram_details::NgramPart<std::string>>, std::hash<std::basic_string<char>>, std::equal_to<std::basic_string<char>>>]
001b368b attr->has_tp()
001b369a IsScalarOr1ElementVector(a_zero_point)
001b36c1 scale must be 1D tensor with size 
001b36e4 axes_tensor->Shape().NumDimensions() == 1
001b370e GRU operator does not support double yet
001b3737 Invalid data type for LSTM operator of 
001b375f hardsigmoid
001b376b ) specified for sequence of size (
001b378e SplitToSequence
001b379e split_size_sum (
001b37b3 dst.DataType() == src.DataType()
001b37d4 onnxruntime::GatherBase::GatherBase(const onnxruntime::OpKernelInfo &)
001b381b border
001b3822 reflection
001b382d detect_negative
001b383d reflect
001b3845 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/reshape_helper.h
001b388d gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = unsigned int]
001b38db /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/scatter.cc
001b391d updates tensor should have shape equal to indices.shape[:-1] + data.shape[indices.shape[-1]:]. 
001b397d axes_tensor->Shape().NumDimensions() == 0 || axes_tensor->Shape().NumDimensions() == 1
001b39d4 nullptr != p.output_tensor
001b39ef Upsample: input tensor's dimension does not match the scales.
001b3a2d RegisterQuantizationKernels
001b3a49 qkv_hidden_sizes first element should be same as the second
001b3a85 Input 'relative_position_bias' dimension 2 should be same as sequence_length, got 
001b3ad8 }, actural: 
001b3ae5 scores_dims.size() == 2
001b3afd pred_tokens_len == (src_tokens_len + 1 - prev_suffix_match_idx_data)
001b3b42 info.GetAttr("beta", &beta_).IsOK()
001b3b66 onnxruntime::contrib::FusedGemm<float>::FusedGemm(const onnxruntime::OpKernelInfo &) [T = float]
001b3bc7 /onnxruntime_src/onnxruntime/contrib_ops/cpu/nchwc_ops.cc
001b3c01 Weight zero point must be zero
001b3c20 input_shape.Size() > 0 || N == 0
001b3c41 QEmbedLayerNormalization
001b3c5a IsScalarOr1ElementVector(tensor_b_scale)
001b3c83 IsScalarOr1ElementVector(tensor_x_zero_point)
001b3cb1 QGemm : zero point of input b must be a scalar or 1D tensor of size 1 or N
001b3cfc void onnxruntime::GemmBroadcastBias(int64_t, int64_t, float, const T *, const onnxruntime::TensorShape *, T *) [T = int]
001b3d75 bias is expected to have 1 dimension, got 
001b3da0 decoder
001b3da8 init_run_decoder_feeds_fetches_manager_
001b3dd0 length_penalty
001b3ddf /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/beam_search_parameters.cc
001b3e33 onnxruntime::common::Status onnxruntime::contrib::GenerationCpuDeviceHelper::CreateGptInputs(const onnxruntime::Tensor *, const OrtValue *, int, int, gsl::span<int32_t> &, onnxruntime::AllocatorPtr, OrtValue &, OrtValue &, OrtValue &)
001b3f1e number of outputs expected to be 2 + 4 * layers, got:
001b3f54 encoder subgraph input 1 shall be named as encoder_attention_mask, got: 
001b3f9d  conv kernal size 1: 
001b3fb3 Char embedding size does not match conv kernal size 2.
001b3fea Cuda
001b3fef Received invalid value of arena_extend_strategy 
001b4020 Available memory of 
001b4035 reserved_chunks_.find(ptr) == reserved_chunks_.end()
001b406a c->in_use() && (c->bin_num == kInvalidBinNum)
001b4098  bytes has max bytes of 
001b40b1 MaxInUse:                 
001b40cc  is not currently registered or supported
001b40f6 Caught exception while destructing CustomOpsLoader with message: 
001b4138 AllocateMLValueTensorSelfOwnBufferHelper
001b4161 , fall back to default allocation behavior
001b418c onnxruntime::common::Status onnxruntime::ExecutionFrame::AllocateAsPerAllocationPlan(OrtValue &, int, const onnxruntime::TensorShape *)
001b4214 type_proto != nullptr
001b422e Duplicate entry for op id: 
001b424a PopulateKernelCreateInfo
001b4263 Could not find an implementation for 
001b4289 Use DeviceBasedPartition as default
001b42ad n >= 0 && static_cast<size_t>(n) < ort_value_info_.size()
001b42e7 !IsNonTensor(*node_output)
001b4302 /onnxruntime_src/onnxruntime/core/framework/op_kernel_context_internal.h
001b434b _kernel_time
001b4358 SaveInputOutputNamesToNodeMapping
001b437a Cannot use user supplied initializer with name: (
001b43ac Destination should be empty
001b43c8 /onnxruntime_src/onnxruntime/core/framework/tensor_shape.cc
001b4404 ) does not match the data size(
001b4424 UnpackInitializerData
001b443a Sparse Indices raw data size does not match expected.
001b4470 feed_locations.size() == copy_info.size()
001b449a onnxruntime::common::Status onnxruntime::utils::BatchOrCopyMLValue(const onnxruntime::SessionState &, const onnxruntime::MLValueCopyInfo &, const OrtValue &, OrtValue &, onnxruntime::Stream *, std::vector<IDataTransfer::SrcDstPair> *, std::vector<IDataTransfer::SparseSrcDstPair> *)
001b45b5 Bias tensor with shape (hidden_size + hidden_size + v_hidden_size) for input projection
001b460d output tensor with shape (total_tokens, hidden_size)
001b4642 Attribute expected to have tensor or sparse tensor type
001b467a The input data as Tensor.
001b4694 /onnxruntime_src/onnxruntime/core/graph/contrib_ops/contrib_defs.cc
001b46da The embedding matrix of size N x M. 'N' is equal to the maximum possible index + 1, and 'M' is equal to the embedding size
001b4755 Number of beams for beam search. 1 means no beam search. Shape is (1)
001b479b The subgraph for initialization of encoder and decoder. It will be called once before `decoder` subgraph.
001b4805 onesided
001b480e ComplexMulConj
001b481d Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero.
001b487e Three modes: `constant`(default) - pads with a given constant value, `reflect` - pads with the reflection of the vector mirrored on the first and last values of the vector along each axis, `edge` - pads with the edge values of array
001b4967 The detection_scores output tensor.
001b498b The first feature map input tensor.
001b49af NumReducedAxes = Sub (Rank, Axis1D)
001b49d3 Mean2D = ReduceMean <axes = [1]> (XU)
001b49f9 sequence_lens
001b4a07 The attention_v tensor in the attention mechanism. Should be of shape `[num_directions, am_attn_size]` 
001b4a6f x_scale
001b4a77 Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.
001b4ad9 Constrain input and output types to 8 bit tensors.
001b4b0c Input tensor of shape [N,C,H,W]
001b4b2c strides of the original tensor.
001b4b4c First operand.
001b4b5b Y_zero_point
001b4b68 Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]`.
001b4c18 present state for key and value with shape (2, batch_size, num_heads, past_sequence_length + sequence_length, head_size)
001b4c91 gamma_scale
001b4c9d order_output
001b4caa cublasLt order of matrix B
001b4cc5 QOrderedGelu
001b4cd2 LoadEdgesFromOrtFormat
001b4ce9 Invalid source node arg slot specified when removing edge.
001b4d24 This is an invalid model. Failed to find NodeArg in all parent graphs. Name=
001b4d71 onnxruntime::common::Status onnxruntime::Graph::UpdateShapeInference(onnxruntime::Node &)
001b4dcb ) is not a registered function/op
001b4ded void onnxruntime::Graph::ToGraphProtoInternal(onnx::GraphProto &) const
001b4e35 No Graph instance was found for attribute 
001b4e60  in node 
001b4e6a input_arg->Type() != nullptr
001b4e87 onnxruntime::FunctionImpl::FunctionImpl(onnxruntime::Graph &, const onnxruntime::IndexedSubGraph &)
001b4eeb nodearg
001b4ef3 Gemv found an unexpected CBLAS_TRANSPOSE input of
001b4f25 Received null OrtThreadingOptions
001b4f47 std::all_of(processor_str.begin(), processor_str.end(), ::isdigit)
001b4f8a bad dimensions
001b4f99 Writing profiler data to file 
001b4fb8 {"cat" : "
001b4fc3 "pid" :
001b4fcb " : 
001b4fd0 onnxruntime::common::Status::Status(onnxruntime::common::StatusCategory, int, const std::string &)
001b5033 NO_MODEL
001b503c Wait
001b5041 SaveValueInfoOrtFormat: value_info_proto for 
001b506f  is missing type info.
001b5086 SaveMapTypeOrtFormat
001b509b LoadMapTypeOrtFormat
001b50b0 int64_data
001b50bb Data of TensorProto ( tensor name: 
001b50e0  is not output of any previous nodes.
001b5106 optional(tensor(bfloat16))
001b5121 optional(tensor(string))
001b513a Output tensor of random values drawn from uniform distribution
001b5179 One and only one of the attributes 'value', 'value_*' or 'sparse_value' must be specified for a Constant node.
001b51e9         {
001b51f3             O1 = Greater (A, B)
001b5213             O2 = Equal (A, B)
001b5231             C = Or (O1, O2)
001b524d         }
001b5257         
001b5260 Constrain input/output to integer tensors.
001b528b less_equal
001b5298 expanded_target = Unsqueeze (target, axes)
001b52c3 target
001b52ca loss_unweighted
001b52da weight_gather_sum
001b52ec Maximum value, above which element is replaced by max
001b5322 Attribute pads has incorrect size.
001b5345 The shape of the convolution kernel. If not present, should be inferred from input 'w'.
001b539f Maximum n-gram length. If this value is 3, 3-grams will be used to generate the output.
001b53f7 List of strings n-grams learned from the training set. Either this or pool_int64s attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
001b5554 locale
001b555b OptionalHasElement is expected to have 1 output.
001b558c /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/optional/old.cc
001b55dc (Optional) The axis of the quantization dimension of the input tensor. Ignored for per-tensor quantization. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
001b56b3 Zero point for input 'x'. Shape must match x_scale. It's optional. Zero point is 0 when it's not specified.
001b571f Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization.
001b5784 L1 norm
001b578c Operator '
001b5797 ) has more inputs (
001b57ab out_sequence
001b57b8 source sequence type missing element type.
001b57e3 Input tensor to be cast.
001b57fc One or more outputs forming list of tensors after splitting
001b5838 Target shape may not have multiple -1 dimensions.
001b586a One float, indicates the value to be filled, default is 0
001b58a4 'axis' must be in [-rank(indices)-1, rank(indices)]
001b58d8 Either `sizes` or `scales` must be provided, but not both of them
001b591a  is undefined so it cannot be parsed.
001b5940 . Expected:
001b594c Values greater than this are mapped to 1, others to 0.
001b5983 A float.
001b598c The input must be a tensor of a numeric type, and of shape [N,C] or [C]. In the latter case, it will be treated as [1,C]
001b5a05 A collection of weights of the model(s).
001b5a2e List of categories, strings.<br>One and only one of the 'cats_*' attributes must be defined.
001b5a8b Indicates the transform to apply to the score. <br> One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
001b5b02 (op_type:
001b5b0c tensor_type
001b5b18 . No opset import for domain
001b5b35 onnx.ValueInfoProto
001b5b49 onnx.NodeProto
001b5b58 onnx.ModelProto
001b5b68 onnx.TensorProto
001b5b79 CHECK failed: (count) <= (buffer_used_): 
001b5ba3  message of type "
001b5bb6 Walk NULL
001b5bc6 [:digit:]
001b5bd0 /build/intermediates/arm64-v8a/Release/_deps/re2-src/re2/dfa.cc
001b5c10 /build/intermediates/arm64-v8a/Release/_deps/re2-src/re2/onepass.cc
001b5c54 Bad args: nsubmatch=
001b5c69 unexpected )
001b5c79 Bengali
001b5c81 Nushu
001b5c87 Tirhuta
001b5c8f Wancho
001b5c96 chipset detection failed: different chipset vendors reported in different system properties
001b5cf2 chipset detection failed: could not disambiguate different chipsets reported in different system properties
001b5d5e HiSilicon
001b5d68 failed to parse file %s: "%.*s" is not an unsigned number
001b5da2 locale constructed with null
001b5dbf %I:%M:%S %p
001b5dcb Wednesday
001b5dd5 July
001b5dde operator^
001b5de8  restrict
001b5df2 decimal64
001b5dfc libunwind: malformed DW_CFA_undefined DWARF unwind, reg too big
001b5e4c OrtStatusPtr OrtApis::FillSparseTensorBlockSparse(OrtValue *, const OrtMemoryInfo *, const int64_t *, size_t, const void *, const int64_t *, size_t, const int32_t *)
001b5ef2 max_dead_bytes_per_chunk
001b5f0b onnxruntime::Tensor *OrtValue::GetMutable()
001b5f37 ++index < c.size()
001b5f4a Map is missing type entry for its value
001b5f72  != 
001b5f77 static bool onnxruntime::utils::ContainerChecker::IsContainerOfType<std::map<std::basic_string<char>, long>>::check(const onnxruntime::utils::ContainerChecker::Cont &, size_t) [T = std::map<std::basic_string<char>, long>]
001b6055 void onnxruntime::InferenceSession::ConstructorCommon(const onnxruntime::SessionOptions &, const onnxruntime::Environment &)
001b60d2 Dynamic block base set to 
001b60ed  Expected: 
001b60f9 Invalid Feed Input Name:
001b6112 onnxruntime::FeedsFetchesInfo::FeedsFetchesInfo(gsl::span<const std::string>, gsl::span<const std::string>, const onnxruntime::OrtValueNameIdxMap &)
001b61a7  DeviceId:
001b61b2 invalid string: control character U+001D (GS) must be escaped to \u001D
001b61fa excessive object size: 
001b6212 Input
001b6218 /onnxruntime_src/onnxruntime/core/session/standalone_op_invoker.cc
001b625b string_view::substr
001b626f ANeuralNetworksModel_identifyInputsAndOutputs
001b629d ANeuralNetworksDevice_getName
001b62bb ANeuralNetworksMemory_createFromAHardwareBuffer
001b62eb SL_ANeuralNetworksDiagnosticCompilationInfo_getModelArchHash
001b6328 SL_ANeuralNetworksDiagnosticExecutionInfo_getSessionId
001b635f SL_ANeuralNetworksDiagnosticExecutionInfo_areDynamicTensorsUsed
001b639f ] has no input type
001b63b3 GetType(*node.InputDefs()[0], input_type)
001b63dd  type: 
001b63e5 TENSOR_QUANT8_ASYMM
001b63f9 , actual: 
001b6404  doesn't have valid type: 
001b641f The initializer is not 2D: 
001b643b ] with output, 
001b644b IsQuantizedIOSupported
001b6462 Input index,  
001b6471 IsOpSupported
001b647f !use_nchw
001b6489 constant
001b6492 pads must be known
001b64a5 ] has actual dim count 
001b64bd Only pooling 2d is supported
001b64da Argmax in maxpooling is not supported
001b6500 Invalid Node with non-constant Bias input. XNNPACK EP should not have asked for the node. Node name:
001b6565 fp16
001b656a QINT8
001b6570 Compute
001b6578 cubic
001b657e Scale value should be greater than or equal to 1.
001b65b0 onnxruntime::ResizeNearestMode onnxruntime::UpsampleBase::StringToNearestMode(const std::string &)
001b6613 xnn_create_fully_connected_nc_f32 returned 
001b663f ROCMExecutionProvider
001b6655 UnsqueezeElimination
001b666a RocmBlasAltImpl
001b667a bn_B_tensor_proto
001b668f virtual onnxruntime::NodeAttributes onnxruntime::(anonymous namespace)::actions::FuseConvActivation::ExtraAttributes(const onnxruntime::ReplaceWithNew::RuntimeState &) const
001b673d virtual std::vector<NodeAndMoveInfo> onnxruntime::(anonymous namespace)::actions::FuseConvAddRelu::ValueMoves(const onnxruntime::ReplaceWithNew::RuntimeState &) const
001b67e4 Slice ends is less than INT_MAX
001b6804 Faild to match gemm path
001b681d Faild to match concat node for Gather paths
001b6849 Mask is neither unidirectional nor all ones
001b6875 Output edge count not expected for mask nodes
001b68a3 Failed in match v_transpose attribute perm. Expected: 0, 2, 1, 3
001b68e4 Failed in match v_matmul and v_add input shape
001b6913 Fused an attention node.
001b692c Output edge count not expected for nodes in path1.
001b695f The third input of Range should be a constant with value 1.
001b699b Input is expected to have dim value in all dimensions.
001b69d2 BitmaskBiasDropout
001b69e5 fast_gelu_output
001b69f6 reorder
001b69fe /onnxruntime_src/onnxruntime/core/optimizer/nchwc_transformer.cc
001b6a3f output_channels <= nchwc_output_channels
001b6a68 _nchwc
001b6a6f /onnxruntime_src/onnxruntime/core/optimizer/qdq_transformer/clip_quantizelinear.cc
001b6ac2 node != nullptr
001b6ad2 ", index: 
001b6add _q_to_dq
001b6ae6 _out
001b6aef virtual onnxruntime::common::Status onnxruntime::Scan<8>::SetupSubgraphExecutionInfo(const onnxruntime::SessionState &, const std::string &, const onnxruntime::SessionState &) [OpSet = 8]
001b6bab session_state
001b6bb9 onnxruntime::scan::detail::Info::Info(const onnxruntime::Node &, const onnxruntime::GraphViewer &, int, bool)
001b6c27 AllocateOutput
001b6c36 Only tensors, tensor sequence, optional tensor, and optional tensor sequence types are supported
001b6c97 Loop
001b6c9c num_subgraph_outputs - 1 == num_outputs
001b6cc4 virtual onnxruntime::common::Status onnxruntime::Loop::Compute(onnxruntime::OpKernelContext *) const
001b6d29 input count mismatch
001b6d3e batch_size is < 1
001b6d50 info.GetAttr<float>("high", &high_).IsOK()
001b6d7b std::unique_ptr<Tensor> onnxruntime::EinsumOp::DeviceHelpers::CpuDeviceHelpers::Diagonal(const onnxruntime::Tensor &, int64_t, int64_t, onnxruntime::AllocatorPtr, void *)
001b6e26 . The shape is: 
001b6e3b Not all dimensions to be reduced have been reduced in the candidate output. Candidate output dims: 
001b6e9f BitwiseNot
001b6eaa Must have 1 or more inputs
001b6ec5 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Reciprocal<double>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Reciprocal<double>]
001b6f92 virtual onnxruntime::common::Status onnxruntime::Sum_6<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
001b700b void onnxruntime::GemmBroadcastBias(int64_t, int64_t, float, const T *, const onnxruntime::TensorShape *, T *) [T = double]
001b7087 threshold
001b7091  Expected std::map<int64_t, float> or std::map<int64_t, std::string>
001b70d6 onnxruntime::ml::PACK_MAP onnxruntime::ml::MakePack(const std::string &)
001b711f /onnxruntime_src/onnxruntime/core/providers/cpu/ml/cast_map.cc
001b715e const T *onnxruntime::OpKernelContext::Input(int) const [T = std::map<std::basic_string<char>, long>]
001b71c4 const T *onnxruntime::OpKernelContext::Input(int) const [T = std::map<std::basic_string<char>, double>]
001b722c ) does not match number of inputdimensions values (
001b7260 kernel_type
001b726c onnxruntime::ml::SVMRegressor<float>::SVMRegressor(const onnxruntime::OpKernelInfo &) [T = float]
001b72ce nodes_falsenodeids.size() == nodes_nodeids.size()
001b7300 TreeEnsemble only works on 1D, 2D tensors.
001b732b  but input tensor has 
001b7342 void onnxruntime::ml::detail::TreeAggregatorAverage<float, float, float>::FinalizeScores(InlinedVector<ScoreValue<ThresholdType>> &, OutputType *, int, int64_t *) const [InputType = float, ThresholdType = float, OutputType = float]
001b742a n_dims == 1
001b7436 Invalid input B: NumDimensions() != 
001b745b Invalid input mean: 
001b7470 DoConvTranspose
001b7480 kernel_shape num_dims is not compatible with X num_dims.
001b74b9  is unrecognized, acceptable values are TF,IDF,TFIDF
001b74ee static onnxruntime::common::Status onnxruntime::NonMaxSuppressionBase::PrepareCompute(onnxruntime::OpKernelContext *, onnxruntime::PrepareContext &)
001b7583 Per-column quantization parameter of batched matrix should have same dimension as the matrix,and its size by K should be equal to the matrix's size.
001b7618 static void onnxruntime::QLinearConv<unsigned char>::ComputeOffset(onnxruntime::OpKernelContext *, int64_t, ActType &, ActType &, uint8_t &) [ActType = unsigned char]
001b76bf W_zero_point_data[i] == W_zero_point_value
001b76ea /onnxruntime_src/onnxruntime/core/providers/cpu/reduction/reduction_ops.cc
001b7735 Axes input is null
001b7748 void onnxruntime::ValidateKeepDims(const onnxruntime::TensorShape &, int64_t)
001b7796 /onnxruntime_src/onnxruntime/core/providers/cpu/rnn/deep_cpu_gru.cc
001b77da Invalid value/s in sequence_lens. All values must be > 0 and < seq_length. seq_length=
001b7831 onnxruntime::rnn::detail::deepcpu::LstmMergeGatesFuncPtr onnxruntime::rnn::detail::deepcpu::LstmMergeGatesFuncByName(const std::string &)
001b78bb onnxruntime::common::Status onnxruntime::SplitToSequence::ComputeImpl(onnxruntime::OpKernelContext &, const onnxruntime::Tensor &, const onnxruntime::Tensor *) const [T = float]
001b796d Invalid data type for split tensor 
001b7991 onnxruntime::common::Status onnxruntime::CreateMelWeightMatrix<float>::operator()(onnxruntime::OpKernelContext *, int64_t, int64_t, int64_t, float, float) [T = float]
001b7a38 onnxruntime::common::Status onnxruntime::CreateMelWeightMatrix<unsigned long>::operator()(onnxruntime::OpKernelContext *, int64_t, int64_t, int64_t, float, float) [T = unsigned long]
001b7af3 %.8g
001b7af8 zeros
001b7afe  does not match input batch size 
001b7b20 onnxruntime::Reshape_1::Reshape_1(const onnxruntime::OpKernelInfo &)
001b7b65 unknown_dim == -1
001b7b77 gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = unsigned short]
001b7bc7  is greater than input dim=
001b7be7 CPU execution provider: BFloat16 data type is not supported with ScatterElements opset 18 when reduction is 'min'.
001b7c5a Ends must be a 1-D array
001b7c73 Input count of Tile OP mismatch, the first one is empty
001b7cab 'repeat' input tensor must be 1 dimensional
001b7cd7 Tile doesn't support string type yet
001b7cfc An axes tensor must be a scalar or a 1-D tensor.
001b7d2d The second input of CDist kernel has wrong shape: 
001b7d60 /onnxruntime_src/onnxruntime/contrib_ops/cpu/bert/ngram_repeat_block.h
001b7da7 /onnxruntime_src/onnxruntime/contrib_ops/cpu/crop_and_resize.h
001b7de6 /onnxruntime_src/onnxruntime/contrib_ops/cpu/element_wise_ops.h
001b7e26 onnxruntime::contrib::ImageScaler<float>::ImageScaler(const onnxruntime::OpKernelInfo &) [T = float]
001b7e8b WASM and 32-bit builds support only COO format
001b7eba channels_ <= X_shape[1]
001b7ed2 (static_cast<size_t>(X_shape[1]) < nchwc_block_size) || ((X_shape[1] % nchwc_block_size) == 0)
001b7f31 ' for NCHWc Upsample
001b7f46  must have shape {
001b7f59 /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/qlinear_binary_op.cc
001b7fa8 void onnxruntime::contrib::QlinearBuildLookupTable(uint8_t *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::contrib::LookupTableArrayTransformer &) [T = signed char]
001b80a7 /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/quant_gemm.cc
001b80ef b_zp_shape.NumDimensions() == 0 || (b_zp_shape.NumDimensions() == 1 && (b_zp_shape[0] == 1 || b_zp_shape[0] == helper.N()))
001b816b QGemm : zero point and scale of input b should have same shape size
001b81af pad_value
001b81b9 parameters_.model_type == IGenerationParameters::kModelTypeGpt || parameters_.model_type == IGenerationParameters::kModelTypeT5
001b8239 info.GetAttr<ONNX_NAMESPACE::GraphProto>("decoder", &proto).IsOK()
001b827c model_type
001b8287 repetition_penalty shall be greater than 0, got 
001b82b8 void onnxruntime::contrib::transformers::BeamHypotheses::Output(int, int, gsl::span<int32_t> &, gsl::span<float> &)
001b832c Seed must be >= 0
001b833e Validate
001b8347 logits
001b834e encoder subgraph output 0 (logits) shall be float or float16 data type
001b8395  Conv kernal size 2 : 
001b83ac Invalid DataTypeImpl TypeProto definition
001b83d6 void onnxruntime::DeviceStreamCollectionImpl::AddDeviceStream(size_t, std::unique_ptr<Stream>)
001b8435 idx < num_streams_
001b8448 feeds.size() == feed_mlvalue_idxs.size()
001b8471 ReleaseMLValueImpl
001b8484 GetCpuPreferredNodes
001b8499  capable of executing this node
001b84b9 PartitionOnnxFormatModel
001b84d2 onnxruntime::KernelLookup::KernelLookup(onnxruntime::ProviderType, gsl::span<const gsl::not_null<const KernelRegistry *>>, const onnxruntime::IKernelTypeStrResolver &)
001b857a  kernel start version: 
001b8592 bool onnxruntime::(anonymous namespace)::MatchKernelDefTypes(const onnxruntime::Node &, const onnxruntime::KernelDef &, const onnxruntime::IKernelTypeStrResolver &, std::string &)
001b8646 ResolveKernelTypeStr
001b865b AddLayoutTransformationRequiredOpsToKernelTypeStrResolver
001b8695 /onnxruntime_src/onnxruntime/core/framework/op_kernel_info.cc
001b86d3 static OrtValueTensorSlicer<T> onnxruntime::OrtValueTensorSlicer<OrtValue>::Create(T &, int64_t, int64_t) [T = OrtValue]
001b874c Invalid dim0_offset of 
001b8764 init_num == values.size()
001b877e KernelUseSharedPrePackedBuffers
001b879e " in node-stream map
001b87b3 onnxruntime::OrtValueIndex onnxruntime::PlannerImpl::Index(const onnxruntime::OrtValueName &)
001b8811 n >= 0 && static_cast<size_t>(n) < plan_.allocation_plan.size()
001b8851 Failed memory size calculation
001b8870  the same as values size: 
001b888b Indices shape must have dim[0] == 2
001b88af Expecting fully sparse tensors to have value shape {0}
001b88e6 /onnxruntime_src/onnxruntime/core/framework/tensorprotoutils.cc
001b8926 GetExternalDataInfo
001b893a onnxruntime::common::Status onnxruntime::utils::CopySparseData(size_t, const onnx::TensorProto &, const onnxruntime::Path &, gsl::span<const int64_t>, std::function<void (size_t, size_t)>)
001b89f7 InternalTestingExecutionProvider
001b8a18 token_offset shall be 2 dimensions
001b8a3b /onnxruntime_src/onnxruntime/core/graph/contrib_ops/bert_defs.cc
001b8a7c window
001b8a83 global
001b8a8a has_key_padding_mask
001b8a9f position_embedding
001b8ab2 Default value is 0.
001b8ac6 The minimum NGram size for suffix matching.
001b8af2 Previous suffix match index
001b8b0e Output 
001b8b16 true if broadcast bias across input for dimensions broadcast_axis to axis-1, otherwise broadcast bias across input for dimensions 0 to broadcast_axis - 1
001b8bb0 4-D tensor of shape (N, C, H_out, W_out).
001b8bda repetition_penalty
001b8bed sequences_scores
001b8bfe An optional string. Token's regular expression in basic POSIX format (pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap09.html#tag_09_03). If set, tokenizer may produce tokens matching the specified pattern. Note that one and only of 'tokenexp' and 'separators' should be set.
001b8d1b type used for stash mean/inv_std_var
001b8d40 Scale tensor.
001b8d4e Constrain output Y and scale type to float tensors.
001b8d82 The detection_boxes output tensor.
001b8da5 position-to-content attention tensor, KcQr^T.
001b8dd3 Maximum relative distance, k.
001b8df1 (Optional) Target device like CPU, DSP, etc.
001b8e1e Rank = Size (XShape)
001b8e33 A list of 3 (or 6 if bidirectional) activation functions for input, output, forget, cell, and hidden. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
001b8f25 Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.For example with LeakyRelu, the default alpha is 0.01.
001b9033 A 1-D values of (height, width).
001b9054 The filled tensor
001b9066 ) needs to be greater than or equal to the left_border (
001b909f Zero point for word embeddings
001b90be Constrain input and output types to float32 tensors.
001b90f3 cublasLt order of input matrix. ORDER_COL = 0, ORDER_ROW = 1, ORDER_COL32 = 2, ORDER_COL4_4R2_8C = 3, ORDER_COL32_2R_4R4 = 4. Please refer https://docs.nvidia.com/cuda/cublas/index.html#cublasLtOrder_t for their meaning.
001b91d0 cublasLt order of output matrix.
001b91f1 scale_K_weight
001b9200 quantization tensor must be int8 tensors.
001b922a scale of the weight
001b923e A_scale
001b9246 C_zero_point
001b9253 'axis' must be in [
001b9267 axis must be in [-rank, rank)
001b9285 Invalid bias shape
001b9298 Graph state to be loaded into must be empty.
001b92c5  Graph may not conform to the ONNX spec and contain initializers that are not graph inputs.
001b9321 Fatal error: 
001b932f Replaced external initializer: 
001b934f Error merging shape info for output. '
001b9376 Tout
001b937b Null tensors attribute. Invalid ORT format model.
001b93ad Attempting to get an output that does not exist.
001b93e1 Mismatch between Graph and IndexedSubGraph. Node not found: 
001b941e ModelProto does not have a graph.
001b9440 Processor id must consist of only digits: 
001b946b QLinearGlobalAveragePool ImageSize too large!
001b9499 Default logger already set. 
001b94b6 /onnxruntime_src/include/onnxruntime/core/platform/EigenNonBlockingThreadPool.h
001b9506 custom_create_thread_fn returned invalid handle.
001b9537 Failed to get symbol 
001b954d  with domain_version of 
001b9566 A boolean termination condition. Optional. Pass empty string to skip.
001b95ac An optional list of M flags. The i-th element of the list specifies the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted, 0 will be used as the scan axis for every scan_input. Negative value for an axis means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
001b96ed Mismatched tensor element type for output 
001b9718 sparse_tensor(
001b9727 complex128
001b9732 The data type for the elements of the output tensor. Default is TensorProto::FLOAT.
001b9786 Scalar. Exclusive upper limit for the range of output values.
001b97c4 The returned output tensor only has values 0 or 1, same shape as input tensor.
001b9813 normalized exponential
001b982a zero point of quantized input b
001b984a input_gather_element_transform = Where (mask, const_zero_casted, input_gather_element)
001b98a1 weight_gather = Where (squeeze_mask, const_zero_casted, const_one_casted)
001b98eb Constrain output types to numeric tensors.
001b9916 upper_edge_hertz
001b9927 X_ReduceMax = ReduceMax <keepdims = 1> (input)
001b9957                     X_Sub = Sub (input, X_ReduceMax)
001b998c                     X_Exp = Exp (X_Sub)
001b99b4                     X_ReduceSum = ReduceSum <keepdims = 1> (X_Exp, axes)
001b99fd                     output = Div (X_Exp, X_ReduceSum)
001b9a33                 
001b9a44 A scalar value indicating the length of the window.
001b9a78 Result, has same dimensions and type as A
001b9aa2 Maximum number of items (integers/strings) to be skipped when constructing an n-gram from X. If max_skip_count=1, min_gram_length=2, max_gram_length=3, this operator may generate 2-grams with skip_count=0 and skip_count=1, and 3-grams with skip_count=0 and skip_count=1
001b9bb0 Normalized tensor.
001b9bc3 Scale tensor of shape `(num_groups)`.
001b9be9 Multiplicative spatial scale factor to translate ROI coordinates from their input scale to the scale used when pooling.
001b9c61 ScaleReshaped = Reshape (ScaleT, ScaleShape)
001b9c8e Number of sampling points in the interpolation grid used to compute the output value of each pooled output bin. If > 0, then exactly sampling_ratio x sampling_ratio grid points are used. If == 0, then an adaptive number of grid points are used (computed as ceil(roi_width / output_width), and likewise for height). Default is 0.
001b9dd7 Error parsing TensorProto shape (expected numeric dimension).
001b9e15 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/quantization/old.cc
001b9e6e     data_abs = Abs(data)
001b9e87     reduced = ReduceSum<keepdims: int = @keepdims>(data_abs, axes)
001b9ed1 One (or two if bidirectional) activation function for input gate. The activation function must be one of the activation functions specified above. Optional: Default `Tanh` if not specified.
001b9f8f Extra unparsed input unexpected.
001b9fb0 Insert and concatenate on a new axis or not, default 0 means do not insert new axis.
001ba005 Input type for input at index 0 is null. Type info is expected.
001ba045 Transposed output.
001ba058 squeezed
001ba061 Blocks of [blocksize, blocksize] are moved.
001ba08d depth
001ba093  has rank 
001ba09e Slice op must have either three, four or five inputs.
001ba0d4 x_shape2 = Shape (padded_input)
001ba0f4 start_dims = Div (sh_diff, k2)
001ba113 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/tensor/old.cc
001ba161 1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1.
001ba1e6 width_scale
001ba1f2 The scale along height dimension. It takes value greater than or equal to 1.
001ba23f List of categories, ints.<br>One and only one of the 'cats_*' attributes must be defined.
001ba299 , node name: 
001ba2a7 onnx.TypeProto
001ba2b6 [:graph:]
001ba2c0 /build/intermediates/arm64-v8a/Release/_deps/re2-src/re2/tostring.cc
001ba305 Bopomofo
001ba30e Gunjala_Gondi
001ba31c Takri
001ba322 failed to parse both lists of possible and present processors
001ba360 failed to allocate %zu bytes for descriptions of %u cores
001ba39a condition_variable wait failed
001ba3b9 iostream
001ba3c9 non-virtual thunk to 
001ba3df std::basic_istream<char, std::char_traits<char> >
001ba411 pixel vector[
001ba41f union
001ba425 terminating with %s exception of type %s: %s
001ba452 _Unwind_Resume() can't return
001ba470 libunwind: malformed DW_CFA_register DWARF unwind, reg too big
001ba4b0 not enough space: expected 
001ba4cc UseCsrIndices
001ba4da UseBlockSparseIndices
001ba4f0 initial_chunk_size_bytes
001ba50b const onnxruntime::TensorSeq &OrtValue::Get() const
001ba53f static bool onnxruntime::utils::ContainerChecker::IsContainerOfType<std::map<std::basic_string<char>, float>>::check(const onnxruntime::utils::ContainerChecker::Cont &, size_t) [T = std::map<std::basic_string<char>, float>]
001ba61f No requested allocator available
001ba640 Creating and using per session threadpools since use_per_session_threads_ is true
001ba692  as all the graph nodes have not been partitioned to the CUDA EP.
001ba6d4 disable_synchronize_execution_providers
001ba6fc GetModelOutputs
001ba710 SetEnableProfiling
001ba723 invalid string: control character U+0017 (ETB) must be escaped to \u0017
001ba76c <U+%.4X>
001ba775 input
001ba77b  Target=
001ba784  known by the checker.
001ba79b libonnxruntime_providers_migraphx.so
001ba7c0 const T *onnxruntime::Tensor::Data() const [T = bool]
001ba7f6 invalid arg_num.
001ba807 Nnapi
001ba80d The actual input dimensions should match the model input dimensions, or model input dimension has 0 (dynamic)
001ba87b ANeuralNetworksCompilation_free
001ba89b SL_ANeuralNetworksDiagnosticCompilationInfo_getOutputDataClass
001ba8da SL_ANeuralNetworksDiagnosticExecutionInfo_getExecutionMode
001ba915 ] has input [
001ba923 ] must be an initializer tensor
001ba943 Var of BN must be known
001ba95b Unsupported op type: 
001ba971 BuildBatchMatMul
001ba982 /gemm_
001ba989 u8s8 Qlinear[Conv/MatMul]  only support 0 as zero point, 
001ba9c3 QDQ NodeUnit [
001ba9d2 ] with external data location are not currently supported
001baa0c [Cast] Only support cast to int32 or float, actual to type, 
001baa49 Input[
001baa50 Perm and input should have same dimension
001baa7e storage_order == 1 is not supported
001baaa2 Dilations of pooling is not supported
001baac8 Tanh
001baacd unsupported Conv in XnnpackEP, we have FLOAT|UINT8|INT8, but got 
001bab0f Not enough elements in strides. Expected: 
001bab3a _nhwc_
001bab41 qdq_to_onnx_type_map.count(qtype)
001bab63 /onnxruntime_src/onnxruntime/core/providers/xnnpack/nn/average_pool.cc
001babaa onnxruntime::xnnpack::Softmax::Softmax(const onnxruntime::OpKernelInfo &)
001babf4 extrapolation_value
001bac08 onnxruntime::xnnpack::Resize::Resize(const onnxruntime::OpKernelInfo &)
001bac50 only support bilinear resize
001bac6d info.GetAttrs<float>("scales", scales_).IsOK()
001bac9c ExpandElimination
001bacae graph.RemoveNode(gemm_node.Index())
001bacd2 ConvAddFusion_B_
001bace3 onnxruntime::FreeDimensionOverrideTransformer::FreeDimensionOverrideTransformer(gsl::span<const FreeDimensionOverride>)
001bad5b Output edge count not expected for nodes in gemm gather path
001bad98 ValidateUnidirMask returns false for mask_slice
001badc8 CheckNodesInPathV
001badda qk_div const not matched.
001badf4 CheckNodesInPathK
001bae06 Pass CheckNodesInPathK
001bae1d Attention
001bae27 unidirectional
001bae36 FuseSubGraphQKImpl
001bae49 The first input of Range should be a constant with value 0.
001bae85 Second input of Gather in path 1 of position shape should be a constant with value 0.
001baedb _Cast
001baee1 axis >= 0
001baeeb epsilon
001baef3 bool onnxruntime::GetTransposePerms(const onnxruntime::Node &, std::vector<int64_t> &)
001baf4a Upsample
001baf53 static std::optional<ExtendedGraphEdge> onnxruntime::graph_utils::ExtendedGraphEdge::TryCreateFromInputOrInitializerToNode(const onnxruntime::Graph &, const onnxruntime::Node &, int)
001bb00a weight_zp_s8_2_u8
001bb01c Failed to set node op schema.
001bb03a auto onnxruntime::GetNodesToOptimizeIndices(gsl::span<const NodeIndex>, onnxruntime::NodeIndex, gsl::span<const NodeIndex>, int, int)::(anonymous class)::operator()(onnxruntime::NodeIndex) const
001bb0fd Copy from/to host memory
001bb116 Data
001bb11b virtual std::unique_ptr<api::ValueInfoRef> onnxruntime::ApiGraph::GetValueInfo(std::string_view) const
001bb182 /onnxruntime_src/onnxruntime/core/providers/cpu/activation/activations.cc
001bb1cc No attribute with name:'
001bb1e5 Scan inputs have inconsistent batch size. Previous value was 
001bb223  but has 
001bb22d scan_output_directions
001bb244 ' dimension 
001bb251 Unsupported value attribute datatype: 
001bb278 PrepareCompute
001bb287 void onnxruntime::Clip::ComputeImpl<unsigned long>::operator()(const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, onnxruntime::Tensor *) const [T = unsigned long]
001bb34e info.GetAttr<std::string>("equation", &equation_).IsOK()
001bb387  is incompatible in the dimension 
001bb3aa BitwiseXor
001bb3b5 shape_data_tensor.Shape().GetDims().size() == 1
001bb3e5 fmod
001bb3ea void onnxruntime::mod_internal::CallModImpl<double>::operator()(bool, onnxruntime::OpKernelContext *) const [T = double, Enable = void]
001bb472 TO_INT64
001bb47b const T *onnxruntime::OpKernelContext::Input(int) const [T = std::map<long, double>]
001bb4d0  in tree 
001bb4da class_nodeids
001bb4e8 void onnxruntime::ml::detail::TreeAggregatorAverage<double, double, float>::FinalizeScores(InlinedVector<ScoreValue<ThresholdType>> &, OutputType *, int, int64_t *) const [InputType = double, ThresholdType = double, OutputType = float]
001bb5d4 void onnxruntime::ml::detail::TreeAggregatorSum<long, float, float>::MergePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = long, ThresholdType = float, OutputType = float]
001bb6ce  and bias size of 
001bb6e1 p_ == 1 || p_ == 2
001bb6f4 R->Shape()[1] == 5
001bb707 op_kernel_info.GetAttr<float>("bias", &bias_temp).IsOK()
001bb740 !sw.empty()
001bb74c size_t(impl_->max_gram_length_) <= impl_->ngram_counts_.size()
001bb78b ngram_indexes
001bb799 Non-empty ngram_indexes is required
001bb7bd Input shape must have either [C] or [B,C] dimensions with B > 0.
001bb7fe will be different.
001bb811 Trying to use OptionalGetElement on an optional type OrtValue which contains no data
001bb866 /onnxruntime_src/onnxruntime/core/providers/cpu/optional/optional_ops.h
001bb8ae /onnxruntime_src/onnxruntime/core/providers/cpu/quantization/matmul_integer.cc
001bb8fd MatmulInteger : input1 zero point must be a scalar or 1D tensor of size 1
001bb947 static std::vector<float> onnxruntime::QLinearConv<signed char>::ComputeOutputScale(onnxruntime::OpKernelContext *, int64_t) [ActType = signed char]
001bb9dc last_loop_red_size > 0
001bb9f3 Only works on matrices with three dimensions.
001bba21 input_forget
001bba2e /onnxruntime_src/onnxruntime/core/providers/cpu/rnn/rnn.cc
001bba69 allowed_directions.find(direction_) != allowed_directions.end()
001bbaa9 Input W must have shape {
001bbac3 onnxruntime::ConcatBase::ConcatBase(const onnxruntime::OpKernelInfo &, bool)
001bbb10 /onnxruntime_src/onnxruntime/core/providers/cpu/signal/dft.cc
001bbb4e onnxruntime::common::Status onnxruntime::discrete_fourier_transform(onnxruntime::OpKernelContext *, int64_t, bool, bool)
001bbbc7 tensor->Shape().Size() == 1
001bbbe3 Ensure that the dft size is smaller than the signal.
001bbc18 /onnxruntime_src/onnxruntime/core/framework/copy.h
001bbc4b auto onnxruntime::StridedCopy(concurrency::ThreadPool *, unsigned char *, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShape &, const unsigned char *, const onnxruntime::TensorShapeVector &)::(anonymous class)::operator()(std::ptrdiff_t, std::ptrdiff_t) const
001bbd63 void onnxruntime::core_impl(const onnxruntime::Tensor *, const onnxruntime::Tensor *, onnxruntime::Tensor *, int64_t, concurrency::ThreadPool *) [Tin = int]
001bbe00 GatherElements op: Unsupported tensor type, size:
001bbe32 mode "
001bbe39 virtual onnxruntime::common::Status onnxruntime::NonZero<bool>::Compute(onnxruntime::OpKernelContext *) const [T = bool]
001bbeb2 edge
001bbeb7 Input tensor has no dimensions
001bbed6 'pads' has wrong number of values
001bbef8 batch_axis
001bbf03 batch_axis != time_axis
001bbf1b CPU execution provider: MLFloat16 data type is not supported with ScatterElements opset 18 when reduction is 'min'.
001bbf8f SpaceDepth ops require a 4-D input. Provided rank: 
001bbfc3  does not align with rank of input data: 
001bbfed  is outside range.
001bc000 Only one of scales or sizes must be provided as input.
001bc037 Attention layer weight shape error! Expected: {
001bc067 onnxruntime::contrib::BahdanauAttention<float>::BahdanauAttention(onnxruntime::AllocatorPtr, const logging::Logger &, int, int, int, int, int, bool, concurrency::ThreadPool *) [T = float]
001bc123 onnxruntime::ElementWiseKernel<onnxruntime::functors::ScaledTanh<float>>::ElementWiseKernel(const onnxruntime::OpKernelInfo &) [F = onnxruntime::functors::ScaledTanh<float>]
001bc1d1 scores_dims[0] == batch_size
001bc1ee ExpandDims
001bc1f9 onnxruntime::common::Status onnxruntime::contrib::NchwcPoolBase::NchwcPool(onnxruntime::OpKernelContext *, MLAS_POOLING_KIND) const
001bc27d input x_zero_point must be a scalar or 1D tensor of size 1 if given
001bc2c1 QGemm
001bc2c7 Input 'attention_mask' is expected to have 2 dimensions, got 
001bc305 repetition_penalty > 0.0f
001bc31f GreedySearchProcessLogits
001bc339 onnxruntime::common::Status onnxruntime::contrib::GenerationCpuDeviceHelper::ExpandBuffer(onnxruntime::Stream *, const OrtValue &, int, onnxruntime::AllocatorPtr, OrtValue &, bool) [T = int]
001bc3f8 /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/greedy_search_impl_base.h
001bc44c subgraph output present_key_self_0 is expected to have 4 dimension, got 
001bc495 decoder subgraph input 1 shall be named as encoder_attention_mask, got: 
001bc4de decoder subgraph input 2 (encoder_hidden_states) shall have float or float16 type
001bc530 /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/subgraph_t5_encoder.cc
001bc581 onnxruntime::common::Status onnxruntime::contrib::transformers::T5EncoderSubgraph::CreateInitialFeeds(const onnxruntime::Tensor &, const OrtValue *, const std::vector<const OrtValue *> &, int, int, std::vector<OrtValue> &, const GenerationDeviceHelper::CreateEncoderInputsFunc &, const GenerationDeviceHelper::AddToFeedsFunc &, IAllocatorUniquePtr<char> &, OrtValue &, onnxruntime::Stream *)
001bc709 Conv kernal size 1 does not match conv_window_size attribute .
001bc748 WordConvEmbedding
001bc75a void onnxruntime::AllocatorManager::InsertAllocator(onnxruntime::AllocatorPtr)
001bc7a9 Requested 
001bc7b4  chunks of size 
001bc7c5 float16
001bc7cd ExecutionFrame
001bc7dc ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < alloc_plan.size()
001bc82d  However the types are incompatible. 
001bc853 OpKernel was null
001bc865 const OrtMemoryInfo &onnxruntime::OpKernelInfo::GetMemoryInfo(int, OrtMemType) const
001bc8ba Can't slice a non-tensor OrtValue. Type was 
001bc8e7 onnxruntime::OrtValueTensorSlicer<OrtValue>::Iterator::Iterator(T &, size_t, size_t, int64_t, onnxruntime::OrtValueTensorSlicer::Iterator::Direction) [T = OrtValue]
001bc98c node_index_info_.has_value()
001bc9a9 cannot use operator[] with a string argument with 
001bc9dc SessionScope
001bc9e9 Inner and Outer indices must either be both zero or non-zero
001bca26  dimensions.
001bca33 ConstantNodeProtoToTensorProto
001bca52 ExecuteGraphImpl
001bca63 Key with shape (batch_size, kv_sequence_length, hidden_size), or packed KV with shape (batch_size, kv_sequence_length, num_heads, 2, head_size)
001bcaf3 3D skip tensor with shape (batch_size, sequence_length, hidden_size)
001bcb38 RestorePadding
001bcb47 X_bias = Add (X, bias)
001bcb5e Alpha value.
001bcb6b upper
001bcb71 Constrain input and output types to all numeric tensors and bool tensors.
001bcbbb Word IDs of generated sequences. Shape is (batch_size, num_return_sequences, max_sequence_length)
001bcc1d Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero.
001bcc7e Input/Output is a string tensor
001bcc9e The string used to pad output tensors when the tokens extracted doesn't match the maximum number of tokens found. If start/end markers are needed, padding will appear outside the markers.
001bcd5a Whether B should be transposed on the last two dimensions before doing multiplication
001bcdb0 RoIs (Regions of Interest) to pool over; rois is 2-D input of shape (num_rois, 4) given as [[y1, x1, y2, x2], ...]. The RoIs' coordinates are normalized in the coordinate system of the input image. Each coordinate set has a 1:1 correspondence with the 'batch_indices' input.
001bcec3 feature_map_0
001bced1 The disentangled attention output tensor.
001bcefb Incompatible dimensions
001bcf14                 CX = Mul (C, X)
001bcf34                 ERFCX = Erf (CX)
001bcf55                 ERFCXPlus1 = Add (ERFCX, One)
001bcf83                 PhiX = Mul (ERFCXPlus1, Half)
001bcfb1                 Y = Mul (X, PhiX)
001bcfd3             
001bcfe0 X2D = Flatten (X)
001bcff2 Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.
001bd0ca auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output spatial size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding.
001bd22e w_scale
001bd236 1-D tensor of ending indices (exclusive) of corresponding axis in axes
001bd27d GRUUnit
001bd285 Constrain 'y_zero_point' and 'y' to 8-bit integer tensors.
001bd2c0 Couple the input and forget gates if 1.
001bd2e8 2D input tensor with shape (input_hidden_size, 3 * hidden_size), hidden_size = num_heads * head_size
001bd34d Scale for 1D gamma tensor
001bd367 scale_global_weight
001bd37b input index: 
001bd389 onnxruntime::Graph::Graph(const onnxruntime::Model &, onnx::GraphProto *, const std::unordered_map<std::string, int> &, onnxruntime::Version, onnxruntime::IOnnxRuntimeOpSchemaCollectionPtr, onnxruntime::Graph *, const onnxruntime::Node *, const logging::Logger &, bool)
001bd497 graph_proto != nullptr
001bd4ae Sparse initializer must have a name. This model is invalid
001bd4e9 Move it out of graph inputs if there is no need to override it, 
001bd52a  as it still has output edges.
001bd549 Node index is out of range
001bd564 Missing name for SparseTensor initializer. Invalid ORT format model.
001bd5a9 Processor id must start from 1: 
001bd5ca Failed to read affinities from affinity string
001bd5fc Session
001bd604 ": {
001bd609 "num_run": 
001bd615 pthread_attr_init failed, error code: 
001bd63c lseek
001bd642 UnmapFile
001bd64c , path: 
001bd655 opset import domain is null. Invalid ORT format model.
001bd68c Sparse tensor indices (
001bd6a4 attr
001bd6a9 init
001bd6ae Tensor initializers must have a non-empty name
001bd6dd  is invalid for a tensor of rank 
001bd6ff Values that are live-out to the enclosing scope. The return values in the `then_branch` and `else_branch` must be of the same shape and same data type.
001bd797 DataTypeUtils::FromDataTypeString - Received invalid data type string 
001bd7de high
001bd7e3 Attribute expected to have a one-dim sparse tensor
001bd816 Output type must be int32 or int64
001bd839 Constrain output to boolean tensor.
001bd85d output = Identity (input)
001bd877 Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N).
001bd912 Dimension on which to do the sort. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
001bd9a0 const_zero_casted = Cast (const_zero_float)
001bd9cc const_one_float
001bd9dc For real input, the following shape is expected: [batch_idx][signal_dim1][signal_dim2]...[signal_dimN][1]. For complex input, the following shape is expected: [batch_idx][signal_dim1][signal_dim2]...[signal_dimN][2]. The first dimension is the batch dimension. The following N dimentions correspond to the signal's dimensions. The final dimension represents the real and imaginary parts of the value in that order.
001bdb7b frame_length
001bdb88 Coefficient of SELU default to 1.6732.
001bdbaf Dilation value along each spatial axis of filter. If not present, the dilation defaults to 1 along each spatial axis.
001bdc25 'output_shape' must be rank 1 tensor.
001bdc4b input_mean
001bdc56 The running variance after the BatchNormalization operator. This op uses the population size (N) for calculating variance, and not the sample size N-1.
001bdcee 1-dimensional tensor with stride value along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.
001bdd70 Output data tensor from Lp pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes.
001bddf1 Square = Mul (X3D, X3D)
001bde09 The storage order of the tensor. 0 is row major, and 1 is column major.
001bde51 Stride along each spatial axis.
001bde71 dilation value along each spatial axis of the filter.
001bdea7 selected indices from the boxes tensor. [num_selected_indices, 3], the selected index format is [batch_index, class_index, box_index].
001bdf2e Type of the element in the optional output
001bdf59 OptionalHasElement is expected to have 1 input.
001bdf89 Output zero point. It's a scalar, which means a per-tensor/layer quantization.
001bdfdd     data_double = Cast<to = 11>(data)
001be003     data_exp = Exp (data_double)
001be024     reduced_sum = ReduceSum<keepdims: int = @keepdims>(data_exp, axes)
001be06b     reduced_double = Log (reduced_sum)
001be092     reduced = CastLike(reduced_double, data)
001be0c6 layout
001be0cd The recurrence weight tensor. Concatenation of `R[zrh]` and `RB[zrh]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 3*hidden_size, hidden_size]`.
001be17f Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM.
001be217  typestr: 
001be222 , has unsupported type: 
001be23b Mismatched attribute type in '
001be25a ONNX Schema 
001be267 Input type for input at index 
001be286  sum of split values=
001be29c Mismatched type:
001be2ad Mismatched tensor element type:
001be2cd Element type of sequence input was unknown
001be2f8 Output tensor produced by casting the first input tensor to have the same type as the second input tensor.
001be363 Support padding modes for outside grid values: `zeros`(default), `border`, `reflection`. zeros: use 0 for out-of-bound grid locations, border: use border values for out-of-bound grid locations, reflection: use values at locations reflected by the border for out-of-bound grid locations. If index 0 represents the margin pixel, the reflected value at index -1 will be the same as the value at index 1. For location far away from the border, it will keep being reflected until becoming in bound. If pixel location x = -3.5 reflects by border -1 and becomes x' = 1.5, then reflects by border 1 and becomes x'' = 0.5.
001be5c9 Rank 1 tensor of booleans to indicate which slices or data elements to be selected. Its length can be less than the input length along the axis or the flattened input size if axis is not specified. In such cases data slices or elements exceeding the condition length are discarded.
001be6e3 Constrain output types to boolean tensors.
001be70e axis must be in [-rank, rank-1].
001be72f values in 'axes' are beyond the bounds of the computed output shape
001be773 Blocksize must be positive
001be78e 'input' must have rank >= 2
001be7aa Which axis to concat on.  Default value is 1.
001be7d8 Output tensor of same shape and type as input.
001be807 Axes that `starts` and `ends` apply to. It's optional. If not present, will be treated as [0, 1, ..., len(`starts`) - 1].
001be881 Unknown value for `keep_aspect_ratio_policy`: 
001be8b0 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/traditionalml/defs.cc
001be906 Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
001be97b Popularity of each node, used for performance and may be omitted.
001be9bd The keys when using int keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
001bea22 Input type is not int64 tensor but keys_int64s is set
001bea58  were provided
001bea67 sequence_type
001bea75 /build/intermediates/arm64-v8a/Release/_deps/re2-src/re2/re2.cc
001beab5 text size: 
001beac1 [:^alpha:]
001beacc [:^ascii:]
001bead7 [:^graph:]
001beae2 [:print:]
001beaec [:space:]
001beaf6 /build/intermediates/arm64-v8a/Release/_deps/re2-src/re2/nfa.cc
001beb36 unexpected error
001beb47 (?HaveMatch:%d)
001beb57 []^-\
001beb5d Bamum
001beb63 Carian
001beb6a Chorasmian
001beb75 Medefaidrin
001beb81 Meroitic_Cursive
001beb92 Nandinagari
001beb9e Osmanya
001beba6 Psalter_Pahlavi
001bebb9 mu not held on entry to nsync_cv_wait_with_deadline()
001bebf0 nsync_mu not held in some mode when calling nsync_mu_wait_with_deadline()
001bec3b uarch
001bec41 failed to allocate %zu bytes for descriptions of %u logical processors
001bec88 failed to allocate %zu bytes for descriptions of %u L1I caches
001becc7 sailfish
001becd0 Leadcore
001becdc ro.product.board
001beced system
001becf7 yptn
001becfc operator%=
001bed07 DW_OP_fbreg not implemented
001bed2b input array doesn't equal tensor size
001bed51 Opaque type is not a non_tensor type!!!
001bed79 Invalid key found: 
001bed8d  was false.
001bed9b IsSparseTensor()
001bedac OrtValue should contain a Tensor or a Sparse Tensor
001bede3 T *onnxruntime::Tensor::MutableData() [T = std::basic_string<char>]
001bee27 When the session is not configured to use per session threadpools, the env must be created with the the CreateEnvWithGlobalThreadPools API.
001beeb3 The old ORT format model (version 
001beed6 Initialize
001beee1 This session cannot use the CUDA Graph feature as requested by the user 
001bef2a NewIOBinding
001bef37 )) , expected: (
001bef4f object
001bef56 custom op registered at runtime
001bef76 SyncProviders
001bef84 Using partitioning stop ops list from configuration: "
001befbb Inconsistent output sizes
001befd5 TENSOR_QUANT8_SYMM_PER_CHANNEL
001beff4 , for NodeUnit with node index: 
001bf015 Node [
001bf01c ]], 
001bf021 mem_initializers_
001bf033 ] is not a quantized op
001bf04b int64_t onnxruntime::HandleNegativeAxis(int64_t, int64_t)
001bf085 AddScalarOperand
001bf096 ] is only supported for opset [
001bf0b6 ] fused
001bf0be  is different than input[0]'s scale: 
001bf0e4 ] GetQuantizationScaleAndZeroPoint for input_scale/zp failed, message: 
001bf12c allowzero
001bf136 Unsqueeze only supports 1-4d shape, input is 
001bf164 count_include_pad == 1 is not supported
001bf18c C of Gemm must be a vector or a tensor with only last dimension != 1
001bf1d1 info.TryGetConstantInput(weight_index, &Weight)
001bf201 Not enough elements in kernel shape. Expected: 
001bf231 dilations.size() == kernel_shape.size()
001bf259 onnxruntime::TensorShapeVector onnxruntime::PoolAttributes::SetOutputSize(const onnxruntime::TensorShape &, int64_t, onnxruntime::TensorShapeVector *) const
001bf2f6 Upsample operator
001bf308 onnxruntime::AspectRatioPolicy onnxruntime::UpsampleBase::StringToKeepAspectRatioPolicy(const std::string &)
001bf375  Output dim value: 
001bf389 onnxruntime::common::Status onnxruntime::MatMulComputeHelper::Compute(const onnxruntime::TensorShape &, const onnxruntime::TensorShape &, bool, bool, bool, bool, bool)
001bf431 /onnxruntime_src/onnxruntime/core/optimizer/graph_transformer.cc
001bf472 /onnxruntime_src/onnxruntime/core/optimizer/graph_transformer_mgr.cc
001bf4b7 EmbedLayerNormFusion
001bf4cc FreeDimensionOverrideTransformer
001bf4ed Faild to match the path (Div-->Where-->Add) for unidirectional mask
001bf531 Pass MatchInputMaskSubgraph
001bf54d MatchPastSubgraph
001bf55f LayerNormalization
001bf572 Gather node in path 2 is not linked to another subgraph.
001bf5ab Position embedding data type shall be float or float16.
001bf5e3 /onnxruntime_src/onnxruntime/core/optimizer/bias_softmax_fusion.cc
001bf626 fused LayerNorm subgraphs 
001bf641 gemm
001bf646 group
001bf64c HardSwish
001bf656 Less
001bf65b ReduceMax
001bf665 info.GetAttr<int64_t>("num_scan_inputs", &num_scan_inputs_).IsOK()
001bf6a8 typename std::enable_if<!std::is_const<reference>::value, reference>::type onnxruntime::OrtValueTensorSlicer<const OrtValue>::Iterator::operator*() [T = const OrtValue]
001bf751 SetupSubgraphExecutionInfo
001bf76c . Output tensor rank was 
001bf786 Empty dimensions for input tensor
001bf7a8 virtual onnxruntime::common::Status onnxruntime::Det<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
001bf81f /onnxruntime_src/onnxruntime/core/providers/cpu/math/einsum.h
001bf85d Batch dimension should match for MatMul;
001bf886 void onnxruntime::EinsumTypedComputeProcessor<int>::FinalizeOutput(const onnxruntime::Tensor &, const gsl::span<const int64_t> &) [T = int]
001bf912 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Abs<unsigned int>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Abs<unsigned int>]
001bf9dd virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Neg<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Neg<float>]
001bfa9a LEFT
001bfa9f largest <= 1
001bfaac onnxruntime::Mod::Mod(const onnxruntime::OpKernelInfo &)
001bfae5 onnxruntime::ml::FeatureVectorizer::FeatureVectorizer(const onnxruntime::OpKernelInfo &)
001bfb3e imputed_value_floats
001bfb53 Must provide imputed_values_float_ or imputed_values_int64_ but not both.
001bfb9d onnxruntime::ml::LinearClassifier::LinearClassifier(const onnxruntime::OpKernelInfo &)
001bfbf4 onnxruntime::ml::ScalerOp<double>::ScalerOp(const onnxruntime::OpKernelInfo &) [T = double]
001bfc50 int64_t onnxruntime::ml::detail::TreeAggregatorClassifier<float, float, float>::_set_score_binary(int &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = float, ThresholdType = float, OutputType = float]
001bfd30 Zipmap does not support empty dim count
001bfd58 strides_.size() == kernel_shape_.size()
001bfd80 onnxruntime::BatchNorm<float>::BatchNorm(const onnxruntime::OpKernelInfo &) [T = float]
001bfdd8 Invalid input scale: 
001bfdee Invalid input var: NumDimensions() != 
001bfe15 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/dropout_op.h
001bfe55 Mismatch between input data and scale: size of scale != input channel count 
001bfea2 pooled_width_ > 0
001bfeb4 Negative ngram_indexes values are not allowed
001bfee2 impl_->weights_.size() == impl_->ngram_indexes_.size()
001bff19 end_idx >= start_idx && end_idx <= total_items
001bff48 -grams
001bff4f /onnxruntime_src/onnxruntime/core/providers/cpu/object_detection/roialign.h
001bff9b IsScalarOr1ElementVector(W_Zero_Point)
001bffc2 Non per-tensor quantization is not supported now.
001bfff4 x_ptr != nullptr
001c0005 virtual onnxruntime::common::Status onnxruntime::MatMulInteger::Compute(onnxruntime::OpKernelContext *) const
001c0073 IsScalarOr1ElementVector(y_scale)
001c0095 fast_shape[0] == output.Shape().Size()
001c00bc activation_alpha
001c00cd A + (M * lda - (lda - K)) <= A_end
001c00f0 thresholdedrelu
001c0100 virtual onnxruntime::common::Status onnxruntime::ConcatFromSequence::Compute(onnxruntime::OpKernelContext *) const
001c0173 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/concatbase.h
001c01b7 , expect 2
001c01c2 Invalid 'mode' attribute value
001c01e1 data_rank > 0
001c01ef ScatterElements
001c01ff Indices vs updates dimensions differs at position=
001c0232 FillVectorsFromInput
001c0247 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/split.cc
001c0287 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/transpose.cc
001c02cb Method IncrementIndexAndComputeOffset assumes this value is strictly positive.
001c031a onnxruntime::UnsqueezeBase::UnsqueezeBase(const onnxruntime::OpKernelInfo &)
001c0367  v_hidden_size=
001c0377 input index out of range
001c0390 TransposeMatMul
001c03a0 info.GetAttrs<float>("bias", bias_).IsOK()
001c03cb /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/matmul_integer16.cc
001c0419 /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/qlinear_concat.cc
001c0465 virtual onnxruntime::common::Status onnxruntime::contrib::QLinearGlobalAveragePool::Compute(onnxruntime::OpKernelContext *) const
001c04e7 tensor_x_zero_point == nullptr || IsScalarOr1ElementVector(tensor_x_zero_point)
001c0537 Input scale is not float for quantized output z @ 7
001c056b static void onnxruntime::contrib::QGemm::CheckInputs(const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::GemmHelper &)
001c066f /onnxruntime_src/onnxruntime/contrib_ops/cpu/tokenizer.cc
001c06a9 Input string contains invalid utf8 chars
001c06d2 early_stopping
001c06e1 no_repeat_ngram_size
001c06f6 input_ids shall have 2 dimensions. Got 
001c071e onnxruntime::common::Status onnxruntime::contrib::GenerationCpuDeviceHelper::GreedySearchProcessLogits(const OrtValue &, transformers::IGreedySearchState<T> *, transformers::ISamplingState<T> *, transformers::ISequences *, onnxruntime::AllocatorPtr &, onnxruntime::concurrency::ThreadPool *, transformers::ILogitsProcessorList *, const transformers::IGenerationParameters *, bool, int, onnxruntime::Stream *, const transformers::IConsoleDumper *) [T = float]
001c08e9 Invalid GPT-2 subgraph: number of outputs shall be larger than 1 (Need past state in outputs).
001c0948 attention_mask
001c0957 subgraph input 3 (past_0) shall shall have same data type of logits output
001c09a2 Invalid hidden_states expension: has_hidden_state_ == false
001c09de  conv_window_size attribute: 
001c09fc void onnxruntime::BFCArena::Merge(BFCArena::ChunkHandle, BFCArena::ChunkHandle)
001c0a4c . Total 
001c0a55 , prev: 
001c0a5e We do not expect duplicate registration of types for: 
001c0a95 expected a registered ONNX type
001c0ab5 OrtValue shape verification failed. Current shape:
001c0ae8 int onnxruntime::NodeIndexInfo::GetMLValueIndex(int) const
001c0b23 IExecutionProvider constructor must be called with true for use_metadef_id_creator
001c0b76  was inserted using the NHWC format as requested by 
001c0bab op_kernel_type_str_args is null.
001c0bcc onnxruntime::MLDataType onnxruntime::utils::GetMLDataType(const onnxruntime::NodeArg &)
001c0c24 Tensor types should have been handled already
001c0c52 Execution frame was null
001c0c6b /onnxruntime_src/onnxruntime/core/framework/mem_pattern_planner.h
001c0cad . Shape:
001c0cb6 session.disable_prepacking
001c0cd1 The op type of a node cannot be empty
001c0cf7 "subtype": 
001c0d03 : 0x
001c0d08 ' Status Message: 
001c0d1b Expecting fully sparse tensors to have indices shape {0}
001c0d54  released
001c0d5e int64_t onnxruntime::TensorShape::SizeToDimension(size_t) const
001c0d9e Argument is not a tensor
001c0db7 Unsupported sparse tensor data type of 
001c0ddf input shall be 3 dimensions
001c0dfb Constrain mask to integer types
001c0e1b 3D output tensor with shape (sequence_length, batch_size, hidden_size)
001c0e62 2D with shape (,hidden_size)
001c0e7f 4D output tensor with shape (1, num_heads, sequence_length, sequence_length)
001c0ecc padding_idx
001c0ed8 data
001c0edd Pads
001c0ee2 an optional list of strings attribute that contains a list of separators - regular expressions to match separators Two consecutive segments in X connected by a separator would be divided into two tokens. For example, if the input is "Hello World!" and this attribute contains only one space character, the corresponding output would be ["Hello", "World!"]. To achieve character-level tokenization, one should set the 'separators' to [""], which contains an empty string.
001c10b9 Whether A should be transposed on the 1st dimension and batch dimensions (dim-1 to dim-rank-2) before doing multiplication
001c1134 An input tensor to hash.
001c114d Specify batchs of sequence words to embedding
001c117b (Optional) A scalar or rank 1 tensor containing a single value to be filled if the mode chosen is `constant` (by default it is 0.0).
001c1200 Saved inverse standard deviation used during training to speed up gradient computation.
001c1258 DisentangledAttention_TRT
001c1272 Constrain output 'mask' types to bit-packed uint32 tensor.
001c12ad XU = Cast (X2D)
001c12bd Output scale. It's a scalar, which means a per-tensor/layer quantization.
001c1307 If 1, mean and variance are computed across channels. Default is 0.
001c134b Constrain shape and strides to uint64.
001c1372 1-D, contiguous, raw, BFP data to be de-quantized.
001c13a5 Input B zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
001c141f Constrain input a_scale, b_scale and output Y data type as float tensor.
001c1468 Input X's zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
001c14e4 Output Y's zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
001c1561 Number of neurons in the hidden layer
001c1587 Y's zero point.
001c1597 X's zero point.
001c15a7 Scale of quantized input 'A'. It is a scalar,which means a per-tensor quantization.
001c15fb scale_A
001c1603 cublasLt order of weight matrix
001c1623 cublasLt order of matrix Y, must be same as order_X. Default is ROW MAJOR.
001c166e Constrain scales to float32
001c168a  does not specify a valid type.
001c16aa Can not get shape initializer data!
001c16ce graph_proto cannot be null
001c16e9  inputs and requires 
001c16ff gsl::not_null<Node *> onnxruntime::Graph::AllocateNode()
001c1738 Output:
001c1740 std::unique_ptr<onnx::OpSchema> onnxruntime::function_utils::CreateSchema(const onnxruntime::Graph &, const onnxruntime::IndexedSubGraph &, bool)
001c17d2 onnx_func_proto
001c17e2 domain_version != -1
001c17f7 void onnxruntime::function_utils::Inliner::bind(google::protobuf::RepeatedPtrField<string> &, const google::protobuf::RepeatedPtrField<string> &) [isOutput = true]
001c189b FLOAT
001c18a1 No graph was found in the protobuf.
001c18c5 Load
001c18ca /onnxruntime_src/onnxruntime/core/graph/schema_registry.cc
001c1905 NO_SUCHFILE
001c1915 TensorProto (tensor name: 
001c1932 ==> Context: 
001c1940 All Tensor types
001c1951 optional(tensor(bool))
001c1968 The value for the sole element for the scalar, UTF-8 string, output tensor.
001c19b4 The data type for the elements of the output tensor. if not specified, we will use the data type of the input tensor.
001c1a2a Attribute 'value_int' expect an integer.
001c1a53 Attribute expected to have a one-dim tensor
001c1a7f Constrain input to integral tensors.
001c1aa4 broadcast
001c1aae input_large_than_max = Less (max, input)
001c1ad7 output = Where (output_large_than_max, max, tmp)
001c1b08 The arcsine of the input tensor computed element-wise
001c1b40 weight_gather = Where (squeeze_mask, const_zero_float, const_one_float)
001c1b88 input and zero_point pair is expected to have same type.
001c1bc1 Weight rank must be 1.
001c1bd8 Slope tensor. If `Slope` is of size 1, the value is sharedacross different channels
001c1c2c Attribute kernel_shape has incorrect size.
001c1c57 Constrain scale and bias types to float tensors.
001c1c88 The input 1-dimensional scale tensor of size C.
001c1cb8 The axis on which to apply normalization, -1 mean last axis.
001c1cf5 lambd
001c1cfb 1-dimensional tensor with padding value for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin is the number of pixels added at the beginning of axis `i` and xi_end is the number of pixels added at the end of axis `i`. If not present, the padding defaults to 0 along start and end of each spatial axis.
001c1f1f FloatEpsilon
001c1f2c num_groups
001c1f37 Bias tensor of shape `(num_groups)`.
001c1f5c training_mode of Dropout must be a scalar.
001c1f87 ScaleShape = Constant <value_ints = [1, -1, 1]> ()
001c1fbb Carries out batch normalization as described in the paper
001c1ff5 https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
001c203e There are five required inputs 'X', 'scale', 'B', 'input_mean' and
001c2081 'input_var'.
001c208e Note that 'input_mean' and 'input_var' are expected to be the estimated
001c20d6 statistics in inference mode (training_mode=False, default),
001c2113 and the running statistics in training mode (training_mode=True).
001c2155 There are multiple cases for the number of outputs, which we list below:
001c219f Output case #1: Y, running_mean, running_var (training_mode=True)
001c21e1 Output case #2: Y (training_mode=False)
001c220a When training_mode=False, extra outputs are invalid.
001c223f The outputs are updated as follows when training_mode=True:
001c227f running_mean = input_mean * momentum + current_mean * (1 - momentum)
001c22c4 running_var = input_var * momentum + current_var * (1 - momentum)
001c2307 Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B
001c2349 where:
001c2351 current_mean = ReduceMean(X, axis=all_except_channel_index)
001c238d current_var =  ReduceVar(X, axis=all_except_channel_index)
001c23c9 Notice that ReduceVar refers to the population variance, and it equals to
001c2413 sum(sqrd(x_i - x_avg)) / N
001c242e where N is the population size (this formula does not use sample size N - 1).
001c2482 When training_mode=False:
001c24a0 Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B
001c24e2 For previous (depreciated) non-spatial cases, implementors are suggested
001c252b to flatten the input shape to (N x C * D1 * D2 * ... * Dn) before a BatchNormalization Op.
001c2587 Expecting primitive type as map key type.
001c25b1 N-D quantized input tensor to be de-quantized.
001c25e0 has output size 
001c25f1 ) in op definition.
001c2605 Constrain input types to any tensor type.
001c262f input_sequence
001c2642  Tensor=
001c264b  expected to have map type
001c2666 Output was expected to have tensor type. Got 
001c2694 (Optional) By default, when any value in the 'shape' input is equal to zero the corresponding dimension value is copied from the input tensor dynamically. allowzero=1 indicates that if any value in the 'shape' input is set to zero, the zero value is honored, similar to NumPy.
001c27a9 Rank 1 tensor containing exactly two elements, in the format [off_value, on_value], where 'on_value' is the value used for filling locations specified in 'indices' input tensor, and 'off_value' is the value used for filling locations other than those specified in 'indices' input tensor. 
001c28ca Supported modes: `constant`(default), `reflect`, `edge`
001c2902 Input axes has invalid data
001c291e axis must be in [-r, r-1]
001c2938 indices must be in [-rank, rank-1].
001c295c ) does not match the number of axes (
001c2982 x_shape_alldims2 = Shape (padded_input)
001c29aa List of non-negative integers, indicate the dimensions to be inserted
001c29f0 Attribute pads has incorrect length
001c2a14 A string.
001c2a1e Second, multiply by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.<br>Must be same length as 'offset'
001c2ae5 The node id of each weight
001c2b00 Only one of the attributes 'nodes_hitrates', 'nodes_hitrates_as_tensor' should be specified.
001c2b5d Only one of the attributes 'target_weights', 'target_weights_as_tensor' should be specified.
001c2bba /build/intermediates/arm64-v8a/Release/_deps/protobuf-src/src/google/protobuf/arena.cc
001c2c11 [:^xdigit:]
001c2c1d  in step
001c2c26 Gothic
001c2c2d Kannada
001c2c35 Mandaic
001c2c3d Nyiakeng_Puachue_Hmong
001c2c54 SignWriting
001c2c60 Telugu
001c2c67 Zanabazar_Square
001c2c78 foster_e_hdd
001c2c85 BEETHOVEN
001c2c8f Snapdragon 
001c2c9b unsupported locale for standard input
001c2cc1 ctype_byname<char>::ctype_byname failed to construct for 
001c2cfb ctype_byname<wchar_t>::ctype_byname failed to construct for 
001c2d38 June
001c2d3d operator--
001c2d48 operator|=
001c2d53 std::basic_iostream<char, std::char_traits<char> >
001c2d86 terminating with %s foreign exception
001c2dac uncaught
001c2db5 std::__libcpp_tls_create() failed in __cxa_thread_atexit()
001c2df0 _Unwind_Resume
001c2dff libunwind: malformed DW_CFA_def_cfa_sf DWARF unwind, reg too big
001c2e4b RegisterCustomOpsLibrary: Failed to load library
001c2e7c Specified provider is not supported.
001c2ea1 Tensor type mismatch. 
001c2eb8 static bool onnxruntime::utils::ContainerChecker::IsContainerOfType<std::map<long, double>>::check(const onnxruntime::utils::ContainerChecker::Cont &, size_t) [T = std::map<long, double>]
001c2f74 const T *onnxruntime::Tensor::Data() const [T = long]
001c2faa AddCustomOpDomains
001c2fbd model_loading_array
001c2fd1 model_loading_from_saved_proto
001c2ff0 This session has already been initialized.
001c301b Initializing session.
001c3031  error message: 
001c3042 ApplyOrtFormatModelRuntimeOptimizations
001c306a SetIntraOpNumThreads
001c307f invalid string: '\u' must be followed by 4 hex digits
001c30b5 invalid string: control character U+000B (VT) must be escaped to \u000B
001c30fd ::OrtKernelInfo input does not have a type
001c3128 all types
001c3132 /onnxruntime_src/onnxruntime/core/session/ort_env.cc
001c3167 Only CPU allocators can be shared between multiple sessions for now.
001c31ae seq(tensor(float16))
001c31c3 seq(tensor(complex128))
001c31db TryGetProviderInfo_ROCM
001c31f3 CUDA and/or ROCM execution provider is either not enabled or not available.
001c323f Unload
001c3246 T *onnxruntime::Tensor::MutableData() [T = unsigned char]
001c3280 gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = long]
001c32c6  number of partitions supported by NNAPI: 
001c32f1 TENSOR_QUANT8_ASYMM_SIGNED
001c330c SetOutputBuffer
001c331c nnapi error: unable to open library %s
001c3344 ANeuralNetworksExecution_getOutputOperandRank
001c3372 ANeuralNetworksExecution_setMeasureTiming
001c339c ANeuralNetworksExecution_getDuration
001c33c1 ANeuralNetworksExecution_setTimeout
001c33e5 ANeuralNetworksMemory_copy
001c3400 SL_ANeuralNetworksDiagnosticCompilationInfo_isControlFlowUsed
001c343e ] A Input type: [
001c3450 Identity
001c3459 _imm_a
001c3460 AddToModelBuilderImpl
001c3476 ] is not supported
001c3489 QLinearMatMul does not support per-channel quantization
001c34c1 u8s8 Qlinear[Conv/MatMul] only supports int8 zero point for weight, 
001c3506 ] has value: 
001c3514 ] zero point can only be [
001c352f ], actual zero point: 
001c3546 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/base_op_builder.cc
001c35a7 ] was added
001c35b3 Negative pad value is not supported: pads[
001c35de Output sizes of N/C channel should match the input sizes, 
001c3619 UnaryOpBuilder, unknown op: 
001c3636  only supports rank-4 tensor, input [
001c365c ] squeezed from 
001c366d beta
001c3672 actual input number, 
001c3688 Node::EdgeConstIterator onnxruntime::NodeUnit::OutputEdgesBegin(size_t) const
001c36d6 QLinearGlobalAveragePool
001c36ef activation
001c36fa ParseScalesDataAndAdjustOutputSize
001c371d PrePack
001c3725 ReluQuantRewrite
001c3736 ConstantSharing
001c3746 BiasGeluFusion
001c3755 /onnxruntime_src/onnxruntime/core/optimizer/gemm_sum_fusion.cc
001c3794 Failed to get Clip min/max constants.
001c37ba Expected Conv then Add.
001c37d2 ThresholdedRelu
001c37e2 /onnxruntime_src/onnxruntime/core/optimizer/dynamic_quantize_matmul_fusion.cc
001c3830 Slice parameter is not expected. Input index:
001c385e Pass MatchGemmSubgraph
001c3875 Start MatchUnidirMaskSubgraph
001c3893 CheckSliceParameters return false for slice2
001c38c0 Failed to find path for mask
001c38dd Failed to find mask path
001c38f6 CheckDistilBertReshapeShape
001c3912 Faild to find path v to Split
001c3930 MatchPastSubgraph returns false
001c3950 Failed to match Shape node. 
001c396d Initializer must have a datatype
001c398e onnxruntime::Initializer &onnxruntime::Initializer::sub(const onnxruntime::Initializer &)
001c39e8 cast != nullptr
001c39f8 Inserting Q/DQ pair between 
001c3a15 q_or_dq_input_defs.size() >= 2
001c3a34 A target node must be set.
001c3a4f MoveInputOutputImpl
001c3a63 Index out of range
001c3a76 void onnxruntime::SelectorActionRegistry::RegisterSelectorAndAction(const std::string &, const onnxruntime::SelectorActionRegistry::OpVersionsMap &, std::unique_ptr<NodeSelector>, std::unique_ptr<Action>)
001c3b43 Acosh
001c3b49 LogSoftmax
001c3b54 com.microsoft.QLinearLeakyRelu
001c3b73 ai.onnx
001c3b7b noop_with_empty_axes
001c3b90 /onnxruntime_src/onnxruntime/core/providers/cpu/element_wise_ranged_transform.h
001c3be0 info_ == nullptr
001c3bf1 Loop had zero iterations and the shape of subgraph output 
001c3c2c void onnxruntime::Scan<9>::Init(const onnxruntime::OpKernelInfo &) [OpSet = 9]
001c3c7b max->Shape().IsScalar()
001c3c93 void onnxruntime::WritableSliceIterator<double>::Init(gsl::span<const int64_t>, gsl::span<const int64_t>, gsl::span<const int64_t>) [T = double]
001c3d24 input_rank == permutation.size()
001c3d45 Einsum subscripts string contains too many subscript labels when compared to the rank of the input
001c3da8 candidate_output.Shape().Size() == output_shape.Size()
001c3ddf inputCount >= 1
001c3def virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Abs<unsigned long>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Abs<unsigned long>]
001c3ebc void onnxruntime::InputBroadcaster::AdvanceBy(size_t)
001c3ef2 Broadcast Output range [
001c3f0b void onnxruntime::BroadcastLooper(TBroadcastHelper &, const onnxruntime::ProcessBroadcastSpanFuncs &) [TBroadcastHelper = onnxruntime::BroadcastHelper]
001c3fa3 onnxruntime::ml::CastMap::CastMap(const onnxruntime::OpKernelInfo &)
001c3fe8 cur_input == end_input || cur_input->first >= 0
001c4018 One and only one of the 'cats_*' attributes must be defined
001c4054 void onnxruntime::ml::detail::TreeEnsembleCommon<long, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = long, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorSum<long, float, float>]
001c41a2 void onnxruntime::ml::detail::TreeAggregatorMax<int, float, float>::MergePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = int, ThresholdType = float, OutputType = float]
001c4297 onnxruntime::ml::TreeEnsembleRegressor<double>::TreeEnsembleRegressor(const onnxruntime::OpKernelInfo &) [T = double]
001c430d Input features_per_batch[
001c4327 Invalid input var: 
001c433b /onnxruntime_src/onnxruntime/core/providers/cpu/nn/conv_transpose.cc
001c4380 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/layer_norm_impl.cc
001c43c6 info.GetAttrs<int64_t>("pooled_shape", pooled_shape).IsOK()
001c4402 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/shrink.h
001c443e auto onnxruntime::string_normalizer::Locale::Locale(const std::string &)::(anonymous class)::operator()() const
001c44b2 size_t(impl_->min_gram_length_) <= impl_->ngram_counts_.size()
001c44f1 center_point_box
001c4502 Number of dimensions for batch indices should be exactly 1
001c453d output_width
001c454c OptionalGetElement
001c455f onnxruntime::Optional::Optional(const onnxruntime::OpKernelInfo &)
001c45a2 axes_tensor != nullptr
001c45b9 virtual onnxruntime::common::Status onnxruntime::DeepCpuGruOp::Compute(onnxruntime::OpKernelContext *) const
001c4626 /onnxruntime_src/onnxruntime/core/providers/cpu/rnn/deep_cpu_gru.h
001c4669 info.GetAttr("direction", &direction).IsOK()
001c4696 /onnxruntime_src/onnxruntime/core/providers/cpu/rnn/rnn.h
001c46d0 scaledtanh
001c46db virtual onnxruntime::common::Status onnxruntime::SequenceConstruct::Compute(onnxruntime::OpKernelContext *) const
001c474d T onnxruntime::signal::get_scalar_value_from_tensor(const onnxruntime::Tensor *) [T = long]
001c47a9 onnxruntime::common::Status onnxruntime::CreateMelWeightMatrix<signed char>::operator()(onnxruntime::OpKernelContext *, int64_t, int64_t, int64_t, float, float) [T = signed char]
001c485c Compress
001c4865 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/gather_elements.h
001c48ae /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/grid_sample.h
001c48f3 Unexpected mode of 
001c4907 Pads tensor should be a 1D tensor of shape [2 * num_axes] or a 2D tensor of shape [1, 2 * num_axes]
001c496b onnxruntime::PadValue onnxruntime::PadValueFromFloat(float, onnxruntime::MLDataType)
001c49c0 onnxruntime::ReverseSequenceOp::ReverseSequenceOp(const onnxruntime::OpKernelInfo &)
001c4a15 Indices and updates must have the same rank
001c4a45 num_axes > 0
001c4a52 Resize: unexpected mode
001c4a6a Resize: input/output value is nullptr
001c4a90 Upsample: input/output value's dimension mismatch
001c4ac2 Input 'relative_position_bias' is expected to have 4 dimensions, got 
001c4b08 onnxruntime::contrib::EmbedLayerNormBase::EmbedLayerNormBase(const onnxruntime::OpKernelInfo &)
001c4b68 }, Got: 
001c4b71 onnxruntime::contrib::CDist<float>::CDist(const onnxruntime::OpKernelInfo &) [T = float]
001c4bca The first input of CDist kernel has wrong shape: 
001c4bfc Input shape dimensions mismatch:
001c4c1d axis_tensor->Shape().IsScalar()
001c4c3d input zero point must be a scalar or 1D tensor of size 1.
001c4c77 /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/nhwc_max_pool.cc
001c4cc2 MatmulInteger : input1 B_scale must be a scalar or 1D tensor of size 1
001c4d09 void onnxruntime::contrib::QlinearBuildLookupTable(uint8_t *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::contrib::LookupTableArrayTransformer &) [T = unsigned char]
001c4e0a tensor_y_scale->IsDataType<float>()
001c4e2e separators
001c4e39 Input string contains invalid utf8 chars: 
001c4e64 tensor(string) expected as input
001c4e85 input_ids and prefix_vocab_mask must have the same batch_size
001c4ec3 max_length (
001c4ed0 virtual void onnxruntime::contrib::transformers::BeamSearchScorer::Process(onnxruntime::contrib::transformers::ISequences *, gsl::span<const float> &, gsl::span<const int32_t> &, gsl::span<const int32_t> &)
001c4f9f /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/sampling.cc
001c4fe5 presence_penalty
001c4ff6  bytes.
001c4ffe   Chunk
001c5006 Stats: 
001c500f NumReserves:              
001c502a utils::HasElemType(thisProto->sparse_tensor_type())
001c505e double
001c5065 sparse tensor type 
001c5079 A dso with name 
001c508a  failed: 
001c5094 Memory pattern planner is not enabled on this execution framework.
001c50d7 Could not find OrtValue with idx '
001c50fa const OrtValue &onnxruntime::IExecutionFrame::GetMLValue(int) const
001c513e metadef_id_generator_
001c5154 PartitionOrtFormatModelImpl
001c5170 Duplicate entry for kernel type str: 
001c5196  is expected to have type: 
001c51b2 SetGraphAndCreateKernels must be called prior to GetExecutionInfo.
001c51f9 shape.Size() must >=0
001c520f Expecting to contain one index, got: 
001c5235 SparseTensor::CooMutator onnxruntime::SparseTensor::MakeCooData(size_t, size_t)
001c5285  rows: 
001c528d MakeBlockSparseData
001c52a1 inner_num == src.Values().Shape().Size()
001c52ca RecycleNodeInputs
001c52dc /onnxruntime_src/onnxruntime/core/framework/stream_execution_context.h
001c5323 ) in proto
001c532e UnpackTensor: the pre-allocate size does not match the size in proto
001c5373 const OrtMemoryInfo &onnxruntime::utils::FindMemoryInfoForValue(const onnxruntime::OrtValueNameIdxMap &, const onnxruntime::SequentialExecutionPlan &, std::string_view)
001c541c has_key_padding_mask or not
001c5438 2D segment IDs with shape (batch_size, sequence_length)
001c5470 skip
001c5475 1D skip tensor with shape (hidden_size
001c549c cur_tokens
001c54a7 1-d tensor with shape (num_heads x head_size)
001c54d5 strides
001c54dd The residual input, must have the same shape as data
001c5512 model type: 0 for decoder only like GPT-2; 1 for encoder decoder like Bart
001c555d Tensor of rank q-1+r-indices[-1].
001c5581 detection_boxes
001c5591 outputs
001c5599 The weight tensor of the memory layer in the attention mechanism. Should be of shape `[num_directions, memory_depth, am_attn_size]` 
001c561e Input tensor. Dimensions are (N, S, D), where N is the batch size, S are image size, and D is hidden dimension
001c568d Input scale. It's a scalar, which means a per-tensor/layer quantization.
001c56d6 Result, has same shape and type as input
001c56ff 1-D, contiguous BFP data
001c5718 Strides of x
001c5725 reduced
001c572d List of tensors/scale/zero_point for concatenation
001c5760 Zero Point for segment embeddings
001c5782 gamma_zero_point
001c5793 Q_weight
001c579c scale_global_gemm
001c57af Performs element-wise binary {name} on 8 bit data types (with Numpy-style broadcasting support).
001c5811 {additionalDocumentation}
001c582c segment_ids input shall be 2 dimensions
001c5854 ' is not a graph input, initializer, or output of a previous node.
001c5897 AddInitializedTensor already has tensor with name 
001c58ca !found
001c58d1 Failed to find existing initializer with name 
001c5900 void onnxruntime::Graph::FinalizeFuseSubGraph(const onnxruntime::IndexedSubGraph &, onnxruntime::Node &)
001c5969 onnxruntime::common::Status onnxruntime::Graph::InlineFunction(onnxruntime::Node &)
001c59bd  , or optional typed entities
001c59db MergeShapeInfo
001c59ea ValidateOpsetForDomain
001c5a01 Graph attribute value was null. Invalid ORT format model.
001c5a3b TENSOR
001c5a42 void onnxruntime::GraphViewerToProto(const onnxruntime::GraphViewer &, onnx::GraphProto &, bool, bool)
001c5aa9 Unsupported model IR version: 
001c5ac8 Save
001c5acd /onnxruntime_src/onnxruntime/core/graph/op_identifier_utils.cc
001c5b0c Invalid processor interval: 
001c5b29 Only one instance of LoggingManager created with InstanceType::Default can exist at any point in time.
001c5b90 points_.empty()
001c5ba0 SaveSequenceTypeOrtFormat
001c5bba graph
001c5bc0 Bad node spec for node. Name: 
001c5bdf Number of scan input axes specified (
001c5c05 An optional list of M flags. The i-th element of the list specifies the direction to be scanned for the i-th scan_input tensor: 0 indicates forward direction and 1 indicates reverse direction. If omitted, all scan_input tensors will be scanned in the forward direction.
001c5d13 optional(seq(tensor(int16)))
001c5d30 An optional list of K flags. The i-th element of the list specifies the axis for the i-th scan_output. The scan outputs are accumulated along the specified axis. If omitted, 0 will be used as the scan axis for every scan_output.
001c5e15 Mismatched type for output 
001c5e31 sparse_value
001c5e3e The values for the elements for the 1D, UTF-8 string, output tensor.
001c5e83 Output tensor, same shape as input tensor T1.
001c5eb1 Lower boundary of the output values.
001c5ed6 Input tensor with shape [batch_size, class_size], where class_size is the number of all possible outcomes. Each value along the axis zero represents the unnormalized log-probability of each corresponding outcome in a batch.
001c5fb6 Second operand, amounts of shift.
001c5fd8 greater_equal
001c5fe6 Left input tensor for the logical operator.
001c6012 log of softmax
001c6021 hardmax
001c6029 The hyperbolic arccosine values of the input tensor computed element-wise
001c6073 Optional rescaling weight tensor. If given, it has to be a tensor of size C. Otherwise, it is treated as if having all ones.
001c60f0 The negative log likelihood loss
001c6111 equation
001c611a log_prob
001c6123 squeeze_mask
001c6130 number of groups input channels and output channels are divided into. default is 1.
001c6184 The pads attribute cannot be used simultaneously with auto_pad attribute
001c61cd Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, pad lengths and group count. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)
001c62eb This number of op outputs should be 3 when Training_mode = True, but it is not.
001c633b Processed_STD
001c6349 (int, default 0) if nonzero, run dropout in test mode where the output is simply Y = X.
001c63a2 Carries out batch normalization as described in the paper
001c63dc https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
001c6425 there are multiple cases for the number of outputs, which we list below:
001c646f Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
001c64b3 Output case #2: Y (test mode)
001c64d2 For previous (depreciated) non-spatial cases, implementors are suggested
001c651b to flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.
001c656e String value expected, but not found.
001c6594 sparse_tensors
001c65a3 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/reduction/old.cc
001c65f4 ) has output size 
001c6607 Unrecognized attribute: 
001c6620 ' is expected to have field 'type_protos'
001c664a Output sequence that contains the inserted tensor at given position.
001c668f SequenceMap_
001c669c The graph to be run for each sample in the sequence(s). It should have as many inputs and outputs as inputs and outputs to the SequenceMap function.
001c6731  expected to have sequence type
001c6751 source optional type missing element type.
001c677c Which axis to scatter on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
001c6800 Input tensor of any shape.
001c681b repeats
001c6823 N-D tensor
001c682e The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if mode is "cubic".
001c6939 Incorrect or missing input value for starts and ends
001c696e (Optional) A scalar value to be used if the mode chosen is `constant` (by default it is 0).
001c69ca (Optional) Axis along which to take slices. If not specified, input is flattened before elements being selected.
001c6a3b Attribute 'scales' must have floats type.
001c6a65 Binarized output data
001c6a7b The input must be an integer map to either string or float.
001c6ab7 Indicates whether to only output as many values as are in the input (dense), or position the input based on using the key of the map as the index of the output (sparse).<br>One of 'DENSE', 'SPARSE'.
001c6b7e max_map
001c6b86 Input data
001c6b91 Value(s) to change to
001c6ba7 Output type is determined by the specified 'values_*' attribute.
001c6be8 Inferred shape and existing shape differ in dimension 
001c6c1f  BackUp() can only be called after Next().
001c6c4a  exceeded maximum protobuf size of 2GB: 
001c6c73 endpos: 
001c6c7c SearchBitState inconsistency
001c6c99 RE2: unexpected op: 
001c6cb1 invalid character class
001c6cc9 Coptic
001c6cd0 Linear_A
001c6cd9 Multani
001c6ce1 Phags_Pa
001c6cea Sharada
001c6cf2 Soyombo
001c6cfa Yezidi
001c6d01 cpuinfo
001c6d09 failed to parse processor information from /proc/cpuinfo
001c6d42 Amlogic
001c6d4a Surge S
001c6d56 failed to parse the list of present processors in %s
001c6d8b package
001c6d93 __next_prime overflow
001c6daf 'block-literal'
001c6dbf operator-
001c6dc9 basic_istream
001c6dd7 std::istream
001c6de7 Use GetStringTensor*() API to retrieve strings
001c6e16 input array is too short
001c6e2f static bool onnxruntime::utils::ContainerChecker::IsContainerOfType<std::vector<std::map<std::basic_string<char>, float>>>::check(const onnxruntime::utils::ContainerChecker::Cont &, size_t) [T = std::vector<std::map<std::basic_string<char>, float>>]
001c6f29 const T &OrtValue::Get() const [T = std::map<std::basic_string<char>, float>]
001c6f77 static bool onnxruntime::utils::ContainerChecker::IsContainerOfType<std::map<long, std::basic_string<char>>>::check(const onnxruntime::utils::ContainerChecker::Cont &, size_t) [T = std::map<long, std::basic_string<char>>]
001c7055 const T *onnxruntime::Tensor::Data() const [T = double]
001c708d Could not finalize session options while constructing the inference session. Error Message: 
001c70ea Failed to create the inter-op thread pool for the parallel executor, setting ExecutionMode to SEQUENTIAL
001c7153 session_env.EnvCreatedWithGlobalThreadPools()
001c7181 CastFloat16Transformer
001c7198 TransformGraph
001c71a7 The only supported values for the environment variable 
001c71e1 static const onnxruntime::logging::Logger &onnxruntime::logging::LoggingManager::DefaultLogger()
001c7242 type_error
001c724d binary
001c7254 invalid number; expected '+', '-', or digit after exponent
001c728f out_of_range
001c729c parse error
001c72a8 ::OrtKernelInfo input index is out of bounds
001c72d5 /onnxruntime_src/onnxruntime/core/session/custom_ops.cc
001c730d seq(tensor(float))
001c7320 libonnxruntime_providers_rocm.so
001c7341 const T *onnxruntime::OpKernelContext::Input(int) const [T = onnxruntime::Tensor]
001c7393 standalone_
001c739f GetCapability
001c73ad TENSOR_QUANT16_SYMM
001c73c1  shape 
001c73c9 ANEURALNETWORKS_UNMAPPABLE
001c73e4 QuantizeLinear
001c73f3 ] has no shape info
001c7407  should match the calculated size: 
001c742b The initializer of graph 
001c7445 ] NNAPI input zero point: 
001c7460 , output name, 
001c7470 PerformBroadcasting
001c7484 /new_shape
001c748f Unsupported operator 
001c74a5 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/pad_op_builder.cc
001c7505 linear
001c750c android_feature_level below 29 does not support nchw Resize.
001c7549 'axes' has an axis outside of the tensor dimension count
001c7582 , Input type 1: 
001c7593 d shape, input 2 is 
001c75a8 kernel_shape
001c75b5 storage_order
001c75c3 PoolOpBuilder, unknown op: 
001c75df ] GetQuantizationScaleAndZeroPoint for output_scale/zp failed, message: 
001c7628 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/conv_op_builder.cc
001c7689  dilations is only supported on Android API level 29+, 
001c76c1 B of Gemm must be known if transB != 1
001c76e8 void *onnxruntime::xnnpack::(anonymous namespace)::xnn_aligned_allocate(void *, size_t, size_t)
001c7748 QINT32
001c774f xnn_create_max_pooling2d_nhwc_
001c776e xnn_setup_max_pooling2d_nhwc_
001c778c info.GetAttr<std::string>("auto_pad", &auto_padding).IsOK()
001c77c8 scales size should be greater than 0.
001c77ee all values in axes should be less than rank of the data
001c7826 onnxruntime::GemmBase::GemmBase(const onnxruntime::OpKernelInfo &)
001c7869 info.GetAttr<int64_t>("transA", &temp).IsOK()
001c7897 ArmNNExecutionProvider
001c78ae virtual onnxruntime::NodeAttributes onnxruntime::(anonymous namespace)::actions::FuseConvAddActivation::ExtraAttributes(const onnxruntime::ReplaceWithNew::RuntimeState &) const
001c795f /onnxruntime_src/include/onnxruntime/core/optimizer/graph_transformer.h
001c79a7 The model has input '
001c79bd gather axis value not expected
001c79dc mask_sub const input not matched
001c79fd Failed to find shape path
001c7a17 v_reshape initializer value is not expected
001c7a43 MatchInputMaskSubgraph returns false
001c7a68 MatchUnidirMaskSubgraph returns NULL
001c7a8d Output edge count not expected for Add or MatMul in path v
001c7ac8 FuseSubGraphDistilBert
001c7adf Second input of Gather in path 2 of position shape should be a constant with value 1.
001c7b35 two paths share the same shape
001c7b54 model_path must not be empty. Ensure that a path is provided when the model is created or loaded.
001c7bb6 Constant initializer NodeArg shape should not be null. NodeArg: 
001c7bfe init_optional_zero_point_int8_b33fd0fa-cd7b-4b10-ae5a-df64cabfe1f8
001c7c41 Existing registration with name 
001c7c62 ApplySavedRuntimeOptimizations
001c7c81 Round
001c7c87 CastLike
001c7c90 RandomNormal
001c7c9d RandomUniformLike
001c7caf /onnxruntime_src/onnxruntime/core/optimizer/utils.cc
001c7ce4 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Sigmoid<double>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Sigmoid<double>]
001c7dab feeds_fetches_manager_ && info_
001c7dcb sequence_lens length of 
001c7de4 Subgraph must have the shape set for all outputs but 
001c7e1a virtual onnxruntime::common::Status onnxruntime::Scan<9>::SetupSubgraphExecutionInfo(const onnxruntime::SessionState &, const std::string &, const onnxruntime::SessionState &) [OpSet = 9]
001c7ed6 onnxruntime::ConstantOfShapeBase<onnxruntime::TypeList<long, onnxruntime::MLFloat16, float, double, signed char, short, int, unsigned char, unsigned short, unsigned int, unsigned long, bool>>::ConstantOfShapeBase(const onnxruntime::OpKernelInfo &) [EnabledOutputTypeList = onnxruntime::TypeList<long, onnxruntime::MLFloat16, float, double, signed char, short, int, unsigned char, unsigned short, unsigned int, unsigned long, bool>]
001c8086 /onnxruntime_src/onnxruntime/core/providers/cpu/generator/random.h
001c80c9 onnxruntime::RandomNormalLike::RandomNormalLike(const onnxruntime::OpKernelInfo &)
001c811c void onnxruntime::Clip::ComputeImpl<long>::operator()(const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, onnxruntime::Tensor *) const [T = long]
001c81d1 virtual onnxruntime::common::Status onnxruntime::CumSum<long>::Compute(onnxruntime::OpKernelContext *) const [T = long]
001c8249 onnxruntime::common::Status onnxruntime::EinsumOp::DeviceHelpers::CpuDeviceHelpers::DataCopy(const onnxruntime::Tensor &, onnxruntime::Tensor &, void *)
001c82e2 Einsum subscripts does not contain enough subscript labels and there is no ellipsis for input 
001c8341 virtual onnxruntime::common::Status onnxruntime::Mean_6<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
001c83bb GEMM: Dimension mismatch, W: 
001c83d9 void onnxruntime::GemmBroadcastBias(int64_t, int64_t, float, const T *, const onnxruntime::TensorShape *, T *) [T = float]
001c8454 const T *onnxruntime::OpKernelContext::Input(int) const [T = std::map<std::basic_string<char>, float>]
001c84bb onnxruntime::ml::DictVectorizerOp<long, std::basic_string<char>>::DictVectorizerOp(const onnxruntime::OpKernelInfo &) [AttrType = long, TargetType = std::basic_string<char>]
001c8569 Number of inputs (
001c857c /onnxruntime_src/onnxruntime/core/providers/cpu/ml/feature_vectorizer.h
001c85c4 Expected 'replace_value_int64' attribute since 'imputed_values_int64' is specified
001c8617 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/normalizer.h
001c8657 Unexpected mode:
001c8668 onnxruntime::ml::TreeEnsembleClassifier<float>::TreeEnsembleClassifier(const onnxruntime::OpKernelInfo &) [T = float]
001c86de virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommon<float, float, float>::Init(const onnxruntime::OpKernelInfo &) [InputType = float, ThresholdType = float, OutputType = float]
001c87ab nodes_falsenodeids.size() == nodes_values.size() || nodes_falsenodeids.size() == nodes_values_as_tensor.size()
001c881a target_class_weights.empty() || target_class_weights_as_tensor.empty()
001c8861 onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommon<long, float, float>::Init(int, int, int, const std::string &, const std::vector<float> &, const std::vector<ThresholdType> &, int64_t, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<float> &, const std::vector<ThresholdType> &, const std::vector<int64_t> &, const std::vector<std::string> &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<float> &, const std::vector<ThresholdType> &, const std::string &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<float> &, const std::vector<ThresholdType> &) [InputType = long, ThresholdType = float, OutputType = float]
001c8b73 void onnxruntime::ml::detail::TreeAggregator<long, float, float>::FinalizeScores(InlinedVector<ScoreValue<ThresholdType>> &, OutputType *, int, int64_t *) const [InputType = long, ThresholdType = float, OutputType = float]
001c8c52 proto.data_type() == proto_type
001c8c72 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/treeregressor.cc
001c8cb6 output_shape is smaller than minimum required. output_shape:
001c8cf3 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/unpool.h
001c8d2f Size of X.shape()[axis:] == 
001c8d4c non-empty pool_int64s is required if pool_strings not provided
001c8d8b Number of items must compose whole 
001c8daf p.first->second->id_ == 0
001c8dc9 prepacked_buffers[0].get() == nullptr
001c8def zero_point == nullptr || std::all_of(zero_point, zero_point + x_zero_point->Shape().Size(), [](int32_t zp) { return zp == 0; })
001c8e6f QLinearMatmul : input scale must be a scalar or 1D tensor of size 1
001c8eb3 fast_shape[0] * fast_shape[2] == output.Shape().Size()
001c8eea activation_beta
001c8efa info.GetAttr("direction", &direction_).IsOK()
001c8f28 void onnxruntime::rnn::detail::ComputeGemm(const int, const int, const int, const float, const float *, const float *, const GemmWeights<float> &, const float, float *, float *, const int, uint8_t *, int32_t *, concurrency::ThreadPool *)
001c9016 Data type of the input tensor MUST be same as that of the input sequence. Sequence data type (
001c9075 void onnxruntime::GetSplitSizesInput(const onnxruntime::Tensor &, std::vector<int64_t> &)
001c90cf lower_edge_hertz produces a mel triangle filter bank that is out of range given the dft_length and the sample_rate.
001c9143 upper_edge_hertz produces a mel triangle filter bank that is out of range given the dft_length and the sample_rate.
001c91b7 virtual onnxruntime::common::Status onnxruntime::Col2Im<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
001c9231 size of 'strides' attribute, if provided, should equal to the number of image dimmensions.
001c928c batch_dims
001c9297 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/onehot.cc
001c92d8 Value tensor should be a 1D tensor of size 1 with the same type as that of the input tensor
001c9334 Invalid sequence length: 
001c934e Indices must have the same rank as Input. Indices rank=
001c9386 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/slice.h
001c93c5 DepthToSpace requires input depth to be a multiple of (block_size * blok_size)
001c9414 bool onnxruntime::TypedDoTransposeEltWise(int64_t, gsl::span<const int64_t>, size_t, const gsl::span<const size_t> &, const uint8_t *, uint8_t *) [T = unsigned int]
001c94b9 Invalid roi input index.
001c94d2 Inputs 'mask_index' with 3D data shall have shape batch_size x sequence_length x total_sequence_length
001c9539 segment_embedding is expected to have 2 dimensions, got 
001c9572 onnxruntime::ElementWiseKernel<onnxruntime::functors::ParametricSoftplus<float>>::ElementWiseKernel(const onnxruntime::OpKernelInfo &) [F = onnxruntime::functors::ParametricSoftplus<float>]
001c9630 /onnxruntime_src/onnxruntime/contrib_ops/cpu/expand_dims.h
001c966b input_num_bytes % 4 == 0
001c9684 IsBQuantParamSupported(b_zp_tensor->Shape(), b_tensor ? b_tensor->Shape() : b_shape_)
001c96da tensor_a_zero_point == nullptr || IsScalarOr1ElementVector(tensor_a_zero_point)
001c972a MatmulInteger : input1 A_zero_point must be a scalar or 1D tensor of size 1 if given
001c977f input y_scale must be a scalar or 1D tensor of size 1
001c97b5 QLinear Pooling unsupported pooling size!
001c97df ) shall be no more than 
001c97f8 /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/beam_search_scorer.cc
001c9848 /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/greedy_search.cc
001c9893 encoder subgraph output 3 shall be named as present_value_self_0, got: 
001c98db Conv filter size does not match embedding_size attribute.
001c9915  char_embedding_size attribute: 
001c9936 Could not find Region for: 
001c9952 (null)
001c9959 void onnxruntime::DeviceStreamCollectionImpl::SetDeviceStream(size_t, onnxruntime::Stream *)
001c99b6 func info for node: 
001c99cb input_offset >= 0 && output_offset >= 0
001c99f3 frame != nullptr
001c9a04 No attribute with this name is defined.
001c9a2c FinalizeSessionState
001c9a41 Using cached version of pre-packed weight for constant initializer: 
001c9a86 void onnxruntime::DeviceBasedPartitioner::Initialize()
001c9abd CreateGraphPartitioner
001c9ada , count: 
001c9ae4 string tensor is not supported for copying between allocators
001c9b22 Failed to copy tensor to 
001c9b3c MakeCsrData
001c9b48 SparseTensor::BlockSparseView onnxruntime::SparseTensor::AsBlockSparse() const
001c9b97 DenseTensorToSparseCsr
001c9bae strides.empty()
001c9bbe p_type != nullptr
001c9bd0 dimension <= num_dims
001c9be6 HasDataType(dense_proto)
001c9bff model format error! Missing 'location'
001c9c26 CopyInputsAcrossDevices
001c9c3e past state for key and value with shape (2, batch_size, num_heads, past_sequence_length, head_size)When past_present_share_buffer is set, its shape is (2, batch_size, num_heads, max_sequence_length, head_size)
001c9d10 additional add to QxK' with shape (batch_size, num_heads, sequence_length, total_sequence_length)
001c9d72 3D input tensor with shape (sequence_length, batch_size, hidden_size), hidden_size = num_heads * head_size
001c9ddd 2D input tensor with shape (hidden_size, hidden_size)
001c9e13 word_embedding
001c9e22 1D input tensor with shape (hidden_size)
001c9e4b Long tensor containing the indices to extract from embedding matrix.
001c9e90 early stop or not
001c9ea2 Mask of vocabulary. Words that masked with 0 are not allowed to be generated, and 1 is allowed. Shape is (vacab_size)
001c9f18 If 1 custom sampling logic
001c9f33 rois
001c9f38 crop_size
001c9f42 (Optional) SNPE version used to convert the model.
001c9f75 target_device
001c9f83 One or more outputs, list of tensors for DLC output
001c9fb7 Second input does not have rank 2
001c9fd9 Input 0 shall be 3 dimensions
001c9ff7 Constrain gamma and beta to float tensors.
001ca022 /onnxruntime_src/onnxruntime/core/graph/contrib_ops/quantization_defs.cc
001ca06b Zero point tensor for input 'B'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.
001ca172 R's scale. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
001ca215 Which axis to concat on
001ca22d Constrain input and output types to 8 bit signed and unsigned tensors.
001ca276 cublasLt order of input matrix. See the schema of QuantizeWithOrder for order definition.
001ca2d0 scale of the input B. Scalar or 1-D float32.
001ca2fd scale of the output
001ca311 /onnxruntime_src/onnxruntime/core/graph/graph.cc
001ca342 Optional Type mismatch. Expected: 
001ca365 This may prevent some of the graph optimizations, like const folding. 
001ca3ac Size mismatch validating subgraph inputs. Got 
001ca3db ) of node (
001ca3e7 onnxruntime::common::Status onnxruntime::Graph::ReplaceInitializedTensorImpl(onnx::TensorProto, bool)
001ca44d nodes_.size() < static_cast<unsigned int>(std::numeric_limits<int>::max())
001ca498 SetOpSchemaFromRegistryForNode(fused_node)
001ca4c3  is not found in model local functions
001ca4ea  is not found or is not constant initializer.
001ca518 Empty graph proto from deserialization of ORT format model
001ca557 SPARSE_TENSOR
001ca565 Initializer with same name exists. Name:
001ca58e index >= 0 && static_cast<size_t>(index) < inputs.size()
001ca5c7 Failed since multiple edges matched:
001ca5ec int onnxruntime::graph_utils::GetIndexFromName(const onnxruntime::Node &, const std::string &, bool)
001ca651 Unexpected CBLAS_TRANSPOSE for TransA of 
001ca67b , thread_pool_size: 
001ca690 "name" :"
001ca69a EP_FAIL
001ca6a2 index >= 0
001ca6ad  error msg: 
001ca6ba string_data
001ca6c6 Location of external TensorProto ( tensor name: 
001ca6f7 ' should be stored in field '
001ca715 ) index value at position [
001ca731 ] not in lexicographic sorted order.
001ca756 ) must have INT64 type.
001ca76e ) must have rank 1 or 2.
001ca787 , type: 
001ca790 optional(seq(tensor(bfloat16)))
001ca7b0 Constrain input types.
001ca7c7 Constrain input and output types to integer tensors.
001ca7fc Constrain input and output types to signed numeric tensors.
001ca838 Second operand, power of the exponent.
001ca861 weight_gather_temp_1 = Where (mask, const_zero_casted, weight_gather_temp)
001ca8ac Operands
001ca8b5 K input must be of type int64.
001ca8d4 auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = input_shape[i] * strides[i]` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.
001caac0 Attribute strides has incorrect size
001caae5 dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each axis.
001cab57 The output tensor of the same shape as input.
001cab85 The lambd value for the Shrink formulation. Default is 0.5.
001cabc1 1-D tensor of floats
001cabd6 List of int64 n-grams learned from the training set. Either this or pool_strings attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
001cad32 Scaled = Mul (NormalizedT, Scale2D)
001cad56 Constrain input and output types to float and 8 bit tensors.
001cad93 RoI pooled output 4-D tensor of shape (num_rois, channels, pooled_shape[0], pooled_shape[1]).
001cadf1 X_squared
001cadfb The output 4-dimensional tensor of the same shape as X.
001cae33 (float, default 0.5) the ratio of random dropout
001cae64 The ratio of random dropout
001cae80 Constrain input type to optional tensor and optional sequence types.
001caec5 Integer value expected, but not found.
001caeed Computes an one-layer GRU. This operator is usually supported via some custom
001caf3b implementation such as CuDNN.
001caf5a Notations:
001caf66 `X` - input tensor
001caf7a `z` - update gate
001caf8d `r` - reset gate
001caf9f `h` - hidden gate
001cafb2 `t` - time step (t-1 means previous time step)
001cafe2 `W[zrh]` - W parameter weight matrix for update, reset, and hidden gates
001cb02c `R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates
001cb077 `Wb[zrh]` - W bias vectors for update, reset, and hidden gates
001cb0b7 `Rb[zrh]` - R bias vectors for update, reset, and hidden gates
001cb0f7 `WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates
001cb14b `RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates
001cb1a0 `WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates
001cb1ea `RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates
001cb234 `H` - Hidden state
001cb248 `num_directions` - 2 if direction == bidirectional else 1
001cb283 Activation functions:
001cb29a   Relu(x)                - max(0, x)
001cb2c0   Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
001cb2f8   Sigmoid(x)             - 1/(1 + e^{-x})
001cb323   (NOTE: Below are optional)
001cb341   Affine(x)              - alpha*x + beta
001cb36c   LeakyRelu(x)           - x if x >= 0 else alpha * x
001cb3a3   ThresholdedRelu(x)     - x if x >= alpha else 0
001cb3d6   ScaledTanh(x)          - alpha*Tanh(beta*x)
001cb405   HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
001cb440   Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
001cb47d   Softsign(x)            - x/(1 + |x|)
001cb4a5   Softplus(x)            - log(1 + e^x)
001cb4ce Equations (Default: f=Sigmoid, g=Tanh):
001cb4f7   - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)
001cb528   - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)
001cb559   - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0
001cb5bb   - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0
001cb617   - Ht = (1 - zt) (.) ht + zt (.) Ht-1
001cb63f : failed validating the check: 
001cb65f Tensors.
001cb668 Constrain input types. Casting from complex is not supported.
001cb6a6 Constrain output to int64 tensor.
001cb6c8 Total number of elements of the input tensor
001cb6f5 Number of outputs to split parts of the tensor into. If the tensor is not evenly splittable the last chunk will be smaller.
001cb771 When True (nonzero), yield X, otherwise yield Y
001cb7a1 (Optional) Specify which axis is batch axis. Must be one of 1 (default), or 0.
001cb7f0 Tensor of rank q >= 1. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
001cb896 constant_value
001cb8a5 If provided, it specifies a subset of axes that 'shape' refer to. If not provided, all axes are assumed [0, 1, ..., r-1], where r = rank(data). Negative value means counting dimensions from the back. Accepted range is [-r, r-1], where r = rank(data). Behavior is undefined if an axis is repeated.
001cb9d0 **History**
001cb9dc - Version 16 adds bfloat16 to the types allowed (for the second and third parameter).
001cba33 (Optional) Axis along which one-hot representation in added. Default: axis=-1. axis=-1 means that the additional dimension will be inserted as the innermost/last dimension in the output tensor.
001cbaf5 Graph has 
001cbb00  inputs but 
001cbb0d /build/intermediates/arm64-v8a/Release/_deps/protobuf-src/src/google/protobuf/io/zero_copy_stream_impl_lite.cc
001cbb7c CHECK failed: (count) >= (0): 
001cbb9e /build/intermediates/arm64-v8a/Release/_deps/re2-src/re2/compile.cc
001cbbe2 unhandled 
001cbbed Bad final char: 
001cbbfe Batak
001cbc0a Cuneiform
001cbc14 Georgian
001cbc1d Khudawadi
001cbc27 Meroitic_Hieroglyphs
001cbc3c Tagalog
001cbc47 checking a waiter condition while unlocked
001cbc73 attempt to nsync_mu_runlock() an nsync_mu held in write mode
001cbcb1 core
001cbcb6 failed to allocate %zu bytes for descriptions of %u L1D caches
001cbcf5 Pinecone
001cbcfe Nuclun 
001cbd06 condition_variable timed_wait failed
001cbd2b %H:%M:%S
001cbd34 November
001cbd3d bad_optional_access
001cbd51 invocation function for block in 
001cbd73 static_cast
001cbd7f sizeof... (
001cbd8f operator-=
001cbd9a %s failed to acquire mutex
001cbdb5 libunwind: malformed DW_CFA_offset_extended_sf DWARF unwind, reg too big
001cbdff getULEB128
001cbe0a malformed uleb128 expression
001cbe27 DWARF opcode not implemented
001cbe4c OrtStatusPtr OrtApis::FillSparseTensorCsr(OrtValue *, const OrtMemoryInfo *, const int64_t *, size_t, const void *, const int64_t *, size_t, const int64_t *, size_t)
001cbef2 RegisterCustomOpsLibrary: Entry point RegisterCustomOps not found in library
001cbf3f std::unique_ptr<IDataTransfer> (anonymous namespace)::GetDataTransfer(const OrtDevice &, const OrtDevice &)
001cbfab Trying to get a TensorSeq, but got: 
001cbfd0 static bool onnxruntime::utils::ContainerChecker::IsContainerOfType<std::map<std::basic_string<char>, double>>::check(const onnxruntime::utils::ContainerChecker::Cont &, size_t) [T = std::map<std::basic_string<char>, double>]
001cc0b2 const T &OrtValue::Get() const [T = std::map<long, std::basic_string<char>>]
001cc0ff const T &OrtValue::Get() const [T = std::map<long, long>]
001cc139 i < tensors_.size()
001cc14d -intra-op
001cc157 session.intra_op_thread_affinities
001cc17a Using global/env threadpools since use_per_session_threads_ is false
001cc1bf Received nullptr for custom registry
001cc1e4 SaveToOrtFormat
001cc1f4 LoadOrtModelWithLoader
001cc20b Failed to load model because protobuf parsing failed.
001cc241 Sequential mode
001cc251 cannot get value
001cc262 null literal
001cc26f tensor(string)
001cc27e seq(tensor(uint16))
001cc292  (domain: 
001cc29d in the inclusive range [
001cc2b6 ] (usually, this means you 
001cc2d2 T *onnxruntime::Tensor::MutableData() [T = long]
001cc303 ANeuralNetworksMemoryDesc_free
001cc322 ANeuralNetworksMemory_createFromDesc
001cc347 ANeuralNetworksEvent_createFromSyncFenceFd
001cc372 ANeuralNetworksEvent_getSyncFenceFd
001cc396 ANEURALNETWORKS_BAD_STATE
001cc3b0 QLinearMatMul
001cc3be B of BN must be known
001cc3d4  actual shape, 
001cc3e4 on identifyInputsAndOutputs
001cc400 , ONNX input scale: 
001cc415  is skipped
001cc421 AddToModelBuilder
001cc433 ClipOpBuilder, unsupported input [
001cc456 Resize only support 4d shape, input is 
001cc47e exclude_outside
001cc48e Resize nearest neighbor, unsupported coord_trans_mode, 
001cc4c6 floor
001cc4cc External data is not supported for the scalar min/max Clip values
001cc50e unsupported AveragePool in XnnpackEP, we have FLOAT|UINT8, but got 
001cc552 /onnxruntime_src/onnxruntime/core/providers/cpu/math/gemm_base.h
001cc593 This transformer is already registered 
001cc5bb NoopElimination
001cc5cb GemmActivationFusion
001cc5e0 ConvAddFusion_Add_B_
001cc5f5 bn_scale_tensor_proto
001cc60b /onnxruntime_src/onnxruntime/core/optimizer/gelu_fusion.cc
001cc646 Slice
001cc64c Gemm does not have 3 inputs
001cc668 Gemm weight is not constant initializer
001cc690 Pass CheckNodesInPathQ
001cc6a7 Faild to find path to qkv_matmul
001cc6c8 Faild to find path v
001cc6dd Cast
001cc6e2 fused GPT2Gelu subgraphs 
001cc6fc std::optional<std::pair<float, int>> onnxruntime::(anonymous namespace)::GetScaleFromNode(const onnxruntime::Graph &, const onnxruntime::Node &, const InlinedHashSet<std::string> &)
001cc7b2 ReorderInput
001cc7bf node_input_def_idx >= 0 && static_cast<size_t>(node_input_def_idx) < node_inputs.size()
001cc817 src_node != nullptr
001cc82b Inserted by QDQPropagationTransformer
001cc851 PropagateDQForward
001cc864 _s8_2_u8
001cc86d ConcatTraining
001cc87c /onnxruntime_src/onnxruntime/core/optimizer/selectors_actions/selector_action_transformer.cc
001cc8d9 inserted_in_name_to_entry
001cc8f3 Not enough produced nodes in the runtime optimization record.
001cc931 TensorrtExecutionProvider
001cc94b dst_type->value_case() == src_type->value_case() && (!dst_data_element_type_present || dst_data_element_type == src_data_element_type)
001cc9d2 NhwcMaxPool
001cc9e2 Cosh
001cc9eb ReduceL1
001cc9f4 RandomUniform
001cca02 unknown kernel type
001cca16 CreateFeedsFetchesManager must be called prior to execution of graph.
001cca5c position_ >= 0 && position_ < sequence_length_
001cca8b iteration_num_ < sequence_len_
001ccaaa Graph in 'body' attribute of Loop should have 
001ccad9 Loop subgraph input 0 has unknown shape: 
001ccb03 ConcatenateLoopOutput
001ccb19 scan_input_directions
001ccb2f  but input '
001ccb3c Must have a single dimension of 1
001ccb5e virtual onnxruntime::common::Status onnxruntime::CumSum<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
001ccbd8 data_1.Shape() == shape
001ccbf0 Invalid direction value of '
001ccc0d Attempting to broadcast an axis by a dimension other than 1. 
001ccc4b void onnxruntime::mod_internal::CallModImpl<float>::operator()(bool, onnxruntime::OpKernelContext *) const [T = float, Enable = void]
001cccd1 k tensor should be a 1D tensor of size 1
001cccfa ArrayFeatureExtractor
001ccd10 TO_STRING
001ccd1a onnxruntime::ml::DictVectorizerOp<long, double>::DictVectorizerOp(const onnxruntime::OpKernelInfo &) [AttrType = long, TargetType = double]
001ccda6 gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = std::basic_string<char>]
001ccdfa onnxruntime::ml::LabelEncoder_2<std::basic_string<char>, long>::LabelEncoder_2(const onnxruntime::OpKernelInfo &) [TKey = std::basic_string<char>, TValue = long]
001cce9c SOFTMAX
001ccea4 shape_size == out.size()
001ccebd onnxruntime::ml::LinearRegressor::LinearRegressor(const onnxruntime::OpKernelInfo &)
001ccf15 onnxruntime::ml::ScalerOp<float>::ScalerOp(const onnxruntime::OpKernelInfo &) [T = float]
001ccf6f onnxruntime::ml::SVMClassifier::SVMClassifier(const onnxruntime::OpKernelInfo &)
001ccfc0 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/svmclassifier.h
001cd003 n_targets
001cd00d nodes_hitrates
001cd01c void onnxruntime::ml::detail::TreeEnsembleCommon<float, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = float, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorSum<float, float, float>]
001cd16d void onnxruntime::ml::detail::TreeEnsembleCommon<double, double, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = double, ThresholdType = double, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorMin<double, double, float>]
001cd2c4 virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommon<int, float, float>::compute(onnxruntime::OpKernelContext *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *) const [InputType = int, ThresholdType = float, OutputType = float]
001cd3de virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommonClassifier<int, float, float>::Init(const onnxruntime::OpKernelInfo &) [InputType = int, ThresholdType = float, OutputType = float]
001cd4b1 Invalid input scale: NumDimensions() != 
001cd4da Invalid input B: 
001cd4ec  group: 
001cd4f5 filter number not equal to input channel number.
001cd526 float onnxruntime::(anonymous namespace)::GetRatioOrDefault(const onnxruntime::Tensor *) [T2 = float]
001cd58c onnxruntime::LpPoolV18<float>::LpPoolV18(const onnxruntime::OpKernelInfo &) [T = float]
001cd5e4 max_skip_count
001cd5f3  <= 
001cd5f8 output != nullptr
001cd60a /onnxruntime_src/onnxruntime/core/providers/cpu/optional/optional_ops.cc
001cd653 /onnxruntime_src/onnxruntime/core/providers/cpu/quantization/qlinearconv.cc
001cd69f QLinearConv : filter zero point shape invalid
001cd6cd QLinearMatmul : weight zero point must be a scalar, 1D tensor of size 1, or last to second dimension is 1
001cd737 /onnxruntime_src/onnxruntime/core/providers/cpu/rnn/lstm_base.cc
001cd778 Input initial_h must have shape {
001cd79a Input R must have shape {
001cd7b4 leakyrelu
001cd7be onnxruntime::common::Status onnxruntime::short_time_fourier_transform(onnxruntime::OpKernelContext *, bool, bool) [T = double, U = std::complex<double>]
001cd857 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/col2im.h
001cd897 void onnxruntime::StridedCopy(concurrency::ThreadPool *, T *, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShape &, const T *, const onnxruntime::TensorShapeVector &) [T = unsigned long]
001cd966 indices
001cd96e GatherNDBase PrepareForCompute: Input count mismatch
001cd9a3 Axes tensor should be a 1D tensor 
001cd9c6 onnxruntime::ReshapeHelper::ReshapeHelper(const onnxruntime::TensorShape &, onnxruntime::TensorShapeVector &, bool)
001cda3a virtual onnxruntime::common::Status onnxruntime::Reshape::Compute(onnxruntime::OpKernelContext *) const
001cdaa2 shapeTensor->Shape().NumDimensions() == 1
001cdacc A shape tensor must be a vector tensor.
001cdaf4 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/reverse_sequence.cc
001cdb3f Unknown tensor type of 
001cdb57 . Must be 0 or 1
001cdb68 gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = unsigned char]
001cdbb2 CPU execution provider: bool data type is not supported with ScatterElements opset 18 when reduction is 'max'.
001cdc21 ScatterND
001cdc2b CPU execution provider: string data type is not supported with ScatterND opset 18 when reduction is 'min'.
001cdc96 Unsupported input type in DepthToSpace op: 
001cdcc2 DepthToSpace op: only 'DCR' and 'CRD' modes are supported
001cdcfc onnxruntime::SplitBase::SplitBase(const onnxruntime::OpKernelInfo &, uint32_t)
001cdd4b (local_source >= source) && (local_source < source + num_blocks)
001cdd8c info.GetAttrs("axes", axes_).IsOK()
001cddb0 Missing/Invalid 'axes' attribute value
001cddd7 past_sequence_length tensor must be of one element when past_present_share_buffer is set
001cde30 Input 'relative_position_bias' dimension 3 should be same as total_sequence_length, got 
001cde89 Attention mechanism memory sequence lengths value must in (0, 
001cdec8 Real memory steps 
001cdedb DynamicSlice
001cdee8 keys
001cdeed /onnxruntime_src/onnxruntime/contrib_ops/cpu/nchwc_ops.h
001cdf26 onnxruntime::contrib::ReorderInput::ReorderInput(const onnxruntime::OpKernelInfo &)
001cdf7a QlinearBuildLookupTable : input X_scale must be a scalar or 1D tensor of size 1
001cdfca onnxruntime::contrib::Tokenizer::Tokenizer(const onnxruntime::OpKernelInfo &)
001ce018 num_beams >= num_return_sequences
001ce03a hypothesis_buffer_offset_ <= hypothesis_buffer_length_
001ce071 input_ids_shape.NumDimensions() == 2
001ce096 Setup
001ce09c subgraph output 0 (logits) shall be float or float16 data type
001ce0db decoder subgraph past inputs shall have same data type as that of encoder_hidden_states
001ce133 encoder subgraph output 1 shall be named encoder_hidden_states, got: 
001ce179 Extend
001ce180  size: 
001ce188 !chunk->in_use()
001ce199 c2->prev == h1
001ce1a8 auto onnxruntime::BFCArena::Extend(size_t)::(anonymous class)::operator()(const size_t) const
001ce206 Incorrect arena extend strategy.
001ce227 p_int < base_int + memory_size_
001ce247 ] already exists with value [
001ce265 thisProto->value_case() == TypeProto::ValueCase::kMapType
001ce29f value_proto != nullptr
001ce2b6  but the actually size is: 
001ce2d2 kernel_type_str is null.
001ce2eb ktsr
001ce2f0 onnxruntime::AllocatorPtr onnxruntime::PrepackedWeightsContainer::GetOrCreateAllocator(const std::string &)
001ce35c onnxruntime::common::Status onnxruntime::PlannerImpl::CreatePlan(const onnxruntime::IStreamCommandHandleRegistry &, const onnxruntime::PathString &, const logging::Logger &)
001ce40a void onnxruntime::PlannerImpl::PartitionIntoStreams(const logging::Logger &, const onnxruntime::ExecutionProviders &, const onnxruntime::PathString &)
001ce4a1 Should not have entry in kernel create info with nullptr for kernel_def
001ce4e9 onnxruntime::common::Status onnxruntime::PlannerImpl::ComputeSingleStreamReusePlan(size_t)
001ce547 null}
001ce54d utils::HasExternalData(tensor_proto)
001ce572 AllocateBuffer
001ce581 Unable to find a data transfer for copying from device type: 
001ce5bf frame_.ReleaseMLValue(static_cast<int>(execution_plan->release_actions[idx].value_index)).IsOK()
001ce620 ort value 
001ce62b Strided tensor is supported for training only for now.
001ce662 tensor failed memory size calculation
001ce688 Invalid tensor shape slice argument.
001ce6ad Invalid SparseTensor indices. INT16 indices must be in the raw data of indices tensor
001ce703 Number of attention heads
001ce71f Predicted token ids from aggressive decoding
001ce74c query_bias
001ce757 Constrain input and output types to all numeric tensors.
001ce790 The bias (or mask) as Tensor.
001ce7ae prefix_vocab_mask
001ce7c0 activation_gamma
001ce7d1 Whether B should be transposed on the 1st dimension and batch dimensions (dim-1 to dim-rank-2) before doing multiplication
001ce84c Version number of the TRT plugin.
001ce86e The inner-most 2 dimensions must have the same size (mat_w:
001ce8aa First input does not have rank 2
001ce8cb 'pads' input must be a 1D (shape: [input_rank]) or 2D tensor (shape: [1, input_rank]) of type int64
001ce92f MeanOfSquare = ReduceMean <axes = [1]> (Square)
001ce95f Input data tensor. Dimensions are (N x H x W x C), where N is the batch size, C is the number of channels, and H and W are the height and width of the data
001ce9fb Input zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
001cea73 block_dim
001cea7d Constrain y to uint8.
001cea93 shape of the original tensor.
001ceab4 Corresponding past and present are same tensor, its shape is (2, batch_size, num_heads, max_sequence_length, head_size)
001ceb2c Constrain bias and scales to float32
001ceb51 QOrderedMatMul
001ceb60 Type mismatch. Current=
001ceb78 Invalid destination node arg slot specified when removing edge.
001cebb8 ) does not have type information set by parent node.
001cebed outer_scope_node_args_consumed.empty()
001cec14 Cannot find NodeArgs for [
001cec2f dst_implicit_input_idx < (int)node->ImplicitInputDefs().size()
001cec6e it != opset_imports.end()
001cec88 initializer != nullptr
001cec9f !graph.GetInitializedTensor(new_initializer.name(), existing)
001cecdd /onnxruntime_src/onnxruntime/core/graph/graph_viewer.cc
001ced15 custom join thread function not set
001ced39 ParsePathRoot
001ced47 open
001ced4c uint64_data
001ced58 ' points outside the directory
001ced77 ) has 
001ced7e then_branch and else_branch produce different number of outputs. 
001cedc0 optional(tensor(int8))
001cedd7 optional(tensor(double))
001cedf0 optional(tensor(complex64))
001cee0c Final N loop carried dependency values then K scan_outputs
001cee47 Invalid data type 
001cee5a If set, defines the broadcast dimensions.
001cee84 The hyperbolic tangent values of the input tensor computed element-wise
001ceecc Quantized matrix multiply results from a * b
001ceef9 Zero point tensor for input 'A'. It's optional and default value is 0. It could be a scalar or N-D tensor. Scalar refers to per tensor quantization whereas N-D refers to per row quantization. If the input is 2D of shape [M, K] then zero point tensor may be an M element vector [zp_1, zp_2, ..., zp_M]. If the input is N-D tensor with shape [D1, D2, M, K] then zero point tensor may have shape [D1, D2, M, 1]. 
001cf093 weight_gather = Squeeze (weight_gather_temp_1, axes)
001cf0c9         {
001cf0d3           A0 = Constant <value = float {0.5}>()
001cf103           A1 = Constant <value = float {0.5}>()
001cf133           A2 = Constant <value = float {0.0}>()
001cf163           Zero = Constant <value = float {0.0}>()
001cf195           One = Constant <value = float {1.0}>()
001cf1c6           Two = Constant <value = float {2.0}>()
001cf1f7           Tau = Constant <value = float {6.2831853}>()
001cf22e           Periodic_Size_FP = Cast <to = 1> (size)
001cf260           Symmetric_Size_FP = Sub(Periodic_Size_FP, One)
001cf299           IsPeriodic = Constant <value_int : int = @periodic>()
001cf2d9           IsPeriodic_FP = Cast <to = 1> (IsPeriodic)
001cf30e           IsSymmetric_FP = Sub(One, IsPeriodic_FP)
001cf341           Periodic_Component = Mul(Periodic_Size_FP, IsPeriodic_FP)
001cf385           Symmetric_Component = Mul(Symmetric_Size_FP, IsSymmetric_FP)
001cf3cc           Size_FP = Add(Periodic_Component, Symmetric_Component)
001cf40d           AngularIncrement = Div (Tau, Size_FP)
001cf43d           Range = Range (Zero, Periodic_Size_FP, One)
001cf473           RangeAngular = Mul (Range, AngularIncrement)
001cf4aa           TwoRangeAngular = Mul (RangeAngular, Two)
001cf4de           CosTwoRangeAngular = Cos (TwoRangeAngular)
001cf513           A2_Component = Mul (A2, CosTwoRangeAngular)
001cf549           CosRangeAngular = Cos (RangeAngular)
001cf578           A1_Component = Mul (A1, CosRangeAngular)
001cf5ab           Temp0 = Sub (A0, A1_Component)
001cf5d4           Temp1 = Add (Temp0, A2_Component)
001cf600           output = Cast <to : int = @output_datatype> (Temp1)
001cf63e         }
001cf648         
001cf652         {
001cf65c           A0 = Constant <value = float {0.42}>()
001cf68d           A1 = Constant <value = float {0.5}>()
001cf6bd           A2 = Constant <value = float {0.08}>()
001cf6ee           Zero = Constant <value = float {0.0}>()
001cf720           One = Constant <value = float {1.0}>()
001cf751           Two = Constant <value = float {2.0}>()
001cf782           Tau = Constant <value = float {6.2831853}>()
001cf7b9           Periodic_Size_FP = Cast <to = 1> (size)
001cf7eb           Symmetric_Size_FP = Sub(Periodic_Size_FP, One)
001cf824           IsPeriodic = Constant <value_int : int = @periodic>()
001cf864           IsPeriodic_FP = Cast <to = 1> (IsPeriodic)
001cf899           IsSymmetric_FP = Sub(One, IsPeriodic_FP)
001cf8cc           Periodic_Component = Mul(Periodic_Size_FP, IsPeriodic_FP)
001cf910           Symmetric_Component = Mul(Symmetric_Size_FP, IsSymmetric_FP)
001cf957           Size_FP = Add(Periodic_Component, Symmetric_Component)
001cf998           AngularIncrement = Div (Tau, Size_FP)
001cf9c8           Range = Range (Zero, Periodic_Size_FP, One)
001cf9fe           RangeAngular = Mul (Range, AngularIncrement)
001cfa35           TwoRangeAngular = Mul (RangeAngular, Two)
001cfa69           CosTwoRangeAngular = Cos (TwoRangeAngular)
001cfa9e           A2_Component = Mul (A2, CosTwoRangeAngular)
001cfad4           CosRangeAngular = Cos (RangeAngular)
001cfb03           A1_Component = Mul (A1, CosRangeAngular)
001cfb36           Temp0 = Sub (A0, A1_Component)
001cfb5f           Temp1 = Add (Temp0, A2_Component)
001cfb8b           output = Cast <to : int = @output_datatype> (Temp1)
001cfbc9         }
001cfbd3         
001cfbdc dft_length input must be a scalar.
001cfbff size input must be a scalar.
001cfc1c X_LogSM_NCD
001cfc28 The input tensor that's coerced into a 2D matrix of size (NxD) as described above.
001cfc7b Zero point tensor for input 'x'. It's optional and default value is 0. It's a scalar, which means a per-tensor/layer quantization.
001cfcfe Constrain input and output to all tensor types.
001cfd2e Minimum n-gram length. If this value is 2 and max_gram_length is 3, output may contain counts of 2-grams and 3-grams.
001cfda4 p value of the Lp norm used to pool over the input data.
001cfddd Multiplicative spatial scale factor to translate ROI coordinates from their input spatial scale to the scale used when pooling, i.e., spatial scale of the input feature map X relative to the input image. E.g.; default is 1.0f. 
001cfec1 Float representing the threshold for deciding whether boxes overlap too much with respect to IOU. It is scalar. Value range [0, 1]. Default to 0.
001cff53 Keep the reduced dimension or not, default 1 means keep reduced dimension.
001cff9e Whether to select the last index or the first index if the {name} appears in multiple indices, default is False (first index).
001d001d Constrain input and output types to high-precision and 8 bit numeric tensors.
001d006b axes as an input and attribute cannot be specified at the same time.
001d00b0 ' is missing.
001d00be Duplicate type constraint name
001d00dd Length of input sequence. It must be a scalar(tensor of empty shape).
001d0123 reshaped
001d012c Three interpolation modes: "nearest" (default), "linear" and "cubic". The "linear" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The "cubic" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor).
001d02a8 grid
001d02ad Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * num_axes] where `num_axes` refers to the number of elements in the `axes` input or the input rank if `axes` are not provided explicitly. `pads` format should be: [x1_begin, x2_begin, ..., x1_end, x2_end,...], where xi_begin is the number of pad values added at the beginning of axis `axes[i]` and xi_end, the number of pad values added at the end of axis `axes[i]`.
001d04fa Dimension could not be inferred: incompatible shapes
001d052f  and Output 
001d053c Input tensor must be 4-dimensional
001d055f The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. One of 'scales' and 'sizes' MUST be specified and it is an error if both are specified. If 'sizes' is needed, the user can use an empty string as the name of 'scales' in this operator's input list.
001d06ff outputs...
001d070a 4-D tensor after resizing, [N,C,H,W]
001d072f Data to be selected
001d0743 Input data. It can be either tensor or scalar.
001d0772 A collection of intercepts.
001d078e The input type must be a tensor of a numeric type, either [C] or [N,C].
001d07d6 Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
001d084c Child node if expression is false
001d086e Defines how to aggregate leaf values within a target. <br>One of 'AVERAGE,' 'SUM,' 'MIN,' 'MAX.'
001d08cf  already exists.
001d08e0 Can't 
001d08e7 bytemap range 
001d08f6 unknown round: 
001d0906 /build/intermediates/arm64-v8a/Release/_deps/re2-src/re2/walker-inl.h
001d094c [:^digit:]
001d0957 [:lower:]
001d0961 [:upper:]
001d096b context does not contain text
001d098b Anatolian_Hieroglyphs
001d09a1 Bassa_Vah
001d09ab Hanunoo
001d09b3 Kayah_Li
001d09bc Lydian
001d09c3 Nabataean
001d09cd New_Tai_Lue
001d09dc Tibetan
001d09e7 processor
001d09f1 hi3650
001d09f8 marlin
001d0a03 September
001d0a14 nullptr
001d0a1c operator<<=
001d0a28 ::operator 
001d0a34 enum
001d0a39 %s failed to release mutex
001d0a54 libunwind: malformed DW_CFA_val_expression DWARF unwind, reg too big
001d0aa7 /onnxruntime_src/onnxruntime/core/session/onnxruntime_c_api.cc
001d0ae6 invalid location range
001d0afd tried Filling sparse tensor with negative value in values shape
001d0b3d Please register the allocator as OrtDeviceAllocator even if the provided allocator has arena logic built-in. OrtArenaAllocator is reserved for internal arena logic based allocators only.
001d0bf8 ModelProto corresponding to the model to be loaded has not been parsed yet. This API should be called in conjunction with a ctor that takes a model abstraction.
001d0c99 Adding default CPU execution provider.
001d0cc0 This session will use the allocator registered with the environment.
001d0d05 session_initialization
001d0d1c Unsupported device id in the memory arena shrink list: 
001d0d54 FinalizeSessionOptions
001d0d6b enable_profiling option in the model file must be an integer
001d0da8 SetGraphOptimizationLevel
001d0dc2 invalid string: control character U+0010 (DLE) must be escaped to \u0010
001d0e0b object separator
001d0e20 ' was not found.
001d0e31  line 
001d0e3b Ensure
001d0e42 Missing Input: 
001d0e52 Tensor size (
001d0e60 invalid node input count: 
001d0e7b , expect: 
001d0e86  shape
001d0e8d Model::SetOutputBuffer, output shape 
001d0eb3 ANeuralNetworksCompilation_setPreference
001d0edc ANeuralNetworksEvent_free
001d0ef6 SL_ANeuralNetworksDiagnosticExecutionInfo_getHardwareExecutionTimeNanos
001d0f3e ASharedMemory_create
001d0f53 _imm_b
001d0f5a  is added
001d0f64 AddOperations
001d0f72 ], with 
001d0f7b Invalid perm is given!
001d0f92 AddBinaryOperator
001d0fa4 Squeeze is not supported on API level 
001d0fcb AddReshapeOperator
001d0fde ]'s 
001d0fe3 Invalid cast to type: 
001d0ffa sizes
001d1000 Input axes of Unsqueeze must be known
001d1026 onnxruntime::AutoPadType onnxruntime::StringToAutoPadType(const std::string &)
001d1075 dilation is not supported on grouped conv
001d109f GemmOpSupportChecker, unknown op: 
001d10c2 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/unary_op_builder.cc
001d1124 /onnxruntime_src/onnxruntime/core/providers/xnnpack/xnnpack_init.cc
001d1168 onnxruntime::xnnpack::ConvBase::ConvBase(const onnxruntime::OpKernelInfo &, bool)
001d11ba Not enough elements in dilations. Expected: 
001d11e7 FP16
001d11ec /onnxruntime_src/onnxruntime/core/providers/xnnpack/detail/utils.cc
001d1230  and zero-point 
001d1241 mismatching number of quantization parameters  
001d1271 MaxUnpool
001d127b stretch
001d1283 mode_ == UpsampleMode::LINEAR
001d12a1 num_dims_with_pad - 1 != num_output_dims
001d12ca sum_node.GetOutputEdgesCount() == 0
001d12ee ConvAddAct
001d12f9 Recurse
001d1301 Conflicting free dimension overrides.
001d1327 FusedGemm
001d1331 ValidateUnidirMask
001d1344 unidir mask is not constant
001d1360 Output edge count not expected for unsqueeze2 of unidirectional mask
001d13a5 equal const not matched.
001d13be CheckNodesInPathV return false
001d13dd Failed to match position subgraph.
001d1400 num_outputs
001d140c data_type() == other.data_type()
001d142d gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = int]
001d146d /onnxruntime_src/onnxruntime/core/optimizer/matmul_integer_to_float.cc
001d14b4 std::optional<float> onnxruntime::(anonymous namespace)::GetScalarConstantInitializer(const onnxruntime::Graph &, const onnxruntime::NodeArg &)
001d1544 /onnxruntime_src/onnxruntime/core/optimizer/optimizer_execution_frame.cc
001d158d CreateReplacementNode
001d15a3 Applying runtime optimization action 
001d15c9 virtual void onnxruntime::ApiGraph::ReshapeInitializer(std::string_view, const std::vector<int64_t> &)
001d1630 int onnxruntime::GetSinceVersionForNewOp(std::string_view, std::string_view, const std::unordered_map<std::string, int> &)
001d16ae ArgMin
001d16b5 RknpuExecutionProvider
001d16cc virtual std::shared_ptr<KernelRegistry> onnxruntime::CPUExecutionProvider::GetKernelRegistry() const
001d1731 Create
001d1738 onnxruntime::ElementWiseKernel<onnxruntime::functors::Selu<float>>::ElementWiseKernel(const onnxruntime::OpKernelInfo &) [F = onnxruntime::functors::Selu<float>]
001d17da then_branch
001d17e6 Subgraph SessionState was not found for '
001d1810 ' attribute.
001d181d SetValueFromTensorProto
001d1835 /onnxruntime_src/onnxruntime/core/providers/cpu/generator/constant_of_shape.cc
001d1884 Cannot apply CumSum operator on a scalar
001d18ad /onnxruntime_src/onnxruntime/core/providers/cpu/math/det.cc
001d18e9 Found a '.' not part of an ellipsis in the output subscript provided
001d192e left_rank == right_rank
001d1946 ExpandBroadcastLooper should only have a shape for the second input.
001d198b ) for tensor of length:
001d19a3 Unsupported Y type: 
001d19b8  K: 
001d19bd info.GetAttr<std::string>("map_form", &attr).IsOK()
001d19f1 DENSE
001d19f7 Invalid PACK_MAP value of 
001d1a12 string_vocabulary
001d1a24 input_tensor_ptr != nullptr
001d1a40 inputdimensions attribute must be provided
001d1a6b imputed_values_float_.empty() ^ imputed_values_int64_.empty()
001d1aa9 Input of tensor(int64) must have output of tensor(string)
001d1ae3  attribtues in LabelEncoder 
001d1b00 onnxruntime::ml::ScalerOp<int>::ScalerOp(const onnxruntime::OpKernelInfo &) [T = int]
001d1b56 LINEAR
001d1b5d TreeEnsembleClassifier
001d1b74 base_values_as_tensor
001d1b8a nodes_values.empty() || nodes_values_as_tensor.empty()
001d1bc1 void onnxruntime::ml::detail::TreeAggregatorSum<double, double, float>::ProcessTreeNodePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const TreeNodeElement<ThresholdType> &) const [InputType = double, ThresholdType = double, OutputType = float]
001d1cbe void onnxruntime::ml::detail::TreeAggregatorClassifier<double, double, float>::FinalizeScores(InlinedVector<ScoreValue<ThresholdType>> &, OutputType *, int, int64_t *) const [InputType = double, ThresholdType = double, OutputType = float]
001d1dad void onnxruntime::ml::detail::TreeAggregatorMin<long, float, float>::MergePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = long, ThresholdType = float, OutputType = float]
001d1ea4 onnxruntime::common::Status onnxruntime::ml::GetVectorAttrsOrDefault(const onnxruntime::OpKernelInfo &, const std::string &, onnx::TensorProto_DataType, std::vector<TH> &) [TH = float]
001d1f5d  inferred output shape:
001d1f75 ratio_tensor->Shape().Size() == 1
001d1f97 onnxruntime::Flatten::Flatten(const onnxruntime::OpKernelInfo &)
001d1fd8 op_kernel_info.GetAttr<int64_t>("axis", &axis_).IsOK()
001d200f alpha_ > 0.0f
001d201d Input contains invalid utf8 chars
001d203f Got weights of size: 
001d2055 scores must be a 3D tensor.
001d2071 Optional
001d207a void onnxruntime::ValidateFastReduceRKR(const gsl::span<const int64_t> &, const onnxruntime::Tensor &)
001d20e1 Can't reduce on dim with value of 0 if 'keepdims' is false. Invalid output shape would be produced. input_shape:
001d2152 Input B must have shape {
001d216c num_inputs >= 1
001d217c onnxruntime::Tensor onnxruntime::CloneTensor(const onnxruntime::Tensor &, onnxruntime::OpKernelContext *, const onnxruntime::DataTransferManager &)
001d2210 onnxruntime::common::Status onnxruntime::CreateMelWeightMatrix<long>::operator()(onnxruntime::OpKernelContext *, int64_t, int64_t, int64_t, float, float) [T = long]
001d22b5 invalid expand shape
001d22ca Cannot use 'reflect' mode to pad dimension with a value of 0. Input shape:
001d2315 Invalid 'pads' attribute value
001d2334 onnxruntime::common::Status onnxruntime::PadImpl(onnxruntime::OpKernelContext *, const onnxruntime::PadsVector &, const onnxruntime::PadsVector &, const onnxruntime::Mode &, T) [T = unsigned int]
001d23f8 A dimension cannot be less than -1, got 
001d2421 gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = signed char]
001d2469 onnxruntime::SpaceDepthBase::SpaceDepthBase(const onnxruntime::OpKernelInfo &)
001d24b8 virtual onnxruntime::common::Status onnxruntime::SplitImpl::Compute(onnxruntime::OpKernelContext *) const
001d2522  must be 1 instead of 
001d2539 (local_source >= source) && (local_source < source + num_blocks * blocksize)
001d2586 4-D input with innermost scale (usually channel of NHWC) as 1.
001d25c5 4D mask in attention cpu kernel is not supported
001d25f6 Attention mechanism memory sequence lengths must have shape {
001d2634 }. Got: 
001d263d !normalize_
001d2649 info.GetAttr<int64_t>("ngram_size", &ngram_size_).IsOK()
001d2682 min_ngram_size_ > 0
001d2696 info.GetAttr("alpha", &alpha_).IsOK()
001d26bc Bias size (
001d26c8 Inverse
001d26d0 /onnxruntime_src/onnxruntime/contrib_ops/cpu/murmur_hash3.cc
001d270d Invalid assumption of output element size
001d2737 X_shape.size() == 4
001d274b W_scale
001d2753 onnxruntime::common::Status onnxruntime::contrib::MatMulIntegerToFloatBase::ComputeCommon(onnxruntime::OpKernelContext *, const uint8_t *, const onnxruntime::TensorShape &, float, uint8_t, bool, const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *) const
001d2890 gamma is expected to have 1 dimension, got 
001d28bc t5_encoder_subgraph_ == nullptr
001d28dc Subgraph SessionState was not found for 'encoder' attribute.
001d2919 onnxruntime::common::Status onnxruntime::contrib::GenerationCpuDeviceHelper::UpdateDecoderFeeds(onnxruntime::AllocatorPtr, onnxruntime::Stream *, const std::vector<OrtValue> &, std::vector<OrtValue> &, int, gsl::span<const int32_t>, gsl::span<const int32_t>, int, int, int, bool, int, transformers::Sequences &, const transformers::IConsoleDumper *) [T = float]
001d2a83 CreateInitialFeeds
001d2a96 Invalid GPT-2 subgraph: number of inputs shall be number of outputs plus 2 or 3 (if past_present_share_buffer)
001d2b05 subgraph input 1 shall be named as position_ids, got: 
001d2b3c expect 3 inputs, got:
001d2b52  The total allocated bytes is now 
001d2b75 p_int >= base_int
001d2b87 utils::HasElemType(thisProto->optional_type())
001d2bb6 utils::HasKeyType(thisProto->map_type())
001d2bdf int8
001d2be4 uint32
001d2beb onnxruntime::IExecutionFrame::IExecutionFrame(const onnxruntime::OrtValueNameIdxMap &, const onnxruntime::NodeIndexInfo &, gsl::span<const int>)
001d2c7c Invalid allocation kind: 
001d2c96 IExecutionProvider::Compile with FusedNodeAndGraph is not implemented by 
001d2ce0 onnxruntime::FeedsFetchesInfo::FeedsFetchesInfo(gsl::span<const std::string_view>, gsl::span<const std::string>, const onnxruntime::OrtValueNameIdxMap &)
001d2d7a ort_value.IsAllocated()
001d2d92 duplicated ort_value index:
001d2dae entry != node_to_subgraph_ss.second.cend()
001d2dd9 onnxruntime::common::Status onnxruntime::PlannerImpl::ComputeValueLocation()
001d2e26 There is no location for this node arg in the outer scope location map
001d2e6d OptimizeReusePlanForMultiStream
001d2e8d \u%04x\u%04x
001d2e9a  is not used by any node.
001d2eb4 Expecting inner index size: 
001d2ed1 Expecting indices to be equal the number of values or be twice as many
001d2f18 Failed to get allocator for location: 
001d2f3f corrupted protobuf data: tensor shape size(
001d2f6b  given file_length: 
001d2f80 tensor can't contain negative dims
001d2fa3 TensorProtoToMLValue
001d2fb8 cur_index == indices_data.end()
001d2fd8 fetch_alloc_info.size() == copy_info.size()
001d3004 Subgraph has nodes running on device: 
001d302b 3D input tensor with shape (batch_size, sequence_length, hidden_size), hidden_size = num_heads * head_size
001d3096 1D beta tensor for layer normalization  with shape (hidden_size)
001d30d7 sum of word_embedding and position_embedding without layer normalization
001d3120 output tensor
001d312e Constrain to integer types.
001d314a Offset of non-padding tokens and paddings. Its shape is (batch_size, sequence_length)
001d31a0 Boolean. Indicates whether upper or lower part of matrix is retained. Default is true.
001d31f7 Input tensor of rank 2 or higher.
001d3219 The id of the token that indicates decoding starts.
001d324d Specify embedding vector of char
001d326e Tensor after padding.
001d3284 InvStdDev
001d328e Score threshold value.
001d32a5 The fourth feature map input tensor.
001d32ca Both attributes isinf_only and isnan_only cannot be set. Unset both to check for both conditions.
001d332c first input tensor has wrong dimension
001d3353 The recurrence weight tensor. Concatenation of `R[iofc]` and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 4*hidden_size, hidden_size]`.
001d3407 /onnxruntime_src/onnxruntime/core/graph/contrib_ops/nhwc_schema_defs.cc
001d344f Whether to use ceil or floor (default) to compute the output shape.
001d3493 Optional 1D bias to be added to the convolution, has size of M.
001d34d3 values
001d34da The timestep for this operation.
001d34fb Scale and Zero-point must be of rank 1
001d3522 Constrain input types to 8 bit signed and unsigned tensors.
001d355e The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.
001d35e0 Constrain seq_lens to integer tensor.
001d3606 Tensor of shape equal to the broadcasted shape of condition, X, and Y
001d364c segment_embedding_zero_point
001d3669 scale_bias
001d3674 Scale tensor for output 'y'. It's a scalar, which means a per-tensor/layer quantization.
001d36cd All inputs to Concat must have same rank
001d36f6 does not have the graph for key 
001d3717 This is an invalid model. Error: two nodes with same node name (
001d3758 Type Error: Type (
001d376b Replacement tensor's dimensions do not match.
001d3799 '. It is not used by any node and should be removed from the model.
001d37dd absl::container_internal::raw_hash_map<>::at
001d380a std::unique_ptr<onnx::OpSchema> onnxruntime::function_utils::CreateSchema(const std::string &, const std::string &, const InlinedHashMap<std::string, const onnx::FunctionProto *> &, const std::unordered_map<std::string, int> &, const onnxruntime::SchemaRegistryManager &, const logging::Logger &, bool)
001d3939 ONNX Runtime only *guarantees* support for models stamped with official released onnx opset versions. Opset 
001d39a6 LoadAttributeOrtFormat
001d39bd bool onnxruntime::graph_utils::RemoveNode(onnxruntime::Graph &, onnxruntime::Node &)
001d3a12 FindPath
001d3a1b ::onnxruntime::TimePoint onnxruntime::profiling::Profiler::Start()
001d3a5e NOT_IMPLEMENTED
001d3a6e !ps_
001d3a73 fstat
001d3a79 nftw_remove
001d3a85 ) has no index values.
001d3a9c op_type
001d3aa4 optional(seq(tensor(int8)))
001d3ac0 map(
001d3ac5 value_string
001d3ad2 Enable broadcasting
001d3ae6 Coefficient of ELU.
001d3afb             X_alpha = Div (X, alpha)
001d3b20             Elu_Result = Elu <alpha = 1.0>(X_alpha)
001d3b54             Y = Mul (alpha, Elu_Result)
001d3b7c         
001d3b85 Constrain input Y types to float/int tensors.
001d3bb3 Tensor of shape [a_1, a_2, ..., a_n, r]
001d3bdb scale of quantized input a
001d3bf7 If necessary the right-hand-side argument will be broadcasted to match the
001d3c42 shape of left-hand-side argument. When broadcasting is specified, the second
001d3c8f tensor can either be of element size 1 (including a scalar tensor and any
001d3cd9 tensor with rank equal to or smaller than the first tensor), or having its
001d3d24 shape as a contiguous subset of the first tensor's shape. The starting of the
001d3d72 mutually equal shape is specified by the argument "axis", and if it is not set,
001d3dc2 suffix matching is assumed. 1-dim expansion doesn't work yet.
001d3e01 For example, the following tensor shapes are supported (with broadcast=1):
001d3e4d   shape(A) = (2, 3, 4, 5), shape(B) = (,), i.e. B is a scalar tensor
001d3e92   shape(A) = (2, 3, 4, 5), shape(B) = (1, 1), i.e. B is an 1-element tensor
001d3ede   shape(A) = (2, 3, 4, 5), shape(B) = (5,)
001d3f09   shape(A) = (2, 3, 4, 5), shape(B) = (4, 5)
001d3f36   shape(A) = (2, 3, 4, 5), shape(B) = (3, 4), with axis=1
001d3f70   shape(A) = (2, 3, 4, 5), shape(B) = (2), with axis=0
001d3fa8 Attribute `broadcast=1` needs to be passed to enable broadcasting.
001d3fec The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. X.shape[1] == (W.shape[1] * group) == C (assuming zero based indices for the shape array). Or in other words FILTER_IN_CHANNEL should be equal to DATA_CHANNEL. 
001d42ca Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1
001d4448 running_var
001d4455           {
001d4461             Lambd = Constant <value_float: float = @lambd>()
001d449e             LambdCast = CastLike (Lambd, input)
001d44ce             Bias = Constant <value_float: float = @bias>()
001d4509             BiasCast = CastLike (Bias, input)
001d4537             Zero = Constant <value = float {0.0}>()
001d456b             ZeroCast = CastLike (Zero, input)
001d4599             NegLmbda = Neg (LambdCast)
001d45c0             InputLessThanNegLambda = Less (input, NegLmbda)
001d45fc             InputAddBias = Add (input, BiasCast)
001d462d             InputSubBias = Sub (input, BiasCast)
001d465e             LambdaLessThanInput = Less (LambdCast, input)
001d4698             InputSubBiasOrZero = Where (LambdaLessThanInput, InputSubBias, ZeroCast)
001d46ed             output = Where(InputLessThanNegLambda, InputAddBias, InputSubBiasOrZero)
001d4742 		      }
001d474c         
001d4755 list of int64s (type: AttributeProto::INTS). This list is parallel to the specified 'pool_*' attribute. The i-th element in ngram_indexes indicate the coordinate of the i-th n-gram in the output tensor.
001d4820 Boolean. Whether the identification of stop words in X is case-sensitive. Default is false
001d487b input must have rank 3.
001d4893 The output tensor of the same shape as `X`.
001d48bf An input tensor with shape [num_batches, num_classes, spatial_dimension]
001d4908 Constrain output type to all tensor or sequence types.
001d493f (line: 
001d4948 Computes an one-layer simple RNN. This operator is usually supported
001d498d via some custom implementation such as CuDNN.
001d49bc Notations:
001d49c8 `X` - input tensor
001d49dc `i` - input gate
001d49ee `t` - time step (t-1 means previous time step)
001d4a1e `Wi` - W parameter weight matrix for input gate
001d4a4f `Ri` - R recurrence weight matrix for input gate
001d4a81 `Wbi` - W parameter bias vector for input gate
001d4ab1 `Rbi` - R parameter bias vector for input gate
001d4ae1 `WBi` - W parameter weight matrix for backward input gate
001d4b1c `RBi` - R recurrence weight matrix for backward input gate
001d4b58 `WBbi` - WR bias vectors for backward input gate
001d4b8a `RBbi` - RR bias vectors for backward input gate
001d4bbc `H` - Hidden state
001d4bd0 `num_directions` - 2 if direction == bidirectional else 1
001d4c0b Activation functions:
001d4c22   Relu(x)                - max(0, x)
001d4c48   Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
001d4c80   Sigmoid(x)             - 1/(1 + e^{-x})
001d4cab   (NOTE: Below are optional)
001d4cc9   Affine(x)              - alpha*x + beta
001d4cf4   LeakyRelu(x)           - x if x >= 0 else alpha * x
001d4d2b   ThresholdedRelu(x)     - x if x >= alpha else 0
001d4d5e   ScaledTanh(x)          - alpha*Tanh(beta*x)
001d4d8d   HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
001d4dc8   Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
001d4e05   Softsign(x)            - x/(1 + |x|)
001d4e2d   Softplus(x)            - log(1 + e^x)
001d4e56 Equations (Default: f=Tanh):
001d4e74   - Ht = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Wbi + Rbi)
001d4ea5 , opset_version = 
001d4eb8  expected to be a sequence type
001d4ed8 Invalid ``body`` argument. Expected a graph
001d4f04 Additional inputs to the graph
001d4f23 Invalid value of attribute 'axis'. Rank=
001d4f4c  expected to have tensor or sparse tensor type. Got: 
001d4f82 1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data). Behavior is undefined if an axis is repeated.
001d5050 Tensor of rank r if axis is specified. Otherwise output is a Tensor of rank 1.
001d509f A N-D input tensor that is to be processed.
001d50cb Invalid dimension value: 
001d50e5 Constrain input and output to only numeric types.
001d5117 Which axis to split on. 
001d5130 Constrain input and output types to all tensor and sequence types.
001d5173 Attribute axes has incorrect length
001d5197 The input must be a tensor of a numeric type. The output will be of the same tensor type.
001d51f1 map_form
001d51fa targets
001d5202 The output type will be a tensor of strings or integers, depending on which of the classlabels_* attributes is used. Its size will match the bactch size of the input.
001d52a9 The kernel type, one of 'LINEAR,' 'POLY,' 'RBF,' 'SIGMOID'.
001d52e5 Input data.
001d52f1 type case unsupported. existing=
001d5312 onnx.StringStringEntryProto
001d532e onnx.SparseTensorProto
001d5345 onnx.TensorShapeProto.Dimension
001d5365 [:^word:]
001d536f should never happen
001d5383 No ranges in char class
001d539b DoCoalesce failed: r2->op() is 
001d53be Cyrillic
001d53c7 Gurmukhi
001d53d0 Ol_Chiki
001d53d9 uarchs_count
001d53e6 failed to allocate %zu bytes for descriptions of %u microarchitectures
001d542d flounder
001d5436 Renesas
001d543e vector
001d5449 reinterpret_cast
001d545c terminating
001d5468 DW_EH_PE_textrel pointer encoding not supported
001d5498 truncated uleb128 expression
001d54b9 OrtStatus *OrtCreateMapMLValue(const onnxruntime::Tensor &, const onnxruntime::Tensor &, OrtValue **) [KeyType = long, ValueType = std::basic_string<char>]
001d5555 Parallel execution mode does not support the DML Execution Provider. 
001d559b So making the execution mode sequential for this session since it uses the DML Execution Provider.
001d55fe IsOptionalTensor(type)
001d5615  OrtAllocatorType:
001d5629 invalid string: control character U+000F (SI) must be escaped to \u000F
001d5671 number overflow parsing '
001d568b true literal
001d5698 false literal
001d56a6 Output buffer is not large enough for ::OrtKernelInfo input name
001d56e7 ::OrtKernelInfo output index is out of bounds
001d5715 CreateCustomRegistry
001d572a SynchronizeOutputs
001d573d An allocator for this device has already been registered for sharing.
001d5783 tensor(complex64)
001d5795 bumped the operator version but 
001d57b6 T *onnxruntime::Tensor::MutableData() [T = float]
001d57e8 XNNPACK
001d57f0 virtual int onnxruntime::standalone::StandAloneKernelContext::NumVariadicInputs(size_t) const
001d584e We do not support 0 size output for now
001d5876 Error in PrepareForExecution, compilation_ is null
001d58a9 SetInputBuffers
001d58b9 ANeuralNetworksModel_free
001d58d3 nnapi error: unable to open both library %s (%s) and library %s (%s)
001d5919 th device
001d5923 ], type [
001d592d TENSOR_FLOAT32
001d593c Input [
001d5944 , the actual input_rank, 
001d595e ], actual scale: 
001d5970 ] is only supported on API >
001d598d /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/concat_op_builder.cc
001d59f0  is not supported
001d5a02 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/relu_op_builder.cc
001d5a63 Input scales or sizes of Resize must be known
001d5a91 activation_params
001d5aa3 [output_datatype]=
001d5ab6 /onnxruntime_src/onnxruntime/core/providers/xnnpack/nn/softmax.cc
001d5af8 Resize operator
001d5b08 round_prefer_ceil
001d5b1a axes should be less than output_dims.size()
001d5b46 MatMulAddFusion
001d5b56 QuickGeluFusion
001d5b6a /onnxruntime_src/onnxruntime/core/optimizer/conv_bn_fusion.cc
001d5ba8 ApplyImpl
001d5bb2 which does not equal the specified override of 
001d5be2 Faild to match path 2 for unidirectional mask
001d5c10 present_k_transpose perm attribute not matched
001d5c3f present_v_unsqueeze axes value not expected
001d5c6b CheckNodesInPathQ
001d5c7d k_matmul and k_add shape not matched
001d5ca2 Output edge count not expected for nodes in path 2 of position shape.
001d5ce8 gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = float]
001d5d2a mul_inputs.size() == 2
001d5d41 /onnxruntime_src/onnxruntime/core/optimizer/selectors_actions/helpers.cc
001d5d8a fused SkipLayerNorm subgraphs 
001d5da9 Existing destination type is not compatible with source type.
001d5de7 com.microsoft.QLinearReduceMean
001d5e07 com.microsoft.QLinearAveragePool
001d5e28 Unsupported ONNX opset
001d5e3f CANNExecutionProvider
001d5e55 virtual onnxruntime::common::Status onnxruntime::Scan<8>::Compute(onnxruntime::OpKernelContext *) const [OpSet = 8]
001d5ec9  Expected 
001d5ed4 ' was 
001d5edb Invalid values in '
001d5eef  did not.
001d5ef9 onnxruntime::common::Status onnxruntime::scan::detail::OutputIterator::AllocateFinalOutput(const onnxruntime::TensorShape &)
001d5f76 If shape was concrete we shouldn't be using a custom allocator
001d5fb5 'Loop' node has 
001d5fc6 onnxruntime::clip_internal::Clip_6Base<float>::Clip_6Base(const onnxruntime::OpKernelInfo &) [T = float]
001d602f void onnxruntime::Clip::ComputeImpl<float>::operator()(const onnxruntime::Tensor *, const onnxruntime::Tensor *, const onnxruntime::Tensor *, onnxruntime::Tensor *) const [T = float]
001d60e6 dims.size() == steps.size()
001d6102 std::unique_ptr<Tensor> onnxruntime::EinsumOp::Transpose(const onnxruntime::Tensor &, const onnxruntime::TensorShape &, const gsl::span<const size_t> &, onnxruntime::AllocatorPtr, void *, const DeviceHelpers::Transpose &)
001d61e0 input_dims[rank - 2] == input_dims[rank - 1]
001d620d left.Shape().Size() == left_shape_override.Size()
001d623f std::unique_ptr<Tensor> onnxruntime::EinsumTypedComputeProcessor<int>::PairwiseOperandProcess(const onnxruntime::Tensor &, const onnxruntime::TensorShape &, const onnxruntime::Tensor &, const onnxruntime::TensorShape &, const gsl::span<const int64_t> &, bool) [T = int]
001d634d  by 
001d6352 Hardmax inputs N, D and N * D must be < 
001d637b . N=
001d6380 Input data with index: 
001d6398 Invalid CAST_TO value of 
001d63b2 const T *onnxruntime::OpKernelContext::Input(int) const [T = std::map<long, std::basic_string<char>>]
001d6418 onnxruntime::common::Status onnxruntime::ml::CastMap::ComputeImpl(onnxruntime::OpKernelContext &, TTo) const [TFrom = float, TTo = long]
001d64a1 onnxruntime::common::Status onnxruntime::ml::CastMap::ComputeImpl(onnxruntime::OpKernelContext &, TTo) const [TFrom = float, TTo = std::basic_string<char>]
001d653d values_floats
001d654b onnxruntime::ml::LabelEncoder::LabelEncoder(const onnxruntime::OpKernelInfo &)
001d659a !coefficients_.empty()
001d65b1 coefficients_.size() > 0
001d65ca nodes_falsenodeids
001d65dd  (falsenode).
001d65eb Unknown aggregation function in TreeEnsemble.
001d6619 ' is specified but is empty.
001d6636 classlabels_strings_.empty() ^ classlabels_int64s_.empty()
001d6671 T *OrtValue::GetMutable() [T = std::vector<std::map<std::basic_string<char>, float>>]
001d66c7 Input channels C is not equal to kernel channels * group.
001d6701  num_input_channels: 
001d6717 !mask || mask->Shape() == X_shape
001d6739 virtual onnxruntime::common::Status onnxruntime::Dropout<float, double>::Compute(onnxruntime::OpKernelContext *) const [T1 = float, T2 = double]
001d67ca Invalid input B: number of dimensions is not 1: 
001d67fb onnxruntime::LpNorm<double>::LpNorm(const onnxruntime::OpKernelInfo &) [T = double]
001d684f virtual onnxruntime::common::Status onnxruntime::LRN<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
001d68c6 Required min_gram_length must be positive: 
001d68f2 status.IsOK() && !pool_int64s.empty()
001d6918 The TypeProto attribute in the Optional op 
001d6944 Must be a scalar or 1D tensor or size 1.
001d696d QLinearConv : input scale must be a scalar or 1D tensor of size 1
001d69af zero_point_ptr == nullptr || (zero_point_ptr->Shape().NumDimensions() == 1 && zero_point_ptr->Shape()[0] == broadcast_dim)
001d6a2a virtual onnxruntime::common::Status onnxruntime::QLinearMatMul::Compute(onnxruntime::OpKernelContext *) const
001d6a98 /onnxruntime_src/onnxruntime/core/providers/cpu/rnn/rnn_helpers.h
001d6ada SequenceEmpty
001d6ae8 onnxruntime::common::Status onnxruntime::CreateMelWeightMatrix<double>::operator()(onnxruntime::OpKernelContext *, int64_t, int64_t, int64_t, float, float) [T = double]
001d6b91 Cannot concatenate scalars
001d6bac src and dst types must match
001d6bc9 void onnxruntime::StridedCopy(concurrency::ThreadPool *, T *, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShape &, const T *, const onnxruntime::TensorShapeVector &) [T = unsigned int]
001d6c97 indices tensor must has rank larger than 0
001d6cc2 onnxruntime::common::Status onnxruntime::PadImpl(onnxruntime::OpKernelContext *, const onnxruntime::PadsVector &, const onnxruntime::PadsVector &, const onnxruntime::Mode &, T) [T = unsigned long]
001d6d87 gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = bool]
001d6dcd gsl::span<T> onnxruntime::Tensor::MutableDataAsSpan() [T = unsigned int]
001d6e16 CPU execution provider: MLFloat16 data type is not supported with ScatterElements opset 16 when reduction is 'mul'.
001d6e8a CPU execution provider: bool data type is not supported with ScatterElements opset 18 when reduction is 'min'.
001d6ef9 Unexpected element size of 
001d6f15 SpaceToDepth requires input width to be a multiple of block_size
001d6f56 Input cannot be split evenly on selected axis. Input shape=
001d6f92 static onnxruntime::TensorShapeVector onnxruntime::SqueezeBase::ComputeOutputShape(const onnxruntime::TensorShape &, const onnxruntime::TensorShapeVector &)
001d702f Dimension of input 
001d7043 . shape=
001d704c Hidden size of Q, K and V shall be same
001d7074 when past_present_share_buffer, past tensor sequence must not smaller than total_sequqnce_length 
001d70d6 Expect to have present state output when past state input is given
001d7119 word_embedding and segment_embedding shall have same dimension 1
001d715d input_ids_dims.size() == 2
001d7178 info.GetAttr<int64_t>("min_ngram_size", &min_ngram_size_).IsOK()
001d71b9 ) + scale_[1] (
001d71c9 Wrong input type encountered for zero point input def of x, y, z
001d720a QGemm : zero point of input a must be a scalar or 1D tensor of size 1
001d7250 y_scale == nullptr || IsScalarOr1ElementVector(y_scale)
001d7288 Tokenizer
001d7292 attribute pad_value is not set
001d72b1 decoder subgraph input 0 shall be named as input_ids, got: 
001d72ed encoder subgraph input 0 shall be named as encoder_input_ids, got: 
001d7331  conv filter size: 
001d7345  memory limit: 
001d7355 Creating 
001d735f Reserving memory in BFCArena for 
001d7381 .  Current allocation summary follows.
001d73a8 Could not find chunk in bin
001d73c4 BFCArena::ChunkHandle onnxruntime::BFCArena::Coalesce(onnxruntime::BFCArena::ChunkHandle)
001d741e NumArenaShrinkages:       
001d7439 float
001d743f uint64
001d7446 onnxruntime::utils::ContainerChecker::ContainerChecker(onnxruntime::MLDataType)
001d7496 onnxruntime::common::Status onnxruntime::ExecutionFrame::AllocateMLValueTensorPreAllocateBuffer(OrtValue &, int, onnxruntime::MLDataType, const OrtMemoryInfo &, const onnxruntime::TensorShape &, bool)
001d755f Node '
001d7566 /onnxruntime_src/onnxruntime/core/framework/fuse_nodes_funcs.cc
001d75a9 LoadKernelTypeStrResolverFromBuffer
001d75cd auto onnxruntime::NodeIndexInfo::Init(const onnxruntime::ConstGraphNodes &, onnxruntime::NodeIndex, const onnxruntime::OrtValueNameIdxMap &)::(anonymous class)::operator()(const onnxruntime::NodeArg &, bool) const
001d76a3 virtual int onnxruntime::OpKernelContext::NumVariadicInputs(size_t) const
001d76ed /onnxruntime_src/onnxruntime/core/framework/ort_value_tensor_slicer.cc
001d7734 onnxruntime::common::Status onnxruntime::SessionOptions::AddExternalInitializers(gsl::span<const std::string>, gsl::span<const OrtValue>)
001d77be . Ignoring allocator from 
001d77d9 SaveMLValueNameIndexMapping
001d77f5 existing_entries.find(attribute_name) == existing_entries.cend()
001d7836 ],"subtype":
001d7843 Launch kernel with node id: 
001d7860 Graph
001d7866 std::vector<int64_t> onnxruntime::SparseTensor::GetCooIndexDims(size_t, size_t) const
001d78bc format_data_.size() == 2U
001d78d6 SparseTensor::CsrMutator onnxruntime::SparseTensor::MakeCsrData(size_t, size_t, size_t)
001d792e Expecting one index. Got: 
001d7949 CopyData
001d7952  is not found
001d7960  can not be writen into Tensor type 
001d7985 nullptr == p_data
001d7997 copy_info.size() == num_feeds
001d79b5 Inputs 0 (query) shall be 3 dimensions
001d79dc global_bias
001d79e8 Constrain input and output integer tensors types
001d7a19 mean
001d7a1e pred_tokens
001d7a2a suffix_match_idx
001d7a3b tensor with shape (1, num_head, seq_len, seq_len)
001d7a6d The id of the end-of-sequence token
001d7a91 Decoder subgraph to execute in a loop.
001d7ab8 Input tensor C. The shape of C should be unidirectional broadcastable to (M, N).
001d7b09 Whether B should be transposed
001d7b28 Matrix multiply results
001d7b40 Integer representing the embedding vector size for each char.If not provide, use the char embedding size of embedding vector.
001d7bbe metric
001d7bc5 RoI pooled output, 4-D tensor of shape (num_rois, C, crop_height, crop_width). The r-th batch element Y[r-1] is a pooled feature map corresponding to the r-th RoI X[r-1].
001d7c70 Output data tensor.
001d7c84 The num_detections output tensor.
001d7ca6 detection_classes
001d7cb8 Background class ID.
001d7ccd factor
001d7cd4 batch_indices shape input tensor has wrong dimension
001d7d09 Constrain seq_lens to integral tensors.
001d7d31 initial_c
001d7d3b /onnxruntime_src/onnxruntime/core/graph/contrib_ops/diffusion_defs.cc
001d7d81 Scale of quantized input 'X'. It must be a scalar.
001d7db4 Whether include pad pixels when calculating values for the edges. Default is 0, doesn't count include pad.
001d7e1f dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis.
001d7e99 Value of alpha
001d7ea8 1-D tensor of starting indices of corresponding axis in `axes`
001d7ee7 drop_states
001d7ef3 gates
001d7ef9 Attribute 
001d7f04 Zero point for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
001d7fec The datatype to dequantize to.
001d800b b_zero_point
001d8018 Constrain scale types to float tensors.
001d8040 weight_zero_point
001d8052 Constrain to float types
001d806b scale_Y
001d8073 QOrderedAttention
001d8085 void onnxruntime::Graph::AddEdge(onnxruntime::NodeIndex, onnxruntime::NodeIndex, int, int)
001d80e0 Node (
001d80e7 This is an invalid model. Model input (
001d810f InitInputsInitializersOutputs
001d812d Failed to convert dense initializer to sparse
001d815b 'was added but does not exist. 
001d817b ], could not find NodeArg 
001d8196 ) Op (
001d819d TAggregatedTypes
001d81b1 SaveAttributeOrtFormat: Unsupported attribute type: 
001d81e6 Missing indicies for sparse initializer: 
001d8210 UNDEFINED
001d821a STRING
001d8221 TENSORS
001d8229 Missing model IR version.
001d8243 Model
001d8249 std::all_of(processor_interval[0].begin(), processor_interval[0].end(), ::isdigit) && std::all_of(processor_interval[1].begin(), processor_interval[1].end(), ::isdigit)
001d82f2 processor_id > 0
001d8303 Failed to parse path root: 
001d831f WaitRevoke
001d832a ) is stored externally but doesn't have a location.
001d835e ' has been used as output names multiple times.
001d838e optional(seq(tensor(int32)))
001d83ab seq(
001d83b0 Attribute 'value_ints' expect a list of integers.
001d83e2 Attribute 'value' of Constant node must exist with 'Tensor' data.
001d8424 First input operand for the bitwise operator.
001d8452 The sign of the input tensor computed element-wise. It has the same shape and type of the input.
001d84b4       const_zero_target_typed = Sub (expanded_target, expanded_target)
001d84fb       expanded_target_int64 = Cast <to = 7> (expanded_target)
001d8539       mask = Equal (expanded_target_int64, const_ignore_index)
001d8578       transform_targets = Where (mask, const_zero_target_typed, expanded_target)
001d85c9     
001d85ce input_gather_element = GatherElements <axis = 1> (input, transform_targets)
001d861a const_one_casted = Cast (const_one_float)
001d8644 num_mel_bins
001d8652                     X_Sub = Sub (input, X_ReduceMax)
001d8687                     X_Exp = Exp (X_Sub)
001d86af                     X_ReduceSum = ReduceSum <keepdims = 1> (X_Exp, axes)
001d86f8                     X_Log = Log (X_ReduceSum)
001d8726                     output = Sub (X_Sub, X_Log)
001d8756                 
001d8767 dft_length input must be scalar.
001d8788 Coefficient of SELU default to 1.0507.
001d87af Input tensor B
001d87be Scalar multiplier for input tensor C, the default value is 1.0.
001d87fe Dimension on which to do the sort.
001d8821 The shape of the spatial dimensions of the image after rearranging the column blocks.This is a 1-dimensional tensor with size of at least 2, containing the value [H_img, W_img]  for a 2-D image or [dim_i1, dim_i2, ..., dim_iN] for a N-D image.
001d8915 Type of Mean and InvStdDev. This also specifies stage one's computation precision.
001d8968 Input data tensor. Dimensions for image cases are `(N x C x H x W)`, where `N` is the batch size, `C` is the number of channels, and `H` and `W` are the height and width of the data. Statistics are computed for every group of channels over `C`, `H`, and `W`. For non-image cases, the dimensions are in the form of `(N x C x D1 x D2 ... Dn)`.
001d8abe X3D = Reshape(XReshaped, Shape3D)
001d8ae0 The epsilon value to use to avoid division by zero, default is 1e-5f.
001d8b26 Unhandled type: %d
001d8b39 Error context: 
001d8b49  column: 
001d8b53 ir_version
001d8b5e Constrain 'y_zero_point' and 'y' to 8-bit unsigned integer tensor.
001d8ba6     data_square = Mul(data, data)
001d8bc8     sum_square = ReduceSum<keepdims: int = @keepdims>(data_square, axes)
001d8c11     sum_square_dbl = Cast <to = 1>(sum_square)
001d8c40     sqrt = Sqrt(sum_square_dbl)
001d8c60     reduced = CastLike(sqrt, data)
001d8c8a The axis in which to compute the arg indices. Accepted range is [-r, r-1] where r = rank(data).
001d8cea The weight tensor for the gates. Concatenation of `W[zrh]` and `WB[zrh]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 3*hidden_size, input_size]`.
001d8d9e Output sequence that has the tensor at the specified position removed.
001d8de5 Expected a sequence type for input 0
001d8e0a _cond_in
001d8e13 Attribute dtype should be of integer type and specify a type.
001d8e51 Input element type of 
001d8e68 Reshaped tensor with same data as input.
001d8e91 The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X' or the length of 'axes', if provided. One of 'scales' and 'sizes' MUST be specified and it is an error if both are specified. If 'sizes' is needed, the user can use an empty string as the name of 'scales' in this operator's input list.
001d9056 (Optional) Whether to sort the unique elements in ascending order before returning as output. Must be one of 0, or 1 (default).
001d90d6 Invalid attribute perm {
001d90ef  values.
001d90f8 x_shape = Gather (x_shape_alldims, axes_input)
001d9127 pad_amount_left = Div(pad_amount, k2)
001d914d The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'.
001d9227 One float, indicates the value to be filled.
001d9254 Number of elements of input 'sizes' (
001d927a  does not match the actual size
001d929a The input must be a tensor of a numeric type or string. The output will be of the same tensor type.
001d92fe cast_to
001d9306 The size of each input in the input list
001d932f A list of ints.
001d933f prob_a
001d9346 The number of graph input cannot be smaller than the number of node input
001d9390 string length exceeds max size
001d93af startpos: 
001d93ba /build/intermediates/arm64-v8a/Release/_deps/re2-src/re2/parse.cc
001d93ff NumCapturesWalker::ShortVisit called
001d9428 (?:)
001d942d Hebrew
001d9436 Syloti_Nagri
001d9443 MStar
001d944d ro.mediatek.platform
001d9462 ro.arch
001d946a failed to read file %s: insufficient buffer of size %zu
001d94aa basic_string
001d94b7 operator 
001d94c1 void
001d94c6 decimal128
001d94d1 libunwind: malformed DW_CFA_restore_extended DWARF unwind, reg too big
001d9519 getTableEntrySize
001d953c onnxruntime_profile_
001d9551 Sequence is missing type entry for its element
001d9580 session.set_denormal_as_zero
001d959d result
001d95a4 LoadWithLoader
001d95b3 Unknown exception
001d95c5 model_loading_uri
001d95d7 session.use_ort_model_bytes_for_initializers
001d9604 GetModelInputs
001d9613 AddPredefinedTransformers
001d962d onnxruntime::MLDataType onnxruntime::utils::GetElementTypeFromOptionalSeqTensor(onnxruntime::MLDataType)
001d9696 r+be
001d969b execution_mode option in the model file must be an integer
001d96d6 [json.exception.
001d96e7 , column 
001d96f1 com.microsoft.nchwc
001d9705 OrtSessionOptionsAppendExecutionProvider_Cuda: Failed to load shared library
001d9752 output_ptr
001d975d T *onnxruntime::Tensor::MutableData() [T = onnxruntime::MLFloat16]
001d97a0 NnapiExecutionProvider
001d97b7 InlinedVector<std::string_view> onnxruntime::utils::SplitString(std::string_view, std::string_view, bool)
001d9821 ] Operator type: [
001d9834 Model::AddOutput output name 
001d9852 PrepareForExecution
001d9866 ret == ANEURALNETWORKS_NO_ERROR
001d9886 ANeuralNetworks_getDeviceCount
001d98a5 ANeuralNetworksCompilation_createForDevices
001d98d1 ANeuralNetworksCompilation_setCaching
001d98f7 SL_ANeuralNetworksDiagnosticExecutionInfo_getDriverExecutionTimeNanos
001d993d Softmax
001d9945 NodeArg [
001d994f ] type: [
001d9959 Unsqueeze
001d9963 nnapi-reference
001d9973 GetTargetDevices
001d9984 RegisterInitializers
001d9999 The input/initializer of graph has unsupported quantized type, name: 
001d99df gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = signed char]
001d9a2c HasSupportedInputOutputsImpl
001d9a49 steps
001d9a4f SAME_LOWER
001d9a5a bias of QDQGemm should be int32, actual type: 
001d9a89 op_type == "QLinearSigmoid"
001d9aa5 pads
001d9aaa [filter_datatype]=
001d9abd InferPadsAndOutputShape
001d9ad9  and outer dimension 
001d9aef invalid dtype of zero point, expected uint8|int8, but got onnx dtype 
001d9b35 UpsampleBase
001d9b42 keep_aspect_ratio of [
001d9b59 Cannot scale 0 by any factor to generate a non-zero value. 
001d9b95 MatMul dimension mismatch
001d9bb2 QDQPropagationTransformer
001d9bcc _sum_transformed
001d9bdd bn_var_tensor_proto
001d9bf1 onnxruntime::Node *onnxruntime::NodesToOptimize::GetNode(size_t, bool) const
001d9c3e /onnxruntime_src/onnxruntime/core/optimizer/gemm_activation_fusion.cc
001d9c84 fused 
001d9c8b ParametricSoftplus
001d9c9e Gemm bias shape is not expected
001d9cbe Failed to match position embedding subgraph.
001d9ceb  and 
001d9cf1 BitmaskDropout
001d9d00 !model_path.IsEmpty()
001d9d16 onnxruntime::Initializer &onnxruntime::Initializer::div(const onnxruntime::Initializer &)
001d9d70 scalers.size() == 1 || scalers.size() == num_blocks
001d9da4 called_ == 1
001d9db1 div_inputs.size() == 2
001d9dc8 void onnxruntime::utils::mltype_dispatcher_internal::UnsupportedTypeDefaultPolicy<onnxruntime::common::Status>::operator()(int32_t, Ret &) const [Ret = onnxruntime::common::Status]
001d9e7d /onnxruntime_src/onnxruntime/core/optimizer/nhwc_transformer.cc
001d9ebd const onnxruntime::Node *onnxruntime::graph_utils::ExtendedGraphEdge::GetNodeAtEnd(const onnxruntime::Graph &, onnxruntime::graph_utils::ExtendedGraphEdge::End) const
001d9f64 __backwardpass
001d9f73 Node index value is too large to save to ORT format model: 
001d9faf  to have different number of elements
001d9fd5 IsNaN
001d9fdb Sign
001d9fe0 OpenVINOExecutionProvider
001d9ffa 'is defined.
001da007 AllocateOutputTensors
001da01d Execute
001da025 The subgraph in 'body' requires 
001da046 Mismatch between expected shape and shape from first output
001da082 All scan outputs MUST be tensors
001da0a3 ONNX_NAMESPACE::TensorProto::DataType_IsValid(dtype_) && dtype_ != ONNX_NAMESPACE::TensorProto::UNDEFINED
001da10d min_ <= max_
001da11a onnxruntime::common::Status onnxruntime::EinsumComputePreprocessor::PostProcessBroadcastedDims()
001da17b Output subscript contains repeated letters
001da1a6  Right shape override: 
001da1be cur1 == end1
001da1cb c_shape != nullptr
001da1de /onnxruntime_src/onnxruntime/core/providers/cpu/math/softmax.cc
001da21e onnxruntime::common::Status onnxruntime::ml::CastMap::ComputeImpl(onnxruntime::OpKernelContext &, TTo) const [TFrom = std::basic_string<char>, TTo = long]
001da2b9 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/dictvectorizer.h
001da2fd classlabels_strings
001da311 Scores output is incorrect size. Expected:
001da33c Unexpected value for 'add_second_class' of 
001da368 Normalizer
001da377 ) or 1
001da382  (weights).
001da38e onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommon<double, double, float>::Init(int, int, int, const std::string &, const std::vector<float> &, const std::vector<ThresholdType> &, int64_t, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<float> &, const std::vector<ThresholdType> &, const std::vector<int64_t> &, const std::vector<std::string> &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<float> &, const std::vector<ThresholdType> &, const std::string &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<int64_t> &, const std::vector<float> &, const std::vector<ThresholdType> &) [InputType = double, ThresholdType = double, OutputType = float]
001da6a6 void onnxruntime::ml::detail::TreeEnsembleCommon<long, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = long, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorMin<long, float, float>]
001da7f4 void onnxruntime::ml::detail::TreeAggregatorSum<int, float, float>::ProcessTreeNodePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const TreeNodeElement<ThresholdType> &) const [InputType = int, ThresholdType = float, OutputType = float]
001da8e9 virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommonClassifier<int, float, float>::compute(onnxruntime::OpKernelContext *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *) const [InputType = int, ThresholdType = float, OutputType = float]
001daa0d /onnxruntime_src/onnxruntime/core/providers/cpu/ml/tree_ensemble_helper.cc
001daa58 onnxruntime::common::Status onnxruntime::ml::GetNumberOfElementsAttrsOrDefault(const onnxruntime::OpKernelInfo &, const std::string &, onnx::TensorProto_DataType, size_t &, onnx::TensorProto &)
001dab1a (std::is_same<double, TH>::value)
001dab3c onnxruntime::ml::TreeEnsembleRegressor<float>::TreeEnsembleRegressor(const onnxruntime::OpKernelInfo &) [T = float]
001dabb0 ] != number of classlabels[
001dabcc ratio must be in the range [0, 1)
001dabee onnxruntime::InstanceNorm<float>::InstanceNorm(const onnxruntime::OpKernelInfo &) [T = float]
001dac4c Unsupported pooling size : 
001dac68 Single dimension value must be greater than 0
001dac96 ngram_counts
001daca3  but ngram_indexes size: 
001dacbd /onnxruntime_src/onnxruntime/core/providers/cpu/object_detection/non_max_suppression.cc
001dad15 0 == center_point_box_ || 1 == center_point_box_
001dad46 static std::vector<float> onnxruntime::QLinearConv<unsigned char>::ComputeOutputScale(onnxruntime::OpKernelContext *, int64_t) [ActType = unsigned char]
001daddf DequantizeLinear with type int32 should have no zero point or all zero points should be 0
001dae39 fast_shape.size() == 2
001dae50 onnxruntime::ReduceKernelBase<true>::ReduceKernelBase(const onnxruntime::OpKernelInfo &, optional<int64_t>) [allow_multi_axes = true]
001daed6 void onnxruntime::rnn::detail::ComputeGemm(const int, const int, const int, const float, TSpanAIter, TSpanAIter, const int, TSpanBIter, TSpanBIter, const int, const float, TSpanCIter, TSpanCIter, const int, concurrency::ThreadPool *) [TSpanAIter = gsl::details::span_iterator<float>, TSpanBIter = gsl::details::span_iterator<const float>, TSpanCIter = gsl::details::span_iterator<float>]
001db05a Affine
001db061 If both frame_length and window are set, then the size of the window must be equal to the frame_length.
001db0c9 lowest_index >= 0 && lowest_index < num_spectrogram_bins
001db102 void onnxruntime::StridedCopy(concurrency::ThreadPool *, T *, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShape &, const T *, const onnxruntime::TensorShapeVector &) [T = unsigned short]
001db1d2 GatherElements op: Cannot operate on scalar input
001db204 GatherElements op: Data type of input 'data' should match the data type of the output
001db25a Divide by zero
001db269 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/grid_sample.cc
001db2af onnxruntime::IsInf::IsInf(const onnxruntime::OpKernelInfo &)
001db2ec virtual onnxruntime::common::Status onnxruntime::NonZero<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
001db367 info.GetAttr<int64_t>("time_axis", &time_axis).IsOK()
001db39d input tensor and indices tensor must has rank larger than 0. 
001db3db  Input shape=
001db3e9 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/squeeze.h
001db42a bool onnxruntime::TypedDoTransposeEltWise(int64_t, gsl::span<const int64_t>, size_t, const gsl::span<const size_t> &, const uint8_t *, uint8_t *) [T = unsigned long]
001db4d0 mask_filter_value
001db4e2 Input 'weights' is expected to have 2 dimensions, got 
001db519 Input 'past' is expected to have 5 dimension, got 
001db54c Attention memory layer weight shape error! Expected:{
001db582 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::ScaledTanh<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::ScaledTanh<float>]
001db651 across_channels
001db661 virtual onnxruntime::common::Status onnxruntime::contrib::ReorderOutput::Compute(onnxruntime::OpKernelContext *) const
001db6d8 virtual onnxruntime::common::Status onnxruntime::contrib::NchwcUpsample::Compute(onnxruntime::OpKernelContext *) const
001db74f scales_.size() == 4
001db763 } for per-channel quantization. Actual:
001db78b DynamicQuantizeLSTM
001db79f Input scale is not float for quantized input y @ 5
001db7d2 IsScalarOr1ElementVector(a_zp)
001db7f1 /onnxruntime_src/onnxruntime/contrib_ops/cpu/skip_layer_norm.cc
001db831 input is expected to have 3 dimensions, got 
001db85e Last dimension of beta and input does not match
001db88e onnxruntime::contrib::SkipLayerNorm<double>::SkipLayerNorm(const onnxruntime::OpKernelInfo &) [T = double]
001db8f9 mincharnum_ > 0
001db909 Input dimensions are either [C] or [N][C] allowed
001db93b init_run_gpt_subgraph_ == nullptr
001db95d decoder_start_token_id
001db974 GreedySearch
001db981 parameters_.model_type == IGenerationParameters::kModelTypeGpt
001db9c0 subgraph past state dimension 4 shall have a positive value for hidden size per head
001dba15 Reserve
001dba1d Could not find Region for 
001dba38   Size: 
001dba41 data_transfer registered is nullptr.
001dba66 bool onnxruntime::data_types_internal::IsCompatible(const onnx::TypeProto &, const onnx::TypeProto &)
001dbacc void onnxruntime::data_types_internal::DataTypeRegistry::RegisterDataType(onnxruntime::MLDataType)
001dbb2f node_index_info_.GetMaxMLValueIdx() == ort_value_idx_map.MaxIdx()
001dbb71 Tensor shape cannot contain any negative value
001dbba0 For ort_value with index: 
001dbbbb Shape mismatch attempting to re-use buffer. 
001dbbe8  node_version: 
001dbbf8  (node 
001dbc00 kernel_type_str_args is null.
001dbc1e /onnxruntime_src/onnxruntime/core/framework/node_index_info.cc
001dbc5d virtual OrtValue *onnxruntime::OpKernelContext::GetOrCreateOutputMLValue(int)
001dbcab CreateKernels
001dbcb9 void onnxruntime::SessionState::AddSubgraphSessionState(onnxruntime::NodeIndex, const std::string &, std::unique_ptr<SessionState>)
001dbd3d  for attribute 
001dbd4d type
001dbd52 void onnxruntime::PlannerImpl::ProcessDef(onnxruntime::OrtValueIndex, const onnxruntime::NodeArg *)
001dbdb6 void onnxruntime::PlannerImpl::GeneratePlanForWeightsHelper(const onnxruntime::GraphViewer &, const onnxruntime::InitializedTensorSet &, const onnxruntime::KernelCreateInfoMap &, const std::string &, size_t, std::vector<std::vector<OrtMemoryInfo>> &)
001dbeb1 activation_size
001dbec1 /onnxruntime_src/onnxruntime/core/framework/session_state_utils.cc
001dbf04 Deserialize tensor 
001dbf18 Subgraph
001dbf21 DeserializeTensorProto() takes either pre-allocated buffer or an allocator!
001dbf6d ExtDataTensorProtoToTensor
001dbf88 Expecting to have at lest 3-D shape. Got:
001dbfb2 This instance should not be empty
001dbfd4 Unsupported element size: 
001dbfef onnxruntime::common::Status onnxruntime::sparse_utils::SparseCsrToDenseTensor(const onnxruntime::DataTransferManager &, const onnxruntime::SparseTensor &, const onnxruntime::AllocatorPtr &, const onnxruntime::AllocatorPtr &, onnxruntime::Tensor &)
001dc0e7 Tensor is expected to contain one of the primitive data types. Got: 
001dc12c dimstart <= dimend && dimend <= values_.size()
001dc15b the ort_value must contain a constructed tensor or sparse tensor
001dc19c /onnxruntime_src/onnxruntime/core/framework/tensor_type_and_shape.cc
001dc1e1 GetFileLength for 
001dc1f4 External initializer: 
001dc20b string tensor can not have raw data
001dc22f indices_shape[1] > 0 && static_cast<size_t>(indices_shape[1]) == dims.size()
001dc27c allocator != nullptr
001dc291 Corresponding past and present are same tensor, its size is (2, batch_size, num_heads, max_sequence_length, head_size)
001dc308 If use_past = true, use cache; else no cache
001dc335 The maximum NGram size for suffix matching.
001dc361 Max sequence length without padding. Its shape is (1)
001dc397  expected to have tensor or sparse type
001dc3bf X_bias = Identity (X)
001dc3d5 Output tensor of the same type as the input tensor. Shape of the output is * x M, where '*' is the shape of input indices, and 'M' is the embedding size.
001dc46f Input tensors to check.
001dc487 Minimum number of characters allowed in the output. For example, if mincharnum is 2, tokens such as "A" and "B" would be ignored
001dc508 Constrain to tensor(int32).
001dc524 plugin_version
001dc533 c2p_attention
001dc541 inputs are expected to have tensor type and output type should not be null.
001dc58d Attribute 'pooled_size' must be >= 1.
001dc5b3 tensor rank too small
001dc5c9 Scaling value
001dc5d7 Scale and Zero-point must be of rank 1 and the number of elements should be equal to the number of rows of the corresponding input.
001dc65b N-D quantized output tensor. It has same shape as input 'x'.
001dc698 MulInteger
001dc6a3 1D input tensor, whose dimension is same as B's last dimension
001dc6e2 a_zero_point
001dc6ef A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. 
001dc77e Z's scale.
001dc789 Zero point for position embeddings
001dc7ac Constrain scales to float32 tensors.
001dc7d1 cublasLt order of input X. Optional. See the schema of QuantizeWithOrder for order definition.
001dc830 scale of the output Y
001dc846 Result, has same element type as two inputs
001dc872  Dimension=
001dc87e Serialization error. Graph attribute was serialized without Graph instance
001dc8c9  is not the same as this node's index:
001dc8f0 ' Model is invalid.
001dc904 This is an invalid model. Graph output (
001dc92d ) is invalid.
001dc93b Error: Duplicate definition-site for (
001dc962 PerformTypeAndShapeInferencing
001dc981 Resolve
001dc989 bool onnxruntime::Graph::RemoveNode(onnxruntime::NodeIndex)
001dc9c5 callnode.TryGetFunctionProto(inlined_fp)
001dc9ee LoadNodeArgsFromOrtFormat: Node [
001dca10 const onnxruntime::ConstPointerContainer::T *onnxruntime::ConstPointerContainer<std::vector<onnxruntime::NodeArg *>>::at(size_t) const [Container = std::vector<onnxruntime::NodeArg *>]
001dcac9 Null string attribute. Invalid ORT format model.
001dcafa num_explicit_inputs == static_cast<size_t>(target_input_idx)
001dcb37  cannot be safely updated to 
001dcb55 Failed to init pytorch cpuinfo library, may cause CPU EP performance degradation due to undetected CPU features.
001dcbc6 static onnxruntime::Path onnxruntime::Path::Parse(const onnxruntime::PathString &)
001dcc1d FAIL
001dcc22 ReadFileIntoBuffer
001dcc35 We do not support type [
001dcc4e LoadTypeInfoOrtFormat
001dcc64 ) is stored externally and should not have data field.
001dcc9b , but it doesn't exist or is not accessible.
001dccc8 ] out of range [0, 
001dccdc ) should refer to attribute in parent node.
001dcd08 No Op registered for 
001dcd1e cond
001dcd23 The initial values of any loop-carried dependencies (values that change across loop iterations)
001dcd83 Final N loop carried dependency values then K scan_outputs. Scan outputs must be Tensors.
001dcddd Final values of the loop's N state variables followed by K scan_outputs
001dce25 optional(tensor(float16))
001dce3f Loop 'body' subgraph outputs should all be tensors but output 
001dce7e Invalid tensor data type 
001dce99           {
001dcea5             sub_result = Sub (limit, start)
001dced1             sub_result_casted = Cast <to = 1> (sub_result)
001dcf0c             delta_casted = Cast <to = 1> (delta)
001dcf3d             div_result = Div (sub_result_casted, delta_casted)
001dcf7c             ceil_result = Ceil (div_result)
001dcfa8             ceil_result_relu = Relu (ceil_result)
001dcfda             ceil_result_relu_int = Cast <to = 7> (ceil_result_relu)
001dd01e             ceil_result_relu_bool = Cast <to = 9> (ceil_result_relu)
001dd063             variadic_output, output = Loop (ceil_result_relu_int, ceil_result_relu_bool, start)
001dd0c3               <body = loop_body_attribute (int64 i, bool cond, prev) => (cond_out, current, range) {
001dd128                 cond_out = Identity (cond)
001dd153                 current = Add (prev, delta)
001dd17f                 range = Identity (prev)
001dd1a7               }>
001dd1b8           }
001dd1c4         
001dd1cd Bernoulli
001dd1d7 Attribute 'value_float' expect a float.
001dd1ff Coefficient of SELU default to 1.67326319217681884765625 (i.e., float32 approximation of 1.6732632423543772848170429916717).
001dd27c slope
001dd282 Hardmax(element in input, axis) = 1 if the element is the first maximum value along the specified axis, 0 otherwise
001dd2f6 The hyperbolic sine values of the input tensor computed element-wise
001dd33b If set to 1 will return exclusive sum in which the top element is not included. In other terms, if set to 1, the j-th output element would be the sum of the first (j-1) elements. Otherwise, it would be the sum of the first j elements.
001dd426 input_gather_element_transform = Where (mask, const_zero_float, input_gather_element)
001dd47c Type of reduction to apply to loss: none, sum, mean (default). 'none': the output is the loss for each sample. 'sum': the output will be summed. 'mean': the sum of the output will be divided by the sum of applied weights.
001dd55a The axis on which to perform the DFT. By default this value is set to 1, which corresponds to the first dimension after the batch index.
001dd5e3 Constrain scalar length types to int64_t.
001dd60d frame_step
001dd618 Wrong op_type name for running propagation: 
001dd645 K input must be a one-dimensional tensor of size 1.
001dd679 periodic
001dd682 expanded_target
001dd692 Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum).
001dd70f UTF-8 strings to normalize
001dd72a Output tensor produced by rearranging blocks into an image.
001dd766 Mean2D = ReduceMean (XU, Axes_1)
001dd787 EX_squared
001dd792 E_Xsquared
001dd79d The scale as a 1-dimensional tensor of size C to be applied to the output.
001dd7e8 selected_indices
001dd7f9 The optional input.
001dd80d type_protos
001dd819 Constrain 'x' to float tensor.
001dd838 The weight tensor for input gate. Concatenation of `Wi` and `WBi` (if bidirectional). The tensor has shape `[num_directions, hidden_size, input_size]`.
001dd8d0 Constrain output types to any tensor type.
001dd8fb Key type of map input 
001dd912 target optional type missing element type.
001dd93d shape input must be 1D tensor
001dd95b If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0.
001dda03 (Optional) Whether map positive infinity to true. Default to 1 so that positive infinity induces true. Set this attribute to 0 if positive infinity should be mapped to false.
001ddab2 A tensor of the same type as 'X' containing all the unique values or subtensors sliced along a provided 'axis' in 'X', either sorted or maintained in the same order they occur in input 'X'
001ddb6f end_dims = Add (start_dims, shape)
001ddb92 output_data = Slice (padded_input, start_dims, end_dims)
001ddbcb length of each output. Values should be >= 0.
001ddbf9 Three interpolation modes: nearest (default), linear and cubic. The "linear" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The "cubic" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor).
001ddd6f The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. Only one of 'scales' and 'sizes' can be specified.
001dde10 The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. If 'size' is needed, the user must set 'scales' to an empty tensor.
001ddf2e tiles
001ddf34 Axis along which to repeat.
001ddf50 Classification outputs (one class per example).
001ddf80 Data to be regressed.
001ddf96 The number of support vectors.
001ddfb5 Cannot use the same name as both a subgraph initializer and subgraph input: 
001de002 onnx.TensorAnnotation
001de018 onnx.OperatorSetIdProto
001de030 size too big: 
001de03f Error compiling '
001de054 [:word:]
001de05d Unexpected special state in RunStateOnByte
001de088 no argument for repetition operator
001de0b1 \x%02x
001de0b8 Braille
001de0c0 Inscriptional_Pahlavi
001de0d6 Inscriptional_Parthian
001de0ed Mende_Kikakui
001de0fb Old_Uyghur
001de106 Tegra SL
001de112 OMAP
001de117 December
001de125 operator&&
001de130 decimal32
001de142 CIE ID is not zero
001de155 FillSparseTensorCoo
001de169 EnableOrtCustomOps: Custom operators in onnxruntime-extensions are not enabled
001de1b8 output buffer is too small. Use GetStringTensorDataLength.
001de1f3 narrowing_error
001de203 index out of range
001de216 const T &OrtValue::Get() const [T = std::vector<std::map<long, float>>]
001de25e For map type num_values MUST be 2
001de280 Key type is not supported yet.
001de29f OrtStatus *OrtCreateMapMLValue(const onnxruntime::Tensor &, const onnxruntime::Tensor &, OrtValue **) [KeyType = std::basic_string<char>, ValueType = long]
001de33b void onnxruntime::TensorSeq::SetType(onnxruntime::MLDataType)
001de379 Provided allocator is null
001de394 session.intra_op.allow_spinning
001de3b4  Please fix either the inputs or the model.
001de3e0  is not expected to be of type sparse tensor.
001de40e Session was not initialized
001de42a memory.enable_memory_arena_shrinkage
001de44f Profiler is disabled.
001de465 const logging::Logger &onnxruntime::InferenceSession::CreateLoggerForRun(const onnxruntime::RunOptions &, std::unique_ptr<logging::Logger> &)
001de4f3 Reading the provided model for the ORT config
001de521 ORTM
001de526 Provided type is not an optional sequence tensor
001de557 name:
001de55d invalid BOM; must be 0xEF 0xBB 0xBF if given
001de58a invalid string: control character U+0002 (STX) must be escaped to \u0002
001de5d3 invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
001de621 invalid string: control character U+000A (LF) must be escaped to \u000A or \n
001de66f tensor(bool)
001de67c com.microsoft
001de68a TensorRT execution provider is not enabled in this build.
001de6c4 void onnxruntime::ProviderSharedLibrary::Ensure()
001de6f6 Required input at index 
001de70f p_ml_value
001de71a IsSameDataType(tensor)
001de731 CreateOp
001de73a Compile
001de742 NonMaxSuppression
001de754 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/model.cc
001de79d ANeuralNetworksExecution_setLoopTimeout
001de7c5 SL_ANeuralNetworksDiagnosticExecutionInfo_getRuntimeExecutionTimeNanos
001de80c ANEURALNETWORKS_UNAVAILABLE_DEVICE
001de82f IsInternalQuantizationSupported
001de84f gsl::span<const T> onnxruntime::Tensor::DataAsSpan() const [T = float]
001de896 Getting count of available devices
001de8b9 Getting 
001de8c2 's size: 
001de8cc Wrong type: 
001de8d9 Only one input dimension of Attr(shape) can be unknown!
001de914  is not in valid range [-
001de92e ]'s output 0
001de93f axes
001de944  transA 
001de951 QLinearConcat
001de95f QLinearLeakyRelu
001de970 The node [
001de97b virtual void onnxruntime::XnnpackExecutionProvider::RegisterAllocator(onnxruntime::AllocatorManager &)
001de9e2 node_to_compute_capability is not in sync with supported_node_unit_map.
001dea2a status == xnn_status_success
001dea47 unsupported Conv in softmax, we have FLOAT|UINT8, but got 
001dea82 keep_aspect_ratio_policy
001dea9b cubic_coeff_a
001deaa9 tf_half_pixel_for_nn
001deabe ConvBnFusion_W_
001dead2 Gelu
001dead7 Pass MatchUnidirMaskSubgraph
001deaf4 Start MatchInputMaskSubgraph
001deb11 mask_unsqueeze_1 axes not matched. Expect: 1
001deb3e Failed to find path for present_k
001deb60 MatchPositionEmbeddingSubgraphsFromGather
001deb8a Input_ids and segment id should have the same shape. 
001debc0 Slice for Fused Gather nodes
001debdd Expecting the same size
001debf5 cast node to cast from float16 to float32 on cpu
001dec26 /onnxruntime_src/onnxruntime/core/optimizer/matmul_transpose_fusion.cc
001dec6d transpose_node.InputDefs().size() == 1
001dec94 size_t onnxruntime::UpdateConsumerCount(onnxruntime::Graph &, onnxruntime::NodeArg *, InlinedHashMap<onnxruntime::NodeArg *, size_t> &)
001ded1c CleanUpNodeSequence
001ded30 /onnxruntime_src/onnxruntime/core/optimizer/qdq_transformer/selectors_actions/shared/utils.cc
001ded8e /onnxruntime_src/onnxruntime/core/optimizer/transpose_optimizer/optimizer_api_impl.cc
001dede4 Reciprocal
001dedf3 GreaterOrEqual
001dee02 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::LeakyRelu<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::LeakyRelu<float>]
001deecb virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Sigmoid<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Sigmoid<float>]
001def90  has batch size of 
001defa4 'If' node has 
001defb3 info.GetAttr<ONNX_NAMESPACE::GraphProto>("then_branch", &proto).IsOK()
001deffa info == nullptr
001df00a . Input tensor rank was 
001df023 const OrtValue &onnxruntime::scan::detail::OutputIterator::GetOutput() const
001df070 Unsupported output datatype with size: 
001df098 Axis tensor must be provided to the CumSum op
001df0c6 Axis tensor should be of type `int32_t` or `int64_t`
001df0fb std::unique_ptr<Tensor> onnxruntime::EinsumOp::MatMul(const onnxruntime::Tensor &, const gsl::span<const int64_t> &, const onnxruntime::Tensor &, const gsl::span<const int64_t> &, onnxruntime::AllocatorPtr, concurrency::ThreadPool *, void *, const DeviceHelpers::MatMul<T> &) [T = double]
001df21c  for input shape 
001df22e Number of subscripts in the input equation does not match number of input tensors
001df280 candidate_output_dims[iter] == 1
001df2a1 Unsupported X type: 
001df2b6 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Sqrt<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Sqrt<float>]
001df375  is invalid.
001df382 InputBroadcaster can only start at span boundary!
001df3b4 void onnxruntime::mod_internal::CallModImpl<onnxruntime::MLFloat16>::operator()(bool, onnxruntime::OpKernelContext *) const
001df430 /onnxruntime_src/onnxruntime/core/providers/cpu/math/hardmax.cc
001df470 num_entries == int_categories.size()
001df495 replaced_value_float
001df4aa onnxruntime::ml::ImputerOp::ImputerOp(const onnxruntime::OpKernelInfo &)
001df4f3 classes_strings
001df503 coefficients
001df510 LOGISTIC
001df519 Invalid normalize value of 
001df535 Unknown Category and zeros = 0.
001df555 POLY
001df55a one_class
001df564 nodes_modes
001df570 nodes_values
001df57d Unable to find node 
001df592 One path in the graph requests feature 
001df5ba void onnxruntime::ml::detail::TreeAggregator<float, float, float>::FinalizeScores(InlinedVector<ScoreValue<ThresholdType>> &, OutputType *, int, int64_t *) const [InputType = float, ThresholdType = float, OutputType = float]
001df69b class_treeids
001df6a9 void onnxruntime::ml::detail::TreeEnsembleCommon<long, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = long, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorMax<long, float, float>]
001df7f7 int64_t onnxruntime::ml::detail::TreeAggregatorClassifier<long, float, float>::_set_score_binary(int &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = long, ThresholdType = float, OutputType = float]
001df8d5 ZipMap
001df8dc virtual onnxruntime::common::Status onnxruntime::BatchNorm<float>::Compute(onnxruntime::OpKernelContext *) const [T = float]
001df959 Invalid input mean: NumDimensions() != 
001df981  kernel channels: 
001df994 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/lp_norm.h
001df9d1 /onnxruntime_src/onnxruntime/core/providers/cpu/nn/roi_pool.cc
001dfa10 roi_batch_id < batch_size
001dfa2a spatial_scale_ > 0
001dfa3d TfIdfVectorizer
001dfa4d  must be of equal size
001dfa64 boxes must be a 3D tensor.
001dfa7f GetThresholdsFromInputs
001dfa97 /onnxruntime_src/onnxruntime/core/providers/cpu/quantization/quantize_linear.cc
001dfae7 onnxruntime::ReduceKernelBase<false>::ReduceKernelBase(const onnxruntime::OpKernelInfo &, optional<int64_t>) [allow_multi_axes = false]
001dfb6f onnxruntime::DeepCpuGruOp::DeepCpuGruOp(const onnxruntime::OpKernelInfo &)
001dfbba !is_prepacked_
001dfbc9 B + (N * ldb - (ldb - K)) <= B_end
001dfbec Input P must have shape {
001dfc06 Invalid sequence index (
001dfc1f SequenceConstruct
001dfc31  yet
001dfc36 onnxruntime::common::Status onnxruntime::SplitToSequence::ComputeImpl(onnxruntime::OpKernelContext &, const onnxruntime::Tensor &, const onnxruntime::Tensor *) const [T = int]
001dfce6 onnxruntime::common::Status onnxruntime::short_time_fourier_transform(onnxruntime::OpKernelContext *, bool, bool) [T = float, U = std::complex<float>]
001dfd7d /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/compress.cc
001dfdc0 void onnxruntime::StridedCopy(concurrency::ThreadPool *, T *, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShape &, const T *, const onnxruntime::TensorShapeVector &) [T = unsigned char]
001dfe8f indices tensor data type not supported
001dfeb6 Only 4-D tensor is supported
001dfed3 MeanVarianceNormalization
001dfeed Cannot use 'edge' mode to pad dimension with a value of 0. Input shape:
001dff35 /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/pad.cc
001dff73 time_axis < 2
001dff81  Axis=
001dff88 Transpose of element size not supported in this build. Size=
001dffc5 Transpose not implemented for empty tensors.
001dfff2 'axes' has a duplicate axis
001e000e onnxruntime::contrib::AttentionBase::AttentionBase(const onnxruntime::OpKernelInfo &, bool)
001e006a Input 'bias' dimension 0 should have same length as sum of Q/K/V hidden sizes:
001e00b9 Inputs 'past' dimension 0 shall have length of 2
001e00ea Input 'mask_index' is expected to have 1, 2, 3 or 4 dimensions, got 
001e012f ], while 
001e0139 /onnxruntime_src/onnxruntime/contrib_ops/cpu/cdist.h
001e016e ngram_size
001e0179 onnxruntime::contrib::CropAndResize<float>::CropAndResize(const onnxruntime::OpKernelInfo &) [T = float]
001e01e2 onnxruntime::contrib::Affine<float>::Affine(const onnxruntime::OpKernelInfo &) [T = float]
001e023d info.GetAttr<int64_t>("across_channels", &across_channels_).IsOK()
001e0280 virtual onnxruntime::common::Status onnxruntime::contrib::transformers::BeamSearch::Compute(onnxruntime::OpKernelContext *) const
001e0302 min_length
001e030d ) shall be greater than input sequence length (
001e033d logits_shape.NumDimensions() == 3
001e035f init_run_gpt_subgraph_ && gpt_subgraph_ && init_run_gpt_subgraph_->past_present_share_buffer_ == gpt_subgraph_->past_present_share_buffer_
001e03ea past_present_share_buffer mode must be same for init decoder and decoder subgraphes
001e043e /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/subgraph_gpt.cc
001e0488 position_ids
001e0495 expect >=6 outputs, got:
001e04ae encoder_input_ids
001e04c0 thisProto->value_case() == TypeProto::ValueCase::kSequenceType
001e04ff We don't expect custom allocators for non-tensor types, so a shape is mandatory here.
001e0555 TraceAllocation for ort_value_idx=
001e0578 void onnxruntime::ExecutionFrame::TraceFree(int)
001e05a9 void onnxruntime::FeedsFetchesManager::SetDeviceCopyChecks(onnxruntime::DeviceCopyCheck, onnxruntime::DeviceCopyCheck)
001e0620 ' OpType:
001e062a Op with name (
001e0639  in the supported version range
001e0659 : Conflicting with a registered kernel with op versions.
001e0692 CPU allocator not found
001e06aa !using_counters_
001e06bb current <= buffer_size_
001e06d3 OrtValue has not been allocated so can't be sliced.
001e0707 SetupAllocators
001e0717 Entry exists in node 
001e072d  Index:
001e0735 ComputeValueLocation
001e074a allocator
001e0754 Only tensors are supported for external outputs for now.
001e078d /onnxruntime_src/onnxruntime/core/framework/sequential_executor.cc
001e07d0 Using user supplied initializer with name (
001e07fc ) because the ORT planned memory location device 
001e082e Sparse format must not be set. Already contains format: 
001e0867 Format() == SparseFormat::kCsrc
001e0887 Expecting two indices. Got: 
001e08a4 since == end
001e08b1 Internal error.
001e08c1 data overflow
001e08cf Invalid SparseTensor indices. Should be rank 0 or 1. Got:
001e0909 CopyLittleEndian
001e091a Merged Q/K/V weights with shape (input_hidden_size, hidden_size + hidden_size + v_hidden_size)
001e0979 MultiHeadAttention
001e098c q_weight
001e0995 2D words IDs with shape (batch_size, sequence_length)
001e09cb Failed to parse max_length or it is not positive integer scalar
001e0a0b residual
001e0a14 Irfft
001e0a1a sparse_tensor(double)
001e0a30 Input can be of any tensor type.
001e0a51 Constrain types to int tensors.
001e0a71 Type of Mean and InvStdDev tensors.
001e0a95 detection_scores
001e0aa6 score_threshold
001e0ab6 PyramidROIAlign_TRT
001e0aca /onnxruntime_src/onnxruntime/core/graph/contrib_ops/nchwc_schema_defs.cc
001e0b13 weight and zero_point pair is expected to have same type.
001e0b4d 1D output tensor
001e0b5e de-quantized tensor.
001e0b73 Constrain input B data type to 8-bit integer tensor.
001e0ba8 The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`.
001e0c07 Constrain output type to float32 or 8 bit tensors.
001e0c3a scale_C
001e0c42 scale of the output for fused kqv gemm
001e0c69 The weight tensor that will be used in the convolutions; has size (C x M/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. 
001e0d43 axis must be in [-rank, rank-1]. input rank was 
001e0d74 Duplicate initializer (dense, sparse or ConstantNode): '
001e0dad ' of input parameter (
001e0dc4 InferAndVerifyTypeMatch
001e0ddc Schema was not found for fused node. Domain:
001e0e09  OpType:
001e0e12 /onnxruntime_src/onnxruntime/core/framework/tensorprotoutils.h
001e0e51 /onnxruntime_src/onnxruntime/core/graph/model_load_utils.h
001e0e8c Missing values for sparse initializer. Invalid ORT format model.
001e0ecd /onnxruntime_src/onnxruntime/core/graph/model.cc
001e0efe system error number 
001e0f13 /onnxruntime_src/onnxruntime/core/util/math_cpu.cc
001e0f46 bool onnxruntime::math::NextPosition(int64_t, const int64_t *, int64_t *)
001e0f90 ISink must be provided.
001e0fa8 /onnxruntime_src/onnxruntime/core/common/profiler.cc
001e0fdd onnxruntime::concurrency::ThreadPool::ParallelSection::ParallelSection(onnxruntime::concurrency::ThreadPool *)
001e104c pthread_attr_setstacksize failed, error code: 
001e107b Field '
001e1083 ) should not be empty.
001e109a sparse_tensor_proto
001e10ae Graph attribute inferencing returned type information for 
001e10e9 Graph to run if condition is true. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the else_branch.
001e119d v_initial
001e11a7 optional(tensor(uint16))
001e11c0 First input operand for the logical operator.
001e11ef           {
001e11fb             Alpha = Constant <value_float: float = @alpha>()
001e1238             AlphaCast = CastLike (Alpha, X)
001e1264             Gamma = Constant <value_float: float = @gamma>()
001e12a1             GammaCast = CastLike (Gamma, X)
001e12cd             Zero = Constant <value = float {0.0}>()
001e1301             ZeroCast = CastLike (Zero, X)
001e132b             ExpX = Exp (X)
001e1346             AlphaMulExpX = Mul(AlphaCast, ExpX)
001e1376             AlphaMulExpXSubAlpha = Sub (AlphaMulExpX, AlphaCast)
001e13b7             Neg = Mul (GammaCast, AlphaMulExpXSubAlpha)
001e13ef             Pos = Mul (GammaCast, X)
001e1414             XLessThanZero = Less (X, ZeroCast)
001e1443             Y = Where(XLessThanZero, Neg, Pos)
001e1472           }
001e147e         
001e148b Output tensor with clipped input elements
001e14b5 A 1-D tensor containing a single positive value corresponding to the number of top elements to retrieve
001e151d N-dimensional quantized matrix a
001e153e A 0-D tensor. Must be in the range [-rank(x), rank(x)-1]. Negative value means counting dimensions from the back.
001e15b0 Inputs
001e15b7 axis attribute value 
001e15cd const_zero_target_typed
001e15e5 input_gather_element_transform
001e1604 Input tensor of any shape broadcastable to X shape, the exponent component.
001e1650 Minimum value, under which element is replaced by min
001e1686 Describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
001e1771 The number of channels to sum over
001e1794 ngram_indexes must be non-empty with no negative values
001e17cc saved_var
001e17d6 Integer indicate the format of the box data. The default is 0. 0 - the box data is supplied as [y1, x1, y2, x2] where (y1, x1) and (y2, x2) are the coordinates of any diagonal pair of box corners and the coordinates can be provided as normalized (i.e., lying in the interval [0, 1]) or absolute. Mostly used for TF models. 1 - the box data is supplied as [x_center, y_center, width, height]. Mostly used for Pytorch models.
001e197e Attribute 'type' should be a TypeProto and it should specify a type.
001e19c3 Input type is null. Type information is expected for the input.
001e1a08     data_square = Mul(data, data)
001e1a2a     reduced = ReduceSum<keepdims: int = @keepdims>(data_square, axes)
001e1a77 ' has been deprecated since version 
001e1a9c  expected to have type info
001e1ab8  Value=
001e1ac0 Sum of split values not equal to 'input' dim size on 'axis'. 'axis' dim size=
001e1b0e Invalid value of attribute 'axis'. Accepted range=[
001e1b42 Mismatch between number of source and target dimensions. Source=
001e1b83 The scale array along each dimension. It takes value greater than or equal to 1. The number of elements of 'scales' should be the same as the rank of input 'X'.
001e1c24 Tensor of rank r >= 2.
001e1c3b Input to extract the centered crop from.
001e1c64 CenterCropPad
001e1c72 Invalid position of 0.
001e1c89 Type of reduction to apply: none (default), add, mul. 'none': no reduction applied. 'add':  reduction using the addition operation. 'mul': reduction using the multiplication operation.
001e1d42 Constrain tiles and axis's type to int64 tensors.
001e1d74 Two interpolation modes: nearest(default), bilinear
001e1da8 load external data into raw data for tensor: 
001e1dd6  expected size 
001e1de6 map(string, double)
001e1dfa The input type must be a tensor of a numeric type.
001e1e2d A list of strings. One and only one of 'keys_*'s should be set.
001e1e6d CHECK failed: (backup_bytes_) == (0): 
001e1e94 CHECK failed: (buffer_used_) == (buffer_size_): 
001e1ec5 /build/intermediates/arm64-v8a/Release/_deps/protobuf-src/src/google/protobuf/stubs/stringpiece.cc
001e1f28 Stack not empty.
001e1f39 [:blank:]
001e1f43 [:xdigit:]
001e1f4e DeadState in RunStateOnByte
001e1f6a invalid repetition size
001e1f82 invalid UTF-8
001e1f90 Old_Persian
001e1f9f unique_lock::unlock: not locked
001e1fbf failed to allocate %zu bytes for %u core mapping entries
001e1ff8 /proc/cpuinfo
001e2006 dragon
001e2014 /sys/devices/system/cpu/cpu%u/cpufreq/cpuinfo_max_freq
001e2051 thread-local wrapper routine for 
001e2073 thread-local initialization routine for 
001e209c sizeof (
001e20a5 operator!=
001e20b0 __uuidof(
001e20ba std::allocator
001e20c9 struct
001e20d0 libunwind: malformed DW_CFA_def_cfa_register DWARF unwind, reg too big
001e2118 Can't binary search on variable length encoded data.
001e2155 RegisterCustomOpsUsingFunction: Registration function was not found
001e2199 OrtStatusPtr OrtApis::CreateOpaqueValue(const char *, const char *, const void *, size_t, OrtValue **)
001e2202 IsTensorSequence()
001e2215 const T &OrtValue::Get() const [T = std::map<std::basic_string<char>, double>]
001e2264 Either the key tensor or the value tensor has NumDimensions > 1
001e22a4 Tensor must always contain primitive types. Found: 
001e22d8 OrtStatus *OrtCreateMapMLValue(const onnxruntime::Tensor &, const onnxruntime::Tensor &, OrtValue **) [KeyType = long, ValueType = double]
001e2363 onnxruntime::InferenceSession::InferenceSession(const onnxruntime::SessionOptions &, const onnxruntime::Environment &, const onnxruntime::PathString &)
001e23fb Unknown error during EndProfiling()
001e241f Input with name: 
001e2431 Output vector pointer is NULL
001e244f Exception during loading: 
001e246a onnxruntime::MLDataType onnxruntime::utils::GetElementTypeFromOptionalTensor(onnxruntime::MLDataType)
001e24d4 invalid comment; missing closing '*/'
001e24fa invalid string: control character U+0005 (ENQ) must be escaped to \u0005
001e2543 invalid string: control character U+0013 (DC3) must be escaped to \u0013
001e258c end of input
001e2599 common::Status onnxruntime::CreateCustomRegistry(gsl::span<OrtCustomOpDomain *const>, std::shared_ptr<CustomRegistry> &)
001e2612 i == input_count - 1
001e2627 Failed to unload handle for dynamic library 
001e2654 Constrain to all fixed size tensor and sequence types. If the dtype attribute is not provided this must be a valid output type.
001e26d4 tensor(float16)
001e26e4 seq(tensor(uint64))
001e26f8 ) from file 
001e2705 , but its domain is not
001e271d OrtSessionOptionsAppendExecutionProvider_TensorRT: Failed to load shared library
001e276e libonnxruntime_providers_shared.so
001e2791 invalid node output count
001e27ab NnapiExecutionProvider::GetCapability,
001e27d2 Unsupported output type: 
001e27ec ANEURALNETWORKS_UNEXPECTED_NULL
001e280c QLinearConv
001e2818 GetShape
001e2821 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/batchnorm_op_builder.cc
001e2887 /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/op_builder_helpers.cc
001e28e6 ] does not evenly divide dimension 
001e290a /joined_gemm_output
001e291e The scale of 
001e292c Dimensions are not compatible, dim1: 
001e2952 Current Android API level [
001e296e We should not reach here, ClipOpBuilder::IsOpSupportedImpl should have caught this.
001e29c2 ] input 
001e29cb The dynamic input shape 
001e29e4 LRN only support 4d shape, input is 
001e2a09 Resize nearest neighbor, unsupported nearest_mode, 
001e2a3d Resize of N/C channels are not supported
001e2a6e static bool onnxruntime::nnapi::UnaryOpBuilder::IsQuantizedOpSupported(const onnxruntime::InitializedTensorSet &, const onnxruntime::NodeUnit &, const onnxruntime::nnapi::OpSupportCheckParams &)
001e2b31 QLinearSoftmax
001e2b40 Not enough elements in pads. Expected: 
001e2b68 No support for fusion of 
001e2b82 input_shape.Size() > 0 || input_shape[0] == 0
001e2bb0 ] is not supportted!
001e2bc5 Dimension: 
001e2bd1 SimplifiedLayerNormFusion
001e2beb add_B_tensor_proto
001e2bfe Shape
001e2c04 virtual onnxruntime::common::Status onnxruntime::ConstantFolding::ApplyImpl(onnxruntime::Graph &, bool &, int, const logging::Logger &) const
001e2c92 fetches.size() == node->OutputDefs().size()
001e2cbe /onnxruntime_src/onnxruntime/core/optimizer/conv_activation_fusion.cc
001e2d04 concat_after_gather does not have expected number of inputs or output edges
001e2d50 Failed to find path for past_k
001e2d6f ConvertMaskToInt32
001e2d82 Failed to find path 1 of position shape.
001e2dab FastGelu
001e2db4 onnxruntime::Initializer::Initializer(const onnx::TensorProto &, const onnxruntime::Path &)
001e2e10 Initializer
001e2e1c std::optional<ExtendedGraphEdge> onnxruntime::(anonymous namespace)::GetPreviousPropagationEdge(const onnxruntime::Graph &, const onnxruntime::graph_utils::ExtendedGraphEdge &)
001e2ecd Total fused reshape node count: 
001e2eee Matched 
001e2ef7 LessOrEqual
001e2f03 ReduceSum
001e2f0d onnxruntime::ElementWiseKernel<onnxruntime::functors::Celu<float>>::ElementWiseKernel(const onnxruntime::OpKernelInfo &) [F = onnxruntime::functors::Celu<float>]
001e2faf void onnxruntime::Scan<8>::Init(const onnxruntime::OpKernelInfo &) [OpSet = 8]
001e2ffe  outputs so the subgraph requires 
001e3021 scan_input_axes
001e3031 onnxruntime::common::Status onnxruntime::ScanImpl::TransposeOutput()
001e3076 t_proto_p->dims_size() == 1
001e3092  is not supported yet
001e30a8 input_shape_1_override[2] == input_shape_2_override[1]
001e30df Incompatible matrix dimensions for matMul
001e3109 std::unique_ptr<Tensor> onnxruntime::EinsumTypedComputeProcessor<float>::PairwiseOperandProcess(const onnxruntime::Tensor &, const onnxruntime::TensorShape &, const onnxruntime::Tensor &, const onnxruntime::TensorShape &, const gsl::span<const int64_t> &, bool) [T = float]
001e321b Einsum op: Input dimensions must be equal along an axis to be reduced across all inputs
001e3273 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Floor<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Floor<float>]
001e3334 onnxruntime::BitShift<unsigned char>::BitShift(const onnxruntime::OpKernelInfo &) [T = unsigned char]
001e339a auto onnxruntime::BitShift<unsigned int>::Compute(onnxruntime::OpKernelContext *)::(anonymous class)::operator()(onnxruntime::BroadcastHelper &) const [T = unsigned int]
001e3444 /onnxruntime_src/onnxruntime/core/providers/cpu/math/element_wise_ops.h
001e348c (fmod == 0) || (fmod == 1)
001e34a7  Expected DENSE or SPARSE
001e34c1 /onnxruntime_src/onnxruntime/core/providers/cpu/ml/feature_vectorizer.cc
001e350a imputed_value_int64s
001e351f virtual common::Status onnxruntime::ml::ImputerOp::Compute(onnxruntime::OpKernelContext *) const
001e3580 Input of tensor(string) must have output of tensor(int64)
001e35ba keys_floats
001e35ca void onnxruntime::ml::detail::TreeEnsembleCommon<float, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = float, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorAverage<float, float, float>]
001e371f void onnxruntime::ml::detail::TreeEnsembleCommon<float, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = float, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorMin<float, float, float>]
001e3870 void onnxruntime::ml::detail::TreeEnsembleCommon<double, double, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = double, ThresholdType = double, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorClassifier<double, double, float>]
001e39ce void onnxruntime::ml::detail::TreeEnsembleCommon<int, float, float>::ComputeAgg(concurrency::ThreadPool *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *, const AGG &) const [InputType = int, ThresholdType = float, OutputType = float, AGG = onnxruntime::ml::detail::TreeAggregatorMax<int, float, float>]
001e3b19 virtual onnxruntime::common::Status onnxruntime::BatchNorm<double>::Compute(onnxruntime::OpKernelContext *) const [T = double]
001e3b98 Input channels is not divisible by group.
001e3bc2 X and mask should have the same shape
001e3be8 info.GetAttr<int64_t>("p", &p_).IsOK()
001e3c0f onnxruntime::StringNormalizer::StringNormalizer(const onnxruntime::OpKernelInfo &)
001e3c62 impl_->weighting_criteria_ != kNone
001e3c86 mode: 
001e3c8d max_skip_count is required
001e3ca8 pool_int64s
001e3cb4 The most inner dimension in boxes must have 4 data.
001e3ce8 /onnxruntime_src/onnxruntime/core/providers/cpu/object_detection/non_max_suppression.h
001e3d3f IsScalarOr1ElementVector(Y_zero_point)
001e3d66 QLinearConv : zero point of per-channel filter must be same
001e3da2 void onnxruntime::ValidateNoTransposeReduce(int64_t)
001e3dd7 must be overloaded.
001e3deb Batchwise recurrent operations (layout == 1) are not supported. If you need support create a github issue with justification.
001e3e69 gsl::span<const T> onnxruntime::rnn::detail::GemmWeights<float>::GetUnpackedSpan() const [T = float]
001e3ece C + (M * ldc - (ldc - N)) <= C_end
001e3ef1 T *onnxruntime::rnn::detail::SafeRawPointer(typename gsl::span<T>, size_t, size_t) [T = float]
001e3f50 info.GetAttrs("activations", activations_).IsOK()
001e3f82 ) != split_dim_size (
001e3f98 onnxruntime::common::Status onnxruntime::short_time_fourier_transform(onnxruntime::OpKernelContext *, bool, bool) [T = float, U = float]
001e4021 HannWindow
001e402c snprintf_result > 0
001e4040 pads_.empty()
001e404e axes_right_stride >= 0 && static_cast<uint64_t>(axes_right_stride) < std::numeric_limits<size_t>::max()
001e40b6 mode_str == "bilinear" || mode_str == "nearest" || mode_str == "bicubic"
001e40ff grid_dims[3] == 2
001e4111 onnxruntime::MeanVarianceNormalization_1<float>::MeanVarianceNormalization_1(const onnxruntime::OpKernelInfo &) [T = float]
001e418d void onnxruntime::DoTransposeImpl(int64_t, gsl::span<const int64_t>, size_t, size_t, const gsl::span<const size_t> &, const std::string *, std::string *)
001e4227 Upsample: input shape needs to be at least a single dimension.
001e4266 /onnxruntime_src/onnxruntime/contrib_ops/cpu/bert/attention_base.h
001e42a9 beta is expected to have size of 
001e42cb  found!
001e42d3 static_cast<int>(activation_func_names.size()) == num_directions_ * 3
001e4319 virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::ParametricSoftplus<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::ParametricSoftplus<float>]
001e43f4 min_ngram_size
001e4403 Null crop_size_ptr
001e4416 axis <= X_NumDims && axis >= -X_NumDims
001e443e , 4*
001e4443 Segment embedding scale must be a scalar or 1D tensor of size 1
001e4483 IsScalarOr1ElementVector(tensor_a_scale)
001e44ac IsScalarOr1ElementVector(tensor_y_scale)
001e44d5 /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/qlinear_where.cc
001e4520 separators must not be empty
001e453d mincharnum is too big for char level tokenezation
001e456f Can not digest separators: 
001e458b input_ids and presence_mask must have the same batch_size
001e45c5 virtual void onnxruntime::contrib::transformers::BeamSearchScorer::Finalize(onnxruntime::contrib::transformers::ISequences *, gsl::span<const float> &, onnxruntime::Tensor *, onnxruntime::Tensor *)
001e468b /onnxruntime_src/onnxruntime/contrib_ops/cpu/transformers/subgraph_base.cc
001e46d6 subgraph input 2 (attention_mask) shall have int32 type
001e470e  initial_growth_chunk_size_bytes: 
001e4731 !c->in_use() && (c->bin_num != kInvalidBinNum)
001e4760 RegionFor
001e476a  | Requested Size: 
001e477e Not implemented
001e478e tensor type 
001e479b Fetches vector passed to GetOutputs contains 
001e47c9 /onnxruntime_src/onnxruntime/core/framework/kernel_def_builder.cc
001e480b Invalid arg_num of 
001e481f . Dimension 0 is 
001e4831 ) node with name '
001e4844 Can not find the execution provider 
001e4869  as input
001e4876 TriggerDownstreamStep: trigger downstream of trigger point: 
001e48b3 _fence_before
001e48c5 Saving initialized tensors.
001e48e1 /onnxruntime_src/onnxruntime/core/framework/sparse_tensor.cc
001e491e MakeCooData
001e492a Must have the same size. Got src_size: 
001e4952 /onnxruntime_src/onnxruntime/core/framework/tensor_allocator_with_mem_pattern.h
001e49a2 Get preallocated buffer for initializer '
001e49cc TensorProtoToTensor() tensor shape mismatch!
001e49f9 TensorProtoToTensor
001e4a0d common::Status onnxruntime::utils::DenseTensorToSparseTensorProto(const onnx::TensorProto &, const onnxruntime::Path &, onnx::SparseTensorProto &)
001e4aa0 DenseTensorToSparseTensorProto
001e4abf UnpackTensorWithExternalDataImpl
001e4ae0 UnpackTensor: the pre-allocated size does not match the raw data size, expected 
001e4b31 common::Status onnxruntime::utils::CopyInputsAcrossDevices(const onnxruntime::SessionState &, gsl::span<const OrtValue>, std::vector<OrtValue> &, gsl::span<const MLValueCopyInfo>, gsl::span<Stream *const>)
001e4bff bias
001e4c04 3D output tensor with shape (batch_size, sequence_length, v_hidden_size)
001e4c4d Constrain input and output to float tensors.
001e4c7a kv_weight
001e4c84 Constrain key_padding_mask to bool tensors.
001e4cb0 Constrain input and output types to float or half tensors.
001e4ceb 2D input tensor with shape (batch_size, sequence_length)
001e4d24 new suffix match index
001e4d3b GemmFastGelu
001e4d48 gemm weight for the gated_ur_linear, shape (head_size, D), D is divisible by 2
001e4d97 apply softmax to elements for dimensions axis or higher
001e4dcf The value used to module the next token probabilities.
001e4e06 signal_ndim
001e4e12 Constrain input type to unsigned or signed 32-bit integer tensor, or string tensor. It should be utf-8 encoded if using unicode.
001e4e93 The pooling method. Two modes are supported: 'bilinear' and 'nearest'. Default is 'bilinear'.
001e4ef1 EfficientNMS_TRT
001e4f02 MultilevelCropAndResize_TRT
001e4f1e patches
001e4f26 Dimension mismatch in unification between 
001e4f51 both data and indices tensor need to have rank larger than zero.
001e4f92 Axis1D = Constant()
001e4fa6 The weight tensor for the gates. Concatenation of `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The tensor has shape `[num_directions, 4*hidden_size, input_size]`.
001e5061 The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`. 
001e50c1 The epsilon value to use to avoid division by zero
001e50f4 groups
001e50fb The scale to apply.
001e510f Input's shape must be 4-D
001e5129 3D input tensor with shape (batch_size, sequence_length, input_hidden_size)
001e5175 input_scale
001e5181 beta_zero_point
001e5191 cublasLt order of matrix A. See the schema of QuantizeWithOrder for order definition.
001e51e7 V_bias
001e51ee Scale tensor for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
001e5246 Optional 1D bias to be added to the convolution, has size of M. Bias must be quantized using scale = x_scale * w_scale and zero_point = 0
001e52d0 dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each spatial axis.
001e534a Tensor(scalar, or dims=[1]). First entry in the range.
001e5381 The past input shall be 5 dimensions
001e53a6 ' the model will use the latest encountered initializer
001e53de Initializer 
001e53eb node_arg
001e53f4  inputs. Either provide all subgraph inputs, or just the required inputs.
001e543e  in node (
001e5449 void onnxruntime::Graph::RemoveInitializedTensor(const std::string &)
001e548f InjectExternalInitializedTensors
001e54b0 /onnxruntime_src/onnxruntime/core/graph/graph_flatbuffers_utils.cc
001e54f3 INTS
001e54f8 Missing opset in the model. All ModelProtos MUST have at least one entry that specifies which version of the ONNX OperatorSet is being imported.
001e5589 Graph is null. Invalid ORT format model.
001e55b2 Number of affinities does not equal to thread_pool_size minus one, affinities: 
001e5602 "tid" :
001e560a "ph" : "X",
001e5616 MODEL_LOADED
001e5623 /onnxruntime_src/onnxruntime/core/common/threadpool.cc
001e565a LogStart must pair with LogEnd
001e5679 Distribution
001e5686 ReadFileIntoBuffer - unexpected end of file. 
001e56b4 ' of node: 
001e56c1 The graph run each iteration. It has N+M inputs: (loop state variables..., scan_input_elts...). It has N+K outputs: (loop state variables..., scan_output_elts...). Each scan_output is created by concatenating the value of the specified scan_output_elt value at the end of each iteration of the loop. It is an error if the dimensions of these values change across loop iterations.
001e583d An attribute specifying the number of scan_inputs M. 
001e5873 Optional tensor specifying lengths of the sequences in a batch. If this input is not specified, all sequences are assumed to be of the maximum sequence length (the dimension of the sequence axis of the scan_input tensors).
001e5952 All inputs to 'Range' op must be of the same type
001e5984 Result tensor.
001e5993 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/logical/old.cc
001e59e2 Value of alpha.
001e59f2 LogSoftmax(input, axis) = Log(Softmax(input, axis=axis))
001e5a2b The error function of the input tensor computed element-wise. It has the same shape and type of the input.
001e5a96 Output tensor of the same type as 'x' with cumulative sums of the x's elements
001e5ae5 const_zero
001e5af0 ignore_index
001e5afd loss_unweighted = Squeeze (loss_N1dd, axes)
001e5b29 A manual rescaling weight given to each class. If given, it has to be a 1D Tensor assigning weight to each of the classes. Otherwise, it is treated as if having all ones.
001e5bd4 auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.
001e5dc6 RoIs tensor must have 2 dimensions
001e5de9 Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
001e5f1f List of stop words. If not set, no word would be removed from X.
001e5f60 Constrain input and output types to all numeric tensor types.
001e5f9e Constrain input types and output Y type to float tensors.
001e5fd8 Stride along each axis.
001e5ff0 Incomplete string literal.
001e600b [ParseError at position 
001e6024 First input tensor must have rank 3
001e6048 When computing the output of the hidden gate, apply the linear transformation before multiplying by the output of the reset gate.
001e60ca concat_result
001e60d8  expected to have optional type
001e60f8 Mismatched map tensor key type:
001e6118 Two interpolation modes: nearest (default), and linear (including bilinear, trilinear, etc)
001e6178 1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X or the length of axes, if provided. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is "tf_crop_and_resize"
001e6294 All inputs to Concat must have same rank. Input 
001e62c5 pads = Concat <axis = 0> (pad_amount_left, pad_amount_right)
001e6302 Constrain output types. Casting to strings and complex are not supported.
001e634d Return elements, either from X or Y, depending on condition.
001e638a Where behaves like
001e639d [numpy.where](https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html)
001e63f2 with three parameters.
001e640b 'pads' input must be a 1D (shape: [2 * input_rank]) tensor of type int64
001e6454 The indices, based on 0 as the first index of any dimension.
001e6491 Data to be binarized
001e64a6 Child node if expression is false.
001e64c9 Label encoder has only one input.
001e64eb onnx.AttributeProto
001e64ff onnx.GraphProto
001e650f onnx.TypeProto.Optional
001e652a Cannot use SearchOnePass for unanchored matches.
001e655b Regexp not destroyed.
001e6571 Case not handled in ComputeSimple: 
001e6595 CoalesceWalker::ShortVisit called
001e65b7 Imperial_Aramaic
001e65c8 Pau_Cin_Hau
001e65d4 failed to allocate %zu bytes for descriptions of %u ARM logical processors
001e6627 codecvt_byname<wchar_t, char, mbstate_t>::codecvt_byname failed to construct for 
001e6679 numpunct_byname<wchar_t>::numpunct_byname failed to construct for 
001e66bc locale not supported
001e66d8 operator,
001e66e2 decimal16
001e66ec noexcept
001e66f5 terminate_handler unexpectedly threw an exception
001e6727 getRegister
001e6733 DW_EH_PE_datarel is invalid with a datarelBase of 0
001e6771 unknown register
001e6782 Sparse Tensor does not contain sparse data
001e67ad shape is invalid
001e67be Integer overflow
001e67cf const T &OrtValue::Get() const [T = std::map<long, double>]
001e680b Value type is not supported yet: 
001e682d Each element of the sequence should be either tensor or map.
001e686a Tensor sequence must contain only primitive types
001e689c session-
001e68a5 Model was not loaded
001e68ba Model was not loaded.
001e68d0 Unsupported device specified in the memory arena shrink list: 
001e690f Unable to shrink arena: 
001e6928 session_options_.session_log_severity_level >= 0 && session_options_.session_log_severity_level <= static_cast<int>(logging::Severity::kFATAL)
001e69b7 Exception during initialization: 
001e69d9 invalid string: ill-formed UTF-8 byte
001e69ff  at line 
001e6a09 Only CPU devices are supported for now.
001e6a31 MemcpyToHost
001e6a3e seq(tensor(string))
001e6a52 Mismatch between source and target type. Source=
001e6a83 com.microsoft.experimental
001e6a9e SessionOptionsAppendExecutionProvider_OpenVINO: Failed to load shared library
001e6aec InvokeOp
001e6af5 All ops will fallback to CPU EP, because system NNAPI feature level [
001e6b3b  number of nodes supported by NNAPI: 
001e6b61 ANeuralNetworksBurst_free
001e6b7b QLinearSigmoid
001e6b8a Only float input is supported now.
001e6bad AddInitializerTransposed
001e6bc6  or no op is using the output (output is graph output)
001e6bfd /onnxruntime_src/onnxruntime/core/providers/nnapi/nnapi_builtin/builders/impl/cast_op_builder.cc
001e6c5e Slice only supports 1-4d shape, input is 
001e6c88 count_include_pad
001e6c9a ANEURALNETWORKS_LOGISTIC only supports 1-4d shape, input is 
001e6cd7 Node::EdgeConstIterator onnxruntime::NodeUnit::OutputEdgesEnd(size_t) const
001e6d23 fp32
001e6d28 xnnpack
001e6d30 auto onnxruntime::xnnpack::FuseActivation(const onnxruntime::NodeUnit &, const onnxruntime::NodeUnit &, const onnxruntime::GraphViewer &)::(anonymous class)::operator()(size_t, float &) const
001e6df0 onnxruntime::UpsampleMode onnxruntime::UpsampleBase::StringToUpsampleMode(const std::string &)
001e6e4f left operand cannot broadcast on dim 
001e6e78 session.disable_double_qdq_remover
001e6e9b session.qdqisint8allowed
001e6eb4 NotWhereFusion
001e6ec3 GatherToSliceFusion
001e6ed7 can't constant fold 
001e6eec start
001e6ef2 /onnxruntime_src/onnxruntime/core/optimizer/common_subexpression_elimination.cc
001e6f42 Gemm bias shape not expected
001e6f5f CheckSliceParameters return false
001e6f81 Failed to match v_concat
001e6f9a k_reshape const not matched
001e6fb6 Mask_Int32
001e6fc1 Failed to find path for k
001e6fdb _Int32
001e6fe2 MatMul_With_Transpose
001e6ff8 PropagateQBackward
001e700b std::optional<ExtendedGraphEdge> onnxruntime::(anonymous namespace)::GetNextPropagationEdge(const onnxruntime::Graph &, const onnxruntime::graph_utils::ExtendedGraphEdge &)
001e70b8 QDQSelectorActionTransformer
001e70d5 dropSplitQDQ
001e70e2 init_optional_zero_point_uint8_b33f88f7-c464-43e3-8692-97ac832bb14a
001e7126 inserted
001e712f Multiple entries for operator is not supported. OpType=
001e7167 onnxruntime::NodesToOptimizeIndices onnxruntime::NodesToOptimizeIndicesBuilder::Build() const
001e71c5 ' doesn't support memcpy 
001e71df ProcessInitializers
001e71f3  does not match rank 
001e720d Attribute name and type don't match for '
001e7237 info.GetAttr<ONNX_NAMESPACE::GraphProto>("body", &proto).IsOK()
001e7277 last_outputs[j + 1].IsTensor()
001e7296 dims.size() == extents.size() && dims.size() >= steps.size()
001e72d3 X != nullptr
001e72e0 std::unique_ptr<Tensor> onnxruntime::EinsumOp::MatMul(const onnxruntime::Tensor &, const gsl::span<const int64_t> &, const onnxruntime::Tensor &, const gsl::span<const int64_t> &, onnxruntime::AllocatorPtr, concurrency::ThreadPool *, void *, const DeviceHelpers::MatMul<T> &) [T = float]
001e7400 input_1.DataType() == input_2.DataType()
001e7429 Ranks of pair-wise operands must be equal. 
001e7455 Einsum op: Input shapes do not align
001e747a virtual onnxruntime::common::Status onnxruntime::ElementWiseKernel<onnxruntime::functors::Ceil<float>>::Compute(onnxruntime::OpKernelContext *) const [F = onnxruntime::functors::Ceil<float>]
001e7539 auto onnxruntime::BitShift<unsigned long>::Compute(onnxruntime::OpKernelContext *)::(anonymous class)::operator()(onnxruntime::BroadcastHelper &) const [T = unsigned long]
001e75e5 void onnxruntime::ExpandBroadcastLooper(onnxruntime::BroadcastHelper &, const onnxruntime::ProcessBroadcastSpanFuncs &)
001e765d BroadcastLooper requires two tensors as input.
001e768c c_shape is required if c_data is provided
001e76b6 Invalid Y argument: index is out of range: Y[
001e76e4 info.GetAttr<int64_t>("max_map", &max_map_).IsOK()
001e7717 const T *onnxruntime::OpKernelContext::Input(int) const [T = std::map<long, float>]
001e776b Input of string must have output of int64
001e7795 cats_strings
001e77a2 info.GetAttr<std::string>("default_string", &default_string_).IsOK()
001e77e7 Invalid type
001e77f4 values_strings
001e7803 default_float
001e7811 onnxruntime::ml::LabelEncoder_2<long, long>::LabelEncoder_2(const onnxruntime::OpKernelInfo &) [TKey = long, TValue = long]
001e788d !scale_.empty()
001e789d scale_.size() == offset_.size()
001e78bd proba_.size() == probb_.size()
001e78dc nodes_truenodeids
001e78ee target_nodeids
001e78fd void onnxruntime::ml::detail::TreeAggregatorMin<float, float, float>::MergePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = float, ThresholdType = float, OutputType = float]
001e79f6 virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommonClassifier<double, double, float>::Init(const onnxruntime::OpKernelInfo &) [InputType = double, ThresholdType = double, OutputType = float]
001e7ad1 virtual onnxruntime::common::Status onnxruntime::ml::detail::TreeEnsembleCommonClassifier<double, double, float>::compute(onnxruntime::OpKernelContext *, const onnxruntime::Tensor *, onnxruntime::Tensor *, onnxruntime::Tensor *) const [InputType = double, ThresholdType = double, OutputType = float]
001e7bfd void onnxruntime::ml::detail::TreeAggregatorMax<long, float, float>::MergePrediction(InlinedVector<ScoreValue<ThresholdType>> &, const InlinedVector<ScoreValue<ThresholdType>> &) const [InputType = long, ThresholdType = float, OutputType = float]
001e7cf4 Invalid input scale: 0th dimension != 
001e7d1b /onnxruntime_src/onnxruntime/core/providers/cpu/nn/pool.h
001e7d55 min_gram_length must be inbounds of ngram_counts: 
001e7d88 status.IsOK() && !impl_->ngram_indexes_.empty()
001e7db8 RoiAlign
001e7dc1 can only be of type(tensor) or (seq(tensor))
001e7dee Only Optional type OrtValues containing Tensors and Sequence Tensors are acceptable
001e7e42 IsScalarOr1ElementVector(X_scale)
001e7e64 IsValidQuantParam(W_scale, M)
001e7e82 Output size mismatch.
001e7e98 Input initial_c must have shape {
001e7eba A + (M * K) <= A_end
001e7ecf onnxruntime::rnn::detail::deepcpu::ActivationFuncPtr onnxruntime::rnn::detail::deepcpu::ActivationFuncByName(const std::string &)
001e7f51 Invalid LSTM merge activation function of 
001e7f7c CloneTensor
001e7f88 Unsupported input signal shape. The signal's first dimension must be the batch dimension and its second dimension must be the signal length dimension. It may optionally include a 3rd dimension of size 2 for complex inputs.
001e8067 Failed to write value with snprintf().
001e808e Col2Im
001e8095 auto onnxruntime::StridedCopy(concurrency::ThreadPool *, unsigned short *, const onnxruntime::TensorShapeVector &, const onnxruntime::TensorShape &, const unsigned short *, const onnxruntime::TensorShapeVector &)::(anonymous class)::operator()(std::ptrdiff_t, std::ptrdiff_t) const
001e81af Null input ptr
001e81be /onnxruntime_src/onnxruntime/core/providers/cpu/tensor/scatter_nd.cc
001e8203 has_starts && has_ends && attr_starts_.size() == attr_ends_.size()
001e8246 the tensor to be tiled using Tile OP must be atleast 1 dimensional
001e8289 onnxruntime::Trilu::Trilu(const onnxruntime::OpKernelInfo &)
001e82c6 Unique
001e82cd info.GetAttr("num_heads", &num_heads).IsOK() && num_heads > 0
001e830b Input 'relative_position_bias' dimension 1 should be same as number of heads, got 
001e835e /onnxruntime_src/onnxruntime/contrib_ops/cpu/attnlstm/deep_cpu_attn_lstm.cc
001e83aa CropAndResize
001e83b8 Axis must be within range [
001e83d4 Expecting COO 2-D indices shape
001e83f4 onnxruntime::MeanVarianceNormalization_0<float>::MeanVarianceNormalization_0(const onnxruntime::OpKernelInfo &, bool) [T = float]
001e8476 input scale must be a scalar or 1D tensor of size 1
001e84aa MatmulInteger : input1 A_scale must be a scalar or 1D tensor of size 1
001e84f1 /onnxruntime_src/onnxruntime/contrib_ops/cpu/quantization/qlinear_global_average_pool.cc
001e854a encoder
001e8552 t5_decoder_subgraph_ == nullptr
001e8572 init_run_decoder_session_state
001e8591 void onnxruntime::contrib::transformers::BeamSearchParameters::ParseFromInputs(onnxruntime::OpKernelContext *)
001e8600 num_return_sequences shall be a positive integer, got 
001e8637 void onnxruntime::contrib::transformers::GreedySearch::Init(const onnxruntime::OpKernelInfo &)
001e8696 virtual onnxruntime::common::Status onnxruntime::contrib::transformers::Sampling::SetupSubgraphExecutionInfo(const onnxruntime::SessionState &, const std::string &, const onnxruntime::SessionState &)
001e875e filter_value
001e876b encoder_attention_mask
001e8782 encoder subgraph output 0 shall be named as logits, got: 
001e87bc  embedding_size attribute: 
001e87d8 void onnxruntime::BFCArena::SplitChunk(BFCArena::ChunkHandle, size_t)
001e881e Overall chunks summary:
001e8836 void onnxruntime::BFCArena::RegionManager::RemoveAllocationRegion(void *)
001e8880 CopyTensorAsync
001e8890 bool onnxruntime::NonTensorTypeBase::IsMapCompatible(const onnx::TypeProto &) const
001e88e4 AllocateMLValueTensorPreAllocateBuffer
001e890b Partition
001e8915 Can't use func with null ptr
001e8932 CreateGraphInfo
001e8942 Done saving OrtValue mappings.
001e8961  doesn't have an implementation that can cache computed pre-packed weights
001e89ac /onnxruntime_src/onnxruntime/core/framework/allocation_planner.cc
001e89ee static size_t onnxruntime::PlannerImpl::GetElementSize(const onnx::DataType &)
001e8a3d /onnxruntime_src/onnxruntime/core/framework/execution_steps.cc
001e8a7c stream 
001e8a84 Must contain BlockSparse format. Got: 
001e8aab onnxruntime::Stream *onnxruntime::StreamExecutionContext::GetDeviceStream(size_t)
001e8afd /onnxruntime_src/onnxruntime/core/framework/tensor.cc
001e8b33 Initialized tensor with unexpected type: 
001e8b5d location
001e8b66 /onnxruntime_src/onnxruntime/core/framework/utils.cc
001e8b9b key and value cache shall be 4 dimensions
001e8bc5 Query with shape (batch_size, sequence_length, hidden_size)
001e8c01 DecoderAttention
001e8c12 scores_out
001e8c1d cumulated_seq_len
001e8c2f The bias input data that is a 1D tensor.
001e8c58 Three interpolation modes: bilinear (default), nearest and bicubic.
001e8c9c filtered_logits
001e8cac 32-bit hash value.
001e8cbf positive
001e8cc8 If value is 1, output type is uint32_t, else int32_t. Default value is 1.
001e8d12 Constrain indice type to int32 or int64
001e8d3a Specify weights of conv
001e8d52 Constrains input to only numeric types.
001e8d7a batch_indices
001e8d88 The first normalization dimension: normalization will be performed along dimensions axis : rank(inputs).
001e8df1 Constrain output Y, scale and bias type to float tensors.
001e8e2b Input rank must be >= 2.
001e8e44 Var = Sub (MeanOfSquare, SquareOfMean)
001e8e6b inputs are expected to have tensor type.
001e8e94 Constrain y to float and bfloat16.
001e8eb7 Keep the reduced dimension or not, default 1 mean keep reduced dimension.
001e8f01 W's scale. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
001e8fa4 Z's zero point.
001e8fb4 Constrain output zero point types to 8 bit tensors.
001e8fe8 segment_embedding_scale
001e9000 Zero Point for 1D beta tensor
001e901e Mask Index Output
001e9030 scale_V_gemm
001e903d B_scale
001e9049 Unsupported non-raw-data data type!
001e906d This is an invalid model. Node (
001e908e sparse_tensor_names_ not in sync with name_to_initial_tensor_
001e90cc NoOp
001e90d1 Input to set must exist.
001e90ed SaveInitializerOrtFormat
001e9106 Missing dimensions for initializer. Invalid ORT format model.
001e9144 const std::string &onnxruntime::graph_utils::GetNodeOutputName(const onnxruntime::Node &, int)
001e91a3 Protobuf serialization failed.
001e91c2 Invalid OpIdentifier string: 
001e91e0 /onnxruntime_src/onnxruntime/core/common/path.cc
001e9211 SUCCESS
001e9219 virtual void onnxruntime::concurrency::ThreadPoolTempl<onnxruntime::Env>::RunInParallelSection(onnxruntime::concurrency::ThreadPoolParallelSection &, std::function<void (unsigned int)>, unsigned int, std::ptrdiff_t) [Environment = onnxruntime::Env]
001e9312 Failed to close file descriptor 
001e9333 , length: 
001e933e Null type info for 
001e9352 Null value type info in fbs::MapType. Invalid ORT format model.
001e9392  values, but NNZ is 
001e93a7 Only bool
001e93b1 optional(tensor(uint64))
001e93ca optional(tensor(int16))
001e93e2 Unsuported type proto value case.
001e9404 2D input tensor to copy shape, and optionally, type information from.
001e944a Upper boundary of the output values.
001e946f output = Cast (X_greater)
001e948a         {
001e9494             O1 = Less (A, B)
001e94b1             O2 = Equal (A, B)
001e94cf             C = Or (O1, O2)
001e94eb         }
001e94f5         
001e94ff           {
001e950b             Alpha = Constant <value_float: float = @alpha>()
001e9548             AlphaCast = CastLike (Alpha, X)
001e9574             Zero = Constant <value = float {0.0}>()
001e95a8             ZeroCast = CastLike (Zero, X)
001e95d2             One = Constant <value = float {1.0}>()
001e9605             OneCast = CastLike (One, X)
001e962d             XLessThanZero = Less (X, ZeroCast)
001e965c             ExpX = Exp (X)
001e9677             ExpXSubOne = Sub (ExpX, OneCast)
001e96a4             AlphaMulExpXSubOne = Mul (AlphaCast, ExpXSubOne)
001e96e1             Y = Where(XLessThanZero, AlphaMulExpXSubOne, X)
001e971d           }
001e9729         
001e9732 The natural log of the input tensor computed element-wise
001e976c Constrain input X and output types to float/int tensors.
001e97a5 zero point of quantized output y
001e97c7       input_gather_element = GatherElements <axis = 1> (input, expanded_target)
001e9817       loss_NCdd = Neg (input_gather_element)
001e9844       loss_N1dd = Slice (loss_NCdd, const_zero, const_one, const_one)
001e988a     
001e988f loss = ReduceSum <keepdims = 0> (loss_Ndd)
001e98ba A scalar representing the size of the DFT. It's an optional value.
001e98fd A {name} window with length: size. The output has the shape: [size].
001e9942 List of tensors for Min
001e995a Second input tensor has wrong dimension
001e9982 Attribute strides has incorrect size.
001e99a8 Attribute kernel_shape must be specified.
001e99d2 %s:%u: %s: Assertion `%s` failed.
001e99f4 X_variance
001e99ff The bias as a 1-dimensional tensor of size C to be applied to the output.
001e9a49 saved_mean
001e9a54 default 1; Pooled output Y's width.
001e9a78 Output element in the optional input.
001e9a9e OptionalGetElement must have an input element.
001e9acd Constrain 'x' to float or int32 tensor.
001e9af5 /build/intermediates/arm64-v8a/Release/_deps/onnx-src/onnx/defs/rnn/defs.cc
001e9b41 (inputs_.size() - 1) == i
001e9b5b Input sequence.
001e9b6b Which axis to split on. A negative value means counting dimensions from the back. Accepted range is [-rank, rank-1].
001e9be0 Keep the split dimension or not. Default 1, which means we keep split dimension. If input 'split' is specified, this attribute is ignored.
001e9c6b Element type of optional input 
001e9c8b 1-D tensor of ending indices (exclusive) of corresponding axis in `axes`
001e9cd4 Type of reduction to apply: none (default), add, mul, max, min. 'none': no reduction applied. 'add':  reduction using the addition operation. 'mul':  reduction using the addition operation. 'max': reduction using the maximum operation.'min': reduction using the minimum operation.
001e9ded Constrain roi type to float or double.
001e9e14 Tensor with same shape of input.
001e9e35 ) and the split dimension of the input (
001e9e5e Neither 'split' input nor 'num_outputs' attribute has been given
001e9e9f Input steps has incorrect length
001e9ec0 pad_amount = Sub(padded_sh, x_shape)
001e9ee5 Constrain input types. Casting from strings and complex are not supported.
001e9f30 Which axis to scatter on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1]
001e9f9e ) is not equal to the existing rank value (
001e9fca  Actual:
001e9fd3 Imputed output data
001e9fe7 Regression outputs (one per target, per example).
001ea019 The input must be a tensor of a numeric type.
001ea047 Shape inference error(s): 
001ea062 CHECK failed: !is_closed_: 
001ea07e parse
001ea084 program size 
001ea092 [:^alnum:]
001ea09d [:^blank:]
001ea0a8 invalid named capture group
001ea0c4 Malformed repeat 
001ea0d9 Adlam
001ea0df Caucasian_Albanian
001ea0f2 Sundanese
001ea0fc Ugaritic
001ea105 nsync_mu_wait woke but condition not true
001ea130 hi3660
001ea137 Allwinner
001ea141 ro.chipname
001ea14d /sys/devices/system/cpu/present
001ea16d unspecified generic_category error
001ea192 basic_iostream
001ea1a1  volatile
001ea1ab Pure virtual function called!
001ea1c9 std::bad_exception
001ea1dc DW_OP_piece not implemented
001ea1ff N11onnxruntime23NotImplementedExceptionE
001ea228 N11onnxruntime20OnnxRuntimeExceptionE
001ea24e N3gsl15narrowing_errorE
001ea266 NSt6__ndk119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
001ea2af NSt6__ndk115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
001ea2f4 NSt6__ndk120__shared_ptr_pointerIPN11onnxruntime18IExecutionProviderENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
001ea368 NSt6__ndk114default_deleteIN11onnxruntime18IExecutionProviderEEE
001ea3a9 NSt6__ndk120__shared_ptr_pointerIPvPFvS1_ENS_9allocatorIvEEEE
001ea3e7 PFvPvE
001ea3ee NSt6__ndk120__shared_ptr_emplaceIN11onnxruntime34IAllocatorImplWrappingOrtAllocatorENS_9allocatorIS2_EEEE
001ea458 NSt6__ndk110__function6__funcIZN7OrtApis19GetBoundOutputNamesEPK12OrtIoBindingP12OrtAllocatorPPcPPmSA_E3$_6NS_9allocatorISC_EEFvSA_EEE
001ea4df NSt6__ndk110__function6__baseIFvPmEEE
001ea505 ZN7OrtApis19GetBoundOutputNamesEPK12OrtIoBindingP12OrtAllocatorPPcPPmS7_E3$_6
001ea553 NSt6__ndk117bad_function_callE
001ea572 NSt6__ndk110__function6__funcIZN7OrtApis19GetBoundOutputNamesEPK12OrtIoBindingP12OrtAllocatorPPcPPmSA_E3$_7NS_9allocatorISC_EEFvS8_EEE
001ea5f9 NSt6__ndk110__function6__baseIFvPcEEE
001ea61f ZN7OrtApis19GetBoundOutputNamesEPK12OrtIoBindingP12OrtAllocatorPPcPPmS7_E3$_7
001ea66d NSt6__ndk110__function6__funcIZN7OrtApis20GetBoundOutputValuesEPK12OrtIoBindingP12OrtAllocatorPPP8OrtValuePmE3$_8NS_9allocatorISD_EEFvSA_EEE
001ea6fa NSt6__ndk110__function6__baseIFvPP8OrtValueEEE
001ea729 ZN7OrtApis20GetBoundOutputValuesEPK12OrtIoBindingP12OrtAllocatorPPP8OrtValuePmE3$_8
001ea77d N11onnxruntime34IAllocatorImplWrappingOrtAllocatorE
001ea7b1 N11onnxruntime10IAllocatorE
001ea7cd N11onnxruntime34OrtAllocatorImplWrappingIAllocatorE
001ea801 N11onnxruntime16OrtAllocatorImplE
001ea823 12OrtAllocator
001ea833 4/IIII>
001ea875 0N11onnxruntime16InferenceSessionE
001ea899 NSt6__ndk118basic_stringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
001ea8e1 N11onnxruntime16GraphTransformerE
001ea903 NSt6__ndk114basic_ofstreamIcNS_11char_traitsIcEEEE
001ea936 NSt6__ndk113basic_filebufIcNS_11char_traitsIcEEEE
001ea968 NSt6__ndk119basic_istringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
001ea9b1 N11onnxruntime23SequentialExecutionPlanE
001ea9da N11onnxruntime17ExecutionPlanBaseE
001ea9fd NSt6__ndk110__function6__funcIZN11onnxruntime16InferenceSession13LoadOnnxModelERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_3NS7_ISC_EEFNS2_6common6StatusERNS_10shared_ptrINS2_5ModelEEEEEE
001eaacd NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERNS_10shared_ptrINS2_5ModelEEEEEE
001eab2b ZN11onnxruntime16InferenceSession13LoadOnnxModelERKNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEE3$_3
001eaba7 NSt6__ndk110__function6__funcIZN11onnxruntime16InferenceSession4LoadEPKviE3$_4NS_9allocatorIS6_EEFNS2_6common6StatusERNS_10shared_ptrINS2_5ModelEEEEEE
001eac3e ZN11onnxruntime16InferenceSession4LoadEPKviE3$_4
001eac6f NSt6__ndk110__function6__funcIZN11onnxruntime16InferenceSession4LoadEvE3$_7NS_9allocatorIS4_EEFNS2_6common6StatusERNS_10shared_ptrINS2_5ModelEEEEEE
001ead03 ZN11onnxruntime16InferenceSession4LoadEvE3$_7
001ead31 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusERNS2_5GraphERbRKNS2_18IExecutionProviderEENS_9allocatorISC_EEFS4_S6_S7_RS8_EEE
001eadbd NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERNS2_5GraphERbRNS2_18IExecutionProviderEEEE
001eae25 PFN11onnxruntime6common6StatusERNS_5GraphERbRKNS_18IExecutionProviderEE
001eae6d FN11onnxruntime6common6StatusERNS_5GraphERbRKNS_18IExecutionProviderEE
001eaeb4 NSt6__ndk110__function6__funcIZN11onnxruntime16InferenceSession12LoadOrtModelERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_8NS7_ISC_EEFNS2_6common6StatusEvEEE
001eaf66 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEvEEE
001eafa7 NSt6__ndk114basic_ifstreamIcNS_11char_traitsIcEEEE
001eafda ZN11onnxruntime16InferenceSession12LoadOrtModelERKNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEE3$_8
001eb055 NSt6__ndk110__function6__funcIZN11onnxruntime16InferenceSession12LoadOrtModelEPKviE3$_9NS_9allocatorIS6_EEFNS2_6common6StatusEvEEE
001eb0d8 ZN11onnxruntime16InferenceSession12LoadOrtModelEPKviE3$_9
001eb112 NSt6__ndk120__shared_ptr_pointerIPN11onnxruntime5ModelENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
001eb178 NSt6__ndk114default_deleteIN11onnxruntime5ModelEEE
001eb1ab NSt6__ndk120__shared_ptr_pointerIPN11onnxruntime20CPUExecutionProviderENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
001eb221 NSt6__ndk114default_deleteIN11onnxruntime20CPUExecutionProviderEEE
001eb264 NSt6__ndk110__function6__funcIZN11onnxruntime16InferenceSession10InitializeEvE4$_12NS_9allocatorIS4_EEFNS2_6common6StatusERKN4onnx8OpSchemaEEEE
001eb2f4 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERKN4onnx8OpSchemaEEEE
001eb346 ZN11onnxruntime16InferenceSession10InitializeEvE4$_12
001eb3b1 ..........>
001eb404 KKKKKKKKKKKKKKKKKK
001eb6e5 Xbh`
001eb6f6 8@FK
001eb6ff 4>D<
001eb711 +5;3
001eb718 AN8nlohmann6detail10type_errorE
001eb738 N8nlohmann6detail9exceptionE
001eb755 N8nlohmann6detail12out_of_rangeE
001eb776 N8nlohmann6detail16invalid_iteratorE
001eb79c N8nlohmann6detail11parse_errorE
001eb859 NSt6__ndk110__function6__funcIN4onnx8OpSchema19num_inputs_allowed_MUliE_ENS_9allocatorIS5_EEFbiEEE
001eb8bc NSt6__ndk110__function6__baseIFbiEEE
001eb8e1 N4onnx8OpSchema19num_inputs_allowed_MUliE_E
001eb90d NSt6__ndk110__function6__funcIN4onnx8OpSchema20num_outputs_allowed_MUliE_ENS_9allocatorIS5_EEFbiEEE
001eb971 N4onnx8OpSchema20num_outputs_allowed_MUliE_E
001eb99e NSt6__ndk120__shared_ptr_emplaceIN11onnxruntime14CustomRegistryENS_9allocatorIS2_EEEE
001eb9f4 NSt6__ndk120__shared_ptr_emplaceIN11onnxruntime14KernelRegistryENS_9allocatorIS2_EEEE
001eba4a NSt6__ndk120__shared_ptr_emplaceIN11onnxruntime27OnnxRuntimeOpSchemaRegistryENS_9allocatorIS2_EEEE
001ebaad NSt6__ndk110__function6__funcIZN11onnxruntime20CreateCustomRegistryEN3gsl4spanIKP17OrtCustomOpDomainLm18446744073709551615EEERNS_10shared_ptrINS2_14CustomRegistryEEEE3$_0NS_9allocatorISD_EEFNS2_6common6StatusERNS2_11FuncManagerERKNS2_12OpKernelInfoERNS_10unique_ptrINS2_8OpKernelENS_14default_deleteISO_EEEEEEE
001ebbe4 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERNS2_11FuncManagerERKNS2_12OpKernelInfoERNS_10unique_ptrINS2_8OpKernelENS_14default_deleteISB_EEEEEEE
001ebc86 N11onnxruntime14CustomOpKernelE
001ebca6 N11onnxruntime8OpKernelE
001ebcbf ZN11onnxruntime20CreateCustomRegistryEN3gsl4spanIKP17OrtCustomOpDomainLm18446744073709551615EEERNSt6__ndk110shared_ptrINS_14CustomRegistryEEEE3$_0
001ebd52 22OrtDefaultCpuAllocator
001ebd6b N3Ort9ExceptionE
001ebd7c 14LoggingWrapper
001ebd8d N11onnxruntime7logging5ISinkE
001ebdc7 N4onnx14InferenceErrorE
001ebddf N4onnx11SchemaErrorE
001ebdf4 NSt6__ndk110__function6__funcIPFvRN4onnx16InferenceContextEENS_9allocatorIS6_EES5_EE
001ebe49 NSt6__ndk110__function6__baseIFvRN4onnx16InferenceContextEEEE
001ebe87 PFvRN4onnx16InferenceContextEE
001ebea6 FvRN4onnx16InferenceContextEE
001ebec4 NSt6__ndk110__function6__baseIFNS_10unique_ptrIN11onnxruntime10IAllocatorENS_14default_deleteIS4_EEEEsEEE
001ebf2e NSt6__ndk110__function6__funcIZN11onnxruntime11Environment26CreateAndRegisterAllocatorERK13OrtMemoryInfoPK11OrtArenaCfgE3$_2NS_9allocatorISA_EEFNS_10unique_ptrINS2_10IAllocatorENS_14default_deleteISE_EEEEsEEE
001ebfff ZN11onnxruntime11Environment26CreateAndRegisterAllocatorERK13OrtMemoryInfoPK11OrtArenaCfgE3$_2
001ec05e NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaIN11onnxruntime7contrib20OpSet_Microsoft_ver1EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS9_EEFvS8_EEE
001ec0fa NSt6__ndk110__function6__baseIFvON4onnx8OpSchemaEEEE
001ec12f ZN4onnx19RegisterOpSetSchemaIN11onnxruntime7contrib20OpSet_Microsoft_ver1EEEviEUlONS_8OpSchemaEE_
001ec191 NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaIN11onnxruntime7contrib21OpSet_ONNX_DeprecatedEEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS9_EEFvS8_EEE
001ec22e ZN4onnx19RegisterOpSetSchemaIN11onnxruntime7contrib21OpSet_ONNX_DeprecatedEEEviEUlONS_8OpSchemaEE_
001ec291 NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaIN11onnxruntime18internal_nhwc_onnx24OpSet_Internal_NHWC_ONNXEEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS9_EEFvS8_EEE
001ec33d ZN4onnx19RegisterOpSetSchemaIN11onnxruntime18internal_nhwc_onnx24OpSet_Internal_NHWC_ONNXEEEviEUlONS_8OpSchemaEE_
001ec3af NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_15OpSet_Onnx_ver1EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ec434 ZN4onnx19RegisterOpSetSchemaINS_15OpSet_Onnx_ver1EEEviEUlONS_8OpSchemaEE_
001ec47e NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_15OpSet_Onnx_ver2EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ec503 ZN4onnx19RegisterOpSetSchemaINS_15OpSet_Onnx_ver2EEEviEUlONS_8OpSchemaEE_
001ec54d NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_15OpSet_Onnx_ver3EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ec5d2 ZN4onnx19RegisterOpSetSchemaINS_15OpSet_Onnx_ver3EEEviEUlONS_8OpSchemaEE_
001ec61c NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_15OpSet_Onnx_ver4EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ec6a1 ZN4onnx19RegisterOpSetSchemaINS_15OpSet_Onnx_ver4EEEviEUlONS_8OpSchemaEE_
001ec6eb NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_15OpSet_Onnx_ver5EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ec770 ZN4onnx19RegisterOpSetSchemaINS_15OpSet_Onnx_ver5EEEviEUlONS_8OpSchemaEE_
001ec7ba NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_15OpSet_Onnx_ver6EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ec83f ZN4onnx19RegisterOpSetSchemaINS_15OpSet_Onnx_ver6EEEviEUlONS_8OpSchemaEE_
001ec889 NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_15OpSet_Onnx_ver7EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ec90e ZN4onnx19RegisterOpSetSchemaINS_15OpSet_Onnx_ver7EEEviEUlONS_8OpSchemaEE_
001ec958 NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_15OpSet_Onnx_ver8EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ec9dd ZN4onnx19RegisterOpSetSchemaINS_15OpSet_Onnx_ver8EEEviEUlONS_8OpSchemaEE_
001eca27 NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_15OpSet_Onnx_ver9EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ecaac ZN4onnx19RegisterOpSetSchemaINS_15OpSet_Onnx_ver9EEEviEUlONS_8OpSchemaEE_
001ecaf6 NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_16OpSet_Onnx_ver10EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ecb7c ZN4onnx19RegisterOpSetSchemaINS_16OpSet_Onnx_ver10EEEviEUlONS_8OpSchemaEE_
001ecbc7 NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_16OpSet_Onnx_ver11EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ecc4d ZN4onnx19RegisterOpSetSchemaINS_16OpSet_Onnx_ver11EEEviEUlONS_8OpSchemaEE_
001ecc98 NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_16OpSet_Onnx_ver12EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ecd1e ZN4onnx19RegisterOpSetSchemaINS_16OpSet_Onnx_ver12EEEviEUlONS_8OpSchemaEE_
001ecd69 NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_16OpSet_Onnx_ver13EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ecdef ZN4onnx19RegisterOpSetSchemaINS_16OpSet_Onnx_ver13EEEviEUlONS_8OpSchemaEE_
001ece3a NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_16OpSet_Onnx_ver14EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ecec0 ZN4onnx19RegisterOpSetSchemaINS_16OpSet_Onnx_ver14EEEviEUlONS_8OpSchemaEE_
001ecf0b NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_16OpSet_Onnx_ver15EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ecf91 ZN4onnx19RegisterOpSetSchemaINS_16OpSet_Onnx_ver15EEEviEUlONS_8OpSchemaEE_
001ecfdc NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_16OpSet_Onnx_ver16EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ed062 ZN4onnx19RegisterOpSetSchemaINS_16OpSet_Onnx_ver16EEEviEUlONS_8OpSchemaEE_
001ed0ad NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_16OpSet_Onnx_ver17EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ed133 ZN4onnx19RegisterOpSetSchemaINS_16OpSet_Onnx_ver17EEEviEUlONS_8OpSchemaEE_
001ed17e NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_16OpSet_Onnx_ver18EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ed204 ZN4onnx19RegisterOpSetSchemaINS_16OpSet_Onnx_ver18EEEviEUlONS_8OpSchemaEE_
001ed24f NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_17OpSet_OnnxML_ver1EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ed2d6 ZN4onnx19RegisterOpSetSchemaINS_17OpSet_OnnxML_ver1EEEviEUlONS_8OpSchemaEE_
001ed322 NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_17OpSet_OnnxML_ver2EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ed3a9 ZN4onnx19RegisterOpSetSchemaINS_17OpSet_OnnxML_ver2EEEviEUlONS_8OpSchemaEE_
001ed3f5 NSt6__ndk110__function6__funcIZN4onnx19RegisterOpSetSchemaINS2_17OpSet_OnnxML_ver3EEEviEUlONS2_8OpSchemaEE_NS_9allocatorIS7_EEFvS6_EEE
001ed47c ZN4onnx19RegisterOpSetSchemaINS_17OpSet_OnnxML_ver3EEEviEUlONS_8OpSchemaEE_
001ed4c8 N11onnxruntime16ProviderHostImplE
001ed4ea N11onnxruntime12ProviderHostE
001ed508 N11onnxruntime40TensorShapeProto_Dimension_Iterator_ImplE
001ed542 N11onnxruntime35TensorShapeProto_Dimension_IteratorE
001ed577 N11onnxruntime23Node__NodeIterator_ImplE
001ed5a0 N11onnxruntime18Node__NodeIteratorE
001ed5c4 N11onnxruntime23Node__EdgeIterator_ImplE
001ed5ed N11onnxruntime18Node__EdgeIteratorE
001ed612 N11onnxruntime28NodeAttributes_Iterator_ImplE
001ed640 N11onnxruntime23NodeAttributes_IteratorE
001ed66f [NSt6__ndk112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
001ed6b2 NSt6__ndk121__basic_string_commonILb1EEE
001ed6db NSt6__ndk120__shared_ptr_emplaceINS_13unordered_mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN11onnxruntime11FuncManager8FuncInfoENS_4hashIS7_EENS_8equal_toIS7_EENS5_INS_4pairIKS7_SA_EEEEEENS5_ISJ_EEEE
001ed7b7 N11onnxruntime10standalone23StandAloneKernelContextE
001ed7ec NSt6__ndk120__shared_ptr_emplaceIN11onnxruntime12_GLOBAL__N_120NnapiProviderFactoryENS_9allocatorIS3_EEEE
001ed856 N11onnxruntime12_GLOBAL__N_120NnapiProviderFactoryE
001ed88a N11onnxruntime25IExecutionProviderFactoryE
001ed8b8 YYY%,
001ed8be 7Y=YYKN11onnxruntime22NnapiExecutionProviderE
001ed8ed NSt6__ndk110__function6__funcIZN11onnxruntime22NnapiExecutionProviderC1EjRKNS_8optionalINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE3$_0NS8_ISE_EEFNS_10unique_ptrINS2_10IAllocatorENS_14default_deleteISH_EEEEsEEE
001ed9d2 ZN11onnxruntime22NnapiExecutionProviderC1EjRKNSt6__ndk18optionalINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEEE3$_0
001eda58 NSt6__ndk110__function6__funcIZN11onnxruntime22NnapiExecutionProviderC1EjRKNS_8optionalINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE3$_1NS8_ISE_EEFNS_10unique_ptrINS2_10IAllocatorENS_14default_deleteISH_EEEEsEEE
001edb3d ZN11onnxruntime22NnapiExecutionProviderC1EjRKNSt6__ndk18optionalINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEEE3$_1
001edbc3 NSt6__ndk110__function6__funcIZNK11onnxruntime22NnapiExecutionProvider13GetCapabilityERKNS2_11GraphViewerERKNS2_18IExecutionProvider13IKernelLookupEE3$_3NS_9allocatorISB_EEFbRKNS2_4NodeEEEE
001edc81 NSt6__ndk110__function6__baseIFbRKN11onnxruntime4NodeEEEE
001edcbb ZNK11onnxruntime22NnapiExecutionProvider13GetCapabilityERKNS_11GraphViewerERKNS_18IExecutionProvider13IKernelLookupEE3$_3
001edd35 NSt6__ndk110__function6__funcIZNK11onnxruntime22NnapiExecutionProvider13GetCapabilityERKNS2_11GraphViewerERKNS2_18IExecutionProvider13IKernelLookupEE3$_4NS_9allocatorISB_EEFbRKNS_6vectorIPKNS2_4NodeENSC_ISH_EEEEEEE
001ede0c NSt6__ndk110__function6__baseIFbRKNS_6vectorIPKN11onnxruntime4NodeENS_9allocatorIS6_EEEEEEE
001ede68 ZNK11onnxruntime22NnapiExecutionProvider13GetCapabilityERKNS_11GraphViewerERKNS_18IExecutionProvider13IKernelLookupEE3$_4
001edee2 NSt6__ndk110__function6__funcIZNK11onnxruntime22NnapiExecutionProvider13GetCapabilityERKNS2_11GraphViewerERKNS2_18IExecutionProvider13IKernelLookupEE3$_5NS_9allocatorISB_EEFNS_12basic_stringIcNS_11char_traitsIcEENSC_IcEEEEvEEE
001edfc5 NSt6__ndk110__function6__baseIFNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEvEEE
001ee023 ZNK11onnxruntime22NnapiExecutionProvider13GetCapabilityERKNS_11GraphViewerERKNS_18IExecutionProvider13IKernelLookupEE3$_5
001ee09d NSt6__ndk110__function6__funcIZN11onnxruntime22NnapiExecutionProvider7CompileERKNS_6vectorINS2_18IExecutionProvider17FusedNodeAndGraphENS_9allocatorIS6_EEEERNS4_INS2_15NodeComputeInfoENS7_ISC_EEEEE3$_8NS7_ISG_EEFiPNS2_14ComputeContextEPPvEEE
001ee18f NSt6__ndk110__function6__baseIFiPN11onnxruntime14ComputeContextEPPvEEE
001ee1d6 ZN11onnxruntime22NnapiExecutionProvider7CompileERKNSt6__ndk16vectorINS_18IExecutionProvider17FusedNodeAndGraphENS1_9allocatorIS4_EEEERNS2_INS_15NodeComputeInfoENS5_ISA_EEEEE3$_8
001ee288 NSt6__ndk110__function6__funcIZN11onnxruntime22NnapiExecutionProvider7CompileERKNS_6vectorINS2_18IExecutionProvider17FusedNodeAndGraphENS_9allocatorIS6_EEEERNS4_INS2_15NodeComputeInfoENS7_ISC_EEEEE3$_9NS7_ISG_EEFvPvEEE
001ee363 NSt6__ndk110__function6__baseIFvPvEEE
001ee389 ZN11onnxruntime22NnapiExecutionProvider7CompileERKNSt6__ndk16vectorINS_18IExecutionProvider17FusedNodeAndGraphENS1_9allocatorIS4_EEEERNS2_INS_15NodeComputeInfoENS5_ISA_EEEEE3$_9
001ee43b NSt6__ndk110__function6__funcIZN11onnxruntime22NnapiExecutionProvider7CompileERKNS_6vectorINS2_18IExecutionProvider17FusedNodeAndGraphENS_9allocatorIS6_EEEERNS4_INS2_15NodeComputeInfoENS7_ISC_EEEEE4$_10NS7_ISG_EEFNS2_6common6StatusEPvPK6OrtApiP16OrtKernelContextEEE
001ee545 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEPvPK6OrtApiP16OrtKernelContextEEE
001ee5a3 ZN11onnxruntime22NnapiExecutionProvider7CompileERKNSt6__ndk16vectorINS_18IExecutionProvider17FusedNodeAndGraphENS1_9allocatorIS4_EEEERNS2_INS_15NodeComputeInfoENS5_ISA_EEEEE4$_10
001ee656 libneuralnetworks.so
001ee675 N11onnxruntime5nnapi27BatchNormalizationOpBuilderE
001ee6ad !%+1:GSYfYYv
001ee739 N11onnxruntime5nnapi13BaseOpBuilderE
001ee75e N11onnxruntime5nnapi10IOpBuilderE
001ee780 N11onnxruntime5nnapi13CastOpBuilderE
001ee7a5 N11onnxruntime5nnapi13ClipOpBuilderE
001ee7ca N11onnxruntime5nnapi15ConcatOpBuilderE
001ee7f1 N11onnxruntime5nnapi21DepthToSpaceOpBuilderE
001ee81e N11onnxruntime5nnapi25DequantizeLinearOpBuilderE
001ee84f N11onnxruntime5nnapi12EluOpBuilderE
001ee873 N11onnxruntime5nnapi16FlattenOpBuilderE
001ee89b N11onnxruntime5nnapi15GatherOpBuilderE
001ee8c2 N11onnxruntime5nnapi17IdentityOpBuilderE
001ee8eb N11onnxruntime5nnapi12LRNOpBuilderE
001ee90f N11onnxruntime5nnapi12PadOpBuilderE
001ee933 N11onnxruntime5nnapi23QuantizeLinearOpBuilderE
001ee962 N11onnxruntime5nnapi13ReluOpBuilderE
001ee987 N11onnxruntime5nnapi16ReshapeOpBuilderE
001ee9af N11onnxruntime5nnapi15ResizeOpBuilderE
001ee9d6 N11onnxruntime5nnapi14SliceOpBuilderE
001ee9fd N11onnxruntime5nnapi16SoftMaxOpBuilderE
001eea25 N11onnxruntime5nnapi16SqueezeOpBuilderE
001eea4d N11onnxruntime5nnapi18TransposeOpBuilderE
001eea77 N11onnxruntime5nnapi18UnsqueezeOpBuilderE
001eeaa1 N11onnxruntime5nnapi15BinaryOpBuilderE
001eeac8 N11onnxruntime5nnapi13PoolOpBuilderE
001eeb0c N11onnxruntime5nnapi13ConvOpBuilderE
001eeb50 N11onnxruntime5nnapi13GemmOpBuilderE
001eeb75 N11onnxruntime5nnapi14UnaryOpBuilderE
001eeb9b N11onnxruntime5nnapi15MinMaxOpBuilderE
001eebc3 NSt6__ndk120__shared_ptr_emplaceIN11onnxruntime22XnnpackProviderFactoryENS_9allocatorIS2_EEEE
001eec21 N11onnxruntime22XnnpackProviderFactoryE
001eec49 N11onnxruntime24XnnpackExecutionProviderE
001eec73 NSt6__ndk110__function6__funcIZN11onnxruntime24XnnpackExecutionProvider17RegisterAllocatorERNS2_16AllocatorManagerEE3$_0NS_9allocatorIS6_EEFNS_10unique_ptrINS2_10IAllocatorENS_14default_deleteISA_EEEEsEEE
001eed41 ZN11onnxruntime24XnnpackExecutionProvider17RegisterAllocatorERNS_16AllocatorManagerEE3$_0
001eed9b NSt6__ndk110__function6__funcIZNK11onnxruntime24XnnpackExecutionProvider13GetCapabilityERKNS2_11GraphViewerERKNS2_18IExecutionProvider13IKernelLookupEE3$_1NS_9allocatorISB_EEFvNS_10unique_ptrINS2_15IndexedSubGraphENS_14default_deleteISF_EEEEEEE
001eee90 NSt6__ndk110__function6__baseIFvNS_10unique_ptrIN11onnxruntime15IndexedSubGraphENS_14default_deleteIS4_EEEEEEE
001eeeff ZNK11onnxruntime24XnnpackExecutionProvider13GetCapabilityERKNS_11GraphViewerERKNS_18IExecutionProvider13IKernelLookupEE3$_1
001eef7b NSt6__ndk120__shared_ptr_pointerIPN11onnxruntime14KernelRegistryENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
001eefeb NSt6__ndk114default_deleteIN11onnxruntime14KernelRegistryEEE
001ef028 NSt6__ndk110__function6__funcIPFbRKN11onnxruntime8NodeUnitERKNS2_11GraphViewerEENS_9allocatorISA_EES9_EE
001ef091 NSt6__ndk110__function6__baseIFbRKN11onnxruntime8NodeUnitERKNS2_11GraphViewerEEEE
001ef0e3 PFbRKN11onnxruntime8NodeUnitERKNS_11GraphViewerEE
001ef115 FbRKN11onnxruntime8NodeUnitERKNS_11GraphViewerEE
001ef146 NSt6__ndk110__function6__funcIPFPKN11onnxruntime8NodeUnitERS4_RKNS2_11GraphViewerERKNS_13unordered_mapIPKNS2_4NodeES5_NS_4hashISD_EENS_8equal_toISD_EENS_9allocatorINS_4pairIKSD_S5_EEEEEEENSI_ISR_EESQ_EE
001ef211 NSt6__ndk110__function6__baseIFPKN11onnxruntime8NodeUnitERS4_RKNS2_11GraphViewerERKNS_13unordered_mapIPKNS2_4NodeES5_NS_4hashISD_EENS_8equal_toISD_EENS_9allocatorINS_4pairIKSD_S5_EEEEEEEEE
001ef2ce PFPKN11onnxruntime8NodeUnitERS1_RKNS_11GraphViewerERKNSt6__ndk113unordered_mapIPKNS_4NodeES2_NS7_4hashISB_EENS7_8equal_toISB_EENS7_9allocatorINS7_4pairIKSB_S2_EEEEEEE
001ef375 FPKN11onnxruntime8NodeUnitERS1_RKNS_11GraphViewerERKNSt6__ndk113unordered_mapIPKNS_4NodeES2_NS7_4hashISB_EENS7_8equal_toISB_EENS7_9allocatorINS7_4pairIKSB_S2_EEEEEEE
001ef42a N11onnxruntime7xnnpack8ConvBaseE
001ef44b N11onnxruntime7xnnpack13XnnpackKernelE
001ef4a8 N11onnxruntime7xnnpack7MaxPoolE
001ef4c8 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusERNS2_11FuncManagerERKNS2_12OpKernelInfoERNS_10unique_ptrINS2_8OpKernelENS_14default_deleteISB_EEEEENS_9allocatorISH_EESG_EE
001ef581 PFN11onnxruntime6common6StatusERNS_11FuncManagerERKNS_12OpKernelInfoERNSt6__ndk110unique_ptrINS_8OpKernelENS7_14default_deleteIS9_EEEEE
001ef609 FN11onnxruntime6common6StatusERNS_11FuncManagerERKNS_12OpKernelInfoERNSt6__ndk110unique_ptrINS_8OpKernelENS7_14default_deleteIS9_EEEEE
001ef690 N11onnxruntime7xnnpack11AveragePoolE
001ef6b5 N11onnxruntime7xnnpack7SoftmaxE
001ef6d5 N11onnxruntime7xnnpack6ResizeE
001ef6f4 N11onnxruntime12UpsampleBaseE
001ef728 N11onnxruntime7xnnpack4GemmE
001ef745 N11onnxruntime8GemmBaseE
001ef75e N11onnxruntime7xnnpack6MatMulE
001ef848 N11onnxruntime7xnnpack4ConvE
001ef890 N11onnxruntime7xnnpack13ConvTransposeE
001ef8b7 N11onnxruntime11RewriteRuleE
001ef8ec N11onnxruntime16EliminateDropoutE
001ef90e N11onnxruntime17ExpandEliminationE
001ef931 N11onnxruntime15CastEliminationE
001ef95b 09N11onnxruntime12DivMulFusionE
001ef97b N11onnxruntime13GemmSumFusionE
001ef9b4 N11onnxruntime19GemmTransposeFusionE
001ef9d9 N11onnxruntime13ConvAddFusionE
001ef9f8 N11onnxruntime13ConvMulFusionE
001efa17 N11onnxruntime12ConvBNFusionE
001efa35 N11onnxruntime23ConvAddActivationFusionE
001efa5e N11onnxruntime12_GLOBAL__N_17actions21FuseConvAddActivationE
001efa9b N11onnxruntime12_GLOBAL__N_19selectors17ConvAddActivationE
001efad6 N11onnxruntime12NodeSelectorE
001efaf4 N11onnxruntime15ConstantFoldingE
001efb15 NSt6__ndk110__function6__funcIZNK11onnxruntime15ConstantFolding9ApplyImplERNS2_5GraphERbiRKNS2_7logging6LoggerEE3$_0NS_9allocatorISB_EEFbRKNS_12basic_stringIcNS_11char_traitsIcEENSC_IcEEEEEEE
001efbd5 NSt6__ndk110__function6__baseIFbRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
001efc35 ZNK11onnxruntime15ConstantFolding9ApplyImplERNS_5GraphERbiRKNS_7logging6LoggerEE3$_0
001efc8a N11onnxruntime32FreeDimensionOverrideTransformerE
001efcbc N11onnxruntime20ConvActivationFusionE
001efce2 N11onnxruntime12_GLOBAL__N_17actions18FuseConvActivationE
001efd1c N11onnxruntime12_GLOBAL__N_19selectors14ConvActivationE
001efd54 N11onnxruntime12_GLOBAL__N_17actions15FuseConvAddReluE
001efd8b N11onnxruntime12_GLOBAL__N_19selectors11ConvAddReluE
001efdc0 N11onnxruntime21DoubleQDQPairsRemoverE
001efde7 NSt6__ndk110__function6__funcIZN11onnxruntime21DoubleQDQPairsRemover15IsNodeRemovableERNS2_5GraphERKmRmS8_S8_E3$_0NS_9allocatorIS9_EEFPKN4onnx11TensorProtoERKNS_12basic_stringIcNS_11char_traitsIcEENSA_IcEEEEEEE
001efeba NSt6__ndk110__function6__baseIFPKN4onnx11TensorProtoERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
001eff2f ZN11onnxruntime21DoubleQDQPairsRemover15IsNodeRemovableERNS_5GraphERKmRmS5_S5_E3$_0
001eff83 ortshared_
001eff8e N11onnxruntime15ConstantSharingE
001effc8 N11onnxruntime30CommonSubexpressionEliminationE
001efff8 N11onnxruntime20GemmActivationFusionE
001f001e N11onnxruntime27DynamicQuantizeMatMulFusionE
001f004b N11onnxruntime10GeluFusionE
001f00b0 N11onnxruntime15AttentionFusionE
001f00d1 N11onnxruntime20EmbedLayerNormFusionE
001f00f7 N11onnxruntime19GatherToSplitFusionE
001f011c N11onnxruntime19GatherToSliceFusionE
001f0141 N11onnxruntime14BiasGeluFusionE
001f0161 N11onnxruntime17BiasSoftmaxFusionE
001f0184 N11onnxruntime17BiasDropoutFusionE
001f01a7 N11onnxruntime14FastGeluFusionE
001f01c7 N11onnxruntime17GeluApproximationE
001f01ea N11onnxruntime17EliminateIdentityE
001f020d NSt6__ndk120__shared_ptr_emplaceIN11onnxruntime12CPUAllocatorENS_9allocatorIS2_EEEE
001f0261 N11onnxruntime21InsertCastTransformerE
001f0288 N11onnxruntime30RemoveDuplicateCastTransformerE
001f02b8 N11onnxruntime15LayerNormFusionE
001f02d9 N11onnxruntime25SimplifiedLayerNormFusionE
001f0304 N11onnxruntime15MatMulAddFusionE
001f0325 N11onnxruntime26MatMulIntegerToFloatFusionE
001f0360 UN11onnxruntime17MatMulScaleFusionE
001f0385 N11onnxruntime21MatmulTransposeFusionE
001f03c0 N11onnxruntime16NchwcTransformerE
001f03e2 N11onnxruntime15NhwcTransformerE
001f0404 HHHH
001f040e N11onnxruntime15NoopEliminationE
001f042f N11onnxruntime14NotWhereFusionE
001f044f N11onnxruntime23OptimizerExecutionFrameE
001f0479 NSt6__ndk110__function6__funcIZN11onnxruntime23OptimizerExecutionFrame4InfoC1ERKNS_6vectorIPKNS2_4NodeENS_9allocatorIS8_EEEERKNS_13unordered_mapINS_12basic_stringIcNS_11char_traitsIcEENS9_IcEEEEPKN4onnx11TensorProtoENS_4hashISJ_EENS_8equal_toISJ_EENS9_INS_4pairIKSJ_SN_EEEEEERKNS2_4PathERKNS2_18IExecutionProviderERKNS_8functionIFbRST_EEEE3$_0NS9_IS1B_EEFNS2_6common6StatusERKNS2_7NodeArgEmEEE
001f0603 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERKNS2_7NodeArgEmEEE
001f0653 ZN11onnxruntime23OptimizerExecutionFrame4InfoC1ERKNSt6__ndk16vectorIPKNS_4NodeENS2_9allocatorIS6_EEEERKNS2_13unordered_mapINS2_12basic_stringIcNS2_11char_traitsIcEENS7_IcEEEEPKN4onnx11TensorProtoENS2_4hashISH_EENS2_8equal_toISH_EENS7_INS2_4pairIKSH_SL_EEEEEERKNS_4PathERKNS_18IExecutionProviderERKNS2_8functionIFbRSR_EEEE3$_0
001f07b0 N11onnxruntime15ClipQuantFusionE
001f07d1 N11onnxruntime26QDQFinalCleanupTransformerE
001f07fd NSt6__ndk110__function6__funcIZN11onnxruntime12_GLOBAL__N_119CleanUpNodeSequenceENS3_12NodeSequenceERNS2_5GraphEmRKNS2_7logging6LoggerEE3$_0NS_9allocatorISB_EEFPKN4onnx11TensorProtoERKNS_12basic_stringIcNS_11char_traitsIcEENSC_IcEEEEEEE
001f08ea ZN11onnxruntime12_GLOBAL__N_119CleanUpNodeSequenceENS0_12NodeSequenceERNS_5GraphEmRKNS_7logging6LoggerEE3$_0
001f0957 N11onnxruntime25QDQPropagationTransformerE
001f0982 NSt6__ndk110__function6__funcIN11onnxruntime12_GLOBAL__N_130GraphConstantInitializerGetterENS_9allocatorIS4_EEFPKN4onnx11TensorProtoERKNS_12basic_stringIcNS_11char_traitsIcEENS5_IcEEEEEEE
001f0a3e N11onnxruntime12_GLOBAL__N_130GraphConstantInitializerGetterE
001f0a7c N11onnxruntime20QDQS8ToU8TransformerE
001f0aa2 N11onnxruntime15ReluQuantFusionE
001f0ac3 N11onnxruntime28QDQSelectorActionTransformerE
001f0af1 N11onnxruntime3QDQ20DropQDQNodesSelectorE
001f0b1b N11onnxruntime3QDQ19DropDQNodesSelectorE
001f0b44 N11onnxruntime3QDQ13UnarySelectorE
001f0b67 N11onnxruntime3QDQ14BinarySelectorE
001f0b8b N11onnxruntime3QDQ14MatMulSelectorE
001f0baf N11onnxruntime3QDQ13WhereSelectorE
001f0bd2 N11onnxruntime3QDQ17QDQReplaceWithNewE
001f0bf9 N11onnxruntime19ReplaceWithNewFixedE
001f0c1e N11onnxruntime3QDQ23UnaryReplaceWithQLinearE
001f0c4b N11onnxruntime3QDQ18ReplaceWithQLinearE
001f0c73 N11onnxruntime3QDQ24MatMulReplaceWithQLinearE
001f0ca1 N11onnxruntime6ActionE
001f0cb8 N11onnxruntime3QDQ21SplitReplaceWithQuantE
001f0ce3 N11onnxruntime3QDQ20GemmReplaceWithQuantE
001f0d0d N11onnxruntime3QDQ24BinaryReplaceWithQLinearE
001f0d3b N11onnxruntime3QDQ26VariadicReplaceWithQLinearE
001f0d6b N11onnxruntime3QDQ22ConvReplaceWithQLinearE
001f0d97 N11onnxruntime3QDQ23WhereReplaceWithQLinearE
001f0dd0 N11onnxruntime3QDQ21ConvNodeGroupSelectorE
001f0dfb N11onnxruntime3QDQ17NodeGroupSelectorE
001f0e22 N11onnxruntime3QDQ23MatMulNodeGroupSelectorE
001f0e4f N11onnxruntime3QDQ12BaseSelectorE
001f0e71 N11onnxruntime3QDQ21InputVariadicSelectorE
001f0e9c N11onnxruntime3QDQ22OutputVariadicSelectorE
001f0ec8 N11onnxruntime3QDQ12ConvSelectorE
001f0eea N11onnxruntime3QDQ12GemmSelectorE
001f0f0c N11onnxruntime3QDQ24DropQDQNodeGroupSelectorE
001f0f3a N11onnxruntime3QDQ23DropDQNodeGroupSelectorE
001f0f67 N11onnxruntime3QDQ22UnaryNodeGroupSelectorE
001f0f93 N11onnxruntime3QDQ23BinaryNodeGroupSelectorE
001f0fc0 N11onnxruntime3QDQ25VariadicNodeGroupSelectorE
001f0fef N11onnxruntime3QDQ21GemmNodeGroupSelectorE
001f101a N11onnxruntime3QDQ22WhereNodeGroupSelectorE
001f1046 NSt6__ndk110__function6__funcIZNK11onnxruntime3QDQ24DropQDQNodeGroupSelector5CheckERKNS2_11GraphViewerERKNS2_4NodeERKNS_6vectorIPS9_NS_9allocatorISC_EEEESH_E3$_2NSD_ISI_EEFPKN4onnx11TensorProtoERKNS_12basic_stringIcNS_11char_traitsIcEENSD_IcEEEEEEE
001f113f ZNK11onnxruntime3QDQ24DropQDQNodeGroupSelector5CheckERKNS_11GraphViewerERKNS_4NodeERKNSt6__ndk16vectorIPS6_NS8_9allocatorISA_EEEESF_E3$_2
001f11c9 NSt6__ndk110__function6__funcIZNK11onnxruntime3QDQ23DropDQNodeGroupSelector5CheckERKNS2_11GraphViewerERKNS2_4NodeERKNS_6vectorIPS9_NS_9allocatorISC_EEEESH_E3$_3NSD_ISI_EEFPKN4onnx11TensorProtoERKNS_12basic_stringIcNS_11char_traitsIcEENSD_IcEEEEEEE
001f12c1 ZNK11onnxruntime3QDQ23DropDQNodeGroupSelector5CheckERKNS_11GraphViewerERKNS_4NodeERKNSt6__ndk16vectorIPS6_NS8_9allocatorISA_EEEESF_E3$_3
001f134a N11onnxruntime15QuickGeluFusionE
001f136b N11onnxruntime12FuseReluClipE
001f1389 N11onnxruntime13ReshapeFusionE
001f13a8 N11onnxruntime15RocmBlasAltImplE
001f13c9 N11onnxruntime25RuleBasedGraphTransformerE
001f13f4 N11onnxruntime11RemoveNodesE
001f1411 N11onnxruntime15MergeIntoTargetE
001f1432 N11onnxruntime14ReplaceWithNewE
001f1452 N11onnxruntime25SelectorActionTransformerE
001f147d N11onnxruntime19SkipLayerNormFusionE
001f14a2 N11onnxruntime14EliminateSliceE
001f14c2 N11onnxruntime17MemcpyTransformerE
001f14e5 NSt6__ndk110__function6__funcIZN11onnxruntime21TransformerMemcpyImpl11ProcessDefsERNS2_4NodeERKNS2_21KernelRegistryManagerERNS_13unordered_mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEPKN4onnx11TensorProtoENS_4hashISF_EENS_8equal_toISF_EENSD_INS_4pairIKSF_SJ_EEEEEEE3$_0NSD_ISU_EEFNS2_6common6StatusERKNS2_7NodeArgEmEEE
001f1637 ZN11onnxruntime21TransformerMemcpyImpl11ProcessDefsERNS_4NodeERKNS_21KernelRegistryManagerERNSt6__ndk113unordered_mapINS6_12basic_stringIcNS6_11char_traitsIcEENS6_9allocatorIcEEEEPKN4onnx11TensorProtoENS6_4hashISD_EENS6_8equal_toISD_EENSB_INS6_4pairIKSD_SH_EEEEEEE3$_0
001f1744 NSt6__ndk110__function6__funcIZN11onnxruntime21TransformerMemcpyImpl19ProcessInitializersERKNS2_21KernelRegistryManagerERKNS_13unordered_mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEPKN4onnx11TensorProtoENS_4hashISD_EENS_8equal_toISD_EENSB_INS_4pairIKSD_SH_EEEEEEE3$_1NSB_IST_EEFNS2_6common6StatusERKNS2_7NodeArgEmEEE
001f1893 ZN11onnxruntime21TransformerMemcpyImpl19ProcessInitializersERKNS_21KernelRegistryManagerERKNSt6__ndk113unordered_mapINS4_12basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEPKN4onnx11TensorProtoENS4_4hashISB_EENS4_8equal_toISB_EENS9_INS4_4pairIKSB_SF_EEEEEEE3$_1
001f199f NSt6__ndk110__function6__funcIZN11onnxruntime21TransformerMemcpyImpl19ProcessInitializersERKNS2_21KernelRegistryManagerERKNS_13unordered_mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEPKN4onnx11TensorProtoENS_4hashISD_EENS_8equal_toISD_EENSB_INS_4pairIKSD_SH_EEEEEEE3$_2NSB_IST_EEFNS2_6common6StatusERKNS2_7NodeArgEmEEE
001f1aee ZN11onnxruntime21TransformerMemcpyImpl19ProcessInitializersERKNS_21KernelRegistryManagerERKNSt6__ndk113unordered_mapINS4_12basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEPKN4onnx11TensorProtoENS4_4hashISB_EENS4_8equal_toISB_EENS9_INS4_4pairIKSB_SF_EEEEEEE3$_2
001f1bfa N11onnxruntime12ApiValueInfoE
001f1c18 N26onnx_layout_transformation3api12ValueInfoRefE
001f1c49 N11onnxruntime9ApiTensorE
001f1c63 N26onnx_layout_transformation3api9TensorRefE
001f1c90 N11onnxruntime7ApiNodeE
001f1ca8 N26onnx_layout_transformation3api7NodeRefE
001f1cd3 N11onnxruntime8ApiGraphE
001f1cec N26onnx_layout_transformation3api8GraphRefE
001f1d19 N11onnxruntime18TransposeOptimizerE
001f1d3d N11onnxruntime20UnsqueezeEliminationE
001f1d64 N11onnxruntime20CPUExecutionProviderE
001f1d8a NSt6__ndk110__function6__funcIZN11onnxruntime20CPUExecutionProvider17RegisterAllocatorERNS2_16AllocatorManagerEE3$_0NS_9allocatorIS6_EEFNS_10unique_ptrINS2_10IAllocatorENS_14default_deleteISA_EEEEsEEE
001f1e53 ZN11onnxruntime20CPUExecutionProvider17RegisterAllocatorERNS_16AllocatorManagerEE3$_0
001f1ea9 N11onnxruntime17ElementWiseKernelINS_8functors3EluIfEEEE
001f1ee2 N11onnxruntime8functors3EluIfEE
001f1f02 N11onnxruntime8functors26ElementWiseRangedTransformIfEE
001f1f3a NSt6__ndk110__function6__funcIN11onnxruntime8functors3EluIfEENS_9allocatorIS5_EEFvllEEE
001f1f92 NSt6__ndk110__function6__baseIFvllEEE
001f1fb8 N11onnxruntime17ElementWiseKernelINS_8functors11HardSigmoidIfEEEE
001f1ffa N11onnxruntime8functors11HardSigmoidIfEE
001f2023 NSt6__ndk110__function6__funcIN11onnxruntime8functors11HardSigmoidIfEENS_9allocatorIS5_EEFvllEEE
001f2084 N11onnxruntime17ElementWiseKernelINS_8functors9LeakyReluIfEEEE
001f20c3 N11onnxruntime8functors9LeakyReluIfEE
001f20e9 NSt6__ndk110__function6__funcIN11onnxruntime8functors9LeakyReluIfEENS_9allocatorIS5_EEFvllEEE
001f2147 N11onnxruntime17ElementWiseKernelINS_8functors4ReluIfEEEE
001f2181 N11onnxruntime8functors4ReluIfEE
001f21a2 NSt6__ndk110__function6__funcIN11onnxruntime8functors4ReluIfEENS_9allocatorIS5_EEFvllEEE
001f21fb N11onnxruntime17ElementWiseKernelINS_8functors4ReluIdEEEE
001f2235 N11onnxruntime8functors4ReluIdEE
001f2256 N11onnxruntime8functors26ElementWiseRangedTransformIdEE
001f228e NSt6__ndk110__function6__funcIN11onnxruntime8functors4ReluIdEENS_9allocatorIS5_EEFvllEEE
001f22e7 N11onnxruntime17ElementWiseKernelINS_8functors4ReluIaEEEE
001f2321 N11onnxruntime8functors4ReluIaEE
001f2342 N11onnxruntime8functors26ElementWiseRangedTransformIaEE
001f237a NSt6__ndk110__function6__funcIN11onnxruntime8functors4ReluIaEENS_9allocatorIS5_EEFvllEEE
001f23d3 N11onnxruntime17ElementWiseKernelINS_8functors4ReluIiEEEE
001f240d N11onnxruntime8functors4ReluIiEE
001f242e N11onnxruntime8functors26ElementWiseRangedTransformIiEE
001f2466 NSt6__ndk110__function6__funcIN11onnxruntime8functors4ReluIiEENS_9allocatorIS5_EEFvllEEE
001f24bf N11onnxruntime17ElementWiseKernelINS_8functors4SeluIfEEEE
001f24f9 N11onnxruntime8functors4SeluIfEE
001f251a NSt6__ndk110__function6__funcIN11onnxruntime8functors4SeluIfEENS_9allocatorIS5_EEFvllEEE
001f2573 N11onnxruntime17ElementWiseKernelINS_8functors7SigmoidIfEEEE
001f25b0 N11onnxruntime8functors7SigmoidIfEE
001f25d4 NSt6__ndk110__function6__funcIN11onnxruntime8functors7SigmoidIfEENS_9allocatorIS5_EEFvllEEE
001f2630 N11onnxruntime17ElementWiseKernelINS_8functors7SigmoidIdEEEE
001f266d N11onnxruntime8functors7SigmoidIdEE
001f2691 NSt6__ndk110__function6__funcIN11onnxruntime8functors7SigmoidIdEENS_9allocatorIS5_EEFvllEEE
001f26ed N11onnxruntime17ElementWiseKernelINS_8functors8SoftplusIfEEEE
001f272b N11onnxruntime8functors8SoftplusIfEE
001f2750 NSt6__ndk110__function6__funcIN11onnxruntime8functors8SoftplusIfEENS_9allocatorIS5_EEFvllEEE
001f27ad N11onnxruntime17ElementWiseKernelINS_8functors8SoftsignIfEEEE
001f27eb N11onnxruntime8functors8SoftsignIfEE
001f2810 NSt6__ndk110__function6__funcIN11onnxruntime8functors8SoftsignIfEENS_9allocatorIS5_EEFvllEEE
001f286d N11onnxruntime17ElementWiseKernelINS_8functors4TanhIfEEEE
001f28a7 N11onnxruntime8functors4TanhIfEE
001f28c8 NSt6__ndk110__function6__funcIN11onnxruntime8functors4TanhIfEENS_9allocatorIS5_EEFvllEEE
001f2921 N11onnxruntime17ElementWiseKernelINS_8functors4TanhIdEEEE
001f295b N11onnxruntime8functors4TanhIdEE
001f297c NSt6__ndk110__function6__funcIN11onnxruntime8functors4TanhIdEENS_9allocatorIS5_EEFvllEEE
001f29d5 N11onnxruntime17ElementWiseKernelINS_8functors4CeluIfEEEE
001f2a0f N11onnxruntime8functors4CeluIfEE
001f2a30 NSt6__ndk110__function6__funcIN11onnxruntime8functors4CeluIfEENS_9allocatorIS5_EEFvllEEE
001f2a89 N11onnxruntime17ElementWiseKernelINS_8functors15ThresholdedReluIfEEEE
001f2acf N11onnxruntime8functors15ThresholdedReluIfEE
001f2afc NSt6__ndk110__function6__funcIN11onnxruntime8functors15ThresholdedReluIfEENS_9allocatorIS5_EEFvllEEE
001f2b61 N11onnxruntime8functors18ParametricSoftplusIfEE
001f2b91 N11onnxruntime8functors10ScaledTanhIfEE
001f2bb9 N11onnxruntime20OrtValueTensorSlicerIK8OrtValueE8IteratorE
001f2bf4 N11onnxruntime4ScanILi8EEE
001f2c0f N11onnxruntime11controlflow18IControlFlowKernelE
001f2c40 NSt6__ndk110__function6__funcIPFN11onnxruntime20OrtValueTensorSlicerIK8OrtValueEERS5_llENS_9allocatorIS9_EES8_EE
001f2cb1 NSt6__ndk110__function6__baseIFN11onnxruntime20OrtValueTensorSlicerIK8OrtValueEERS5_llEEE
001f2d0b PFN11onnxruntime20OrtValueTensorSlicerIK8OrtValueEERS2_llE
001f2d46 FN11onnxruntime20OrtValueTensorSlicerIK8OrtValueEERS2_llE
001f2d80 NSt6__ndk110__function6__funcIPFN11onnxruntime20OrtValueTensorSlicerI8OrtValueEERS4_llENS_9allocatorIS8_EES7_EE
001f2df0 NSt6__ndk110__function6__baseIFN11onnxruntime20OrtValueTensorSlicerI8OrtValueEERS4_llEEE
001f2e49 PFN11onnxruntime20OrtValueTensorSlicerI8OrtValueEERS1_llE
001f2e83 FN11onnxruntime20OrtValueTensorSlicerI8OrtValueEERS1_llE
001f2ebc NSt6__ndk110__function6__funcIZN11onnxruntime4ScanILi8EE4InitERKNS2_12OpKernelInfoEE3$_0NS_9allocatorIS8_EEFNS2_6common6StatusERKN3gsl4spanIKmLm18446744073709551615EEERKNS2_6TensorERSJ_PNS2_6StreamEEEE
001f2f86 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERKN3gsl4spanIKmLm18446744073709551615EEERKNS2_6TensorERSB_PNS2_6StreamEEEE
001f300d ZN11onnxruntime4ScanILi8EE4InitERKNS_12OpKernelInfoEE3$_0
001f3047 NSt6__ndk110__function6__funcIZN11onnxruntime4ScanILi8EE4InitERKNS2_12OpKernelInfoEE3$_1NS_9allocatorIS8_EEFNS2_6common6StatusEPvmEEE
001f30cd NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEPvmEEE
001f3110 ZN11onnxruntime4ScanILi8EE4InitERKNS_12OpKernelInfoEE3$_1
001f314a N11onnxruntime20OrtValueTensorSlicerI8OrtValueE8IteratorE
001f3185 NSt6__ndk110__function6__funcIZN11onnxruntime4scan6detail15IterateSequenceERNS2_23OpKernelContextInternalERKNS2_12SessionStateERNS_6vectorINS4_17LoopStateVariableENS_9allocatorISB_EEEERNSA_INS2_20OrtValueTensorSlicerIK8OrtValueE8IteratorENSC_ISK_EEEEliiiRKNSA_IPSI_NSC_ISO_EEEERNSA_INS_10unique_ptrINS4_14OutputIteratorENS_14default_deleteISU_EEEENSC_ISX_EEEERKNS2_19FeedsFetchesManagerEE3$_1NSC_IS14_EEFNS2_6common6StatusERKNS2_11TensorShapeERK13OrtMemoryInfoRSH_RbEEE
001f335b NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERKNS2_11TensorShapeERK13OrtMemoryInfoR8OrtValueRbEEE
001f33cc ZN11onnxruntime4scan6detail15IterateSequenceERNS_23OpKernelContextInternalERKNS_12SessionStateERNSt6__ndk16vectorINS1_17LoopStateVariableENS7_9allocatorIS9_EEEERNS8_INS_20OrtValueTensorSlicerIK8OrtValueE8IteratorENSA_ISI_EEEEliiiRKNS8_IPSG_NSA_ISM_EEEERNS8_INS7_10unique_ptrINS1_14OutputIteratorENS7_14default_deleteISS_EEEENSA_ISV_EEEERKNS_19FeedsFetchesManagerEE3$_1
001f353d N11onnxruntime2IfE
001f3551 NSt6__ndk110__function6__funcIZN11onnxruntime6IfImpl7ExecuteERKNS2_19FeedsFetchesManagerEE3$_4NS_9allocatorIS7_EEFNS2_6common6StatusERKNS2_11TensorShapeERK13OrtMemoryInfoR8OrtValueRbEEE
001f360b ZN11onnxruntime6IfImpl7ExecuteERKNS_19FeedsFetchesManagerEE3$_4
001f364b N11onnxruntime4LoopE
001f3660 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusEPvRNS_6vectorI8OrtValueNS_9allocatorIS7_EEEES5_mENS8_ISD_EESC_EE
001f36de NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEPvRNS_6vectorI8OrtValueNS_9allocatorIS7_EEEES5_mEEE
001f374e PFN11onnxruntime6common6StatusEPvRNSt6__ndk16vectorI8OrtValueNS3_9allocatorIS5_EEEES2_mE
001f37a7 FN11onnxruntime6common6StatusEPvRNSt6__ndk16vectorI8OrtValueNS3_9allocatorIS5_EEEES2_mE
001f37ff N11onnxruntime4ScanILi9EEE
001f381a NSt6__ndk110__function6__funcIZN11onnxruntime4ScanILi9EE4InitERKNS2_12OpKernelInfoEE3$_0NS_9allocatorIS8_EEFNS2_6common6StatusERKN3gsl4spanIKmLm18446744073709551615EEERKNS2_6TensorERSJ_PNS2_6StreamEEEE
001f38e4 ZN11onnxruntime4ScanILi9EE4InitERKNS_12OpKernelInfoEE3$_0
001f391e NSt6__ndk110__function6__funcIZN11onnxruntime4ScanILi9EE4InitERKNS2_12OpKernelInfoEE3$_1NS_9allocatorIS8_EEFNS2_6common6StatusEPvmEEE
001f39a4 ZN11onnxruntime4ScanILi9EE4InitERKNS_12OpKernelInfoEE3$_1
001f39de N11onnxruntime18CpuProviderFactoryE
001f3a02 NSt6__ndk120__shared_ptr_emplaceIN11onnxruntime18CpuProviderFactoryENS_9allocatorIS2_EEEE
001f3a5c N11onnxruntime19ProviderHostCPUImplE
001f3a81 N11onnxruntime15ProviderHostCPUE
001f3aa6 TTT3
001f3ac4 N11onnxruntime12_GLOBAL__N_115ConstantOfShapeE
001f3af3 N11onnxruntime19ConstantOfShapeBaseINS_8TypeListIJlNS_9MLFloat16EfdasihtjmbEEEEE
001f3b44 N11onnxruntime12RandomNormalE
001f3b62 N11onnxruntime16RandomNormalLikeE
001f3b84 N11onnxruntime13RandomUniformE
001f3ba3 N11onnxruntime17RandomUniformLikeE
001f3bc6 N11onnxruntime11MultinomialE
001f3be3 N11onnxruntime5RangeE
001f3bf9 N11onnxruntime4ClipE
001f3c0e N11onnxruntime6Clip_6IfEE
001f3c28 N11onnxruntime13clip_internal10Clip_6BaseIfEE
001f3c56 N11onnxruntime6CumSumIfEE
001f3c70 N11onnxruntime6CumSumIdEE
001f3c8a N11onnxruntime6CumSumIiEE
001f3ca4 N11onnxruntime6CumSumIlEE
001f3cbe N11onnxruntime3DetIfEE
001f3cd6 ,,,,
001f3cdc ,,,!N11onnxruntime6EinsumE
001f3cf7 NSt6__ndk110__function6__funcIPFNS_10unique_ptrIN11onnxruntime6TensorENS_14default_deleteIS4_EEEERKS4_llNS_10shared_ptrINS3_10IAllocatorEEEPvENS_9allocatorISF_EESE_EE
001f3d9e NSt6__ndk110__function6__baseIFNS_10unique_ptrIN11onnxruntime6TensorENS_14default_deleteIS4_EEEERKS4_llNS_10shared_ptrINS3_10IAllocatorEEEPvEEE
001f3e2e PFNSt6__ndk110unique_ptrIN11onnxruntime6TensorENS_14default_deleteIS2_EEEERKS2_llNS_10shared_ptrINS1_10IAllocatorEEEPvE
001f3ea6 FNSt6__ndk110unique_ptrIN11onnxruntime6TensorENS_14default_deleteIS2_EEEERKS2_llNS_10shared_ptrINS1_10IAllocatorEEEPvE
001f3f1d NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusERKN3gsl4spanIKmLm18446744073709551615EEERKNS2_6TensorERSB_PKNS2_11TensorShapeEPvENS_9allocatorISK_EESJ_EE
001f3fc4 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERKN3gsl4spanIKmLm18446744073709551615EEERKNS2_6TensorERSB_PKNS2_11TensorShapeEPvEEE
001f4054 PFN11onnxruntime6common6StatusERKN3gsl4spanIKmLm18446744073709551615EEERKNS_6TensorERS8_PKNS_11TensorShapeEPvE
001f40c3 FN11onnxruntime6common6StatusERKN3gsl4spanIKmLm18446744073709551615EEERKNS_6TensorERS8_PKNS_11TensorShapeEPvE
001f4131 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusEPKfS6_PfmmmmmmmPNS2_11concurrency10ThreadPoolEPvENS_9allocatorISD_EESC_EE
001f41b8 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEPKfS6_PfmmmmmmmPNS2_11concurrency10ThreadPoolEPvEEE
001f4228 PFN11onnxruntime6common6StatusEPKfS3_PfmmmmmmmPNS_11concurrency10ThreadPoolEPvE
001f4278 FN11onnxruntime6common6StatusEPKfS3_PfmmmmmmmPNS_11concurrency10ThreadPoolEPvE
001f42c7 NSt6__ndk110__function6__funcIPFNS_10unique_ptrIN11onnxruntime6TensorENS_14default_deleteIS4_EEEERKS4_N3gsl4spanIKlLm18446744073709551615EEEbNS_10shared_ptrINS3_10IAllocatorEEEPKNS3_11TensorShapeEPNS3_11concurrency10ThreadPoolEPvENS_9allocatorISP_EESO_EE
001f43c6 NSt6__ndk110__function6__baseIFNS_10unique_ptrIN11onnxruntime6TensorENS_14default_deleteIS4_EEEERKS4_N3gsl4spanIKlLm18446744073709551615EEEbNS_10shared_ptrINS3_10IAllocatorEEEPKNS3_11TensorShapeEPNS3_11concurrency10ThreadPoolEPvEEE
001f44ae PFNSt6__ndk110unique_ptrIN11onnxruntime6TensorENS_14default_deleteIS2_EEEERKS2_N3gsl4spanIKlLm18446744073709551615EEEbNS_10shared_ptrINS1_10IAllocatorEEEPKNS1_11TensorShapeEPNS1_11concurrency10ThreadPoolEPvE
001f457e FNSt6__ndk110unique_ptrIN11onnxruntime6TensorENS_14default_deleteIS2_EEEERKS2_N3gsl4spanIKlLm18446744073709551615EEEbNS_10shared_ptrINS1_10IAllocatorEEEPKNS1_11TensorShapeEPNS1_11concurrency10ThreadPoolEPvE
001f464d NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusERKNS2_6TensorERS5_PvENS_9allocatorISB_EESA_EE
001f46b8 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERKNS2_6TensorERS5_PvEEE
001f470c PFN11onnxruntime6common6StatusERKNS_6TensorERS2_PvE
001f4740 FN11onnxruntime6common6StatusERKNS_6TensorERS2_PvE
001f4773 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusEPKiS6_PimmmmmmmPNS2_11concurrency10ThreadPoolEPvENS_9allocatorISD_EESC_EE
001f47fa NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEPKiS6_PimmmmmmmPNS2_11concurrency10ThreadPoolEPvEEE
001f486a PFN11onnxruntime6common6StatusEPKiS3_PimmmmmmmPNS_11concurrency10ThreadPoolEPvE
001f48ba FN11onnxruntime6common6StatusEPKiS3_PimmmmmmmPNS_11concurrency10ThreadPoolEPvE
001f4909 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusEPKdS6_PdmmmmmmmPNS2_11concurrency10ThreadPoolEPvENS_9allocatorISD_EESC_EE
001f4990 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEPKdS6_PdmmmmmmmPNS2_11concurrency10ThreadPoolEPvEEE
001f4a00 PFN11onnxruntime6common6StatusEPKdS3_PdmmmmmmmPNS_11concurrency10ThreadPoolEPvE
001f4a50 FN11onnxruntime6common6StatusEPKdS3_PdmmmmmmmPNS_11concurrency10ThreadPoolEPvE
001f4a9f NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusEPKlS6_PlmmmmmmmPNS2_11concurrency10ThreadPoolEPvENS_9allocatorISD_EESC_EE
001f4b26 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEPKlS6_PlmmmmmmmPNS2_11concurrency10ThreadPoolEPvEEE
001f4b96 PFN11onnxruntime6common6StatusEPKlS3_PlmmmmmmmPNS_11concurrency10ThreadPoolEPvE
001f4be6 FN11onnxruntime6common6StatusEPKlS3_PlmmmmmmmPNS_11concurrency10ThreadPoolEPvE
001f4c41 ,,,,
001f4c47 ,,,!
001f4c4c ,,,,
001f4c52 ,,,!
001f4c57 ,,,,
001f4c5d ,,,!
001f4c62 ,,,,
001f4c68 ,,,!
001f4c6d 3333L
001f4c73 333]n"
001f4c7a 3333L
001f4c80 333]n"N11onnxruntime3PowE
001f4c9a N11onnxruntime5Min_8E
001f4cb0 N11onnxruntime5Max_8E
001f4cc6 N11onnxruntime3NotE
001f4cda N11onnxruntime3AndE
001f4cee N11onnxruntime2OrE
001f4d01 N11onnxruntime3XorE
001f4d15 N11onnxruntime3ModE
001f4d29 N11onnxruntime3AddIfEE
001f4d40 N11onnxruntime3AddIdEE
001f4d57 N11onnxruntime3AddIiEE
001f4d6e N11onnxruntime3AddIlEE
001f4d85 N11onnxruntime3SubIfEE
001f4d9c N11onnxruntime3SubIdEE
001f4db3 N11onnxruntime3SubIiEE
001f4dca N11onnxruntime3SubIlEE
001f4de1 N11onnxruntime3MulIfEE
001f4df8 N11onnxruntime3MulIdEE
001f4e0f N11onnxruntime3MulIiEE
001f4e26 N11onnxruntime3MulIlEE
001f4e3d N11onnxruntime3DivIfEE
001f4e54 N11onnxruntime3DivIdEE
001f4e6b N11onnxruntime3DivIiEE
001f4e82 N11onnxruntime3DivIlEE
001f4e99 N11onnxruntime17ElementWiseKernelINS_8functors3AbsIfEEEE
001f4ed2 N11onnxruntime8functors3AbsIfEE
001f4ef2 NSt6__ndk110__function6__funcIN11onnxruntime8functors3AbsIfEENS_9allocatorIS5_EEFvllEEE
001f4f4a N11onnxruntime17ElementWiseKernelINS_8functors3AbsIdEEEE
001f4f83 N11onnxruntime8functors3AbsIdEE
001f4fa3 NSt6__ndk110__function6__funcIN11onnxruntime8functors3AbsIdEENS_9allocatorIS5_EEFvllEEE
001f4ffb N11onnxruntime17ElementWiseKernelINS_8functors3AbsIaEEEE
001f5034 N11onnxruntime8functors3AbsIaEE
001f5054 NSt6__ndk110__function6__funcIN11onnxruntime8functors3AbsIaEENS_9allocatorIS5_EEFvllEEE
001f50ac N11onnxruntime17ElementWiseKernelINS_8functors3AbsIsEEEE
001f50e5 N11onnxruntime8functors3AbsIsEE
001f5105 N11onnxruntime8functors26ElementWiseRangedTransformIsEE
001f513d NSt6__ndk110__function6__funcIN11onnxruntime8functors3AbsIsEENS_9allocatorIS5_EEFvllEEE
001f5195 N11onnxruntime17ElementWiseKernelINS_8functors3AbsIiEEEE
001f51ce N11onnxruntime8functors3AbsIiEE
001f51ee NSt6__ndk110__function6__funcIN11onnxruntime8functors3AbsIiEENS_9allocatorIS5_EEFvllEEE
001f5246 N11onnxruntime17ElementWiseKernelINS_8functors3AbsIlEEEE
001f527f N11onnxruntime8functors3AbsIlEE
001f529f N11onnxruntime8functors26ElementWiseRangedTransformIlEE
001f52d7 NSt6__ndk110__function6__funcIN11onnxruntime8functors3AbsIlEENS_9allocatorIS5_EEFvllEEE
001f532f N11onnxruntime17ElementWiseKernelINS_8functors3AbsIhEEEE
001f5368 N11onnxruntime8functors3AbsIhEE
001f5388 N11onnxruntime8functors26ElementWiseRangedTransformIhEE
001f53c0 NSt6__ndk110__function6__funcIN11onnxruntime8functors3AbsIhEENS_9allocatorIS5_EEFvllEEE
001f5418 N11onnxruntime17ElementWiseKernelINS_8functors3AbsItEEEE
001f5451 N11onnxruntime8functors3AbsItEE
001f5471 N11onnxruntime8functors26ElementWiseRangedTransformItEE
001f54a9 NSt6__ndk110__function6__funcIN11onnxruntime8functors3AbsItEENS_9allocatorIS5_EEFvllEEE
001f5501 N11onnxruntime17ElementWiseKernelINS_8functors3AbsIjEEEE
001f553a N11onnxruntime8functors3AbsIjEE
001f555a N11onnxruntime8functors26ElementWiseRangedTransformIjEE
001f5592 NSt6__ndk110__function6__funcIN11onnxruntime8functors3AbsIjEENS_9allocatorIS5_EEFvllEEE
001f55ea N11onnxruntime17ElementWiseKernelINS_8functors3AbsImEEEE
001f5623 N11onnxruntime8functors3AbsImEE
001f5643 N11onnxruntime8functors26ElementWiseRangedTransformImEE
001f567b NSt6__ndk110__function6__funcIN11onnxruntime8functors3AbsImEENS_9allocatorIS5_EEFvllEEE
001f56d3 N11onnxruntime17ElementWiseKernelINS_8functors3NegIfEEEE
001f570c N11onnxruntime8functors3NegIfEE
001f572c NSt6__ndk110__function6__funcIN11onnxruntime8functors3NegIfEENS_9allocatorIS5_EEFvllEEE
001f5784 N11onnxruntime17ElementWiseKernelINS_8functors3NegIdEEEE
001f57bd N11onnxruntime8functors3NegIdEE
001f57dd NSt6__ndk110__function6__funcIN11onnxruntime8functors3NegIdEENS_9allocatorIS5_EEFvllEEE
001f5835 N11onnxruntime17ElementWiseKernelINS_8functors3NegIaEEEE
001f586e N11onnxruntime8functors3NegIaEE
001f588e NSt6__ndk110__function6__funcIN11onnxruntime8functors3NegIaEENS_9allocatorIS5_EEFvllEEE
001f58e6 N11onnxruntime17ElementWiseKernelINS_8functors3NegIiEEEE
001f591f N11onnxruntime8functors3NegIiEE
001f593f NSt6__ndk110__function6__funcIN11onnxruntime8functors3NegIiEENS_9allocatorIS5_EEFvllEEE
001f5997 N11onnxruntime17ElementWiseKernelINS_8functors3NegIlEEEE
001f59d0 N11onnxruntime8functors3NegIlEE
001f59f0 NSt6__ndk110__function6__funcIN11onnxruntime8functors3NegIlEENS_9allocatorIS5_EEFvllEEE
001f5a48 N11onnxruntime17ElementWiseKernelINS_8functors5FloorIfEEEE
001f5a83 N11onnxruntime8functors5FloorIfEE
001f5aa5 NSt6__ndk110__function6__funcIN11onnxruntime8functors5FloorIfEENS_9allocatorIS5_EEFvllEEE
001f5aff N11onnxruntime17ElementWiseKernelINS_8functors5FloorIdEEEE
001f5b3a N11onnxruntime8functors5FloorIdEE
001f5b5c NSt6__ndk110__function6__funcIN11onnxruntime8functors5FloorIdEENS_9allocatorIS5_EEFvllEEE
001f5bb6 N11onnxruntime17ElementWiseKernelINS_8functors4CeilIfEEEE
001f5bf0 N11onnxruntime8functors4CeilIfEE
001f5c11 NSt6__ndk110__function6__funcIN11onnxruntime8functors4CeilIfEENS_9allocatorIS5_EEFvllEEE
001f5c6a N11onnxruntime17ElementWiseKernelINS_8functors4CeilIdEEEE
001f5ca4 N11onnxruntime8functors4CeilIdEE
001f5cc5 NSt6__ndk110__function6__funcIN11onnxruntime8functors4CeilIdEENS_9allocatorIS5_EEFvllEEE
001f5d1e N11onnxruntime17ElementWiseKernelINS_8functors10ReciprocalIfEEEE
001f5d5f N11onnxruntime8functors10ReciprocalIfEE
001f5d87 NSt6__ndk110__function6__funcIN11onnxruntime8functors10ReciprocalIfEENS_9allocatorIS5_EEFvllEEE
001f5de7 N11onnxruntime17ElementWiseKernelINS_8functors10ReciprocalIdEEEE
001f5e28 N11onnxruntime8functors10ReciprocalIdEE
001f5e50 NSt6__ndk110__function6__funcIN11onnxruntime8functors10ReciprocalIdEENS_9allocatorIS5_EEFvllEEE
001f5eb0 N11onnxruntime17ElementWiseKernelINS_8functors4SqrtIfEEEE
001f5eea N11onnxruntime8functors4SqrtIfEE
001f5f0b NSt6__ndk110__function6__funcIN11onnxruntime8functors4SqrtIfEENS_9allocatorIS5_EEFvllEEE
001f5f64 N11onnxruntime17ElementWiseKernelINS_8functors4SqrtIdEEEE
001f5f9e N11onnxruntime8functors4SqrtIdEE
001f5fbf NSt6__ndk110__function6__funcIN11onnxruntime8functors4SqrtIdEENS_9allocatorIS5_EEFvllEEE
001f6018 N11onnxruntime17ElementWiseKernelINS_8functors3ExpIfEEEE
001f6051 N11onnxruntime8functors3ExpIfEE
001f6071 NSt6__ndk110__function6__funcIN11onnxruntime8functors3ExpIfEENS_9allocatorIS5_EEFvllEEE
001f60c9 N11onnxruntime17ElementWiseKernelINS_8functors3ExpIdEEEE
001f6102 N11onnxruntime8functors3ExpIdEE
001f6122 NSt6__ndk110__function6__funcIN11onnxruntime8functors3ExpIdEENS_9allocatorIS5_EEFvllEEE
001f617a N11onnxruntime17ElementWiseKernelINS_8functors3LogIfEEEE
001f61b3 N11onnxruntime8functors3LogIfEE
001f61d3 NSt6__ndk110__function6__funcIN11onnxruntime8functors3LogIfEENS_9allocatorIS5_EEFvllEEE
001f622b N11onnxruntime17ElementWiseKernelINS_8functors3LogIdEEEE
001f6264 N11onnxruntime8functors3LogIdEE
001f6284 NSt6__ndk110__function6__funcIN11onnxruntime8functors3LogIdEENS_9allocatorIS5_EEFvllEEE
001f62dc N11onnxruntime5Sum_6IfEE
001f62f5 N11onnxruntime5Sum_6IdEE
001f630e N11onnxruntime5Sum_8IfEE
001f6327 N11onnxruntime5Sum_8IdEE
001f6340 N11onnxruntime5Max_6IfEE
001f6359 N11onnxruntime5Min_6IfEE
001f6372 N11onnxruntime4LessIfEE
001f638a N11onnxruntime4LessIdEE
001f63a2 N11onnxruntime4LessIiEE
001f63ba N11onnxruntime4LessIlEE
001f63d2 N11onnxruntime7GreaterIfEE
001f63ed N11onnxruntime7GreaterIdEE
001f6408 N11onnxruntime7GreaterIiEE
001f6423 N11onnxruntime7GreaterIlEE
001f643e N11onnxruntime5EqualIbEE
001f6457 N11onnxruntime5EqualIiEE
001f6470 N11onnxruntime5EqualIlEE
001f6489 N11onnxruntime5EqualIfEE
001f64a2 N11onnxruntime5EqualIdEE
001f64bb N11onnxruntime11LessOrEqualIfEE
001f64db N11onnxruntime11LessOrEqualIdEE
001f64fb N11onnxruntime11LessOrEqualIiEE
001f651b N11onnxruntime11LessOrEqualIlEE
001f653b N11onnxruntime14GreaterOrEqualIfEE
001f655e N11onnxruntime14GreaterOrEqualIdEE
001f6581 N11onnxruntime14GreaterOrEqualIiEE
001f65a4 N11onnxruntime14GreaterOrEqualIlEE
001f65c7 N11onnxruntime6Mean_6IfEE
001f65e1 N11onnxruntime6Mean_8IfEE
001f65fb N11onnxruntime8BitShiftIhEE
001f6617 N11onnxruntime8BitShiftIjEE
001f6633 N11onnxruntime8BitShiftImEE
001f664f N11onnxruntime10BitwiseAndIaEE
001f666e N11onnxruntime10BitwiseAndIsEE
001f668d N11onnxruntime10BitwiseAndIiEE
001f66ac N11onnxruntime10BitwiseAndIlEE
001f66cb N11onnxruntime10BitwiseAndIhEE
001f66ea N11onnxruntime10BitwiseAndItEE
001f6709 N11onnxruntime10BitwiseAndIjEE
001f6728 N11onnxruntime10BitwiseAndImEE
001f6747 N11onnxruntime10BitwiseNotIaEE
001f6766 N11onnxruntime10BitwiseNotIsEE
001f6785 N11onnxruntime10BitwiseNotIiEE
001f67a4 N11onnxruntime10BitwiseNotIlEE
001f67c3 N11onnxruntime10BitwiseNotIhEE
001f67e2 N11onnxruntime10BitwiseNotItEE
001f6801 N11onnxruntime10BitwiseNotIjEE
001f6820 N11onnxruntime10BitwiseNotImEE
001f683f N11onnxruntime9BitwiseOrIaEE
001f685c N11onnxruntime9BitwiseOrIsEE
001f6879 N11onnxruntime9BitwiseOrIiEE
001f6896 N11onnxruntime9BitwiseOrIlEE
001f68b3 N11onnxruntime9BitwiseOrIhEE
001f68d0 N11onnxruntime9BitwiseOrItEE
001f68ed N11onnxruntime9BitwiseOrIjEE
001f690a N11onnxruntime9BitwiseOrImEE
001f6927 N11onnxruntime10BitwiseXorIaEE
001f6946 N11onnxruntime10BitwiseXorIsEE
001f6965 N11onnxruntime10BitwiseXorIiEE
001f6984 N11onnxruntime10BitwiseXorIlEE
001f69a3 N11onnxruntime10BitwiseXorIhEE
001f69c2 N11onnxruntime10BitwiseXorItEE
001f69e1 N11onnxruntime10BitwiseXorIjEE
001f6a00 N11onnxruntime10BitwiseXorImEE
001f6a1f N11onnxruntime3ErfIfEE
001f6a36 N11onnxruntime3SinIfEE
001f6a8c p7M}6p7M
001f6ab8 N11onnxruntime3SinIdEE
001f6acf N11onnxruntime3CosIfEE
001f6ae6 N11onnxruntime3TanIfEE
001f6afd N11onnxruntime4AsinIfEE
001f6b15 N11onnxruntime4AcosIfEE
001f6b2d N11onnxruntime4AtanIfEE
001f6b45 N11onnxruntime4SinhIfEE
001f6b5d N11onnxruntime4CoshIfEE
001f6b75 N11onnxruntime5AsinhIfEE
001f6b8e N11onnxruntime5AcoshIfEE
001f6ba7 N11onnxruntime5AtanhIfEE
001f6bc0 N11onnxruntime5PReluIfEE
001f6bd9 N11onnxruntime8Expand_8INSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
001f6c37 NSt6__ndk110__function6__funcIZN11onnxruntimeL21ParallelizeSingleSpanINS2_15BroadcastHelperEEEvRT_RKNS2_25ProcessBroadcastSpanFuncsEEUlllE_NS_9allocatorISA_EEFvllEEE
001f6cdd ZN11onnxruntimeL21ParallelizeSingleSpanINS_15BroadcastHelperEEEvRT_RKNS_25ProcessBroadcastSpanFuncsEEUlllE_
001f6d49 NSt6__ndk110__function6__funcIZN11onnxruntimeL21ParallelizeSingleSpanINS2_15BroadcastHelperEEEvRT_RKNS2_25ProcessBroadcastSpanFuncsEEUlllE0_NS_9allocatorISA_EEFvllEEE
001f6df0 ZN11onnxruntimeL21ParallelizeSingleSpanINS_15BroadcastHelperEEEvRT_RKNS_25ProcessBroadcastSpanFuncsEEUlllE0_
001f6e5d NSt6__ndk110__function6__funcIZN11onnxruntimeL21ParallelizeSingleSpanINS2_15BroadcastHelperEEEvRT_RKNS2_25ProcessBroadcastSpanFuncsEEUlllE1_NS_9allocatorISA_EEFvllEEE
001f6f04 ZN11onnxruntimeL21ParallelizeSingleSpanINS_15BroadcastHelperEEEvRT_RKNS_25ProcessBroadcastSpanFuncsEEUlllE1_
001f6f71 NSt6__ndk110__function6__funcIZN11onnxruntime19UntypedBroadcastTwoERNS2_15OpKernelContextERKNS2_25ProcessBroadcastSpanFuncsEdPvE5$_253NS_9allocatorIS9_EEFvllEEE
001f7012 ZN11onnxruntime19UntypedBroadcastTwoERNS_15OpKernelContextERKNS_25ProcessBroadcastSpanFuncsEdPvE5$_253
001f7079 N11onnxruntime4GemmIfEE
001f7091 N11onnxruntime4GemmIdEE
001f70a9 NSt6__ndk110__function6__funcIZNK11onnxruntime4GemmIdE17ComputeActivationEPdmPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorIS9_EEFvllEEE
001f7137 ZNK11onnxruntime4GemmIdE17ComputeActivationEPdmPNS_11concurrency10ThreadPoolEEUlllE_
001f718c NSt6__ndk110__function6__funcIZNK11onnxruntime4GemmIfE17ComputeActivationEPfmPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorIS9_EEFvllEEE
001f721a ZNK11onnxruntime4GemmIfE17ComputeActivationEPfmPNS_11concurrency10ThreadPoolEEUlllE_
001f726f N11onnxruntime7HardmaxIfEE
001f728a N11onnxruntime6MatMulIfEE
001f72a4 N11onnxruntime6MatMulIdEE
001f72be N11onnxruntime6MatMulIiEE
001f72d8 N11onnxruntime6MatMulIlEE
001f72f2 N11onnxruntime5RoundINS_9MLFloat16EEE
001f7318 N11onnxruntime5RoundIfEE
001f7331 N11onnxruntime5RoundIdEE
001f734a N11onnxruntime4SignE
001f735f N11onnxruntime7SoftmaxIfEE
001f737a N11onnxruntime7SoftmaxIdEE
001f73f5 N11onnxruntime4TopKILi9EfEE
001f7411 N11onnxruntime4TopKILi9EdEE
001f742d N11onnxruntime4TopKILi10EfEE
001f744a N11onnxruntime4TopKILi10EdEE
001f7467 N11onnxruntime4TopKILi11EfEE
001f7484 N11onnxruntime4TopKILi11EdEE
001f74a1 N11onnxruntime4TopKILi11EiEE
001f74be N11onnxruntime4TopKILi11ElEE
001f74db NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_15GreaterValueCmpIfEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISG_EEFvlEEE
001f75a6 NSt6__ndk110__function6__baseIFvlEEE
001f75cb ZN11onnxruntimeL16FindTopKElementsINS_15GreaterValueCmpIfEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE_
001f765b NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_15GreaterValueCmpIfEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE0_NS_9allocatorISG_EEFvlEEE
001f7727 ZN11onnxruntimeL16FindTopKElementsINS_15GreaterValueCmpIfEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE0_
001f77b8 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_15GreaterValueCmpIfEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE1_NS_9allocatorISG_EEFvlEEE
001f7884 ZN11onnxruntimeL16FindTopKElementsINS_15GreaterValueCmpIfEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE1_
001f7915 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_14LesserValueCmpIfEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISG_EEFvlEEE
001f79df ZN11onnxruntimeL16FindTopKElementsINS_14LesserValueCmpIfEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE_
001f7a6e NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_14LesserValueCmpIfEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE0_NS_9allocatorISG_EEFvlEEE
001f7b39 ZN11onnxruntimeL16FindTopKElementsINS_14LesserValueCmpIfEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE0_
001f7bc9 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_14LesserValueCmpIfEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE1_NS_9allocatorISG_EEFvlEEE
001f7c94 ZN11onnxruntimeL16FindTopKElementsINS_14LesserValueCmpIfEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE1_
001f7d24 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_15GreaterValueCmpIdEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISG_EEFvlEEE
001f7def ZN11onnxruntimeL16FindTopKElementsINS_15GreaterValueCmpIdEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE_
001f7e7f NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_15GreaterValueCmpIdEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE0_NS_9allocatorISG_EEFvlEEE
001f7f4b ZN11onnxruntimeL16FindTopKElementsINS_15GreaterValueCmpIdEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE0_
001f7fdc NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_15GreaterValueCmpIdEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE1_NS_9allocatorISG_EEFvlEEE
001f80a8 ZN11onnxruntimeL16FindTopKElementsINS_15GreaterValueCmpIdEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE1_
001f8139 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_14LesserValueCmpIdEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISG_EEFvlEEE
001f8203 ZN11onnxruntimeL16FindTopKElementsINS_14LesserValueCmpIdEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE_
001f8292 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_14LesserValueCmpIdEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE0_NS_9allocatorISG_EEFvlEEE
001f835d ZN11onnxruntimeL16FindTopKElementsINS_14LesserValueCmpIdEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE0_
001f83ed NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_14LesserValueCmpIdEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE1_NS_9allocatorISG_EEFvlEEE
001f84b8 ZN11onnxruntimeL16FindTopKElementsINS_14LesserValueCmpIdEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE1_
001f8548 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_15GreaterValueCmpIiEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISG_EEFvlEEE
001f8613 ZN11onnxruntimeL16FindTopKElementsINS_15GreaterValueCmpIiEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE_
001f86a3 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_15GreaterValueCmpIiEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE0_NS_9allocatorISG_EEFvlEEE
001f876f ZN11onnxruntimeL16FindTopKElementsINS_15GreaterValueCmpIiEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE0_
001f8800 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_15GreaterValueCmpIiEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE1_NS_9allocatorISG_EEFvlEEE
001f88cc ZN11onnxruntimeL16FindTopKElementsINS_15GreaterValueCmpIiEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE1_
001f895d NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_14LesserValueCmpIiEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISG_EEFvlEEE
001f8a27 ZN11onnxruntimeL16FindTopKElementsINS_14LesserValueCmpIiEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE_
001f8ab6 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_14LesserValueCmpIiEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE0_NS_9allocatorISG_EEFvlEEE
001f8b81 ZN11onnxruntimeL16FindTopKElementsINS_14LesserValueCmpIiEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE0_
001f8c11 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_14LesserValueCmpIiEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE1_NS_9allocatorISG_EEFvlEEE
001f8cdc ZN11onnxruntimeL16FindTopKElementsINS_14LesserValueCmpIiEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE1_
001f8d6c NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_15GreaterValueCmpIlEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISG_EEFvlEEE
001f8e37 ZN11onnxruntimeL16FindTopKElementsINS_15GreaterValueCmpIlEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE_
001f8ec7 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_15GreaterValueCmpIlEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE0_NS_9allocatorISG_EEFvlEEE
001f8f93 ZN11onnxruntimeL16FindTopKElementsINS_15GreaterValueCmpIlEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE0_
001f9024 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_15GreaterValueCmpIlEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE1_NS_9allocatorISG_EEFvlEEE
001f90f0 ZN11onnxruntimeL16FindTopKElementsINS_15GreaterValueCmpIlEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE1_
001f9181 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_14LesserValueCmpIlEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISG_EEFvlEEE
001f924b ZN11onnxruntimeL16FindTopKElementsINS_14LesserValueCmpIlEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE_
001f92da NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_14LesserValueCmpIlEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE0_NS_9allocatorISG_EEFvlEEE
001f93a5 ZN11onnxruntimeL16FindTopKElementsINS_14LesserValueCmpIlEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE0_
001f9435 NSt6__ndk110__function6__funcIZN11onnxruntimeL16FindTopKElementsINS2_14LesserValueCmpIlEEEEvPKNS2_6TensorERKNS2_11TensorShapeEPS6_SC_SB_jbjPNS2_11concurrency10ThreadPoolEEUllE1_NS_9allocatorISG_EEFvlEEE
001f9500 ZN11onnxruntimeL16FindTopKElementsINS_14LesserValueCmpIlEEEEvPKNS_6TensorERKNS_11TensorShapeEPS3_S9_S8_jbjPNS_11concurrency10ThreadPoolEEUllE1_
001f9590 N11onnxruntime2ml23ArrayFeatureExtractorOpIfEE
001f95bf N11onnxruntime2ml23ArrayFeatureExtractorOpIdEE
001f95ee N11onnxruntime2ml23ArrayFeatureExtractorOpIiEE
001f961d N11onnxruntime2ml23ArrayFeatureExtractorOpIlEE
001f964c N11onnxruntime2ml23ArrayFeatureExtractorOpINSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
001f96bd N11onnxruntime2ml11BinarizerOpIfEE
001f96e0 N11onnxruntime2ml7CastMapE
001f96fb N11onnxruntime2ml14CategoryMapperE
001f971f N11onnxruntime2ml16DictVectorizerOpINSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEElEE
001f978a N11onnxruntime2ml16DictVectorizerOpINSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEfEE
001f97f5 N11onnxruntime2ml16DictVectorizerOpINSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEdEE
001f9860 N11onnxruntime2ml16DictVectorizerOpIlNSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
001f98cb N11onnxruntime2ml16DictVectorizerOpIlfEE
001f98f4 N11onnxruntime2ml16DictVectorizerOpIldEE
001f9934 N11onnxruntime2ml17FeatureVectorizerE
001f995a N11onnxruntime2ml9ImputerOpE
001f9977 N11onnxruntime2ml12LabelEncoderE
001f9999 N11onnxruntime2ml14LabelEncoder_2IfNSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
001f9a02 N11onnxruntime2ml14LabelEncoder_2INSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEfEE
001f9a6b N11onnxruntime2ml14LabelEncoder_2IlfEE
001f9a92 N11onnxruntime2ml14LabelEncoder_2IflEE
001f9ab9 N11onnxruntime2ml14LabelEncoder_2IlNSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
001f9b22 N11onnxruntime2ml14LabelEncoder_2INSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEElEE
001f9b8b N11onnxruntime2ml14LabelEncoder_2IllEE
001f9bba N11onnxruntime2ml16LinearClassifierE
001f9bdf NSt6__ndk110__function6__funcIZN11onnxruntime2ml29batched_update_scores_inplaceIfEEvN3gsl4spanIT_Lm18446744073709551615EEEllNS3_19POST_EVAL_TRANSFORMEibPNS2_11concurrency10ThreadPoolEEUlfPfE_NS_9allocatorISE_EEFvfSD_EEE
001f9cbb NSt6__ndk110__function6__baseIFvfPfEEE
001f9ce2 ZN11onnxruntime2ml29batched_update_scores_inplaceIfEEvN3gsl4spanIT_Lm18446744073709551615EEEllNS0_19POST_EVAL_TRANSFORMEibPNS_11concurrency10ThreadPoolEEUlfPfE_
001f9d83 NSt6__ndk110__function6__funcIZN11onnxruntime2ml29batched_update_scores_inplaceIfEEvN3gsl4spanIT_Lm18446744073709551615EEEllNS3_19POST_EVAL_TRANSFORMEibPNS2_11concurrency10ThreadPoolEEUlfPfE0_NS_9allocatorISE_EEFvfSD_EEE
001f9e60 ZN11onnxruntime2ml29batched_update_scores_inplaceIfEEvN3gsl4spanIT_Lm18446744073709551615EEEllNS0_19POST_EVAL_TRANSFORMEibPNS_11concurrency10ThreadPoolEEUlfPfE0_
001f9f02 NSt6__ndk110__function6__funcIZN11onnxruntime2ml29batched_update_scores_inplaceIfEEvN3gsl4spanIT_Lm18446744073709551615EEEllNS3_19POST_EVAL_TRANSFORMEibPNS2_11concurrency10ThreadPoolEEUlfPfE1_NS_9allocatorISE_EEFvfSD_EEE
001f9fdf ZN11onnxruntime2ml29batched_update_scores_inplaceIfEEvN3gsl4spanIT_Lm18446744073709551615EEEllNS0_19POST_EVAL_TRANSFORMEibPNS_11concurrency10ThreadPoolEEUlfPfE1_
001fa081 N11onnxruntime2ml15LinearRegressorE
001fa0a5 N11onnxruntime2ml10NormalizerE
001fa0c4 N11onnxruntime2ml15OneHotEncoderOpIlEE
001fa0ec N11onnxruntime2ml15OneHotEncoderOpIfEE
001fa113 N11onnxruntime2ml15OneHotEncoderOpIdEE
001fa13a N11onnxruntime2ml15OneHotEncoderOpINSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
001fa1a3 N11onnxruntime2ml8ScalerOpIfEE
001fa1c2 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRNS_8functionIFvlEEEEEvPS4_lOT_lEUllE_NS_9allocatorISD_EES7_EE
001fa25d ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRNSt6__ndk18functionIFvlEEEEEvPS1_lOT_lEUllE_
001fa2c9 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml8ScalerOpIfE7ComputeEPNS2_15OpKernelContextEEUllE_NS_9allocatorIS8_EEFvlEEE
001fa346 ZNK11onnxruntime2ml8ScalerOpIfE7ComputeEPNS_15OpKernelContextEEUllE_
001fa38b NSt6__ndk110__function6__funcIZNK11onnxruntime2ml8ScalerOpIfE7ComputeEPNS2_15OpKernelContextEEUllE0_NS_9allocatorIS8_EEFvlEEE
001fa409 ZNK11onnxruntime2ml8ScalerOpIfE7ComputeEPNS_15OpKernelContextEEUllE0_
001fa44f N11onnxruntime2ml8ScalerOpIdEE
001fa46e NSt6__ndk110__function6__funcIZNK11onnxruntime2ml8ScalerOpIdE7ComputeEPNS2_15OpKernelContextEEUllE_NS_9allocatorIS8_EEFvlEEE
001fa4eb ZNK11onnxruntime2ml8ScalerOpIdE7ComputeEPNS_15OpKernelContextEEUllE_
001fa530 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml8ScalerOpIdE7ComputeEPNS2_15OpKernelContextEEUllE0_NS_9allocatorIS8_EEFvlEEE
001fa5ae ZNK11onnxruntime2ml8ScalerOpIdE7ComputeEPNS_15OpKernelContextEEUllE0_
001fa5f4 N11onnxruntime2ml8ScalerOpIlEE
001fa613 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml8ScalerOpIlE7ComputeEPNS2_15OpKernelContextEEUllE_NS_9allocatorIS8_EEFvlEEE
001fa690 ZNK11onnxruntime2ml8ScalerOpIlE7ComputeEPNS_15OpKernelContextEEUllE_
001fa6d5 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml8ScalerOpIlE7ComputeEPNS2_15OpKernelContextEEUllE0_NS_9allocatorIS8_EEFvlEEE
001fa753 ZNK11onnxruntime2ml8ScalerOpIlE7ComputeEPNS_15OpKernelContextEEUllE0_
001fa799 N11onnxruntime2ml8ScalerOpIiEE
001fa7b8 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml8ScalerOpIiE7ComputeEPNS2_15OpKernelContextEEUllE_NS_9allocatorIS8_EEFvlEEE
001fa835 ZNK11onnxruntime2ml8ScalerOpIiE7ComputeEPNS_15OpKernelContextEEUllE_
001fa87a NSt6__ndk110__function6__funcIZNK11onnxruntime2ml8ScalerOpIiE7ComputeEPNS2_15OpKernelContextEEUllE0_NS_9allocatorIS8_EEFvlEEE
001fa8f8 ZNK11onnxruntime2ml8ScalerOpIiE7ComputeEPNS_15OpKernelContextEEUllE0_
001fa93e N11onnxruntime2ml13SVMClassifierE
001fa960 N11onnxruntime2ml9SVMCommonE
001fa97d NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZNKS2_2ml13SVMClassifier11ComputeImplERNS2_15OpKernelContextEN3gsl4spanIKfLm18446744073709551615EEERKNS2_11TensorShapeEE3$_2EEvPS4_lOT_lEUllE_NS_9allocatorISM_EEFvlEEE
001faa82 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZNKS_2ml13SVMClassifier11ComputeImplERNS_15OpKernelContextEN3gsl4spanIKfLm18446744073709551615EEERKNS_11TensorShapeEE3$_2EEvPS1_lOT_lEUllE_
001fab4d N11onnxruntime2ml12SVMRegressorIfEE
001fab71 NSt6__ndk110__function6__funcIZN11onnxruntime10IAllocator13MakeUniquePtrIfEENS_10unique_ptrIT_NS_8functionIFvPS6_EEEEENS_10shared_ptrIS3_EEmbPNS2_6StreamENS7_IFvRSE_RNS2_11synchronize12NotificationEEEEEUlPfE_NS_9allocatorISN_EEFvSM_EEE
001fac5d NSt6__ndk110__function6__baseIFvPfEEE
001fac83 ZN11onnxruntime10IAllocator13MakeUniquePtrIfEENSt6__ndk110unique_ptrIT_NS2_8functionIFvPS4_EEEEENS2_10shared_ptrIS0_EEmbPNS_6StreamENS5_IFvRSC_RNS_11synchronize12NotificationEEEEEUlPfE_
001fad7b ?O_o
001fad8b ?O_o
001fad96 N11onnxruntime2ml22TreeEnsembleClassifierIfEE
001fadc4 N11onnxruntime2ml6detail28TreeEnsembleCommonClassifierIfffEE
001fae01 N11onnxruntime2ml6detail18TreeEnsembleCommonIfffEE
001fae34 N11onnxruntime2ml6detail28TreeEnsembleCommonAttributesE
001fae6d NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS7_21TreeAggregatorAverageIfffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001faf72 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_21TreeAggregatorAverageIfffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
001fb03e NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_21TreeAggregatorAverageIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
001fb119 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_21TreeAggregatorAverageIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
001fb1bb NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_21TreeAggregatorAverageIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
001fb296 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_21TreeAggregatorAverageIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
001fb338 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS7_21TreeAggregatorAverageIfffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001fb43e ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_21TreeAggregatorAverageIfffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
001fb50b NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_21TreeAggregatorAverageIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
001fb5e6 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_21TreeAggregatorAverageIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
001fb688 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_21TreeAggregatorAverageIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
001fb763 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_21TreeAggregatorAverageIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
001fb805 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_21TreeAggregatorAverageIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
001fb8e0 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_21TreeAggregatorAverageIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
001fb982 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_21TreeAggregatorAverageIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
001fba5d ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_21TreeAggregatorAverageIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
001fbaff NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS7_17TreeAggregatorSumIfffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001fbc00 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorSumIfffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
001fbcc8 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorSumIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
001fbd9f ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorSumIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
001fbe3d NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorSumIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
001fbf14 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorSumIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
001fbfb2 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS7_17TreeAggregatorSumIfffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001fc0b4 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorSumIfffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
001fc17d NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorSumIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
001fc254 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorSumIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
001fc2f2 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorSumIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
001fc3c9 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorSumIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
001fc467 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorSumIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
001fc53e ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorSumIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
001fc5dc NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorSumIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
001fc6b3 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorSumIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
001fc751 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS7_17TreeAggregatorMinIfffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001fc852 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMinIfffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
001fc91a NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMinIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
001fc9f1 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorMinIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
001fca8f NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMinIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
001fcb66 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorMinIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
001fcc04 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS7_17TreeAggregatorMinIfffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001fcd06 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMinIfffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
001fcdcf NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMinIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
001fcea6 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorMinIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
001fcf44 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMinIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
001fd01b ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorMinIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
001fd0b9 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMinIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
001fd190 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorMinIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
001fd22e NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMinIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
001fd305 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorMinIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
001fd3a3 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS7_17TreeAggregatorMaxIfffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001fd4a4 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMaxIfffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
001fd56c NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMaxIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
001fd643 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorMaxIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
001fd6e1 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMaxIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
001fd7b8 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorMaxIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
001fd856 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS7_17TreeAggregatorMaxIfffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001fd958 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMaxIfffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
001fda21 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMaxIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
001fdaf8 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorMaxIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
001fdb96 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMaxIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
001fdc6d ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorMaxIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
001fdd0b NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMaxIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
001fdde2 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorMaxIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
001fde80 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_17TreeAggregatorMaxIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
001fdf57 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_17TreeAggregatorMaxIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
001fdff5 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS7_24TreeAggregatorClassifierIfffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001fe0fd ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_24TreeAggregatorClassifierIfffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
001fe1cc NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_24TreeAggregatorClassifierIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
001fe2aa ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_24TreeAggregatorClassifierIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
001fe34f NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_24TreeAggregatorClassifierIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
001fe42d ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_24TreeAggregatorClassifierIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
001fe4d2 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS7_24TreeAggregatorClassifierIfffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001fe5db ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_24TreeAggregatorClassifierIfffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
001fe6ab NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_24TreeAggregatorClassifierIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
001fe789 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_24TreeAggregatorClassifierIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
001fe82e NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_24TreeAggregatorClassifierIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
001fe90c ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_24TreeAggregatorClassifierIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
001fe9b1 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_24TreeAggregatorClassifierIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
001fea8f ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_24TreeAggregatorClassifierIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
001feb34 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS4_24TreeAggregatorClassifierIfffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
001fec12 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIfffE10ComputeAggINS1_24TreeAggregatorClassifierIfffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
001fecb7 N11onnxruntime2ml22TreeEnsembleClassifierIdEE
001fece5 N11onnxruntime2ml6detail28TreeEnsembleCommonClassifierIddfEE
001fed22 N11onnxruntime2ml6detail18TreeEnsembleCommonIddfEE
001fed55 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS7_21TreeAggregatorAverageIddfEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001fee5a ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_21TreeAggregatorAverageIddfEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
001fef26 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_21TreeAggregatorAverageIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
001ff001 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_21TreeAggregatorAverageIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
001ff0a3 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_21TreeAggregatorAverageIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
001ff17e ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_21TreeAggregatorAverageIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
001ff220 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS7_21TreeAggregatorAverageIddfEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001ff326 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_21TreeAggregatorAverageIddfEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
001ff3f3 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_21TreeAggregatorAverageIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
001ff4ce ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_21TreeAggregatorAverageIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
001ff570 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_21TreeAggregatorAverageIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
001ff64b ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_21TreeAggregatorAverageIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
001ff6ed NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_21TreeAggregatorAverageIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
001ff7c8 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_21TreeAggregatorAverageIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
001ff86a NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_21TreeAggregatorAverageIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
001ff945 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_21TreeAggregatorAverageIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
001ff9e7 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS7_17TreeAggregatorSumIddfEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001ffae8 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorSumIddfEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
001ffbb0 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorSumIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
001ffc87 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorSumIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
001ffd25 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorSumIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
001ffdfc ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorSumIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
001ffe9a NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS7_17TreeAggregatorSumIddfEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
001fff9c ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorSumIddfEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
00200065 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorSumIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
0020013c ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorSumIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
002001da NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorSumIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
002002b1 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorSumIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
0020034f NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorSumIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
00200426 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorSumIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
002004c4 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorSumIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
0020059b ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorSumIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
00200639 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS7_17TreeAggregatorMinIddfEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
0020073a ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMinIddfEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
00200802 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMinIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
002008d9 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorMinIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
00200977 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMinIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
00200a4e ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorMinIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
00200aec NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS7_17TreeAggregatorMinIddfEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00200bee ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMinIddfEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
00200cb7 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMinIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
00200d8e ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorMinIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
00200e2c NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMinIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
00200f03 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorMinIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
00200fa1 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMinIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
00201078 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorMinIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
00201116 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMinIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
002011ed ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorMinIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
0020128b NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS7_17TreeAggregatorMaxIddfEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
0020138c ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMaxIddfEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
00201454 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMaxIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
0020152b ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorMaxIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
002015c9 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMaxIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
002016a0 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorMaxIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
0020173e NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS7_17TreeAggregatorMaxIddfEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00201840 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMaxIddfEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
00201909 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMaxIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
002019e0 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorMaxIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
00201a7e NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMaxIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
00201b55 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorMaxIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
00201bf3 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMaxIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
00201cca ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorMaxIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
00201d68 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_17TreeAggregatorMaxIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
00201e3f ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_17TreeAggregatorMaxIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
00201edd NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS7_24TreeAggregatorClassifierIddfEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00201fe5 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_24TreeAggregatorClassifierIddfEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
002020b4 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_24TreeAggregatorClassifierIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
00202192 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_24TreeAggregatorClassifierIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
00202237 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_24TreeAggregatorClassifierIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
00202315 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_24TreeAggregatorClassifierIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
002023ba NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS7_24TreeAggregatorClassifierIddfEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
002024c3 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_24TreeAggregatorClassifierIddfEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
00202593 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_24TreeAggregatorClassifierIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
00202671 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_24TreeAggregatorClassifierIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
00202716 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_24TreeAggregatorClassifierIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
002027f4 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_24TreeAggregatorClassifierIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
00202899 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_24TreeAggregatorClassifierIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
00202977 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_24TreeAggregatorClassifierIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
00202a1c NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS4_24TreeAggregatorClassifierIddfEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
00202afa ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIddfE10ComputeAggINS1_24TreeAggregatorClassifierIddfEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
00202b9f N11onnxruntime2ml22TreeEnsembleClassifierIlEE
00202bcd N11onnxruntime2ml6detail28TreeEnsembleCommonClassifierIlffEE
00202c0a N11onnxruntime2ml6detail18TreeEnsembleCommonIlffEE
00202c3d NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS7_21TreeAggregatorAverageIlffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00202d42 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_21TreeAggregatorAverageIlffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
00202e0e NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_21TreeAggregatorAverageIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
00202ee9 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_21TreeAggregatorAverageIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
00202f8b NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_21TreeAggregatorAverageIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
00203066 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_21TreeAggregatorAverageIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
00203108 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS7_21TreeAggregatorAverageIlffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
0020320e ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_21TreeAggregatorAverageIlffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
002032db NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_21TreeAggregatorAverageIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
002033b6 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_21TreeAggregatorAverageIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
00203458 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_21TreeAggregatorAverageIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
00203533 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_21TreeAggregatorAverageIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
002035d5 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_21TreeAggregatorAverageIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
002036b0 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_21TreeAggregatorAverageIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
00203752 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_21TreeAggregatorAverageIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
0020382d ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_21TreeAggregatorAverageIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
002038cf NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS7_17TreeAggregatorSumIlffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
002039d0 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorSumIlffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
00203a98 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorSumIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
00203b6f ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorSumIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
00203c0d NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorSumIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
00203ce4 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorSumIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
00203d82 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS7_17TreeAggregatorSumIlffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00203e84 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorSumIlffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
00203f4d NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorSumIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
00204024 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorSumIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
002040c2 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorSumIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
00204199 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorSumIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
00204237 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorSumIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
0020430e ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorSumIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
002043ac NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorSumIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
00204483 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorSumIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
00204521 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS7_17TreeAggregatorMinIlffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00204622 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMinIlffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
002046ea NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMinIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
002047c1 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorMinIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
0020485f NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMinIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
00204936 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorMinIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
002049d4 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS7_17TreeAggregatorMinIlffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00204ad6 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMinIlffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
00204b9f NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMinIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
00204c76 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorMinIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
00204d14 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMinIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
00204deb ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorMinIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
00204e89 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMinIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
00204f60 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorMinIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
00204ffe NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMinIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
002050d5 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorMinIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
00205173 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS7_17TreeAggregatorMaxIlffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00205274 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMaxIlffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
0020533c NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMaxIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
00205413 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorMaxIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
002054b1 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMaxIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
00205588 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorMaxIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
00205626 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS7_17TreeAggregatorMaxIlffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00205728 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMaxIlffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
002057f1 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMaxIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
002058c8 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorMaxIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
00205966 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMaxIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
00205a3d ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorMaxIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
00205adb NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMaxIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
00205bb2 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorMaxIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
00205c50 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_17TreeAggregatorMaxIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
00205d27 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_17TreeAggregatorMaxIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
00205dc5 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS7_24TreeAggregatorClassifierIlffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00205ecd ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_24TreeAggregatorClassifierIlffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
00205f9c NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_24TreeAggregatorClassifierIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
0020607a ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_24TreeAggregatorClassifierIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
0020611f NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_24TreeAggregatorClassifierIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
002061fd ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_24TreeAggregatorClassifierIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
002062a2 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS7_24TreeAggregatorClassifierIlffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
002063ab ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_24TreeAggregatorClassifierIlffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
0020647b NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_24TreeAggregatorClassifierIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
00206559 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_24TreeAggregatorClassifierIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
002065fe NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_24TreeAggregatorClassifierIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
002066dc ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_24TreeAggregatorClassifierIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
00206781 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_24TreeAggregatorClassifierIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
0020685f ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_24TreeAggregatorClassifierIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
00206904 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS4_24TreeAggregatorClassifierIlffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
002069e2 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIlffE10ComputeAggINS1_24TreeAggregatorClassifierIlffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
00206a87 N11onnxruntime2ml22TreeEnsembleClassifierIiEE
00206ab5 N11onnxruntime2ml6detail28TreeEnsembleCommonClassifierIiffEE
00206af2 N11onnxruntime2ml6detail18TreeEnsembleCommonIiffEE
00206b25 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS7_21TreeAggregatorAverageIiffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00206c2a ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_21TreeAggregatorAverageIiffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
00206cf6 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_21TreeAggregatorAverageIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
00206dd1 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_21TreeAggregatorAverageIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
00206e73 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_21TreeAggregatorAverageIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
00206f4e ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_21TreeAggregatorAverageIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
00206ff0 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS7_21TreeAggregatorAverageIiffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
002070f6 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_21TreeAggregatorAverageIiffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
002071c3 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_21TreeAggregatorAverageIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
0020729e ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_21TreeAggregatorAverageIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
00207340 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_21TreeAggregatorAverageIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
0020741b ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_21TreeAggregatorAverageIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
002074bd NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_21TreeAggregatorAverageIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
00207598 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_21TreeAggregatorAverageIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
0020763a NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_21TreeAggregatorAverageIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
00207715 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_21TreeAggregatorAverageIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
002077b7 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS7_17TreeAggregatorSumIiffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
002078b8 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorSumIiffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
00207980 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorSumIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
00207a57 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorSumIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
00207af5 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorSumIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
00207bcc ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorSumIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
00207c6a NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS7_17TreeAggregatorSumIiffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00207d6c ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorSumIiffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
00207e35 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorSumIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
00207f0c ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorSumIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
00207faa NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorSumIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
00208081 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorSumIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
0020811f NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorSumIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
002081f6 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorSumIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
00208294 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorSumIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
0020836b ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorSumIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
00208409 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS7_17TreeAggregatorMinIiffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
0020850a ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMinIiffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
002085d2 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMinIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
002086a9 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorMinIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
00208747 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMinIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
0020881e ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorMinIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
002088bc NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS7_17TreeAggregatorMinIiffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
002089be ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMinIiffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
00208a87 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMinIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
00208b5e ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorMinIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
00208bfc NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMinIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
00208cd3 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorMinIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
00208d71 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMinIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
00208e48 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorMinIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
00208ee6 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMinIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
00208fbd ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorMinIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
0020905b NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS7_17TreeAggregatorMaxIiffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
0020915c ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMaxIiffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
00209224 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMaxIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
002092fb ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorMaxIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
00209399 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMaxIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
00209470 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorMaxIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
0020950e NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS7_17TreeAggregatorMaxIiffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00209610 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMaxIiffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
002096d9 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMaxIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
002097b0 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorMaxIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
0020984e NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMaxIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
00209925 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorMaxIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
002099c3 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMaxIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
00209a9a ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorMaxIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
00209b38 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_17TreeAggregatorMaxIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
00209c0f ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_17TreeAggregatorMaxIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
00209cad NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS7_24TreeAggregatorClassifierIiffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
00209db5 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_24TreeAggregatorClassifierIiffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE_EEvSA_lOSF_lEUllE_
00209e84 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_24TreeAggregatorClassifierIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE0_NS_9allocatorISK_EEFvlEEE
00209f62 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_24TreeAggregatorClassifierIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE0_
0020a007 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_24TreeAggregatorClassifierIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE1_NS_9allocatorISK_EEFvlEEE
0020a0e5 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_24TreeAggregatorClassifierIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE1_
0020a18a NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS7_24TreeAggregatorClassifierIiffEEEEvPS4_PKNS2_6TensorEPSE_SH_RKT_EUllE2_EEvSD_lOSI_lEUllE_NS_9allocatorISN_EEFvlEEE
0020a293 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_24TreeAggregatorClassifierIiffEEEEvPS1_PKNS_6TensorEPSB_SE_RKT_EUllE2_EEvSA_lOSF_lEUllE_
0020a363 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_24TreeAggregatorClassifierIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE3_NS_9allocatorISK_EEFvlEEE
0020a441 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_24TreeAggregatorClassifierIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE3_
0020a4e6 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_24TreeAggregatorClassifierIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE4_NS_9allocatorISK_EEFvlEEE
0020a5c4 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_24TreeAggregatorClassifierIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE4_
0020a669 NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_24TreeAggregatorClassifierIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE5_NS_9allocatorISK_EEFvlEEE
0020a747 ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_24TreeAggregatorClassifierIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE5_
0020a7ec NSt6__ndk110__function6__funcIZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS4_24TreeAggregatorClassifierIiffEEEEvPNS2_11concurrency10ThreadPoolEPKNS2_6TensorEPSD_SG_RKT_EUllE6_NS_9allocatorISK_EEFvlEEE
0020a8ca ZNK11onnxruntime2ml6detail18TreeEnsembleCommonIiffE10ComputeAggINS1_24TreeAggregatorClassifierIiffEEEEvPNS_11concurrency10ThreadPoolEPKNS_6TensorEPSA_SD_RKT_EUllE6_
0020a96f N11onnxruntime2ml21TreeEnsembleRegressorIfEE
0020a99c N11onnxruntime2ml21TreeEnsembleRegressorIdEE
0020a9c9 N11onnxruntime2ml8ZipMapOpE
0020a9e6 N11onnxruntime9MaxUnpoolE
0020aa00 N11onnxruntime9BatchNormIfEE
0020aa1d N11onnxruntime9BatchNormIdEE
0020aa3a N11onnxruntime4ConvIfEE
0020aa52 N11onnxruntime13ConvTransposeIfEE
0020aa74 N11onnxruntime7DropoutIffEE
0020aa90 N11onnxruntime7DropoutIfdEE
0020aaac N11onnxruntime7DropoutIdfEE
0020aac8 N11onnxruntime7DropoutIddEE
0020aae4 N11onnxruntime7FlattenE
0020aafc N11onnxruntime12InstanceNormIfEE
0020ab1d N11onnxruntime9LayerNormE
0020ab37 N11onnxruntime13LayerNormImplE
0020ab56 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNS2_12_GLOBAL__N_111ComputeImplIffEENS2_6common6StatusEPNS2_15OpKernelContextElfbEUllE_EEvPS4_lOT_lEUllE_NS_9allocatorISG_EEFvlEEE
0020ac36 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNS_12_GLOBAL__N_111ComputeImplIffEENS_6common6StatusEPNS_15OpKernelContextElfbEUllE_EEvPS1_lOT_lEUllE_
0020acdc NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNS2_12_GLOBAL__N_111ComputeImplIddEENS2_6common6StatusEPNS2_15OpKernelContextElfbEUllE_EEvPS4_lOT_lEUllE_NS_9allocatorISG_EEFvlEEE
0020adbc ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNS_12_GLOBAL__N_111ComputeImplIddEENS_6common6StatusEPNS_15OpKernelContextElfbEUllE_EEvPS1_lOT_lEUllE_
0020ae62 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNS2_12_GLOBAL__N_111ComputeImplIdfEENS2_6common6StatusEPNS2_15OpKernelContextElfbEUllE_EEvPS4_lOT_lEUllE_NS_9allocatorISG_EEFvlEEE
0020af42 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNS_12_GLOBAL__N_111ComputeImplIdfEENS_6common6StatusEPNS_15OpKernelContextElfbEUllE_EEvPS1_lOT_lEUllE_
0020afe8 N11onnxruntime6LpNormIfEE
0020b002 N11onnxruntime6LpNormIdEE
0020b01c N11onnxruntime3LRNIfEE
0020b033 NSt6__ndk110__function6__funcIN11onnxruntime8functors4PowxIfEENS_9allocatorIS5_EEFvllEEE
0020b08c N11onnxruntime8functors4PowxIfEE
0020b0ad N11onnxruntime9MaxPoolV8E
0020b0c7 N11onnxruntime8PoolBaseE
0020b0e0 N11onnxruntime4PoolIfNS_11AveragePoolEEE
0020b109 N11onnxruntime4PoolIfNS_7MaxPoolILi1EEEEE
0020b133 N11onnxruntime4PoolIfNS_6LpPoolEEE
0020b156 NSt6__ndk110__function6__funcIN11onnxruntime10Pool1DTaskIfNS2_6LpPoolEEENS_9allocatorIS5_EEFvllEEE
0020b1b9 N11onnxruntime10Pool1DTaskIfNS_6LpPoolEEE
0020b1e3 NSt6__ndk110__function6__funcIN11onnxruntime10Pool2DTaskIfNS2_6LpPoolEEENS_9allocatorIS5_EEFvllEEE
0020b246 N11onnxruntime10Pool2DTaskIfNS_6LpPoolEEE
0020b270 NSt6__ndk110__function6__funcIN11onnxruntime10Pool3DTaskIfNS2_6LpPoolEEENS_9allocatorIS5_EEFvllEEE
0020b2d3 N11onnxruntime10Pool3DTaskIfNS_6LpPoolEEE
0020b2fd N11onnxruntime9LpPoolV18IfEE
0020b31a NSt6__ndk110__function6__funcIN11onnxruntime12LpPool1DTaskIfEENS_9allocatorIS4_EEFvllEEE
0020b373 N11onnxruntime12LpPool1DTaskIfEE
0020b394 NSt6__ndk110__function6__funcIN11onnxruntime12LpPool2DTaskIfEENS_9allocatorIS4_EEFvllEEE
0020b3ed N11onnxruntime12LpPool2DTaskIfEE
0020b40e NSt6__ndk110__function6__funcIN11onnxruntime12LpPool3DTaskIfEENS_9allocatorIS4_EEFvllEEE
0020b467 N11onnxruntime12LpPool3DTaskIfEE
0020b488 NSt6__ndk110__function6__funcIN11onnxruntime13MaxPool1DTaskIfEENS_9allocatorIS4_EEFvllEEE
0020b4e2 N11onnxruntime13MaxPool1DTaskIfEE
0020b504 NSt6__ndk110__function6__funcIN11onnxruntime13MaxPool2DTaskIfEENS_9allocatorIS4_EEFvllEEE
0020b55e N11onnxruntime13MaxPool2DTaskIfEE
0020b580 NSt6__ndk110__function6__funcIN11onnxruntime13MaxPool3DTaskIfEENS_9allocatorIS4_EEFvllEEE
0020b5da N11onnxruntime13MaxPool3DTaskIfEE
0020b5fc NSt6__ndk110__function6__funcIN11onnxruntime13MaxPool1DTaskIdEENS_9allocatorIS4_EEFvllEEE
0020b656 N11onnxruntime13MaxPool1DTaskIdEE
0020b678 NSt6__ndk110__function6__funcIN11onnxruntime13MaxPool2DTaskIdEENS_9allocatorIS4_EEFvllEEE
0020b6d2 N11onnxruntime13MaxPool2DTaskIdEE
0020b6f4 NSt6__ndk110__function6__funcIN11onnxruntime13MaxPool3DTaskIdEENS_9allocatorIS4_EEFvllEEE
0020b74e N11onnxruntime13MaxPool3DTaskIdEE
0020b770 NSt6__ndk110__function6__funcIN11onnxruntime13MaxPool1DTaskIaEENS_9allocatorIS4_EEFvllEEE
0020b7ca N11onnxruntime13MaxPool1DTaskIaEE
0020b7ec NSt6__ndk110__function6__funcIN11onnxruntime13MaxPool2DTaskIaEENS_9allocatorIS4_EEFvllEEE
0020b846 N11onnxruntime13MaxPool2DTaskIaEE
0020b868 NSt6__ndk110__function6__funcIN11onnxruntime13MaxPool3DTaskIaEENS_9allocatorIS4_EEFvllEEE
0020b8c2 N11onnxruntime13MaxPool3DTaskIaEE
0020b8e4 NSt6__ndk110__function6__funcIN11onnxruntime13MaxPool1DTaskIhEENS_9allocatorIS4_EEFvllEEE
0020b93e N11onnxruntime13MaxPool1DTaskIhEE
0020b960 NSt6__ndk110__function6__funcIN11onnxruntime13MaxPool2DTaskIhEENS_9allocatorIS4_EEFvllEEE
0020b9ba N11onnxruntime13MaxPool2DTaskIhEE
0020b9dc NSt6__ndk110__function6__funcIN11onnxruntime13MaxPool3DTaskIhEENS_9allocatorIS4_EEFvllEEE
0020ba36 N11onnxruntime13MaxPool3DTaskIhEE
0020ba58 N11onnxruntime7RoiPoolIfEE
0020ba73 N11onnxruntime6ShrinkE
0020bf48 N11onnxruntime16StringNormalizerE
0020bf6a NSt6__ndk112codecvt_utf8IwLm1114111ELNS_12codecvt_modeE0EEE
0020bfa6 N11onnxruntime15TfIdfVectorizerE
0020bfc7 NSt6__ndk110__function6__funcIZNK11onnxruntime15TfIdfVectorizer7ComputeEPNS2_15OpKernelContextEE3$_2NS_9allocatorIS6_EEFvlEEE
0020c045 ZNK11onnxruntime15TfIdfVectorizer7ComputeEPNS_15OpKernelContextEE3$_2
0020c08b NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForINS_8functionIFvlEEEEEvPS4_lOT_lEUllE_NS_9allocatorISC_EES7_EE
0020c125 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForINSt6__ndk18functionIFvlEEEEEvPS1_lOT_lEUllE_
0020c190 N11onnxruntime17NonMaxSuppressionE
0020c1b3 N11onnxruntime21NonMaxSuppressionBaseE
0020c1da N11onnxruntime8RoiAlignIfEE
0020c1f6 N11onnxruntime12RoiAlignBaseE
0020c214 NSt6__ndk110__function6__funcIZN11onnxruntime12_GLOBAL__N_115RoiAlignForwardIfEEvRKNS2_11TensorShapeEPKT_flllSA_lPS8_NS2_12RoiAlignModeEbPKlPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0020c2e1 ZN11onnxruntime12_GLOBAL__N_115RoiAlignForwardIfEEvRKNS_11TensorShapeEPKT_flllS7_lPS5_NS_12RoiAlignModeEbPKlPNS_11concurrency10ThreadPoolEEUlllE_
0020c373 N11onnxruntime8RoiAlignIdEE
0020c38f NSt6__ndk110__function6__funcIZN11onnxruntime12_GLOBAL__N_115RoiAlignForwardIdEEvRKNS2_11TensorShapeEPKT_flllSA_lPS8_NS2_12RoiAlignModeEbPKlPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0020c45c ZN11onnxruntime12_GLOBAL__N_115RoiAlignForwardIdEEvRKNS_11TensorShapeEPKT_flllS7_lPS5_NS_12RoiAlignModeEbPKlPNS_11concurrency10ThreadPoolEEUlllE_
0020c4ee N11onnxruntime8OptionalE
0020c507 N11onnxruntime18OptionalHasElementE
0020c52b N11onnxruntime18OptionalGetElementE
0020c54f N11onnxruntime11ConvIntegerE
0020c56c N11onnxruntime21DynamicQuantizeLinearIhEE
0020c596 NSt6__ndk110__function6__funcIZN11onnxruntime24GetQuantizationParameterIhLb0ELb0ELi0EEEvPKflRfRT_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISC_EEFvllEEE
0020c638 ZN11onnxruntime24GetQuantizationParameterIhLb0ELb0ELi0EEEvPKflRfRT_PNS_11concurrency10ThreadPoolEEUlllE_
0020c6be p@NSt6__ndk110__function6__funcIZN11onnxruntime17ParQuantizeLinearIhEEvPKfPT_mfS6_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISB_EEFvllEEE
0020c751 ZN11onnxruntime17ParQuantizeLinearIhEEvPKfPT_mfS3_PNS_11concurrency10ThreadPoolEEUlllE_
0020c7a9 N11onnxruntime13MatMulIntegerE
0020c7c8 N11onnxruntime17MatMulIntegerBaseE
0020c7eb N11onnxruntime11QLinearConvIhEE
0020c80b NSt6__ndk110__function6__funcIZNK11onnxruntime11QLinearConvIhE7ComputeEPNS2_15OpKernelContextEEUllE_NS_9allocatorIS7_EEFvlEEE
0020c889 ZNK11onnxruntime11QLinearConvIhE7ComputeEPNS_15OpKernelContextEEUllE_
0020c8cf NSt6__ndk110__function6__funcIZNK11onnxruntime11QLinearConvIhE7ComputeEPNS2_15OpKernelContextEEUllE0_NS_9allocatorIS7_EEFvlEEE
0020c94e ZNK11onnxruntime11QLinearConvIhE7ComputeEPNS_15OpKernelContextEEUllE0_
0020c995 N11onnxruntime11QLinearConvIaEE
0020c9b5 NSt6__ndk110__function6__funcIZNK11onnxruntime11QLinearConvIaE7ComputeEPNS2_15OpKernelContextEEUllE_NS_9allocatorIS7_EEFvlEEE
0020ca33 ZNK11onnxruntime11QLinearConvIaE7ComputeEPNS_15OpKernelContextEEUllE_
0020ca79 NSt6__ndk110__function6__funcIZNK11onnxruntime11QLinearConvIaE7ComputeEPNS2_15OpKernelContextEEUllE0_NS_9allocatorIS7_EEFvlEEE
0020caf8 ZNK11onnxruntime11QLinearConvIaE7ComputeEPNS_15OpKernelContextEEUllE0_
0020cb3f N11onnxruntime16DequantizeLinearIaEE
0020cb64 N11onnxruntime16DequantizeLinearIhEE
0020cb89 N11onnxruntime16DequantizeLinearIiEE
0020cbae N11onnxruntime14QuantizeLinearIaEE
0020cbd1 NSt6__ndk110__function6__funcIZN11onnxruntime17ParQuantizeLinearIaEEvPKfPT_mfS6_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISB_EEFvllEEE
0020cc62 ZN11onnxruntime17ParQuantizeLinearIaEEvPKfPT_mfS3_PNS_11concurrency10ThreadPoolEEUlllE_
0020ccba N11onnxruntime14QuantizeLinearIhEE
0020ccf6 p@N11onnxruntime13QLinearMatMulE
0020cd17 35MLAS_QGEMM_REQUANT_OUTPUT_PROCESSOR
0020cd3d 27MLAS_QGEMM_OUTPUT_PROCESSOR
0020cd83 N11onnxruntime9ReduceSumIfEE
0020cda0 N11onnxruntime12ReduceKernelILb1EEE
0020cdc4 N11onnxruntime16ReduceKernelBaseILb1EEE
0020cdec N11onnxruntime9ReduceSumIiEE
0020ce09 N11onnxruntime9ReduceSumIdEE
0020ce26 N11onnxruntime9ReduceSumIlEE
0020ce43 N11onnxruntime8ReduceL1IfEE
0020ce5f NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_18ReduceAggregatorL1IfEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0020cf7b ZN11onnxruntime22NoTransposeReduce1LoopINS_18ReduceAggregatorL1IfEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0020d05a N11onnxruntime8ReduceL1IiEE
0020d076 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_18ReduceAggregatorL1IiEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0020d192 ZN11onnxruntime22NoTransposeReduce1LoopINS_18ReduceAggregatorL1IiEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0020d271 N11onnxruntime8ReduceL2IfEE
0020d28d NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_18ReduceAggregatorL2IfEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0020d3a9 ZN11onnxruntime22NoTransposeReduce1LoopINS_18ReduceAggregatorL2IfEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0020d488 N11onnxruntime8ReduceL2IiEE
0020d4a4 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_18ReduceAggregatorL2IiEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0020d5c0 ZN11onnxruntime22NoTransposeReduce1LoopINS_18ReduceAggregatorL2IiEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0020d69f N11onnxruntime12ReduceLogSumIfEE
0020d6c0 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_22ReduceAggregatorLogSumIfEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0020d7e0 ZN11onnxruntime22NoTransposeReduce1LoopINS_22ReduceAggregatorLogSumIfEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0020d8c3 N11onnxruntime12ReduceLogSumIiEE
0020d8e4 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_22ReduceAggregatorLogSumIiEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0020da04 ZN11onnxruntime22NoTransposeReduce1LoopINS_22ReduceAggregatorLogSumIiEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0020dae7 N11onnxruntime15ReduceLogSumExpIfEE
0020db0b NSt6__ndk110__function6__funcIZN11onnxruntime23NoTransposeReduce2LoopsINS2_25ReduceAggregatorLogSumExpIfEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0020dc2f ZN11onnxruntime23NoTransposeReduce2LoopsINS_25ReduceAggregatorLogSumExpIfEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0020dd16 N11onnxruntime15ReduceLogSumExpIiEE
0020dd3a NSt6__ndk110__function6__funcIZN11onnxruntime23NoTransposeReduce2LoopsINS2_25ReduceAggregatorLogSumExpIiEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0020de5e ZN11onnxruntime23NoTransposeReduce2LoopsINS_25ReduceAggregatorLogSumExpIiEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0020df45 N11onnxruntime15ReduceLogSumExpIdEE
0020df69 NSt6__ndk110__function6__funcIZN11onnxruntime23NoTransposeReduce2LoopsINS2_25ReduceAggregatorLogSumExpIdEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0020e08d ZN11onnxruntime23NoTransposeReduce2LoopsINS_25ReduceAggregatorLogSumExpIdEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0020e174 N11onnxruntime9ReduceMaxIfEE
0020e191 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIfE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0020e260 ZN11onnxruntime19ReduceAggregatorMaxIfE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0020e2f5 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIfE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0020e3c4 ZN11onnxruntime19ReduceAggregatorMaxIfE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0020e459 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIfE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0020e529 ZN11onnxruntime19ReduceAggregatorMaxIfE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0020e5bf NSt6__ndk110__function6__funcIZN11onnxruntime16ReduceAggregatorIffE19CommonFastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolENS_8functionIFfPKfEEENSI_IFvRfSK_lEEEEUlllE_NS_9allocatorISQ_EEFvllEEE
0020e6b8 ZN11onnxruntime16ReduceAggregatorIffE19CommonFastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolENSt6__ndk18functionIFfPKfEEENSG_IFvRfSI_lEEEEUlllE_
0020e77e NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIfE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKfE_NS_9allocatorISK_EEFfSJ_EEE
0020e850 NSt6__ndk110__function6__baseIFfPKfEEE
0020e877 ZN11onnxruntime19ReduceAggregatorMaxIfE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKfE_
0020e90e NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIfE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRfPKflE_NS_9allocatorISL_EEFvSI_SK_lEEE
0020e9e7 NSt6__ndk110__function6__baseIFvRfPKflEEE
0020ea11 ZN11onnxruntime19ReduceAggregatorMaxIfE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRfPKflE_
0020eaab NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorMaxIfEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0020ebc8 ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorMaxIfEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0020eca8 N11onnxruntime9ReduceMaxIiEE
0020ecc5 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIiE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0020ed94 ZN11onnxruntime19ReduceAggregatorMaxIiE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0020ee29 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIiE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0020eef8 ZN11onnxruntime19ReduceAggregatorMaxIiE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0020ef8d NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIiE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0020f05d ZN11onnxruntime19ReduceAggregatorMaxIiE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0020f0f3 NSt6__ndk110__function6__funcIZN11onnxruntime16ReduceAggregatorIiiE19CommonFastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolENS_8functionIFiPKiEEENSI_IFvRiSK_lEEEEUlllE_NS_9allocatorISQ_EEFvllEEE
0020f1ec ZN11onnxruntime16ReduceAggregatorIiiE19CommonFastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolENSt6__ndk18functionIFiPKiEEENSG_IFvRiSI_lEEEEUlllE_
0020f2b2 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIiE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKiE_NS_9allocatorISK_EEFiSJ_EEE
0020f384 NSt6__ndk110__function6__baseIFiPKiEEE
0020f3ab ZN11onnxruntime19ReduceAggregatorMaxIiE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKiE_
0020f442 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIiE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRiPKilE_NS_9allocatorISL_EEFvSI_SK_lEEE
0020f51b NSt6__ndk110__function6__baseIFvRiPKilEEE
0020f545 ZN11onnxruntime19ReduceAggregatorMaxIiE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRiPKilE_
0020f5df NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorMaxIiEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0020f6fc ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorMaxIiEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0020f7dc N11onnxruntime9ReduceMaxIlEE
0020f7f9 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIlE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0020f8c8 ZN11onnxruntime19ReduceAggregatorMaxIlE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0020f95d NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIlE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0020fa2c ZN11onnxruntime19ReduceAggregatorMaxIlE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0020fac1 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIlE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0020fb91 ZN11onnxruntime19ReduceAggregatorMaxIlE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0020fc27 NSt6__ndk110__function6__funcIZN11onnxruntime16ReduceAggregatorIllE19CommonFastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolENS_8functionIFlPSA_EEENSI_IFvRlSJ_lEEEEUlllE_NS_9allocatorISP_EEFvllEEE
0020fd21 ZN11onnxruntime16ReduceAggregatorIllE19CommonFastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolENSt6__ndk18functionIFlPS7_EEENSG_IFvRlSH_lEEEEUlllE_
0020fde8 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIlE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPSA_E_NS_9allocatorISJ_EEFlSI_EEE
0020febb NSt6__ndk110__function6__baseIFlPKlEEE
0020fee2 ZN11onnxruntime19ReduceAggregatorMaxIlE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPS7_E_
0020ff7a NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIlE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRlPSA_lE_NS_9allocatorISK_EEFvSI_SJ_lEEE
00210054 NSt6__ndk110__function6__baseIFvRlPKllEEE
0021007e ZN11onnxruntime19ReduceAggregatorMaxIlE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRlPS7_lE_
00210119 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorMaxIlEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00210236 ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorMaxIlEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00210316 N11onnxruntime9ReduceMaxIdEE
00210333 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIdE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00210402 ZN11onnxruntime19ReduceAggregatorMaxIdE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00210497 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIdE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00210566 ZN11onnxruntime19ReduceAggregatorMaxIdE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
002105fb NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIdE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
002106cb ZN11onnxruntime19ReduceAggregatorMaxIdE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00210761 NSt6__ndk110__function6__funcIZN11onnxruntime16ReduceAggregatorIddE19CommonFastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolENS_8functionIFdPKdEEENSI_IFvRdSK_lEEEEUlllE_NS_9allocatorISQ_EEFvllEEE
0021085a ZN11onnxruntime16ReduceAggregatorIddE19CommonFastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolENSt6__ndk18functionIFdPKdEEENSG_IFvRdSI_lEEEEUlllE_
00210920 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIdE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKdE_NS_9allocatorISK_EEFdSJ_EEE
002109f2 NSt6__ndk110__function6__baseIFdPKdEEE
00210a19 ZN11onnxruntime19ReduceAggregatorMaxIdE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKdE_
00210ab0 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIdE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRdPKdlE_NS_9allocatorISL_EEFvSI_SK_lEEE
00210b89 NSt6__ndk110__function6__baseIFvRdPKdlEEE
00210bb3 ZN11onnxruntime19ReduceAggregatorMaxIdE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRdPKdlE_
00210c4d NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorMaxIdEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00210d6a ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorMaxIdEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00210e4a N11onnxruntime9ReduceMaxIaEE
00210e67 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIaE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00210f36 ZN11onnxruntime19ReduceAggregatorMaxIaE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00210fcb NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIaE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021109a ZN11onnxruntime19ReduceAggregatorMaxIaE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0021112f NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIaE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
002111ff ZN11onnxruntime19ReduceAggregatorMaxIaE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00211295 NSt6__ndk110__function6__funcIZN11onnxruntime16ReduceAggregatorIaaE19CommonFastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolENS_8functionIFaPKaEEENSI_IFvRaSK_lEEEEUlllE_NS_9allocatorISQ_EEFvllEEE
0021138e ZN11onnxruntime16ReduceAggregatorIaaE19CommonFastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolENSt6__ndk18functionIFaPKaEEENSG_IFvRaSI_lEEEEUlllE_
00211454 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIaE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKaE_NS_9allocatorISK_EEFaSJ_EEE
00211526 NSt6__ndk110__function6__baseIFaPKaEEE
0021154d ZN11onnxruntime19ReduceAggregatorMaxIaE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKaE_
002115e4 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIaE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRaPKalE_NS_9allocatorISL_EEFvSI_SK_lEEE
002116bd NSt6__ndk110__function6__baseIFvRaPKalEEE
002116e7 ZN11onnxruntime19ReduceAggregatorMaxIaE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRaPKalE_
00211781 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorMaxIaEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0021189e ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorMaxIaEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0021197e N11onnxruntime9ReduceMaxIhEE
0021199b NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIhE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00211a6a ZN11onnxruntime19ReduceAggregatorMaxIhE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00211aff NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIhE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00211bce ZN11onnxruntime19ReduceAggregatorMaxIhE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00211c63 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIhE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00211d33 ZN11onnxruntime19ReduceAggregatorMaxIhE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00211dc9 NSt6__ndk110__function6__funcIZN11onnxruntime16ReduceAggregatorIhhE19CommonFastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolENS_8functionIFhPKhEEENSI_IFvRhSK_lEEEEUlllE_NS_9allocatorISQ_EEFvllEEE
00211ec2 ZN11onnxruntime16ReduceAggregatorIhhE19CommonFastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolENSt6__ndk18functionIFhPKhEEENSG_IFvRhSI_lEEEEUlllE_
00211f88 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIhE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKhE_NS_9allocatorISK_EEFhSJ_EEE
0021205a NSt6__ndk110__function6__baseIFhPKhEEE
00212081 ZN11onnxruntime19ReduceAggregatorMaxIhE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKhE_
00212118 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMaxIhE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRhPKhlE_NS_9allocatorISL_EEFvSI_SK_lEEE
002121f1 NSt6__ndk110__function6__baseIFvRhPKhlEEE
0021221b ZN11onnxruntime19ReduceAggregatorMaxIhE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRhPKhlE_
002122b5 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorMaxIhEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
002123d2 ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorMaxIhEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
002124b2 N11onnxruntime10ReduceMeanIfEE
002124d1 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_20ReduceAggregatorMeanIfEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
002125ef ZN11onnxruntime22NoTransposeReduce1LoopINS_20ReduceAggregatorMeanIfEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
002126d0 N11onnxruntime10ReduceMeanIiEE
002126ef NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_20ReduceAggregatorMeanIiEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0021280d ZN11onnxruntime22NoTransposeReduce1LoopINS_20ReduceAggregatorMeanIiEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
002128ee N11onnxruntime10ReduceMeanIdEE
0021290d NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_20ReduceAggregatorMeanIdEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00212a2b ZN11onnxruntime22NoTransposeReduce1LoopINS_20ReduceAggregatorMeanIdEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00212b0c N11onnxruntime9ReduceMinIfEE
00212b29 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIfE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00212bf8 ZN11onnxruntime19ReduceAggregatorMinIfE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00212c8d NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIfE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00212d5c ZN11onnxruntime19ReduceAggregatorMinIfE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00212df1 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIfE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00212ec1 ZN11onnxruntime19ReduceAggregatorMinIfE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00212f57 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIfE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKfE_NS_9allocatorISK_EEFfSJ_EEE
00213029 ZN11onnxruntime19ReduceAggregatorMinIfE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKfE_
002130c0 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIfE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRfPKflE_NS_9allocatorISL_EEFvSI_SK_lEEE
00213199 ZN11onnxruntime19ReduceAggregatorMinIfE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRfPKflE_
00213233 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorMinIfEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00213350 ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorMinIfEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00213430 N11onnxruntime9ReduceMinIiEE
0021344d NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIiE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021351c ZN11onnxruntime19ReduceAggregatorMinIiE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
002135b1 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIiE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00213680 ZN11onnxruntime19ReduceAggregatorMinIiE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00213715 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIiE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
002137e5 ZN11onnxruntime19ReduceAggregatorMinIiE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0021387b NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIiE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKiE_NS_9allocatorISK_EEFiSJ_EEE
0021394d ZN11onnxruntime19ReduceAggregatorMinIiE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKiE_
002139e4 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIiE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRiPKilE_NS_9allocatorISL_EEFvSI_SK_lEEE
00213abd ZN11onnxruntime19ReduceAggregatorMinIiE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRiPKilE_
00213b57 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorMinIiEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00213c74 ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorMinIiEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00213d54 N11onnxruntime9ReduceMinIlEE
00213d71 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIlE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00213e40 ZN11onnxruntime19ReduceAggregatorMinIlE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00213ed5 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIlE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00213fa4 ZN11onnxruntime19ReduceAggregatorMinIlE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00214039 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIlE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00214109 ZN11onnxruntime19ReduceAggregatorMinIlE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0021419f NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIlE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPSA_E_NS_9allocatorISJ_EEFlSI_EEE
00214272 ZN11onnxruntime19ReduceAggregatorMinIlE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPS7_E_
0021430a NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIlE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRlPSA_lE_NS_9allocatorISK_EEFvSI_SJ_lEEE
002143e4 ZN11onnxruntime19ReduceAggregatorMinIlE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRlPS7_lE_
0021447f NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorMinIlEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0021459c ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorMinIlEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0021467c N11onnxruntime9ReduceMinIdEE
00214699 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIdE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00214768 ZN11onnxruntime19ReduceAggregatorMinIdE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
002147fd NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIdE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
002148cc ZN11onnxruntime19ReduceAggregatorMinIdE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00214961 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIdE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00214a31 ZN11onnxruntime19ReduceAggregatorMinIdE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00214ac7 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIdE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKdE_NS_9allocatorISK_EEFdSJ_EEE
00214b99 ZN11onnxruntime19ReduceAggregatorMinIdE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKdE_
00214c30 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIdE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRdPKdlE_NS_9allocatorISL_EEFvSI_SK_lEEE
00214d09 ZN11onnxruntime19ReduceAggregatorMinIdE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRdPKdlE_
00214da3 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorMinIdEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00214ec0 ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorMinIdEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00214fa0 N11onnxruntime9ReduceMinIaEE
00214fbd NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIaE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021508c ZN11onnxruntime19ReduceAggregatorMinIaE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00215121 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIaE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
002151f0 ZN11onnxruntime19ReduceAggregatorMinIaE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00215285 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIaE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00215355 ZN11onnxruntime19ReduceAggregatorMinIaE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
002153eb NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIaE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKaE_NS_9allocatorISK_EEFaSJ_EEE
002154bd ZN11onnxruntime19ReduceAggregatorMinIaE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKaE_
00215554 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIaE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRaPKalE_NS_9allocatorISL_EEFvSI_SK_lEEE
0021562d ZN11onnxruntime19ReduceAggregatorMinIaE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRaPKalE_
002156c7 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorMinIaEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
002157e4 ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorMinIaEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
002158c4 N11onnxruntime9ReduceMinIhEE
002158e1 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIhE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
002159b0 ZN11onnxruntime19ReduceAggregatorMinIhE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00215a45 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIhE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00215b14 ZN11onnxruntime19ReduceAggregatorMinIhE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00215ba9 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIhE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00215c79 ZN11onnxruntime19ReduceAggregatorMinIhE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00215d0f NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIhE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKhE_NS_9allocatorISK_EEFhSJ_EEE
00215de1 ZN11onnxruntime19ReduceAggregatorMinIhE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKhE_
00215e78 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorMinIhE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRhPKhlE_NS_9allocatorISL_EEFvSI_SK_lEEE
00215f51 ZN11onnxruntime19ReduceAggregatorMinIhE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRhPKhlE_
00215feb NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorMinIhEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00216108 ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorMinIhEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
002161e8 N11onnxruntime10ReduceProdIfEE
00216207 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_20ReduceAggregatorProdIfEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00216325 ZN11onnxruntime22NoTransposeReduce1LoopINS_20ReduceAggregatorProdIfEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00216406 N11onnxruntime10ReduceProdIiEE
00216425 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_20ReduceAggregatorProdIiEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00216543 ZN11onnxruntime22NoTransposeReduce1LoopINS_20ReduceAggregatorProdIiEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00216624 N11onnxruntime10ReduceProdIlEE
00216643 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_20ReduceAggregatorProdIlEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00216761 ZN11onnxruntime22NoTransposeReduce1LoopINS_20ReduceAggregatorProdIlEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00216842 N11onnxruntime15ReduceSumSquareIfEE
00216866 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_25ReduceAggregatorSumSquareIffEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0021698a ZN11onnxruntime22NoTransposeReduce1LoopINS_25ReduceAggregatorSumSquareIffEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00216a71 N11onnxruntime15ReduceSumSquareIiEE
00216a95 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_25ReduceAggregatorSumSquareIiiEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00216bb9 ZN11onnxruntime22NoTransposeReduce1LoopINS_25ReduceAggregatorSumSquareIiiEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00216ca0 N11onnxruntime15ReduceSumSquareIdEE
00216cc4 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_25ReduceAggregatorSumSquareIddEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00216de8 ZN11onnxruntime22NoTransposeReduce1LoopINS_25ReduceAggregatorSumSquareIddEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00216ecf N11onnxruntime6ArgMaxIfEE
00216ee9 N11onnxruntime12ReduceKernelILb0EEE
00216f0d N11onnxruntime16ReduceKernelBaseILb0EEE
00216f35 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_31ReduceAggregatorArgMaxLastIndexIflEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0021705f ZN11onnxruntime22NoTransposeReduce1LoopINS_31ReduceAggregatorArgMaxLastIndexIflEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0021714c NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_22ReduceAggregatorArgMaxIflEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0021726d ZN11onnxruntime22NoTransposeReduce1LoopINS_22ReduceAggregatorArgMaxIflEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00217351 N11onnxruntime6ArgMaxIiEE
0021736b NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_31ReduceAggregatorArgMaxLastIndexIilEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00217495 ZN11onnxruntime22NoTransposeReduce1LoopINS_31ReduceAggregatorArgMaxLastIndexIilEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00217582 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_22ReduceAggregatorArgMaxIilEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
002176a3 ZN11onnxruntime22NoTransposeReduce1LoopINS_22ReduceAggregatorArgMaxIilEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00217787 N11onnxruntime6ArgMaxIaEE
002177a1 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_31ReduceAggregatorArgMaxLastIndexIalEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
002178cb ZN11onnxruntime22NoTransposeReduce1LoopINS_31ReduceAggregatorArgMaxLastIndexIalEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
002179b8 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_22ReduceAggregatorArgMaxIalEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00217ad9 ZN11onnxruntime22NoTransposeReduce1LoopINS_22ReduceAggregatorArgMaxIalEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00217bbd N11onnxruntime6ArgMaxIhEE
00217bd7 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_31ReduceAggregatorArgMaxLastIndexIhlEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00217d01 ZN11onnxruntime22NoTransposeReduce1LoopINS_31ReduceAggregatorArgMaxLastIndexIhlEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00217dee NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_22ReduceAggregatorArgMaxIhlEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00217f0f ZN11onnxruntime22NoTransposeReduce1LoopINS_22ReduceAggregatorArgMaxIhlEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00217ff3 N11onnxruntime6ArgMaxIdEE
0021800d NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_31ReduceAggregatorArgMaxLastIndexIdlEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00218137 ZN11onnxruntime22NoTransposeReduce1LoopINS_31ReduceAggregatorArgMaxLastIndexIdlEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00218224 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_22ReduceAggregatorArgMaxIdlEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00218345 ZN11onnxruntime22NoTransposeReduce1LoopINS_22ReduceAggregatorArgMaxIdlEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00218429 N11onnxruntime6ArgMinIfEE
00218443 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_31ReduceAggregatorArgMinLastIndexIflEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0021856d ZN11onnxruntime22NoTransposeReduce1LoopINS_31ReduceAggregatorArgMinLastIndexIflEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0021865a NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_22ReduceAggregatorArgMinIflEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0021877b ZN11onnxruntime22NoTransposeReduce1LoopINS_22ReduceAggregatorArgMinIflEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0021885f N11onnxruntime6ArgMinIiEE
00218879 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_31ReduceAggregatorArgMinLastIndexIilEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
002189a3 ZN11onnxruntime22NoTransposeReduce1LoopINS_31ReduceAggregatorArgMinLastIndexIilEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00218a90 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_22ReduceAggregatorArgMinIilEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00218bb1 ZN11onnxruntime22NoTransposeReduce1LoopINS_22ReduceAggregatorArgMinIilEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00218c95 N11onnxruntime6ArgMinIdEE
00218caf NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_31ReduceAggregatorArgMinLastIndexIdlEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00218dd9 ZN11onnxruntime22NoTransposeReduce1LoopINS_31ReduceAggregatorArgMinLastIndexIdlEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
00218ec6 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_22ReduceAggregatorArgMinIdlEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
00218fe7 ZN11onnxruntime22NoTransposeReduce1LoopINS_22ReduceAggregatorArgMinIdlEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
002190cb NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIfE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021919a ZN11onnxruntime19ReduceAggregatorSumIfE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0021922f NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIfE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
002192fe ZN11onnxruntime19ReduceAggregatorSumIfE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00219393 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIfE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00219463 ZN11onnxruntime19ReduceAggregatorSumIfE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
002194f9 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIfE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKfE_NS_9allocatorISK_EEFfSJ_EEE
002195cb ZN11onnxruntime19ReduceAggregatorSumIfE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKfE_
00219662 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIfE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRfPKflE_NS_9allocatorISL_EEFvSI_SK_lEEE
0021973b ZN11onnxruntime19ReduceAggregatorSumIfE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRfPKflE_
002197d5 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorSumIfEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
002198f2 ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorSumIfEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
002199d2 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIiE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00219aa1 ZN11onnxruntime19ReduceAggregatorSumIiE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00219b36 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIiE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00219c05 ZN11onnxruntime19ReduceAggregatorSumIiE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00219c9a NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIiE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
00219d6a ZN11onnxruntime19ReduceAggregatorSumIiE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
00219e00 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIiE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKiE_NS_9allocatorISK_EEFiSJ_EEE
00219ed2 ZN11onnxruntime19ReduceAggregatorSumIiE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKiE_
00219f69 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIiE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRiPKilE_NS_9allocatorISL_EEFvSI_SK_lEEE
0021a042 ZN11onnxruntime19ReduceAggregatorSumIiE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRiPKilE_
0021a0dc NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorSumIiEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0021a1f9 ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorSumIiEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0021a2d9 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIdE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021a3a8 ZN11onnxruntime19ReduceAggregatorSumIdE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0021a43d NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIdE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021a50c ZN11onnxruntime19ReduceAggregatorSumIdE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0021a5a1 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIdE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021a671 ZN11onnxruntime19ReduceAggregatorSumIdE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0021a707 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIdE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPKdE_NS_9allocatorISK_EEFdSJ_EEE
0021a7d9 ZN11onnxruntime19ReduceAggregatorSumIdE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPKdE_
0021a870 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIdE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRdPKdlE_NS_9allocatorISL_EEFvSI_SK_lEEE
0021a949 ZN11onnxruntime19ReduceAggregatorSumIdE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRdPKdlE_
0021a9e3 NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorSumIdEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0021ab00 ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorSumIdEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0021abe0 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIlE12FastReduceKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021acaf ZN11onnxruntime19ReduceAggregatorSumIlE12FastReduceKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0021ad44 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIlE12FastReduceRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021ae13 ZN11onnxruntime19ReduceAggregatorSumIlE12FastReduceRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0021aea8 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIlE13FastReduceKRKERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021af78 ZN11onnxruntime19ReduceAggregatorSumIlE13FastReduceKRKERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlllE_
0021b00e NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIlE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlPSA_E_NS_9allocatorISJ_EEFlSI_EEE
0021b0e1 ZN11onnxruntime19ReduceAggregatorSumIlE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlPS7_E_
0021b179 NSt6__ndk110__function6__funcIZN11onnxruntime19ReduceAggregatorSumIlE13FastReduceRKRERKNS2_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS5_PNS2_11concurrency10ThreadPoolEEUlRlPSA_lE_NS_9allocatorISK_EEFvSI_SJ_lEEE
0021b253 ZN11onnxruntime19ReduceAggregatorSumIlE13FastReduceRKRERKNS_6TensorERKN3gsl4spanIKlLm18446744073709551615EEERS2_PNS_11concurrency10ThreadPoolEEUlRlPS7_lE_
0021b2ee NSt6__ndk110__function6__funcIZN11onnxruntime22NoTransposeReduce1LoopINS2_19ReduceAggregatorSumIlEEEEvPNS2_6TensorERKNS2_11TensorShapeERKS6_N3gsl4spanIKlLm18446744073709551615EEEPNS2_11concurrency10ThreadPoolERNS2_34ResultsNoTransposePrepareForReduceEEUlllE_NS_9allocatorISM_EEFvllEEE
0021b40b ZN11onnxruntime22NoTransposeReduce1LoopINS_19ReduceAggregatorSumIlEEEEvPNS_6TensorERKNS_11TensorShapeERKS3_N3gsl4spanIKlLm18446744073709551615EEEPNS_11concurrency10ThreadPoolERNS_34ResultsNoTransposePrepareForReduceEEUlllE_
0021b4eb N11onnxruntime12DeepCpuGruOpE
0021b509 NSt6__ndk110__function6__funcIZN11onnxruntime10IAllocator13MakeUniquePtrIiEENS_10unique_ptrIT_NS_8functionIFvPS6_EEEEENS_10shared_ptrIS3_EEmbPNS2_6StreamENS7_IFvRSE_RNS2_11synchronize12NotificationEEEEEUlPiE_NS_9allocatorISN_EEFvSM_EEE
0021b5f5 NSt6__ndk110__function6__baseIFvPiEEE
0021b61b ZN11onnxruntime10IAllocator13MakeUniquePtrIiEENSt6__ndk110unique_ptrIT_NS2_8functionIFvPS4_EEEEENS2_10shared_ptrIS0_EEmbPNS_6StreamENS5_IFvRSC_RNS_11synchronize12NotificationEEEEEUlPiE_
0021b6d5 N11onnxruntime13DeepCpuLstmOpE
0021b6f4 N11onnxruntime8LSTMBaseE
0021b70d N11onnxruntime3RNNIfEE
0021b725 NSt6__ndk110__function6__funcIPFffffENS_9allocatorIS3_EES2_EE
0021b763 NSt6__ndk110__function6__baseIFffffEEE
0021b78a PFffffE
0021b792 FffffE
0021b7b6 p@NSt6__ndk110__function6__funcIZN11onnxruntime4lstmL23ExecuteLambdaInParallelIZNS3_18UniDirectionalLstmIfE7ComputeIfEEvRKN3gsl4spanIKfLm18446744073709551615EEERKNS9_IKiLm18446744073709551615EEEiRKNS2_3rnn6detail11GemmWeightsIT_EESO_RNS9_IfLm18446744073709551615EEESQ_SQ_EUliPNS2_11concurrency10ThreadPoolEE_EEvSL_iidST_EUlllE_NS_9allocatorISV_EEFvllEEE
0021b918 ZN11onnxruntime4lstmL23ExecuteLambdaInParallelIZNS0_18UniDirectionalLstmIfE7ComputeIfEEvRKN3gsl4spanIKfLm18446744073709551615EEERKNS6_IKiLm18446744073709551615EEEiRKNS_3rnn6detail11GemmWeightsIT_EESL_RNS6_IfLm18446744073709551615EEESN_SN_EUliPNS_11concurrency10ThreadPoolEE_EEvSI_iidSQ_EUlllE_
0021ba3e NSt6__ndk110__function6__funcIZN11onnxruntime10IAllocator13MakeUniquePtrIhEENS_10unique_ptrIT_NS_8functionIFvPS6_EEEEENS_10shared_ptrIS3_EEmbPNS2_6StreamENS7_IFvRSE_RNS2_11synchronize12NotificationEEEEEUlPhE_NS_9allocatorISN_EEFvSM_EEE
0021bb2a NSt6__ndk110__function6__baseIFvPhEEE
0021bb50 ZN11onnxruntime10IAllocator13MakeUniquePtrIhEENSt6__ndk110unique_ptrIT_NS2_8functionIFvPS4_EEEEENS2_10shared_ptrIS0_EEmbPNS_6StreamENS5_IFvRSC_RNS_11synchronize12NotificationEEEEEUlPhE_
0021bc0a NSt6__ndk110__function6__funcIZN11onnxruntime4lstmL23ExecuteLambdaInParallelIZNS3_18UniDirectionalLstmIfE7ComputeIhEEvRKN3gsl4spanIKfLm18446744073709551615EEERKNS9_IKiLm18446744073709551615EEEiRKNS2_3rnn6detail11GemmWeightsIT_EESO_RNS9_IfLm18446744073709551615EEESQ_SQ_EUliPNS2_11concurrency10ThreadPoolEE_EEvSL_iidST_EUlllE_NS_9allocatorISV_EEFvllEEE
0021bd6a ZN11onnxruntime4lstmL23ExecuteLambdaInParallelIZNS0_18UniDirectionalLstmIfE7ComputeIhEEvRKN3gsl4spanIKfLm18446744073709551615EEERKNS6_IKiLm18446744073709551615EEEiRKNS_3rnn6detail11GemmWeightsIT_EESL_RNS6_IfLm18446744073709551615EEESN_SN_EUliPNS_11concurrency10ThreadPoolEE_EEvSI_iidSQ_EUlllE_
0021be90 N11onnxruntime18ConcatFromSequenceE
0021beb4 N11onnxruntime10ConcatBaseE
0021beea 0N11onnxruntime14SequenceLengthE
0021bf0b N11onnxruntime10SequenceAtE
0021bf27 N11onnxruntime14SequenceInsertE
0021bf47 N11onnxruntime13SequenceEraseE
0021bf66 N11onnxruntime17SequenceConstructE
0021bf89 N11onnxruntime13SequenceEmptyE
0021bfa8 N11onnxruntime15SplitToSequenceE
0021bfca ::::
0021bfd0 :::	N11onnxruntime3DFTE
0021bfe8 N11onnxruntime4STFTE
0021c0fe ::::
0021c104 :::	
0021c109 ;;;;
0021c10f ;;;	N11onnxruntime10HannWindowE
0021c12f N11onnxruntime26VariableOutputDataTypeBaseE
0021c15b N11onnxruntime13HammingWindowE
0021c17a N11onnxruntime14BlackmanWindowE
0021c19a N11onnxruntime15MelWeightMatrixE
0021c1bb N11onnxruntime12_GLOBAL__N_14CastE
0021c1de N11onnxruntime6Col2ImIfEE
0021c1f8 N11onnxruntime8CompressE
0021c215 888*N11onnxruntime6ConcatE
0021c230 NSt6__ndk110__function6__funcIZN11onnxruntime11StridedCopyINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEvPNS2_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENS7_IlEEEERKNS2_11TensorShapeEPKSD_SL_EUlllE_NS7_ISR_EEFvllEEE
0021c334 ZN11onnxruntime11StridedCopyINSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEEvPNS_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENS5_IlEEEERKNS_11TensorShapeEPKSB_SJ_EUlllE_
0021c410 NSt6__ndk110__function6__funcIZN11onnxruntime11StridedCopyINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEvPNS2_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENS7_IlEEEERKNS2_11TensorShapeEPKSD_SL_EUlllE0_NS7_ISR_EEFvllEEE
0021c515 ZN11onnxruntime11StridedCopyINSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEEvPNS_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENS5_IlEEEERKNS_11TensorShapeEPKSB_SJ_EUlllE0_
0021c5f2 NSt6__ndk110__function6__funcIZN11onnxruntime11StridedCopyIjEEvPNS2_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENS_9allocatorIlEEEERKNS2_11TensorShapeEPKS7_SG_EUlllE_NSC_ISM_EEFvllEEE
0021c6c6 ZN11onnxruntime11StridedCopyIjEEvPNS_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENSt6__ndk19allocatorIlEEEERKNS_11TensorShapeEPKS4_SE_EUlllE_
0021c770 NSt6__ndk110__function6__funcIZN11onnxruntime11StridedCopyIjEEvPNS2_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENS_9allocatorIlEEEERKNS2_11TensorShapeEPKS7_SG_EUlllE0_NSC_ISM_EEFvllEEE
0021c845 ZN11onnxruntime11StridedCopyIjEEvPNS_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENSt6__ndk19allocatorIlEEEERKNS_11TensorShapeEPKS4_SE_EUlllE0_
0021c8f0 NSt6__ndk110__function6__funcIZN11onnxruntime11StridedCopyImEEvPNS2_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENS_9allocatorIlEEEERKNS2_11TensorShapeEPKS7_SG_EUlllE_NSC_ISM_EEFvllEEE
0021c9c4 ZN11onnxruntime11StridedCopyImEEvPNS_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENSt6__ndk19allocatorIlEEEERKNS_11TensorShapeEPKS4_SE_EUlllE_
0021ca6e NSt6__ndk110__function6__funcIZN11onnxruntime11StridedCopyImEEvPNS2_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENS_9allocatorIlEEEERKNS2_11TensorShapeEPKS7_SG_EUlllE0_NSC_ISM_EEFvllEEE
0021cb43 ZN11onnxruntime11StridedCopyImEEvPNS_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENSt6__ndk19allocatorIlEEEERKNS_11TensorShapeEPKS4_SE_EUlllE0_
0021cbee NSt6__ndk110__function6__funcIZN11onnxruntime11StridedCopyItEEvPNS2_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENS_9allocatorIlEEEERKNS2_11TensorShapeEPKS7_SG_EUlllE_NSC_ISM_EEFvllEEE
0021ccc2 ZN11onnxruntime11StridedCopyItEEvPNS_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENSt6__ndk19allocatorIlEEEERKNS_11TensorShapeEPKS4_SE_EUlllE_
0021cd6c NSt6__ndk110__function6__funcIZN11onnxruntime11StridedCopyItEEvPNS2_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENS_9allocatorIlEEEERKNS2_11TensorShapeEPKS7_SG_EUlllE0_NSC_ISM_EEFvllEEE
0021ce41 ZN11onnxruntime11StridedCopyItEEvPNS_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENSt6__ndk19allocatorIlEEEERKNS_11TensorShapeEPKS4_SE_EUlllE0_
0021ceec NSt6__ndk110__function6__funcIZN11onnxruntime11StridedCopyIhEEvPNS2_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENS_9allocatorIlEEEERKNS2_11TensorShapeEPKS7_SG_EUlllE_NSC_ISM_EEFvllEEE
0021cfc0 ZN11onnxruntime11StridedCopyIhEEvPNS_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENSt6__ndk19allocatorIlEEEERKNS_11TensorShapeEPKS4_SE_EUlllE_
0021d06a NSt6__ndk110__function6__funcIZN11onnxruntime11StridedCopyIhEEvPNS2_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENS_9allocatorIlEEEERKNS2_11TensorShapeEPKS7_SG_EUlllE0_NSC_ISM_EEFvllEEE
0021d13f ZN11onnxruntime11StridedCopyIhEEvPNS_11concurrency10ThreadPoolEPT_RKN4absl12lts_2022062313InlinedVectorIlLm5ENSt6__ndk19allocatorIlEEEERKNS_11TensorShapeEPKS4_SE_EUlllE0_
0021d1ea N11onnxruntime6ExpandIfEE
0021d204 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIfE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS7_EEFvllEEE
0021d27e ZNK11onnxruntime6ExpandIfE7ComputeEPNS_15OpKernelContextEEUlllE_
0021d2bf NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIfE7ComputeEPNS2_15OpKernelContextEEUlllE0_NS_9allocatorIS7_EEFvllEEE
0021d33a ZNK11onnxruntime6ExpandIfE7ComputeEPNS_15OpKernelContextEEUlllE0_
0021d37c N11onnxruntime6ExpandIdEE
0021d396 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIdE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS7_EEFvllEEE
0021d410 ZNK11onnxruntime6ExpandIdE7ComputeEPNS_15OpKernelContextEEUlllE_
0021d451 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIdE7ComputeEPNS2_15OpKernelContextEEUlllE0_NS_9allocatorIS7_EEFvllEEE
0021d4cc ZNK11onnxruntime6ExpandIdE7ComputeEPNS_15OpKernelContextEEUlllE0_
0021d50e N11onnxruntime6ExpandIaEE
0021d528 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIaE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS7_EEFvllEEE
0021d5a2 ZNK11onnxruntime6ExpandIaE7ComputeEPNS_15OpKernelContextEEUlllE_
0021d5e3 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIaE7ComputeEPNS2_15OpKernelContextEEUlllE0_NS_9allocatorIS7_EEFvllEEE
0021d65e ZNK11onnxruntime6ExpandIaE7ComputeEPNS_15OpKernelContextEEUlllE0_
0021d6a0 N11onnxruntime6ExpandIsEE
0021d6ba NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIsE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS7_EEFvllEEE
0021d734 ZNK11onnxruntime6ExpandIsE7ComputeEPNS_15OpKernelContextEEUlllE_
0021d775 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIsE7ComputeEPNS2_15OpKernelContextEEUlllE0_NS_9allocatorIS7_EEFvllEEE
0021d7f0 ZNK11onnxruntime6ExpandIsE7ComputeEPNS_15OpKernelContextEEUlllE0_
0021d832 N11onnxruntime6ExpandIiEE
0021d84c NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIiE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS7_EEFvllEEE
0021d8c6 ZNK11onnxruntime6ExpandIiE7ComputeEPNS_15OpKernelContextEEUlllE_
0021d907 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIiE7ComputeEPNS2_15OpKernelContextEEUlllE0_NS_9allocatorIS7_EEFvllEEE
0021d982 ZNK11onnxruntime6ExpandIiE7ComputeEPNS_15OpKernelContextEEUlllE0_
0021d9c4 N11onnxruntime6ExpandIlEE
0021d9de NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIlE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS7_EEFvllEEE
0021da58 ZNK11onnxruntime6ExpandIlE7ComputeEPNS_15OpKernelContextEEUlllE_
0021da99 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIlE7ComputeEPNS2_15OpKernelContextEEUlllE0_NS_9allocatorIS7_EEFvllEEE
0021db14 ZNK11onnxruntime6ExpandIlE7ComputeEPNS_15OpKernelContextEEUlllE0_
0021db56 N11onnxruntime6ExpandIhEE
0021db70 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIhE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS7_EEFvllEEE
0021dbea ZNK11onnxruntime6ExpandIhE7ComputeEPNS_15OpKernelContextEEUlllE_
0021dc2b NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIhE7ComputeEPNS2_15OpKernelContextEEUlllE0_NS_9allocatorIS7_EEFvllEEE
0021dca6 ZNK11onnxruntime6ExpandIhE7ComputeEPNS_15OpKernelContextEEUlllE0_
0021dce8 N11onnxruntime6ExpandItEE
0021dd02 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandItE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS7_EEFvllEEE
0021dd7c ZNK11onnxruntime6ExpandItE7ComputeEPNS_15OpKernelContextEEUlllE_
0021ddbd NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandItE7ComputeEPNS2_15OpKernelContextEEUlllE0_NS_9allocatorIS7_EEFvllEEE
0021de38 ZNK11onnxruntime6ExpandItE7ComputeEPNS_15OpKernelContextEEUlllE0_
0021de7a N11onnxruntime6ExpandIjEE
0021de94 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIjE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS7_EEFvllEEE
0021df0e ZNK11onnxruntime6ExpandIjE7ComputeEPNS_15OpKernelContextEEUlllE_
0021df4f NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIjE7ComputeEPNS2_15OpKernelContextEEUlllE0_NS_9allocatorIS7_EEFvllEEE
0021dfca ZNK11onnxruntime6ExpandIjE7ComputeEPNS_15OpKernelContextEEUlllE0_
0021e00c N11onnxruntime6ExpandImEE
0021e026 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandImE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS7_EEFvllEEE
0021e0a0 ZNK11onnxruntime6ExpandImE7ComputeEPNS_15OpKernelContextEEUlllE_
0021e0e1 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandImE7ComputeEPNS2_15OpKernelContextEEUlllE0_NS_9allocatorIS7_EEFvllEEE
0021e15c ZNK11onnxruntime6ExpandImE7ComputeEPNS_15OpKernelContextEEUlllE0_
0021e19e N11onnxruntime6ExpandIbEE
0021e1b8 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIbE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS7_EEFvllEEE
0021e232 ZNK11onnxruntime6ExpandIbE7ComputeEPNS_15OpKernelContextEEUlllE_
0021e273 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandIbE7ComputeEPNS2_15OpKernelContextEEUlllE0_NS_9allocatorIS7_EEFvllEEE
0021e2ee ZNK11onnxruntime6ExpandIbE7ComputeEPNS_15OpKernelContextEEUlllE0_
0021e330 N11onnxruntime6ExpandINS_9MLFloat16EEE
0021e357 NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandINS2_9MLFloat16EE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS8_EEFvllEEE
0021e3df ZNK11onnxruntime6ExpandINS_9MLFloat16EE7ComputeEPNS_15OpKernelContextEEUlllE_
0021e42d NSt6__ndk110__function6__funcIZNK11onnxruntime6ExpandINS2_9MLFloat16EE7ComputeEPNS2_15OpKernelContextEEUlllE0_NS_9allocatorIS8_EEFvllEEE
0021e4b6 ZNK11onnxruntime6ExpandINS_9MLFloat16EE7ComputeEPNS_15OpKernelContextEEUlllE0_
0021e505 N11onnxruntime7EyeLikeE
0021e51d N11onnxruntime6GatherE
0021e534 N11onnxruntime10GatherBaseE
0021e550 NSt6__ndk110__function6__funcIZN11onnxruntime14GatherCopyDataIiEENS2_6common6StatusEPKNS2_6TensorEPKhPhbmlllllRKNS2_11TensorShapeElPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021e614 ZN11onnxruntime14GatherCopyDataIiEENS_6common6StatusEPKNS_6TensorEPKhPhbmlllllRKNS_11TensorShapeElPNS_11concurrency10ThreadPoolEEUlllE_
0021e69c NSt6__ndk110__function6__funcIZN11onnxruntime14GatherCopyDataIlEENS2_6common6StatusEPKNS2_6TensorEPKhPhbmlllllRKNS2_11TensorShapeElPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021e760 ZN11onnxruntime14GatherCopyDataIlEENS_6common6StatusEPKNS_6TensorEPKhPhbmlllllRKNS_11TensorShapeElPNS_11concurrency10ThreadPoolEEUlllE_
0021e808 N11onnxruntime14GatherElementsE
0021e828 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS2_L9core_implIiEEvPKNS2_6TensorES9_PS7_lPS4_ENKUlPT_PT0_E_clINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEKSN_EEDaSD_SF_EUlmE_EEvSB_lOSC_lEUllE_NSL_ISS_EEFvlEEE
0021e937 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS_L9core_implIiEEvPKNS_6TensorES6_PS4_lPS1_ENKUlPT_PT0_E_clINSt6__ndk112basic_stringIcNSF_11char_traitsIcEENSF_9allocatorIcEEEEKSL_EEDaSA_SC_EUlmE_EEvS8_lOS9_lEUllE_
0021ea1f NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS2_L9core_implIiEEvPKNS2_6TensorES9_PS7_lPS4_ENKUlPT_PT0_E_clIjKjEEDaSD_SF_EUlmE_EEvSB_lOSC_lEUllE_NS_9allocatorISM_EEFvlEEE
0021eafc ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS_L9core_implIiEEvPKNS_6TensorES6_PS4_lPS1_ENKUlPT_PT0_E_clIjKjEEDaSA_SC_EUlmE_EEvS8_lOS9_lEUllE_
0021eba0 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS2_L9core_implIiEEvPKNS2_6TensorES9_PS7_lPS4_ENKUlPT_PT0_E_clItKtEEDaSD_SF_EUlmE_EEvSB_lOSC_lEUllE_NS_9allocatorISM_EEFvlEEE
0021ec7d ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS_L9core_implIiEEvPKNS_6TensorES6_PS4_lPS1_ENKUlPT_PT0_E_clItKtEEDaSA_SC_EUlmE_EEvS8_lOS9_lEUllE_
0021ed21 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS2_L9core_implIiEEvPKNS2_6TensorES9_PS7_lPS4_ENKUlPT_PT0_E_clIhKhEEDaSD_SF_EUlmE_EEvSB_lOSC_lEUllE_NS_9allocatorISM_EEFvlEEE
0021edfe ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS_L9core_implIiEEvPKNS_6TensorES6_PS4_lPS1_ENKUlPT_PT0_E_clIhKhEEDaSA_SC_EUlmE_EEvS8_lOS9_lEUllE_
0021eea2 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS2_L9core_implIiEEvPKNS2_6TensorES9_PS7_lPS4_ENKUlPT_PT0_E_clImKmEEDaSD_SF_EUlmE_EEvSB_lOSC_lEUllE_NS_9allocatorISM_EEFvlEEE
0021ef7f ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS_L9core_implIiEEvPKNS_6TensorES6_PS4_lPS1_ENKUlPT_PT0_E_clImKmEEDaSA_SC_EUlmE_EEvS8_lOS9_lEUllE_
0021f023 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS2_L9core_implIlEEvPKNS2_6TensorES9_PS7_lPS4_ENKUlPT_PT0_E_clINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEKSN_EEDaSD_SF_EUlmE_EEvSB_lOSC_lEUllE_NSL_ISS_EEFvlEEE
0021f132 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS_L9core_implIlEEvPKNS_6TensorES6_PS4_lPS1_ENKUlPT_PT0_E_clINSt6__ndk112basic_stringIcNSF_11char_traitsIcEENSF_9allocatorIcEEEEKSL_EEDaSA_SC_EUlmE_EEvS8_lOS9_lEUllE_
0021f21a NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS2_L9core_implIlEEvPKNS2_6TensorES9_PS7_lPS4_ENKUlPT_PT0_E_clIjKjEEDaSD_SF_EUlmE_EEvSB_lOSC_lEUllE_NS_9allocatorISM_EEFvlEEE
0021f2f7 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS_L9core_implIlEEvPKNS_6TensorES6_PS4_lPS1_ENKUlPT_PT0_E_clIjKjEEDaSA_SC_EUlmE_EEvS8_lOS9_lEUllE_
0021f39b NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS2_L9core_implIlEEvPKNS2_6TensorES9_PS7_lPS4_ENKUlPT_PT0_E_clItKtEEDaSD_SF_EUlmE_EEvSB_lOSC_lEUllE_NS_9allocatorISM_EEFvlEEE
0021f478 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS_L9core_implIlEEvPKNS_6TensorES6_PS4_lPS1_ENKUlPT_PT0_E_clItKtEEDaSA_SC_EUlmE_EEvS8_lOS9_lEUllE_
0021f51c NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS2_L9core_implIlEEvPKNS2_6TensorES9_PS7_lPS4_ENKUlPT_PT0_E_clIhKhEEDaSD_SF_EUlmE_EEvSB_lOSC_lEUllE_NS_9allocatorISM_EEFvlEEE
0021f5f9 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS_L9core_implIlEEvPKNS_6TensorES6_PS4_lPS1_ENKUlPT_PT0_E_clIhKhEEDaSA_SC_EUlmE_EEvS8_lOS9_lEUllE_
0021f69d NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS2_L9core_implIlEEvPKNS2_6TensorES9_PS7_lPS4_ENKUlPT_PT0_E_clImKmEEDaSD_SF_EUlmE_EEvSB_lOSC_lEUllE_NS_9allocatorISM_EEFvlEEE
0021f77a ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIRZZNS_L9core_implIlEEvPKNS_6TensorES6_PS4_lPS1_ENKUlPT_PT0_E_clImKmEEDaSA_SC_EUlmE_EEvS8_lOS9_lEUllE_
0021f81e N11onnxruntime8GatherNDE
0021f837 N11onnxruntime12GatherNDBaseE
0021f855 NSt6__ndk110__function6__funcIZNK11onnxruntime12GatherNDBase17PrepareForComputeIiEENS2_6common6StatusERKNS2_11TensorShapeEPKNS2_6TensorElRNS3_7PrepareEPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021f92d ZNK11onnxruntime12GatherNDBase17PrepareForComputeIiEENS_6common6StatusERKNS_11TensorShapeEPKNS_6TensorElRNS0_7PrepareEPNS_11concurrency10ThreadPoolEEUlllE_
0021f9c9 NSt6__ndk110__function6__funcIZNK11onnxruntime12GatherNDBase17PrepareForComputeIlEENS2_6common6StatusERKNS2_11TensorShapeEPKNS2_6TensorElRNS3_7PrepareEPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISI_EEFvllEEE
0021faa1 ZNK11onnxruntime12GatherNDBase17PrepareForComputeIlEENS_6common6StatusERKNS_11TensorShapeEPKNS_6TensorElRNS0_7PrepareEPNS_11concurrency10ThreadPoolEEUlllE_
0021fb3d NSt6__ndk110__function6__funcIZNK11onnxruntime8GatherND12GatherNumberERKNS2_12GatherNDBase7PrepareEPNS2_11concurrency10ThreadPoolEE3$_5NS_9allocatorISB_EEFvllEEE
0021fbdf ZNK11onnxruntime8GatherND12GatherNumberERKNS_12GatherNDBase7PrepareEPNS_11concurrency10ThreadPoolEE3$_5
0021fc47 NSt6__ndk110__function6__funcIZNK11onnxruntime8GatherND12GatherStringERKNS2_12GatherNDBase7PrepareEPNS2_11concurrency10ThreadPoolEE3$_7NS_9allocatorISB_EEFvllEEE
0021fce9 ZNK11onnxruntime8GatherND12GatherStringERKNS_12GatherNDBase7PrepareEPNS_11concurrency10ThreadPoolEE3$_7
0021fd51 N11onnxruntime10GridSampleIfEE
0021fd70 NSt6__ndk110__function6__funcIZNK11onnxruntime10GridSampleIfE7ComputeEPNS2_15OpKernelContextEEUllE_NS_9allocatorIS7_EEFvlEEE
0021fded ZNK11onnxruntime10GridSampleIfE7ComputeEPNS_15OpKernelContextEEUllE_
0021fe32 N11onnxruntime10IdentityOpILb1EEE
0021fe54 N11onnxruntime10IdentityOpILb0EEE
0021fe76 N11onnxruntime5IsInfE
0021fe8c N11onnxruntime5IsNaNIfEE
0021fea5 N11onnxruntime5IsNaNIdEE
0021febe N11onnxruntime5IsNaNINS_9MLFloat16EEE
0021ff00 N11onnxruntime27MeanVarianceNormalization_1IfEE
0021ff30 N11onnxruntime27MeanVarianceNormalization_0IfEE
0021ff60 N11onnxruntime7NonZeroIbEE
0021ff7b N11onnxruntime7NonZeroIhEE
0021ff96 N11onnxruntime7NonZeroIiEE
0021ffb1 N11onnxruntime7NonZeroIlEE
0021ffcc N11onnxruntime7NonZeroIfEE
0021ffe7 N11onnxruntime8OneHotOpIlllEE
00220005 N11onnxruntime8OneHotOpIfllEE
00220023 N11onnxruntime8OneHotOpIlNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEElEE
00220083 N11onnxruntime8OneHotOpIfNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEElEE
002200e3 N11onnxruntime8OneHotOpIlflEE
00220101 N11onnxruntime8OneHotOpIifiEE
0022011f N11onnxruntime8OneHotOpIiffEE
0022013d N11onnxruntime8OneHotOpIfffEE
0022015b N11onnxruntime8OneHotOpIlifEE
00220179 N11onnxruntime8OneHotOpIlffEE
00220197 N11onnxruntime8OneHotOpIlfiEE
002201b5 N11onnxruntime3PadE
002201c9 N11onnxruntime7PadBaseE
002201e1 N11onnxruntime9Reshape_1E
002201fb N11onnxruntime7ReshapeE
00220213 N11onnxruntime6ResizeIfEE
0022022d N11onnxruntime8UpsampleIfEE
00220249 N11onnxruntime6ResizeIiEE
00220263 N11onnxruntime8UpsampleIiEE
0022027f N11onnxruntime6ResizeIaEE
00220299 N11onnxruntime8UpsampleIaEE
002202b5 N11onnxruntime6ResizeIhEE
002202cf N11onnxruntime8UpsampleIhEE
002202f3 f<X.J
002202fa tN11onnxruntime17ReverseSequenceOpE
0022031e N11onnxruntime7ScatterINS_8TypeListIJfdlmijstahNS_9MLFloat16ENS_8BFloat16EbNSt6__ndk112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEEEEEE
002203e9 1N11onnxruntime9ScatterNDE
00220404 NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetIfEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISC_EEFvllEEE
002204c2 ZNK11onnxruntime23ScatterNDDispatchTargetIfEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
00220545 NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetIdEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISC_EEFvllEEE
00220603 ZNK11onnxruntime23ScatterNDDispatchTargetIdEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
00220686 NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetIlEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISC_EEFvllEEE
00220744 ZNK11onnxruntime23ScatterNDDispatchTargetIlEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
002207c7 NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetImEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISC_EEFvllEEE
00220885 ZNK11onnxruntime23ScatterNDDispatchTargetImEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
00220908 NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetIiEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISC_EEFvllEEE
002209c6 ZNK11onnxruntime23ScatterNDDispatchTargetIiEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
00220a49 NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetIjEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISC_EEFvllEEE
00220b07 ZNK11onnxruntime23ScatterNDDispatchTargetIjEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
00220b8a NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetIsEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISC_EEFvllEEE
00220c48 ZNK11onnxruntime23ScatterNDDispatchTargetIsEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
00220ccb NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetItEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISC_EEFvllEEE
00220d89 ZNK11onnxruntime23ScatterNDDispatchTargetItEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
00220e0c NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetIaEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISC_EEFvllEEE
00220eca ZNK11onnxruntime23ScatterNDDispatchTargetIaEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
00220f4d NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetIhEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISC_EEFvllEEE
0022100b ZNK11onnxruntime23ScatterNDDispatchTargetIhEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
0022108e NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetINS2_9MLFloat16EEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISD_EEFvllEEE
0022115a ZNK11onnxruntime23ScatterNDDispatchTargetINS_9MLFloat16EEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
002211ea NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetINS2_8BFloat16EEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISD_EEFvllEEE
002212b5 ZNK11onnxruntime23ScatterNDDispatchTargetINS_8BFloat16EEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
00221344 NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetIbEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS_9allocatorISC_EEFvllEEE
00221402 ZNK11onnxruntime23ScatterNDDispatchTargetIbEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
00221485 NSt6__ndk110__function6__funcIZNK11onnxruntime23ScatterNDDispatchTargetINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEclEPNS2_15OpKernelContextEPNS2_11concurrency10ThreadPoolENS2_9ScatterND9ReductionEEUlllE_NS7_ISI_EEFvllEEE
00221573 ZNK11onnxruntime23ScatterNDDispatchTargetINSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEclEPNS_15OpKernelContextEPNS_11concurrency10ThreadPoolENS_9ScatterND9ReductionEEUlllE_
00221638 N11onnxruntime5ShapeE
0022164e N11onnxruntime4SizeE
0022167c N11onnxruntime6Slice1E
00221693 N11onnxruntime9SliceBaseE
002216ad N11onnxruntime7Slice10E
00221728 N11onnxruntime12SpaceToDepthE
00221746 N11onnxruntime14SpaceDepthBaseE
00221766 N11onnxruntime12DepthToSpaceE
00221784 N11onnxruntime9SplitImplE
0022179e N11onnxruntime9SplitBaseE
002217b8 N11onnxruntime10Split_1_13E
002217d4 N11onnxruntime8Split_18E
002217ed N11onnxruntime7SqueezeE
00221805 N11onnxruntime11SqueezeBaseE
00221823 22;;
0022182e )N11onnxruntime4TileE
00221854 N11onnxruntime9TransposeE
0022186e N11onnxruntime13TransposeBaseE
0022188d N11onnxruntime5TriluE
002218ab N11onnxruntime6UniqueE
002218c3 N11onnxruntime9UnsqueezeE
002218dd N11onnxruntime13UnsqueezeBaseE
0022190c N11onnxruntime23BilinearParamsAntiAliasIfEE
00221938 N11onnxruntime21FilterParamsAntiAliasIfEE
00221963 NSt6__ndk110__function6__funcIZN11onnxruntime28ComputeInterpolationAtLevel1IffEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS5_IS6_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EERKNS2_25FilterParamsBaseAntiAliasISB_EEPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISM_EEFvlEEE
00221a8a ZN11onnxruntime28ComputeInterpolationAtLevel1IffEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS2_IS3_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EERKNS_25FilterParamsBaseAntiAliasIS8_EEPNS_11concurrency10ThreadPoolEEUllE_
00221b77 NSt6__ndk110__function6__funcIZN11onnxruntime28ComputeInterpolationAtLevel2IffEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS5_IS6_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EERKNS2_25FilterParamsBaseAntiAliasISB_EEPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISM_EEFvlEEE
00221c9e ZN11onnxruntime28ComputeInterpolationAtLevel2IffEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS2_IS3_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EERKNS_25FilterParamsBaseAntiAliasIS8_EEPNS_11concurrency10ThreadPoolEEUllE_
00221d8b NSt6__ndk110__function6__funcIZN11onnxruntime28ComputeInterpolationAtLevel2IffEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS5_IS6_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EERKNS2_25FilterParamsBaseAntiAliasISB_EEPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISM_EEFvllEEE
00221eb4 ZN11onnxruntime28ComputeInterpolationAtLevel2IffEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS2_IS3_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EERKNS_25FilterParamsBaseAntiAliasIS8_EEPNS_11concurrency10ThreadPoolEEUlllE_
00221fa2 NSt6__ndk110__function6__funcIZN11onnxruntime19HandleExtrapolationIffEEvllllfN3gsl4spanIT_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EEPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISG_EEFvlEEE
00222077 ZN11onnxruntime19HandleExtrapolationIffEEvllllfN3gsl4spanIT_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EEPNS_11concurrency10ThreadPoolEEUllE_
00222113 NSt6__ndk110__function6__funcIZN11onnxruntime16UpsampleBilinearIfEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEbfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUllE_NS5_ISP_EEFvlEEE
002221f0 ZN11onnxruntime16UpsampleBilinearIfEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEbfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUllE_
002222a6 NSt6__ndk110__function6__funcIZN11onnxruntime27NhwcUpsampleBilinearIntegerIfLb1EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00222393 ZN11onnxruntime27NhwcUpsampleBilinearIntegerIfLb1EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
00222458 NSt6__ndk110__function6__funcIZN11onnxruntime20NhwcUpsampleBilinearIfLb1EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
0022253e ZN11onnxruntime20NhwcUpsampleBilinearIfLb1EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
002225fc NSt6__ndk110__function6__funcIZN11onnxruntime27NhwcUpsampleBilinearIntegerIfLb0EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
002226e9 ZN11onnxruntime27NhwcUpsampleBilinearIntegerIfLb0EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
002227ae NSt6__ndk110__function6__funcIZN11onnxruntime20NhwcUpsampleBilinearIfLb0EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00222894 ZN11onnxruntime20NhwcUpsampleBilinearIfLb0EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
00222952 N11onnxruntime24TriLinearParamsAntiAliasIfEE
0022297f NSt6__ndk110__function6__funcIZN11onnxruntime17UpsampleTrilinearIfEEvllllllllfffRKNS_6vectorIfNS_9allocatorIfEEEEbfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUllE_NS5_ISP_EEFvlEEE
00222a60 ZN11onnxruntime17UpsampleTrilinearIfEEvllllllllfffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEbfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUllE_
00222b1a N11onnxruntime22BiCubicParamsAntiAliasIfEE
00222b45 NSt6__ndk110__function6__funcIZN11onnxruntime28ComputeInterpolationAtLevel1IifEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS5_IS6_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EERKNS2_25FilterParamsBaseAntiAliasISB_EEPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISM_EEFvlEEE
00222c6c ZN11onnxruntime28ComputeInterpolationAtLevel1IifEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS2_IS3_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EERKNS_25FilterParamsBaseAntiAliasIS8_EEPNS_11concurrency10ThreadPoolEEUllE_
00222d59 NSt6__ndk110__function6__funcIZN11onnxruntime28ComputeInterpolationAtLevel2IifEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS5_IS6_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EERKNS2_25FilterParamsBaseAntiAliasISB_EEPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISM_EEFvlEEE
00222e80 ZN11onnxruntime28ComputeInterpolationAtLevel2IifEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS2_IS3_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EERKNS_25FilterParamsBaseAntiAliasIS8_EEPNS_11concurrency10ThreadPoolEEUllE_
00222f6d NSt6__ndk110__function6__funcIZN11onnxruntime28ComputeInterpolationAtLevel2IifEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS5_IS6_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EERKNS2_25FilterParamsBaseAntiAliasISB_EEPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISM_EEFvllEEE
00223096 ZN11onnxruntime28ComputeInterpolationAtLevel2IifEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS2_IS3_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EERKNS_25FilterParamsBaseAntiAliasIS8_EEPNS_11concurrency10ThreadPoolEEUlllE_
00223184 NSt6__ndk110__function6__funcIZN11onnxruntime19HandleExtrapolationIifEEvllllfN3gsl4spanIT_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EEPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISG_EEFvlEEE
00223259 ZN11onnxruntime19HandleExtrapolationIifEEvllllfN3gsl4spanIT_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EEPNS_11concurrency10ThreadPoolEEUllE_
002232f5 NSt6__ndk110__function6__funcIZN11onnxruntime16UpsampleBilinearIiEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEbfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUllE_NS5_ISP_EEFvlEEE
002233d2 ZN11onnxruntime16UpsampleBilinearIiEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEbfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUllE_
00223488 NSt6__ndk110__function6__funcIZN11onnxruntime27NhwcUpsampleBilinearIntegerIiLb1EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00223575 ZN11onnxruntime27NhwcUpsampleBilinearIntegerIiLb1EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
0022363a NSt6__ndk110__function6__funcIZN11onnxruntime20NhwcUpsampleBilinearIiLb1EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00223720 ZN11onnxruntime20NhwcUpsampleBilinearIiLb1EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
002237de NSt6__ndk110__function6__funcIZN11onnxruntime27NhwcUpsampleBilinearIntegerIiLb0EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
002238cb ZN11onnxruntime27NhwcUpsampleBilinearIntegerIiLb0EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
00223990 NSt6__ndk110__function6__funcIZN11onnxruntime20NhwcUpsampleBilinearIiLb0EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00223a76 ZN11onnxruntime20NhwcUpsampleBilinearIiLb0EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
00223b34 NSt6__ndk110__function6__funcIZN11onnxruntime17UpsampleTrilinearIiEEvllllllllfffRKNS_6vectorIfNS_9allocatorIfEEEEbfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUllE_NS5_ISP_EEFvlEEE
00223c15 ZN11onnxruntime17UpsampleTrilinearIiEEvllllllllfffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEbfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUllE_
00223ccf N11onnxruntime23BilinearParamsAntiAliasIiEE
00223cfb N11onnxruntime21FilterParamsAntiAliasIiEE
00223d25 NSt6__ndk110__function6__funcIZN11onnxruntime10IAllocator13MakeUniquePtrIaEENS_10unique_ptrIT_NS_8functionIFvPS6_EEEEENS_10shared_ptrIS3_EEmbPNS2_6StreamENS7_IFvRSE_RNS2_11synchronize12NotificationEEEEEUlPaE_NS_9allocatorISN_EEFvSM_EEE
00223e11 NSt6__ndk110__function6__baseIFvPaEEE
00223e37 ZN11onnxruntime10IAllocator13MakeUniquePtrIaEENSt6__ndk110unique_ptrIT_NS2_8functionIFvPS4_EEEEENS2_10shared_ptrIS0_EEmbPNS_6StreamENS5_IFvRSC_RNS_11synchronize12NotificationEEEEEUlPaE_
00223ef1 NSt6__ndk110__function6__funcIZN11onnxruntime28ComputeInterpolationAtLevel1IaiEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS5_IS6_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EERKNS2_25FilterParamsBaseAntiAliasISB_EEPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISM_EEFvlEEE
00224018 ZN11onnxruntime28ComputeInterpolationAtLevel1IaiEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS2_IS3_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EERKNS_25FilterParamsBaseAntiAliasIS8_EEPNS_11concurrency10ThreadPoolEEUllE_
00224105 NSt6__ndk110__function6__funcIZN11onnxruntime28ComputeInterpolationAtLevel2IaiEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS5_IS6_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EERKNS2_25FilterParamsBaseAntiAliasISB_EEPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISM_EEFvlEEE
0022422c ZN11onnxruntime28ComputeInterpolationAtLevel2IaiEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS2_IS3_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EERKNS_25FilterParamsBaseAntiAliasIS8_EEPNS_11concurrency10ThreadPoolEEUllE_
00224319 NSt6__ndk110__function6__funcIZN11onnxruntime28ComputeInterpolationAtLevel2IaiEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS5_IS6_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EERKNS2_25FilterParamsBaseAntiAliasISB_EEPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISM_EEFvllEEE
00224442 ZN11onnxruntime28ComputeInterpolationAtLevel2IaiEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS2_IS3_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EERKNS_25FilterParamsBaseAntiAliasIS8_EEPNS_11concurrency10ThreadPoolEEUlllE_
00224530 NSt6__ndk110__function6__funcIZN11onnxruntime19HandleExtrapolationIaiEEvllllfN3gsl4spanIT_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EEPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISG_EEFvlEEE
00224605 ZN11onnxruntime19HandleExtrapolationIaiEEvllllfN3gsl4spanIT_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EEPNS_11concurrency10ThreadPoolEEUllE_
002246a1 NSt6__ndk110__function6__funcIZN11onnxruntime16UpsampleBilinearIaEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEbfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUllE_NS5_ISP_EEFvlEEE
0022477e ZN11onnxruntime16UpsampleBilinearIaEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEbfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUllE_
00224834 NSt6__ndk110__function6__funcIZN11onnxruntime27NhwcUpsampleBilinearIntegerIaLb1EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00224921 ZN11onnxruntime27NhwcUpsampleBilinearIntegerIaLb1EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
002249e6 NSt6__ndk110__function6__funcIZN11onnxruntime20NhwcUpsampleBilinearIaLb1EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00224acc ZN11onnxruntime20NhwcUpsampleBilinearIaLb1EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
00224b8a NSt6__ndk110__function6__funcIZN11onnxruntime27NhwcUpsampleBilinearIntegerIaLb0EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00224c77 ZN11onnxruntime27NhwcUpsampleBilinearIntegerIaLb0EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
00224d3c NSt6__ndk110__function6__funcIZN11onnxruntime20NhwcUpsampleBilinearIaLb0EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00224e22 ZN11onnxruntime20NhwcUpsampleBilinearIaLb0EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
00224ee0 N11onnxruntime24TriLinearParamsAntiAliasIiEE
00224f0d NSt6__ndk110__function6__funcIZN11onnxruntime17UpsampleTrilinearIaEEvllllllllfffRKNS_6vectorIfNS_9allocatorIfEEEEbfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUllE_NS5_ISP_EEFvlEEE
00224fee ZN11onnxruntime17UpsampleTrilinearIaEEvllllllllfffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEbfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUllE_
002250a8 N11onnxruntime22BiCubicParamsAntiAliasIiEE
002250d3 NSt6__ndk110__function6__funcIZN11onnxruntime28ComputeInterpolationAtLevel1IhiEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS5_IS6_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EERKNS2_25FilterParamsBaseAntiAliasISB_EEPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISM_EEFvlEEE
002251fa ZN11onnxruntime28ComputeInterpolationAtLevel1IhiEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS2_IS3_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EERKNS_25FilterParamsBaseAntiAliasIS8_EEPNS_11concurrency10ThreadPoolEEUllE_
002252e7 NSt6__ndk110__function6__funcIZN11onnxruntime28ComputeInterpolationAtLevel2IhiEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS5_IS6_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EERKNS2_25FilterParamsBaseAntiAliasISB_EEPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISM_EEFvlEEE
0022540e ZN11onnxruntime28ComputeInterpolationAtLevel2IhiEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS2_IS3_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EERKNS_25FilterParamsBaseAntiAliasIS8_EEPNS_11concurrency10ThreadPoolEEUllE_
002254fb NSt6__ndk110__function6__funcIZN11onnxruntime28ComputeInterpolationAtLevel2IhiEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS5_IS6_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EERKNS2_25FilterParamsBaseAntiAliasISB_EEPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISM_EEFvllEEE
00225624 ZN11onnxruntime28ComputeInterpolationAtLevel2IhiEEvlllllN3gsl4spanIKT_Lm18446744073709551615EEENS2_IS3_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EERKNS_25FilterParamsBaseAntiAliasIS8_EEPNS_11concurrency10ThreadPoolEEUlllE_
00225712 NSt6__ndk110__function6__funcIZN11onnxruntime19HandleExtrapolationIhiEEvllllfN3gsl4spanIT_Lm18446744073709551615EEERKNS2_21FilterParamsAntiAliasIT0_EEPNS2_11concurrency10ThreadPoolEEUllE_NS_9allocatorISG_EEFvlEEE
002257e7 ZN11onnxruntime19HandleExtrapolationIhiEEvllllfN3gsl4spanIT_Lm18446744073709551615EEERKNS_21FilterParamsAntiAliasIT0_EEPNS_11concurrency10ThreadPoolEEUllE_
00225883 NSt6__ndk110__function6__funcIZN11onnxruntime16UpsampleBilinearIhEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEbfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUllE_NS5_ISP_EEFvlEEE
00225960 ZN11onnxruntime16UpsampleBilinearIhEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEbfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUllE_
00225a16 NSt6__ndk110__function6__funcIZN11onnxruntime27NhwcUpsampleBilinearIntegerIhLb1EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00225b03 ZN11onnxruntime27NhwcUpsampleBilinearIntegerIhLb1EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
00225bc8 NSt6__ndk110__function6__funcIZN11onnxruntime20NhwcUpsampleBilinearIhLb1EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00225cae ZN11onnxruntime20NhwcUpsampleBilinearIhLb1EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
00225d6c NSt6__ndk110__function6__funcIZN11onnxruntime27NhwcUpsampleBilinearIntegerIhLb0EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00225e59 ZN11onnxruntime27NhwcUpsampleBilinearIntegerIhLb0EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
00225f1e NSt6__ndk110__function6__funcIZN11onnxruntime20NhwcUpsampleBilinearIhLb0EEEviiiiiiffRKNS_6vectorIfNS_9allocatorIfEEEEfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUlllE_NS5_ISP_EEFvllEEE
00226004 ZN11onnxruntime20NhwcUpsampleBilinearIhLb0EEEviiiiiiffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUlllE_
002260c2 NSt6__ndk110__function6__funcIZN11onnxruntime17UpsampleTrilinearIhEEvllllllllfffRKNS_6vectorIfNS_9allocatorIfEEEEbfPKT_PSA_RNS_10shared_ptrINS2_10IAllocatorEEERKPFfffffffEPNS2_11concurrency10ThreadPoolEEUllE_NS5_ISP_EEFvlEEE
002261a3 ZN11onnxruntime17UpsampleTrilinearIhEEvllllllllfffRKNSt6__ndk16vectorIfNS1_9allocatorIfEEEEbfPKT_PS8_RNS1_10shared_ptrINS_10IAllocatorEEERKPFfffffffEPNS_11concurrency10ThreadPoolEEUllE_
0022625d N11onnxruntime5WhereIhEE
00226276 N11onnxruntime5WhereIiEE
0022628f N11onnxruntime5WhereIlEE
002262a8 N11onnxruntime5WhereIfEE
002262c1 N11onnxruntime5WhereIdEE
002262da N11onnxruntime5WhereINSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
00226335 N11onnxruntime7contrib9AttentionIfEE
0022635a N11onnxruntime7contrib16AttentionCPUBaseE
00226384 N11onnxruntime7contrib13AttentionBaseE
002263ab NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib9AttentionIfE7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS8_EEFvllEEE
00226430 ZNK11onnxruntime7contrib9AttentionIfE7ComputeEPNS_15OpKernelContextEEUlllE_
0022647c NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib16AttentionCPUBase21ComputeAttentionProbsIfEEvPT_PKS6_S9_PKiN3gsl4spanIKlLm18446744073709551615EEES7_biiiiS9_S7_PNS2_11concurrency10ThreadPoolES9_EUlllE_NS_9allocatorISJ_EEFvllEEE
00226566 ZNK11onnxruntime7contrib16AttentionCPUBase21ComputeAttentionProbsIfEEvPT_PKS3_S6_PKiN3gsl4spanIKlLm18446744073709551615EEES4_biiiiS6_S4_PNS_11concurrency10ThreadPoolES6_EUlllE_
00226617 NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib16AttentionCPUBase23ComputeVxAttentionScoreIfEEvPT_S7_PKS6_S9_iiiiiiS9_S7_PNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISD_EEFvllEEE
002266d8 ZNK11onnxruntime7contrib16AttentionCPUBase23ComputeVxAttentionScoreIfEEvPT_S4_PKS3_S6_iiiiiiS6_S4_PNS_11concurrency10ThreadPoolEEUlllE_
00226763 (N11onnxruntime7contrib18EmbedLayerNormBaseE
00226790 N11onnxruntime7contrib14EmbedLayerNormIfEE
002267bb NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_7contrib14EmbedLayerNormIfE7ComputeEPNS2_15OpKernelContextEEUllE_EEvPS4_lOT_lEUllE_NS_9allocatorISF_EEFvlEEE
0022688a ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_7contrib14EmbedLayerNormIfE7ComputeEPNS_15OpKernelContextEEUllE_EEvPS1_lOT_lEUllE_
00226920 N11onnxruntime7contrib17DeepCpuAttnLstmOpE
0022694b N11onnxruntime7contrib16AttentionWrapperIfEE
00226978 N11onnxruntime7contrib17BahdanauAttentionIfEE
002269a6 N11onnxruntime7contrib19IAttentionMechanismIfEE
002269d6 N11onnxruntime7contrib28ConvTransposeWithDynamicPadsIfEE
00226a0f N11onnxruntime7contrib5CDistIfEE
00226a30 N11onnxruntime7contrib5CDistIdEE
00226a51 N11onnxruntime7contrib8BiasGeluIfLb0EEE
00226a79 N11onnxruntime7contrib8BiasGeluIfLb1EEE
00226aa1 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_7contrib8BiasGeluIfLb0EE7ComputeEPNS2_15OpKernelContextEEUllE0_EEvPS4_lOT_lEUllE_NS_9allocatorISF_EEFvlEEE
00226b6e ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_7contrib8BiasGeluIfLb0EE7ComputeEPNS_15OpKernelContextEEUllE0_EEvPS1_lOT_lEUllE_
00226c02 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_7contrib8BiasGeluIfLb1EE7ComputeEPNS2_15OpKernelContextEEUllE_EEvPS4_lOT_lEUllE_NS_9allocatorISF_EEFvlEEE
00226cce ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_7contrib8BiasGeluIfLb1EE7ComputeEPNS_15OpKernelContextEEUllE_EEvPS1_lOT_lEUllE_
00226d61 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_7contrib8BiasGeluIfLb1EE7ComputeEPNS2_15OpKernelContextEEUllE0_EEvPS4_lOT_lEUllE_NS_9allocatorISF_EEFvlEEE
00226e2e ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_7contrib8BiasGeluIfLb1EE7ComputeEPNS_15OpKernelContextEEUllE0_EEvPS1_lOT_lEUllE_
00226ec2 N11onnxruntime17ElementWiseKernelINS_8functors18ParametricSoftplusIfEEEE
00226f0b NSt6__ndk110__function6__funcIN11onnxruntime8functors18ParametricSoftplusIfEENS_9allocatorIS5_EEFvllEEE
00226f73 N11onnxruntime17ElementWiseKernelINS_8functors10ScaledTanhIfEEEE
00226fb4 NSt6__ndk110__function6__funcIN11onnxruntime8functors10ScaledTanhIfEENS_9allocatorIS5_EEFvllEEE
00227014 N11onnxruntime7contrib4GeluIfEE
00227034 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_7contrib4GeluIfE7ComputeEPNS2_15OpKernelContextEEUllE_EEvPS4_lOT_lEUllE_NS_9allocatorISF_EEFvlEEE
002270f8 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_7contrib4GeluIfE7ComputeEPNS_15OpKernelContextEEUllE_EEvPS1_lOT_lEUllE_
00227183 N11onnxruntime7contrib9QuickGeluIfEE
002271a8 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_7contrib9QuickGeluIfE7ComputeEPNS2_15OpKernelContextEEUllE_EEvPS4_lOT_lEUllE_NS_9allocatorISF_EEFvlEEE
00227271 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_7contrib9QuickGeluIfE7ComputeEPNS_15OpKernelContextEEUllE_EEvPS1_lOT_lEUllE_
00227301 N11onnxruntime7contrib16NGramRepeatBlockE
0022732b NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib16NGramRepeatBlock7ComputeEPNS2_15OpKernelContextEEUlllE_NS_9allocatorIS7_EEFvllEEE
002273b5 ZNK11onnxruntime7contrib16NGramRepeatBlock7ComputeEPNS_15OpKernelContextEEUlllE_
00227406 N11onnxruntime7contrib19BifurcationDetectorE
00227433 N11onnxruntime7contrib4CropIfEE
00227453 N11onnxruntime7contrib8CropBaseE
00227474 N11onnxruntime7contrib13CropAndResizeIfEE
0022749e NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNS2_7contrib20CropAndResizeForwardIfEEvRKNS2_11TensorShapeEPKT_fllSD_lPSB_RKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEPKiPS4_EUllE_EEvSP_lOSB_lEUllE_NSI_ISS_EEFvlEEE
002275b1 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNS_7contrib20CropAndResizeForwardIfEEvRKNS_11TensorShapeEPKT_fllSA_lPS8_RKNSt6__ndk112basic_stringIcNSC_11char_traitsIcEENSC_9allocatorIcEEEEPKiPS1_EUllE_EEvSN_lOS8_lEUllE_
0022769d N11onnxruntime7contrib6AffineIfEE
002276bf N11onnxruntime7contrib5ScaleIfEE
002276e0 N11onnxruntime7contrib10ExpandDimsE
00227704 N11onnxruntime7contrib14FusedConvFloatE
0022772c N11onnxruntime7contrib9FusedGemmIfEE
00227752 N11onnxruntime7contrib11ImageScalerIfEE
0022777a N11onnxruntime7contrib7InverseE
0022779a NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib7Inverse7ComputeEPNS2_15OpKernelContextEE3$_1NS_9allocatorIS7_EEFvlEEE
00227817 ZNK11onnxruntime7contrib7Inverse7ComputeEPNS_15OpKernelContextEE3$_1
0022785c N11onnxruntime7contrib9LayerNormILb0EEE
00227884 N11onnxruntime7contrib9LayerNormILb1EEE
002278ac N11onnxruntime7contrib19SparseToDenseMatMulE
002278d9 N11onnxruntime7contrib15MaxpoolWithMaskE
00227902 NSt6__ndk110__function6__funcIN11onnxruntime7contrib21MaxpoolWithMask1DTaskIfEENS_9allocatorIS5_EEFvllEEE
0022796c N11onnxruntime7contrib21MaxpoolWithMask1DTaskIfEE
0022799e NSt6__ndk110__function6__funcIN11onnxruntime7contrib21MaxpoolWithMask2DTaskIfEENS_9allocatorIS5_EEFvllEEE
00227a08 N11onnxruntime7contrib21MaxpoolWithMask2DTaskIfEE
00227a3a NSt6__ndk110__function6__funcIN11onnxruntime7contrib21MaxpoolWithMask3DTaskIfEENS_9allocatorIS5_EEFvllEEE
00227aa4 N11onnxruntime7contrib21MaxpoolWithMask3DTaskIfEE
00227ad6 N11onnxruntime7contrib11MurmurHash3E
00227afb N11onnxruntime7contrib12ReorderInputE
00227b21 N11onnxruntime7contrib13ReorderOutputE
00227b48 N11onnxruntime7contrib9NchwcConvE
00227b6a N11onnxruntime7contrib12NchwcMaxPoolE
00227b90 N11onnxruntime7contrib13NchwcPoolBaseE
00227bb7 N11onnxruntime7contrib16NchwcAveragePoolE
00227be1 N11onnxruntime7contrib13NchwcUpsampleE
00227c08 NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib12ReorderInput7ComputeEPNS2_15OpKernelContextEE3$_0NS_9allocatorIS7_EEFvlEEE
00227c8b ZNK11onnxruntime7contrib12ReorderInput7ComputeEPNS_15OpKernelContextEE3$_0
00227cd6 NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib13NchwcUpsample7ComputeEPNS2_15OpKernelContextEE3$_1NS_9allocatorIS7_EEFvlEEE
00227d5a ZNK11onnxruntime7contrib13NchwcUpsample7ComputeEPNS_15OpKernelContextEE3$_1
00227da6 N11onnxruntime7contrib10QAttentionIfEE
00227dcd N11onnxruntime7contrib19DynamicQuantizeLSTME
00227dfa N11onnxruntime7contrib21DynamicQuantizeMatMulE
00227e29 N11onnxruntime7contrib24MatMulIntegerToFloatBaseE
00227e5b N11onnxruntime7contrib20MatMulIntegerToFloatE
00227ea6 p@N11onnxruntime7contrib15MatMulInteger16IssiEE
00227ed6 N11onnxruntime7contrib11NhwcMaxPoolIaEE
00227efe N11onnxruntime7contrib11NhwcMaxPoolIhEE
00227f26 N11onnxruntime7contrib15QEmbedLayerNormIfEE
00227f52 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNS2_7contrib12_GLOBAL__N_115ComputeInternalIfaEENS2_6common6StatusEPNS2_15OpKernelContextEfEUllE_EEvPS4_lOT_lEUllE_NS_9allocatorISH_EEFvlEEE
0022803c ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNS_7contrib12_GLOBAL__N_115ComputeInternalIfaEENS_6common6StatusEPNS_15OpKernelContextEfEUllE_EEvPS1_lOT_lEUllE_
002280ec NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNS2_7contrib12_GLOBAL__N_115ComputeInternalIfhEENS2_6common6StatusEPNS2_15OpKernelContextEfEUllE_EEvPS4_lOT_lEUllE_NS_9allocatorISH_EEFvlEEE
002281d6 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNS_7contrib12_GLOBAL__N_115ComputeInternalIfhEENS_6common6StatusEPNS_15OpKernelContextEfEUllE_EEvPS1_lOT_lEUllE_
00228286 N11onnxruntime7contrib16QLinearLeakyReluIaEE
002282b3 N11onnxruntime7contrib17QLinearLookupBaseIaEE
002282e1 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib16QLinearLeakyReluIaEC1ERKNS2_12OpKernelInfoEEUlfE_NS_9allocatorIS9_EEFffEEE
00228363 NSt6__ndk110__function6__baseIFffEEE
00228388 ZN11onnxruntime7contrib16QLinearLeakyReluIaEC1ERKNS_12OpKernelInfoEEUlfE_
002283d2 NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib16QLinearLeakyReluIaE7ComputeEPNS2_15OpKernelContextEEUlfE_NS_9allocatorIS8_EEFffEEE
0022845d ZNK11onnxruntime7contrib16QLinearLeakyReluIaE7ComputeEPNS_15OpKernelContextEEUlfE_
002284b0 NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib17QLinearLookupBaseIaE11ComputeBaseIZNKS3_16QLinearLeakyReluIaE7ComputeEPNS2_15OpKernelContextEEUlfE_EENS2_6common6StatusESA_T_EUlllE_NS_9allocatorISF_EEFvllEEE
00228587 ZNK11onnxruntime7contrib17QLinearLookupBaseIaE11ComputeBaseIZNKS0_16QLinearLeakyReluIaE7ComputeEPNS_15OpKernelContextEEUlfE_EENS_6common6StatusES7_T_EUlllE_
00228624 N11onnxruntime7contrib16QLinearLeakyReluIhEE
00228651 N11onnxruntime7contrib17QLinearLookupBaseIhEE
0022867f NSt6__ndk110__function6__funcIZN11onnxruntime7contrib16QLinearLeakyReluIhEC1ERKNS2_12OpKernelInfoEEUlfE_NS_9allocatorIS9_EEFffEEE
00228701 ZN11onnxruntime7contrib16QLinearLeakyReluIhEC1ERKNS_12OpKernelInfoEEUlfE_
0022874b NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib16QLinearLeakyReluIhE7ComputeEPNS2_15OpKernelContextEEUlfE_NS_9allocatorIS8_EEFffEEE
002287d6 ZNK11onnxruntime7contrib16QLinearLeakyReluIhE7ComputeEPNS_15OpKernelContextEEUlfE_
00228829 NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib17QLinearLookupBaseIhE11ComputeBaseIZNKS3_16QLinearLeakyReluIhE7ComputeEPNS2_15OpKernelContextEEUlfE_EENS2_6common6StatusESA_T_EUlllE_NS_9allocatorISF_EEFvllEEE
00228900 ZNK11onnxruntime7contrib17QLinearLookupBaseIhE11ComputeBaseIZNKS0_16QLinearLeakyReluIhE7ComputeEPNS_15OpKernelContextEEUlfE_EENS_6common6StatusES7_T_EUlllE_
0022899d N11onnxruntime7contrib14QLinearSigmoidIaEE
002289c8 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib14QLinearSigmoidIaEC1ERKNS2_12OpKernelInfoEEUlPKfPfmE_NS_9allocatorISC_EEFvSA_SB_mEEE
00228a53 NSt6__ndk110__function6__baseIFvPKfPfmEEE
00228a7d ZN11onnxruntime7contrib14QLinearSigmoidIaEC1ERKNS_12OpKernelInfoEEUlPKfPfmE_
00228aca NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib14QLinearSigmoidIaE7ComputeEPNS2_15OpKernelContextEEUlPKfPfmE_NS_9allocatorISB_EEFvS9_SA_mEEE
00228b5e ZNK11onnxruntime7contrib14QLinearSigmoidIaE7ComputeEPNS_15OpKernelContextEEUlPKfPfmE_
00228bb4 NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib17QLinearLookupBaseIaE11ComputeBaseIZNKS3_14QLinearSigmoidIaE7ComputeEPNS2_15OpKernelContextEEUlPKfPfmE_EENS2_6common6StatusESA_T_EUlllE_NS_9allocatorISI_EEFvllEEE
00228c8e ZNK11onnxruntime7contrib17QLinearLookupBaseIaE11ComputeBaseIZNKS0_14QLinearSigmoidIaE7ComputeEPNS_15OpKernelContextEEUlPKfPfmE_EENS_6common6StatusES7_T_EUlllE_
00228d2e N11onnxruntime7contrib14QLinearSigmoidIhEE
00228d59 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib14QLinearSigmoidIhEC1ERKNS2_12OpKernelInfoEEUlPKfPfmE_NS_9allocatorISC_EEFvSA_SB_mEEE
00228de4 ZN11onnxruntime7contrib14QLinearSigmoidIhEC1ERKNS_12OpKernelInfoEEUlPKfPfmE_
00228e31 NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib14QLinearSigmoidIhE7ComputeEPNS2_15OpKernelContextEEUlPKfPfmE_NS_9allocatorISB_EEFvS9_SA_mEEE
00228ec5 ZNK11onnxruntime7contrib14QLinearSigmoidIhE7ComputeEPNS_15OpKernelContextEEUlPKfPfmE_
00228f1b NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib17QLinearLookupBaseIhE11ComputeBaseIZNKS3_14QLinearSigmoidIhE7ComputeEPNS2_15OpKernelContextEEUlPKfPfmE_EENS2_6common6StatusESA_T_EUlllE_NS_9allocatorISI_EEFvllEEE
00228ff5 ZNK11onnxruntime7contrib17QLinearLookupBaseIhE11ComputeBaseIZNKS0_14QLinearSigmoidIhE7ComputeEPNS_15OpKernelContextEEUlPKfPfmE_EENS_6common6StatusES7_T_EUlllE_
00229095 N11onnxruntime7contrib10QLinearAddIaEE
002290bc NSt6__ndk110__function6__funcIZN11onnxruntimeL21ParallelizeSingleSpanINS2_7contrib12_GLOBAL__N_122QLinearBroadcastHelperEEEvRT_RKNS2_25ProcessBroadcastSpanFuncsEEUlllE_NS_9allocatorISC_EEFvllEEE
0022917f ZN11onnxruntimeL21ParallelizeSingleSpanINS_7contrib12_GLOBAL__N_122QLinearBroadcastHelperEEEvRT_RKNS_25ProcessBroadcastSpanFuncsEEUlllE_
00229208 NSt6__ndk110__function6__funcIZN11onnxruntimeL21ParallelizeSingleSpanINS2_7contrib12_GLOBAL__N_122QLinearBroadcastHelperEEEvRT_RKNS2_25ProcessBroadcastSpanFuncsEEUlllE0_NS_9allocatorISC_EEFvllEEE
002292cc ZN11onnxruntimeL21ParallelizeSingleSpanINS_7contrib12_GLOBAL__N_122QLinearBroadcastHelperEEEvRT_RKNS_25ProcessBroadcastSpanFuncsEEUlllE0_
00229356 NSt6__ndk110__function6__funcIZN11onnxruntimeL21ParallelizeSingleSpanINS2_7contrib12_GLOBAL__N_122QLinearBroadcastHelperEEEvRT_RKNS2_25ProcessBroadcastSpanFuncsEEUlllE1_NS_9allocatorISC_EEFvllEEE
0022941a ZN11onnxruntimeL21ParallelizeSingleSpanINS_7contrib12_GLOBAL__N_122QLinearBroadcastHelperEEEvRT_RKNS_25ProcessBroadcastSpanFuncsEEUlllE1_
002294a4 N11onnxruntime7contrib10QLinearAddIhEE
002294cb N11onnxruntime7contrib10QLinearMulIaEE
002294f2 N11onnxruntime7contrib10QLinearMulIhEE
00229519 N11onnxruntime7contrib13QLinearConcatE
00229540 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib13QLinearConcatC1ERKNS2_12OpKernelInfoEE3$_0NS_9allocatorIS8_EEFffEEE
002295bb ZN11onnxruntime7contrib13QLinearConcatC1ERKNS_12OpKernelInfoEE3$_0
002295fe NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib13QLinearConcat7ComputeEPNS2_15OpKernelContextEE3$_1NS_9allocatorIS7_EEFffEEE
00229682 ZNK11onnxruntime7contrib13QLinearConcat7ComputeEPNS_15OpKernelContextEE3$_1
002296ce N11onnxruntime7contrib24QLinearGlobalAveragePoolE
00229700 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib27ComputeQLinearGlobalAvgPoolIhEENS2_6common6StatusEPKT_fS7_PS7_fS7_lllbPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISE_EEFvllEEE
002297be ZN11onnxruntime7contrib27ComputeQLinearGlobalAvgPoolIhEENS_6common6StatusEPKT_fS4_PS4_fS4_lllbPNS_11concurrency10ThreadPoolEEUlllE_
00229842 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib27ComputeQLinearGlobalAvgPoolIhEENS2_6common6StatusEPKT_fS7_PS7_fS7_lllbPNS2_11concurrency10ThreadPoolEEUlllE0_NS_9allocatorISE_EEFvllEEE
00229901 ZN11onnxruntime7contrib27ComputeQLinearGlobalAvgPoolIhEENS_6common6StatusEPKT_fS4_PS4_fS4_lllbPNS_11concurrency10ThreadPoolEEUlllE0_
00229986 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib27ComputeQLinearGlobalAvgPoolIaEENS2_6common6StatusEPKT_fS7_PS7_fS7_lllbPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISE_EEFvllEEE
00229a44 ZN11onnxruntime7contrib27ComputeQLinearGlobalAvgPoolIaEENS_6common6StatusEPKT_fS4_PS4_fS4_lllbPNS_11concurrency10ThreadPoolEEUlllE_
00229ac8 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib27ComputeQLinearGlobalAvgPoolIaEENS2_6common6StatusEPKT_fS7_PS7_fS7_lllbPNS2_11concurrency10ThreadPoolEEUlllE0_NS_9allocatorISE_EEFvllEEE
00229b87 ZN11onnxruntime7contrib27ComputeQLinearGlobalAvgPoolIaEENS_6common6StatusEPKT_fS4_PS4_fS4_lllbPNS_11concurrency10ThreadPoolEEUlllE0_
00229c0c NSt6__ndk110__function6__funcIZN11onnxruntime7contrib23QlinearBuildLookupTableIhEEvPhPKNS2_6TensorES8_S8_S8_RKNS_8functionIFffEEEEUlPKfPfmE_NS_9allocatorISH_EEFvSF_SG_mEEE
00229cb8 ZN11onnxruntime7contrib23QlinearBuildLookupTableIhEEvPhPKNS_6TensorES5_S5_S5_RKNSt6__ndk18functionIFffEEEEUlPKfPfmE_
00229d2d NSt6__ndk110__function6__funcIZN11onnxruntime7contrib23QlinearBuildLookupTableIaEEvPhPKNS2_6TensorES8_S8_S8_RKNS_8functionIFffEEEEUlPKfPfmE_NS_9allocatorISH_EEFvSF_SG_mEEE
00229dd9 ZN11onnxruntime7contrib23QlinearBuildLookupTableIaEEvPhPKNS_6TensorES5_S5_S5_RKNSt6__ndk18functionIFffEEEEUlPKfPfmE_
00229e4e N11onnxruntime7contrib18QLinearAveragePoolE
00229e7a NSt6__ndk110__function6__funcIZN11onnxruntime7contrib16dequantize_arrayIaEEvlPKT_fS5_PfPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISC_EEFvllEEE
00229f12 ZN11onnxruntime7contrib16dequantize_arrayIaEEvlPKT_fS2_PfPNS_11concurrency10ThreadPoolEEUlllE_
00229f71 NSt6__ndk110__function6__funcIN11onnxruntime7contrib21QLinearPoolNhwc1DTaskIaNS2_11AveragePoolEEENS_9allocatorIS6_EEFvllEEE
00229fed N11onnxruntime7contrib21QLinearPoolNhwc1DTaskIaNS_11AveragePoolEEE
0022a030 NSt6__ndk110__function6__funcIN11onnxruntime7contrib17QLinearPool1DTaskIaNS2_11AveragePoolEEENS_9allocatorIS6_EEFvllEEE
0022a0a8 N11onnxruntime7contrib17QLinearPool1DTaskIaNS_11AveragePoolEEE
0022a0e7 NSt6__ndk110__function6__funcIN11onnxruntime7contrib21QLinearPoolNhwc2DTaskIaNS2_11AveragePoolEEENS_9allocatorIS6_EEFvllEEE
0022a163 N11onnxruntime7contrib21QLinearPoolNhwc2DTaskIaNS_11AveragePoolEEE
0022a1a6 NSt6__ndk110__function6__funcIN11onnxruntime7contrib17QLinearPool2DTaskIaNS2_11AveragePoolEEENS_9allocatorIS6_EEFvllEEE
0022a21e N11onnxruntime7contrib17QLinearPool2DTaskIaNS_11AveragePoolEEE
0022a25d NSt6__ndk110__function6__funcIN11onnxruntime7contrib21QLinearPoolNhwc3DTaskIaNS2_11AveragePoolEEENS_9allocatorIS6_EEFvllEEE
0022a2d9 N11onnxruntime7contrib21QLinearPoolNhwc3DTaskIaNS_11AveragePoolEEE
0022a31c NSt6__ndk110__function6__funcIN11onnxruntime7contrib17QLinearPool3DTaskIaNS2_11AveragePoolEEENS_9allocatorIS6_EEFvllEEE
0022a394 N11onnxruntime7contrib17QLinearPool3DTaskIaNS_11AveragePoolEEE
0022a3d3 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib16dequantize_arrayIhEEvlPKT_fS5_PfPNS2_11concurrency10ThreadPoolEEUlllE_NS_9allocatorISC_EEFvllEEE
0022a46b ZN11onnxruntime7contrib16dequantize_arrayIhEEvlPKT_fS2_PfPNS_11concurrency10ThreadPoolEEUlllE_
0022a4ca NSt6__ndk110__function6__funcIN11onnxruntime7contrib21QLinearPoolNhwc1DTaskIhNS2_11AveragePoolEEENS_9allocatorIS6_EEFvllEEE
0022a546 N11onnxruntime7contrib21QLinearPoolNhwc1DTaskIhNS_11AveragePoolEEE
0022a589 NSt6__ndk110__function6__funcIN11onnxruntime7contrib17QLinearPool1DTaskIhNS2_11AveragePoolEEENS_9allocatorIS6_EEFvllEEE
0022a601 N11onnxruntime7contrib17QLinearPool1DTaskIhNS_11AveragePoolEEE
0022a640 NSt6__ndk110__function6__funcIN11onnxruntime7contrib21QLinearPoolNhwc2DTaskIhNS2_11AveragePoolEEENS_9allocatorIS6_EEFvllEEE
0022a6bc N11onnxruntime7contrib21QLinearPoolNhwc2DTaskIhNS_11AveragePoolEEE
0022a6ff NSt6__ndk110__function6__funcIN11onnxruntime7contrib17QLinearPool2DTaskIhNS2_11AveragePoolEEENS_9allocatorIS6_EEFvllEEE
0022a777 N11onnxruntime7contrib17QLinearPool2DTaskIhNS_11AveragePoolEEE
0022a7b6 NSt6__ndk110__function6__funcIN11onnxruntime7contrib21QLinearPoolNhwc3DTaskIhNS2_11AveragePoolEEENS_9allocatorIS6_EEFvllEEE
0022a832 N11onnxruntime7contrib21QLinearPoolNhwc3DTaskIhNS_11AveragePoolEEE
0022a875 NSt6__ndk110__function6__funcIN11onnxruntime7contrib17QLinearPool3DTaskIhNS2_11AveragePoolEEENS_9allocatorIS6_EEFvllEEE
0022a8ed N11onnxruntime7contrib17QLinearPool3DTaskIhNS_11AveragePoolEEE
0022a92c N11onnxruntime7contrib14QLinearSoftmaxE
0022a954 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib17QlinearSoftmaxCPUIhEENS2_6common6StatusEmmPKT_PS7_PKffS7_PNS2_11concurrency10ThreadPoolEE3$_0NS_9allocatorISG_EEFvllEEE
0022aa03 ZN11onnxruntime7contrib17QlinearSoftmaxCPUIhEENS_6common6StatusEmmPKT_PS4_PKffS4_PNS_11concurrency10ThreadPoolEE3$_0
0022aa78 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib17QlinearSoftmaxCPUIaEENS2_6common6StatusEmmPKT_PS7_PKffS7_PNS2_11concurrency10ThreadPoolEE3$_1NS_9allocatorISG_EEFvllEEE
0022ab27 ZN11onnxruntime7contrib17QlinearSoftmaxCPUIaEENS_6common6StatusEmmPKT_PS4_PKffS4_PNS_11concurrency10ThreadPoolEE3$_1
0022aba8 N11onnxruntime7contrib12QLinearWhereE
0022abce NSt6__ndk110__function6__funcIZN11onnxruntime7contrib12QLinearWhereC1ERKNS2_12OpKernelInfoEE3$_0NS_9allocatorIS8_EEFffEEE
0022ac48 ZN11onnxruntime7contrib12QLinearWhereC1ERKNS_12OpKernelInfoEE3$_0
0022ac8a NSt6__ndk110__function6__funcIZNK11onnxruntime7contrib12QLinearWhere7ComputeEPNS2_15OpKernelContextEE3$_1NS_9allocatorIS7_EEFffEEE
0022ad0d ZNK11onnxruntime7contrib12QLinearWhere7ComputeEPNS_15OpKernelContextEE3$_1
0022ad58 N11onnxruntime7contrib5QGemmE
0022ad76 N11onnxruntime7contrib8SampleOpIfEE
0022ad9a N11onnxruntime7contrib13SkipLayerNormIfEE
0022adc4 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_7contrib13SkipLayerNormIfE7ComputeEPNS2_15OpKernelContextEEUllE_EEvPS4_lOT_lEUllE_NS_9allocatorISF_EEFvlEEE
0022ae92 ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_7contrib13SkipLayerNormIfE7ComputeEPNS_15OpKernelContextEEUllE_EEvPS1_lOT_lEUllE_
0022af27 N11onnxruntime7contrib13SkipLayerNormIdEE
0022af51 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS2_7contrib13SkipLayerNormIdE7ComputeEPNS2_15OpKernelContextEEUllE_EEvPS4_lOT_lEUllE_NS_9allocatorISF_EEFvlEEE
0022b01f ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZNKS_7contrib13SkipLayerNormIdE7ComputeEPNS_15OpKernelContextEEUllE_EEvPS1_lOT_lEUllE_
0022b0b6 N11onnxruntime7contrib9TokenizerE
0022b0d8 N11onnxruntime7contrib12transformers10BeamSearchE
0022b10a N11onnxruntime7contrib12transformers13BeamSearchGptIfEE
0022b142 N11onnxruntime7contrib12transformers14BeamSearchBaseIfEE
0022b17b N11onnxruntime7contrib12transformers12GenerateBaseE
0022b1af N11onnxruntime7contrib12transformers13BeamSearchGptINS_9MLFloat16EEE
0022b1f4 N11onnxruntime7contrib12transformers14BeamSearchBaseINS_9MLFloat16EEE
0022b23a N11onnxruntime7contrib12transformers12BeamSearchT5IfEE
0022b271 N11onnxruntime7contrib12transformers12BeamSearchT5INS_9MLFloat16EEE
0022b2b5 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusEPKNS2_18IExecutionProviderEPNS2_6StreamESt16initializer_listI8OrtValueERNS_6vectorISB_NS_9allocatorISB_EEEERNS_10unique_ptrIcNS_8functionIFvPcEEEEEENSE_ISQ_EESP_EE
0022b396 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEPKNS2_18IExecutionProviderEPNS2_6StreamESt16initializer_listI8OrtValueERNS_6vectorISB_NS_9allocatorISB_EEEERNS_10unique_ptrIcNS_8functionIFvPcEEEEEEEE
0022b469 PFN11onnxruntime6common6StatusEPKNS_18IExecutionProviderEPNS_6StreamESt16initializer_listI8OrtValueERNSt6__ndk16vectorIS8_NSA_9allocatorIS8_EEEERNSA_10unique_ptrIcNSA_8functionIFvPcEEEEEE
0022b525 FN11onnxruntime6common6StatusEPKNS_18IExecutionProviderEPNS_6StreamESt16initializer_listI8OrtValueERNSt6__ndk16vectorIS8_NSA_9allocatorIS8_EEEERNSA_10unique_ptrIcNSA_8functionIFvPcEEEEEE
0022b5e0 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusEPKNS2_6TensorEijbbNS_10shared_ptrINS2_10IAllocatorEEEPNS2_6StreamEPNS2_11concurrency10ThreadPoolERS5_SG_ENS_9allocatorISI_EESH_EE
0022b69f NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEPKNS2_6TensorEijbbNS_10shared_ptrINS2_10IAllocatorEEEPNS2_6StreamEPNS2_11concurrency10ThreadPoolERS5_SG_EEE
0022b747 PFN11onnxruntime6common6StatusEPKNS_6TensorEijbbNSt6__ndk110shared_ptrINS_10IAllocatorEEEPNS_6StreamEPNS_11concurrency10ThreadPoolERS2_SE_E
0022b7d3 FN11onnxruntime6common6StatusEPKNS_6TensorEijbbNSt6__ndk110shared_ptrINS_10IAllocatorEEEPNS_6StreamEPNS_11concurrency10ThreadPoolERS2_SE_E
0022b85e NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusERK8OrtValuePNS2_7contrib12transformers16IBeamSearchStateIfEEPNS9_19IBeamSearchCpuStateEPNS9_10ISequencesERNS_10shared_ptrINS2_10IAllocatorEEEPNS2_11concurrency10ThreadPoolEPNS9_20ILogitsProcessorListEPNS9_11IBeamScorerEPKNS9_21IGenerationParametersEiPNS2_6StreamEPKNS9_14IConsoleDumperEENS_9allocatorIS11_EES10_EE
0022b9d5 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERK8OrtValuePNS2_7contrib12transformers16IBeamSearchStateIfEEPNS9_19IBeamSearchCpuStateEPNS9_10ISequencesERNS_10shared_ptrINS2_10IAllocatorEEEPNS2_11concurrency10ThreadPoolEPNS9_20ILogitsProcessorListEPNS9_11IBeamScorerEPKNS9_21IGenerationParametersEiPNS2_6StreamEPKNS9_14IConsoleDumperEEEE
0022bb33 PFN11onnxruntime6common6StatusERK8OrtValuePNS_7contrib12transformers16IBeamSearchStateIfEEPNS6_19IBeamSearchCpuStateEPNS6_10ISequencesERNSt6__ndk110shared_ptrINS_10IAllocatorEEEPNS_11concurrency10ThreadPoolEPNS6_20ILogitsProcessorListEPNS6_11IBeamScorerEPKNS6_21IGenerationParametersEiPNS_6StreamEPKNS6_14IConsoleDumperEE
0022bc75 FN11onnxruntime6common6StatusERK8OrtValuePNS_7contrib12transformers16IBeamSearchStateIfEEPNS6_19IBeamSearchCpuStateEPNS6_10ISequencesERNSt6__ndk110shared_ptrINS_10IAllocatorEEEPNS_11concurrency10ThreadPoolEPNS6_20ILogitsProcessorListEPNS6_11IBeamScorerEPKNS6_21IGenerationParametersEiPNS_6StreamEPKNS6_14IConsoleDumperEE
0022bdb6 NSt6__ndk110__function6__funcIPFvPN11onnxruntime7contrib12transformers16IBeamSearchStateIfEERN3gsl4spanIiLm18446744073709551615EEEiiPNS2_6StreamEENS_9allocatorISF_EESE_EE
0022be61 NSt6__ndk110__function6__baseIFvPN11onnxruntime7contrib12transformers16IBeamSearchStateIfEERN3gsl4spanIiLm18446744073709551615EEEiiPNS2_6StreamEEEE
0022bef5 PFvPN11onnxruntime7contrib12transformers16IBeamSearchStateIfEERN3gsl4spanIiLm18446744073709551615EEEiiPNS_6StreamEE
0022bf69 FvPN11onnxruntime7contrib12transformers16IBeamSearchStateIfEERN3gsl4spanIiLm18446744073709551615EEEiiPNS_6StreamEE
0022bfdc NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusEN3gsl4spanIfLm18446744073709551615EEENS6_IKfLm18446744073709551615EEEPNS2_6StreamEiENS_9allocatorISD_EESC_EE
0022c086 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEN3gsl4spanIfLm18446744073709551615EEENS6_IKfLm18446744073709551615EEEPNS2_6StreamEiEEE
0022c119 PFN11onnxruntime6common6StatusEN3gsl4spanIfLm18446744073709551615EEENS3_IKfLm18446744073709551615EEEPNS_6StreamEiE
0022c18c FN11onnxruntime6common6StatusEN3gsl4spanIfLm18446744073709551615EEENS3_IKfLm18446744073709551615EEEPNS_6StreamEiE
0022c1fe NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusEN3gsl4spanIiLm18446744073709551615EEENS6_IKiLm18446744073709551615EEEPNS2_6StreamEiENS_9allocatorISD_EESC_EE
0022c2a8 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEN3gsl4spanIiLm18446744073709551615EEENS6_IKiLm18446744073709551615EEEPNS2_6StreamEiEEE
0022c33b PFN11onnxruntime6common6StatusEN3gsl4spanIiLm18446744073709551615EEENS3_IKiLm18446744073709551615EEEPNS_6StreamEiE
0022c3ae FN11onnxruntime6common6StatusEN3gsl4spanIiLm18446744073709551615EEENS3_IKiLm18446744073709551615EEEPNS_6StreamEiE
0022c420 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusENS_10shared_ptrINS2_10IAllocatorEEEPNS2_6StreamERKNS_6vectorI8OrtValueNS_9allocatorISB_EEEERSE_iRSB_bN3gsl4spanIKiLm18446744073709551615EEESM_iiibiENSC_ISO_EESN_EE
0022c501 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusENS_10shared_ptrINS2_10IAllocatorEEEPNS2_6StreamERKNS_6vectorI8OrtValueNS_9allocatorISB_EEEERSE_iRSB_bN3gsl4spanIKiLm18446744073709551615EEESM_iiibiEEE
0022c5d4 PFN11onnxruntime6common6StatusENSt6__ndk110shared_ptrINS_10IAllocatorEEEPNS_6StreamERKNS2_6vectorI8OrtValueNS2_9allocatorIS9_EEEERSC_iRS9_bN3gsl4spanIKiLm18446744073709551615EEESK_iiibiE
0022c68f FN11onnxruntime6common6StatusENSt6__ndk110shared_ptrINS_10IAllocatorEEEPNS_6StreamERKNS2_6vectorI8OrtValueNS2_9allocatorIS9_EEEERSC_iRS9_bN3gsl4spanIKiLm18446744073709551615EEESK_iiibiE
0022c749 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusEPKNS2_6TensorEPK8OrtValueiiRN3gsl4spanIiLm18446744073709551615EEENS_10shared_ptrINS2_10IAllocatorEEERS8_SI_SI_ENS_9allocatorISK_EESJ_EE
0022c80e NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEPKNS2_6TensorEPK8OrtValueiiRN3gsl4spanIiLm18446744073709551615EEENS_10shared_ptrINS2_10IAllocatorEEERS8_SI_SI_EEE
0022c8bc PFN11onnxruntime6common6StatusEPKNS_6TensorEPK8OrtValueiiRN3gsl4spanIiLm18446744073709551615EEENSt6__ndk110shared_ptrINS_10IAllocatorEEERS5_SG_SG_E
0022c950 FN11onnxruntime6common6StatusEPKNS_6TensorEPK8OrtValueiiRN3gsl4spanIiLm18446744073709551615EEENSt6__ndk110shared_ptrINS_10IAllocatorEEERS5_SG_SG_E
0022c9e3 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusEPKNS2_6TensorEPK8OrtValueiiNS_10shared_ptrINS2_10IAllocatorEEERS8_SE_SE_ENS_9allocatorISG_EESF_EE
0022ca82 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEPKNS2_6TensorEPK8OrtValueiiNS_10shared_ptrINS2_10IAllocatorEEERS8_SE_SE_EEE
0022cb0a PFN11onnxruntime6common6StatusEPKNS_6TensorEPK8OrtValueiiNSt6__ndk110shared_ptrINS_10IAllocatorEEERS5_SC_SC_E
0022cb78 FN11onnxruntime6common6StatusEPKNS_6TensorEPK8OrtValueiiNSt6__ndk110shared_ptrINS_10IAllocatorEEERS5_SC_SC_E
0022cbe5 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusENS_10shared_ptrINS2_10IAllocatorEEEPNS2_6StreamERKNS_6vectorI8OrtValueNS_9allocatorISB_EEEERSE_iN3gsl4spanIKiLm18446744073709551615EEESL_iiibiRNS2_7contrib12transformers9SequencesEPKNSN_14IConsoleDumperEENSC_ISU_EEST_EE
0022ccfe NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusENS_10shared_ptrINS2_10IAllocatorEEEPNS2_6StreamERKNS_6vectorI8OrtValueNS_9allocatorISB_EEEERSE_iN3gsl4spanIKiLm18446744073709551615EEESL_iiibiRNS2_7contrib12transformers9SequencesEPKNSN_14IConsoleDumperEEEE
0022ce09 PFN11onnxruntime6common6StatusENSt6__ndk110shared_ptrINS_10IAllocatorEEEPNS_6StreamERKNS2_6vectorI8OrtValueNS2_9allocatorIS9_EEEERSC_iN3gsl4spanIKiLm18446744073709551615EEESJ_iiibiRNS_7contrib12transformers9SequencesEPKNSL_14IConsoleDumperEE
0022cefb FN11onnxruntime6common6StatusENSt6__ndk110shared_ptrINS_10IAllocatorEEEPNS_6StreamERKNS2_6vectorI8OrtValueNS2_9allocatorIS9_EEEERSC_iN3gsl4spanIKiLm18446744073709551615EEESJ_iiibiRNS_7contrib12transformers9SequencesEPKNSL_14IConsoleDumperEE
0022cfec NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusEPNS2_6StreamERK8OrtValueiNS_10shared_ptrINS2_10IAllocatorEEERS7_bENS_9allocatorISF_EESE_EE
0022d084 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusEPNS2_6StreamERK8OrtValueiNS_10shared_ptrINS2_10IAllocatorEEERS7_bEEE
0022d105 PFN11onnxruntime6common6StatusEPNS_6StreamERK8OrtValueiNSt6__ndk110shared_ptrINS_10IAllocatorEEERS4_bE
0022d16c FN11onnxruntime6common6StatusEPNS_6StreamERK8OrtValueiNSt6__ndk110shared_ptrINS_10IAllocatorEEERS4_bE
0022d1dc N11onnxruntime7contrib12transformers16BeamSearchScorerE
0022d214 N11onnxruntime7contrib12transformers11IBeamScorerE
0022d247 NSt6__ndk110__function6__funcIZN11onnxruntime10IAllocator13MakeUniquePtrIbEENS_10unique_ptrIT_NS_8functionIFvPS6_EEEEENS_10shared_ptrIS3_EEmbPNS2_6StreamENS7_IFvRSE_RNS2_11synchronize12NotificationEEEEEUlPbE_NS_9allocatorISN_EEFvSM_EEE
0022d333 NSt6__ndk110__function6__baseIFvPbEEE
0022d359 ZN11onnxruntime10IAllocator13MakeUniquePtrIbEENSt6__ndk110unique_ptrIT_NS2_8functionIFvPS4_EEEEENS2_10shared_ptrIS0_EEmbPNS_6StreamENS5_IFvRSC_RNS_11synchronize12NotificationEEEEEUlPbE_
0022d413 N11onnxruntime7contrib12transformers22CpuTensorConsoleDumperE
0022d451 N11onnxruntime7contrib12transformers14IConsoleDumperE
0022d4a6 NSt6__ndk110__function6__funcINS_7greaterIfEENS_9allocatorIS3_EEFbffEEE
0022d4ee NSt6__ndk110__function6__baseIFbffEEE
0022d514 NSt6__ndk17greaterIfEE
0022d52b NSt6__ndk115binary_functionIffbEE
0022d54d NSt6__ndk110__function6__funcINS_4lessIfEENS_9allocatorIS3_EEFbffEEE
0022d592 NSt6__ndk14lessIfEE
0022d5a6 N11onnxruntime7contrib12transformers12GreedySearchE
0022d5da N11onnxruntime7contrib12transformers15GreedySearchGptIfNS1_22GreedySearchParametersEEE
0022d631 N11onnxruntime7contrib12transformers16GreedySearchBaseIfNS1_22GreedySearchParametersEEE
0022d689 N11onnxruntime7contrib12transformers15GreedySearchGptINS_9MLFloat16ENS1_22GreedySearchParametersEEE
0022d6ed N11onnxruntime7contrib12transformers16GreedySearchBaseINS_9MLFloat16ENS1_22GreedySearchParametersEEE
0022d752 NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusERK8OrtValuePNS2_7contrib12transformers18IGreedySearchStateIfEEPNS9_14ISamplingStateIfEEPNS9_10ISequencesERNS_10shared_ptrINS2_10IAllocatorEEEPNS2_11concurrency10ThreadPoolEPNS9_20ILogitsProcessorListEPKNS9_21IGenerationParametersEbiPNS2_6StreamEPKNS9_14IConsoleDumperEENS_9allocatorIS10_EESZ_EE
0022d8b6 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERK8OrtValuePNS2_7contrib12transformers18IGreedySearchStateIfEEPNS9_14ISamplingStateIfEEPNS9_10ISequencesERNS_10shared_ptrINS2_10IAllocatorEEEPNS2_11concurrency10ThreadPoolEPNS9_20ILogitsProcessorListEPKNS9_21IGenerationParametersEbiPNS2_6StreamEPKNS9_14IConsoleDumperEEEE
0022da02 PFN11onnxruntime6common6StatusERK8OrtValuePNS_7contrib12transformers18IGreedySearchStateIfEEPNS6_14ISamplingStateIfEEPNS6_10ISequencesERNSt6__ndk110shared_ptrINS_10IAllocatorEEEPNS_11concurrency10ThreadPoolEPNS6_20ILogitsProcessorListEPKNS6_21IGenerationParametersEbiPNS_6StreamEPKNS6_14IConsoleDumperEE
0022db32 FN11onnxruntime6common6StatusERK8OrtValuePNS_7contrib12transformers18IGreedySearchStateIfEEPNS6_14ISamplingStateIfEEPNS6_10ISequencesERNSt6__ndk110shared_ptrINS_10IAllocatorEEEPNS_11concurrency10ThreadPoolEPNS6_20ILogitsProcessorListEPKNS6_21IGenerationParametersEbiPNS_6StreamEPKNS6_14IConsoleDumperEE
0022dc61 NSt6__ndk110__function6__funcIPFvPN11onnxruntime7contrib12transformers18IGreedySearchStateIfEERN3gsl4spanIiLm18446744073709551615EEEPNS2_6StreamEENS_9allocatorISF_EESE_EE
0022dd0c NSt6__ndk110__function6__baseIFvPN11onnxruntime7contrib12transformers18IGreedySearchStateIfEERN3gsl4spanIiLm18446744073709551615EEEPNS2_6StreamEEEE
0022dda0 PFvPN11onnxruntime7contrib12transformers18IGreedySearchStateIfEERN3gsl4spanIiLm18446744073709551615EEEPNS_6StreamEE
0022de14 FvPN11onnxruntime7contrib12transformers18IGreedySearchStateIfEERN3gsl4spanIiLm18446744073709551615EEEPNS_6StreamEE
0022de8c N11onnxruntime7contrib12transformers19LogitsProcessorListE
0022dec7 N11onnxruntime7contrib12transformers20ILogitsProcessorListE
0022df03 N11onnxruntime7contrib12transformers32RepetitionPenaltyLogitsProcessorIfEE
0022df4e N11onnxruntime7contrib12transformers16ILogitsProcessorIfEE
0022df89 N11onnxruntime7contrib12transformers28NoRepeatNGramLogitsProcessorIfEE
0022dfd0 N11onnxruntime7contrib12transformers24VocabMaskLogitsProcessorIfEE
0022e013 N11onnxruntime7contrib12transformers30PrefixVocabMaskLogitsProcessorIfEE
0022e05c N11onnxruntime7contrib12transformers24MinLengthLogitsProcessorIfEE
0022e09f N11onnxruntime7contrib12transformers26TemperatureLogitsProcessorIfEE
0022e0e4 N11onnxruntime7contrib12transformers30PresencePenaltyLogitsProcessorIfEE
0022e12d N11onnxruntime7contrib12transformers8SamplingE
0022e15c N11onnxruntime7contrib12transformers15GreedySearchGptIfNS1_18SamplingParametersEEE
0022e1af N11onnxruntime7contrib12transformers16GreedySearchBaseIfNS1_18SamplingParametersEEE
0022e203 N11onnxruntime7contrib12transformers15GreedySearchGptINS_9MLFloat16ENS1_18SamplingParametersEEE
0022e263 N11onnxruntime7contrib12transformers16GreedySearchBaseINS_9MLFloat16ENS1_18SamplingParametersEEE
0022e2c4 N11onnxruntime7contrib12transformers9SequencesE
0022e2f4 N11onnxruntime7contrib12transformers10ISequencesE
0022e326 N11onnxruntime7contrib12transformers8SubgraphE
0022e355 N11onnxruntime7contrib12transformers11GptSubgraphE
0022e388 N11onnxruntime7contrib12transformers17T5DecoderSubgraphE
0022e3c1 N11onnxruntime7contrib12transformers17T5EncoderSubgraphE
0022e3fa N11onnxruntime7contrib6UniqueIfEE
0022e41c N11onnxruntime7contrib17WordConvEmbeddingE
0022e447 N11onnxruntime12CPUAllocatorE
0022e465 NSt6__ndk120__shared_ptr_pointerIPN11onnxruntime16StreamAwareArenaENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
0022e4d7 NSt6__ndk114default_deleteIN11onnxruntime16StreamAwareArenaEEE
0022e516 NSt6__ndk120__shared_ptr_pointerIPN11onnxruntime8BFCArenaENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
0022e57f NSt6__ndk114default_deleteIN11onnxruntime8BFCArenaEEE
0022e5b5 NSt6__ndk120__shared_ptr_pointerIPN11onnxruntime10IAllocatorENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
0022e621 NSt6__ndk114default_deleteIN11onnxruntime10IAllocatorEEE
0022e668 N11onnxruntime8BFCArenaE
0022e681 N11onnxruntime16StreamAwareArenaE
0022e6b1 N11onnxruntime13IDataTransferE
0022e6d0 N11onnxruntime15CPUDataTransferE
0022e756 N11onnxruntime14TensorTypeBaseE
0022e776 N11onnxruntime12DataTypeImplE
0022e794 N11onnxruntime20SparseTensorTypeBaseE
0022e7ba N11onnxruntime22SequenceTensorTypeBaseE
0022e7e2 N11onnxruntime16OptionalTypeBaseE
0022e804 N11onnxruntime17NonTensorTypeBaseE
0022e827 NSt6__ndk110__function6__funcIZN11onnxruntime19data_types_internal16DataTypeRegistryC1EvEUlPKNS2_12DataTypeImplEE_NS_9allocatorIS8_EEFvS7_EEE
0022e8b5 NSt6__ndk110__function6__baseIFvPKN11onnxruntime12DataTypeImplEEEE
0022e8f8 ZN11onnxruntime19data_types_internal16DataTypeRegistryC1EvEUlPKNS_12DataTypeImplEE_
0022e94c N11onnxruntime10TensorTypeIiEE
0022e96b N11onnxruntime10TensorTypeIfEE
0022e98a N11onnxruntime10TensorTypeIbEE
0022e9a9 N11onnxruntime10TensorTypeINSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
0022ea0a N11onnxruntime10TensorTypeIaEE
0022ea29 N11onnxruntime10TensorTypeIhEE
0022ea48 N11onnxruntime10TensorTypeItEE
0022ea67 N11onnxruntime10TensorTypeIsEE
0022ea86 N11onnxruntime10TensorTypeIlEE
0022eaa5 N11onnxruntime10TensorTypeIdEE
0022eac4 N11onnxruntime10TensorTypeIjEE
0022eae3 N11onnxruntime10TensorTypeImEE
0022eb02 N11onnxruntime10TensorTypeINS_9MLFloat16EEE
0022eb2e N11onnxruntime10TensorTypeINS_8BFloat16EEE
0022eb59 N11onnxruntime16SparseTensorTypeIiEE
0022eb7e N11onnxruntime16SparseTensorTypeIfEE
0022eba3 N11onnxruntime16SparseTensorTypeIbEE
0022ebc8 N11onnxruntime16SparseTensorTypeINSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
0022ec2f N11onnxruntime16SparseTensorTypeIaEE
0022ec54 N11onnxruntime16SparseTensorTypeIhEE
0022ec79 N11onnxruntime16SparseTensorTypeItEE
0022ec9e N11onnxruntime16SparseTensorTypeIsEE
0022ecc3 N11onnxruntime16SparseTensorTypeIlEE
0022ece8 N11onnxruntime16SparseTensorTypeIdEE
0022ed0d N11onnxruntime16SparseTensorTypeIjEE
0022ed32 N11onnxruntime16SparseTensorTypeImEE
0022ed57 N11onnxruntime16SparseTensorTypeINS_9MLFloat16EEE
0022ed89 N11onnxruntime16SparseTensorTypeINS_8BFloat16EEE
0022edba N11onnxruntime7MapTypeINSt6__ndk13mapINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEES8_NS1_4lessIS8_EENS6_INS1_4pairIKS8_S8_EEEEEEEE
0022ee4e N11onnxruntime13NonTensorTypeINSt6__ndk13mapINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEES8_NS1_4lessIS8_EENS6_INS1_4pairIKS8_S8_EEEEEEEE
0022eee9 N11onnxruntime7MapTypeINSt6__ndk13mapINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEElNS1_4lessIS8_EENS6_INS1_4pairIKS8_lEEEEEEEE
0022ef79 N11onnxruntime13NonTensorTypeINSt6__ndk13mapINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEElNS1_4lessIS8_EENS6_INS1_4pairIKS8_lEEEEEEEE
0022f010 N11onnxruntime7MapTypeINSt6__ndk13mapINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEfNS1_4lessIS8_EENS6_INS1_4pairIKS8_fEEEEEEEE
0022f0a0 N11onnxruntime13NonTensorTypeINSt6__ndk13mapINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEfNS1_4lessIS8_EENS6_INS1_4pairIKS8_fEEEEEEEE
0022f137 N11onnxruntime7MapTypeINSt6__ndk13mapINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEdNS1_4lessIS8_EENS6_INS1_4pairIKS8_dEEEEEEEE
0022f1c7 N11onnxruntime13NonTensorTypeINSt6__ndk13mapINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEdNS1_4lessIS8_EENS6_INS1_4pairIKS8_dEEEEEEEE
0022f25e N11onnxruntime7MapTypeINSt6__ndk13mapIlNS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS1_4lessIlEENS6_INS1_4pairIKlS8_EEEEEEEE
0022f2ec N11onnxruntime13NonTensorTypeINSt6__ndk13mapIlNS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS1_4lessIlEENS6_INS1_4pairIKlS8_EEEEEEEE
0022f381 N11onnxruntime7MapTypeINSt6__ndk13mapIllNS1_4lessIlEENS1_9allocatorINS1_4pairIKllEEEEEEEE
0022f3db N11onnxruntime13NonTensorTypeINSt6__ndk13mapIllNS1_4lessIlEENS1_9allocatorINS1_4pairIKllEEEEEEEE
0022f43c N11onnxruntime7MapTypeINSt6__ndk13mapIlfNS1_4lessIlEENS1_9allocatorINS1_4pairIKlfEEEEEEEE
0022f496 N11onnxruntime13NonTensorTypeINSt6__ndk13mapIlfNS1_4lessIlEENS1_9allocatorINS1_4pairIKlfEEEEEEEE
0022f4f7 N11onnxruntime7MapTypeINSt6__ndk13mapIldNS1_4lessIlEENS1_9allocatorINS1_4pairIKldEEEEEEEE
0022f551 N11onnxruntime13NonTensorTypeINSt6__ndk13mapIldNS1_4lessIlEENS1_9allocatorINS1_4pairIKldEEEEEEEE
0022f5b2 N11onnxruntime18SequenceTensorTypeIfEE
0022f5d9 N11onnxruntime18SequenceTensorTypeIdEE
0022f600 N11onnxruntime18SequenceTensorTypeIaEE
0022f627 N11onnxruntime18SequenceTensorTypeIhEE
0022f64e N11onnxruntime18SequenceTensorTypeIsEE
0022f675 N11onnxruntime18SequenceTensorTypeItEE
0022f69c N11onnxruntime18SequenceTensorTypeIiEE
0022f6c3 N11onnxruntime18SequenceTensorTypeIjEE
0022f6ea N11onnxruntime18SequenceTensorTypeIlEE
0022f711 N11onnxruntime18SequenceTensorTypeImEE
0022f738 N11onnxruntime18SequenceTensorTypeIbEE
0022f75f N11onnxruntime18SequenceTensorTypeINSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
0022f7c8 N11onnxruntime18SequenceTensorTypeINS_9MLFloat16EEE
0022f7fc N11onnxruntime18SequenceTensorTypeINS_8BFloat16EEE
0022f82f N11onnxruntime12SequenceTypeINSt6__ndk16vectorINS1_3mapINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEfNS1_4lessIS9_EENS7_INS1_4pairIKS9_fEEEEEENS7_ISG_EEEEEE
0022f8dd N11onnxruntime13NonTensorTypeINSt6__ndk16vectorINS1_3mapINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEfNS1_4lessIS9_EENS7_INS1_4pairIKS9_fEEEEEENS7_ISG_EEEEEE
0022f98c N11onnxruntime12SequenceTypeINSt6__ndk16vectorINS1_3mapIlfNS1_4lessIlEENS1_9allocatorINS1_4pairIKlfEEEEEENS6_ISB_EEEEEE
0022fa04 N11onnxruntime13NonTensorTypeINSt6__ndk16vectorINS1_3mapIlfNS1_4lessIlEENS1_9allocatorINS1_4pairIKlfEEEEEENS6_ISB_EEEEEE
0022fa7d N11onnxruntime12OptionalTypeINS_6TensorEiEE
0022faa9 N11onnxruntime12OptionalTypeINS_6TensorEfEE
0022fad5 N11onnxruntime12OptionalTypeINS_6TensorEbEE
0022fb01 N11onnxruntime12OptionalTypeINS_6TensorENSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
0022fb6f N11onnxruntime12OptionalTypeINS_6TensorEaEE
0022fb9b N11onnxruntime12OptionalTypeINS_6TensorEhEE
0022fbc7 N11onnxruntime12OptionalTypeINS_6TensorEtEE
0022fbf3 N11onnxruntime12OptionalTypeINS_6TensorEsEE
0022fc1f N11onnxruntime12OptionalTypeINS_6TensorElEE
0022fc4b N11onnxruntime12OptionalTypeINS_6TensorEdEE
0022fc77 N11onnxruntime12OptionalTypeINS_6TensorEjEE
0022fca3 N11onnxruntime12OptionalTypeINS_6TensorEmEE
0022fccf N11onnxruntime12OptionalTypeINS_6TensorENS_9MLFloat16EEE
0022fd08 N11onnxruntime12OptionalTypeINS_6TensorENS_8BFloat16EEE
0022fd40 N11onnxruntime12OptionalTypeINS_9TensorSeqEiEE
0022fd6f N11onnxruntime12OptionalTypeINS_9TensorSeqEfEE
0022fd9e N11onnxruntime12OptionalTypeINS_9TensorSeqEbEE
0022fdcd N11onnxruntime12OptionalTypeINS_9TensorSeqENSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
0022fe3e N11onnxruntime12OptionalTypeINS_9TensorSeqEaEE
0022fe6d N11onnxruntime12OptionalTypeINS_9TensorSeqEhEE
0022fe9c N11onnxruntime12OptionalTypeINS_9TensorSeqEtEE
0022fecb N11onnxruntime12OptionalTypeINS_9TensorSeqEsEE
0022fefa N11onnxruntime12OptionalTypeINS_9TensorSeqElEE
0022ff29 N11onnxruntime12OptionalTypeINS_9TensorSeqEdEE
0022ff58 N11onnxruntime12OptionalTypeINS_9TensorSeqEjEE
0022ff87 N11onnxruntime12OptionalTypeINS_9TensorSeqEmEE
0022ffb6 N11onnxruntime12OptionalTypeINS_9TensorSeqENS_9MLFloat16EEE
0022fff2 N11onnxruntime12OptionalTypeINS_9TensorSeqENS_8BFloat16EEE
0023002d N11onnxruntime17PrimitiveDataTypeIiEE
00230053 N11onnxruntime21PrimitiveDataTypeBaseE
0023007a N11onnxruntime17PrimitiveDataTypeIfEE
002300a0 N11onnxruntime17PrimitiveDataTypeIbEE
002300c6 N11onnxruntime17PrimitiveDataTypeINSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEEE
0023012e N11onnxruntime17PrimitiveDataTypeIaEE
00230154 N11onnxruntime17PrimitiveDataTypeIhEE
0023017a N11onnxruntime17PrimitiveDataTypeItEE
002301a0 N11onnxruntime17PrimitiveDataTypeIsEE
002301c6 N11onnxruntime17PrimitiveDataTypeIlEE
002301ec N11onnxruntime17PrimitiveDataTypeIdEE
00230212 N11onnxruntime17PrimitiveDataTypeIjEE
00230238 N11onnxruntime17PrimitiveDataTypeImEE
0023025e N11onnxruntime17PrimitiveDataTypeINS_9MLFloat16EEE
00230291 N11onnxruntime17PrimitiveDataTypeINS_8BFloat16EEE
002302c3 N11onnxruntime11ExLibLoaderE
002302e6 uN11onnxruntime15IExecutionFrameE
00230308 N11onnxruntime14ExecutionFrameE
00230328 NSt6__ndk110__function6__funcIZN11onnxruntime14ExecutionFrameC1EN3gsl4spanIKiLm18446744073709551615EEENS5_IK8OrtValueLm18446744073709551615EEES7_SA_RKNS_13unordered_mapImNS_8functionIFNS2_6common6StatusERKNS2_11TensorShapeERK13OrtMemoryInfoRS8_RbEEENS_4hashImEENS_8equal_toImEENS_9allocatorINS_4pairIKmSO_EEEEEERKNS2_12SessionStateENS5_IPNS2_6StreamELm18446744073709551615EEEE3$_0NST_IS17_EEFbRKNS_12basic_stringIcNS_11char_traitsIcEENST_IcEEEEEEE
002304e8 ZN11onnxruntime14ExecutionFrameC1EN3gsl4spanIKiLm18446744073709551615EEENS2_IK8OrtValueLm18446744073709551615EEES4_S7_RKNSt6__ndk113unordered_mapImNS8_8functionIFNS_6common6StatusERKNS_11TensorShapeERK13OrtMemoryInfoRS5_RbEEENS8_4hashImEENS8_8equal_toImEENS8_9allocatorINS8_4pairIKmSM_EEEEEERKNS_12SessionStateENS2_IPNS_6StreamELm18446744073709551615EEEE3$_0
0023064f N11onnxruntime18IExecutionProviderE
00230674 NSt6__ndk110__function6__funcIZN11onnxruntime20GetCpuPreferredNodesERKNS2_11GraphViewerERKNS2_18IExecutionProvider13IKernelLookupEN3gsl4spanIKmLm18446744073709551615EEEE3$_1NS_9allocatorISE_EEFNS2_6common6StatusERKNS2_7NodeArgEmEEE
0023075c ZN11onnxruntime20GetCpuPreferredNodesERKNS_11GraphViewerERKNS_18IExecutionProvider13IKernelLookupEN3gsl4spanIKmLm18446744073709551615EEEE3$_1
002307ea N11onnxruntime12KernelLookupE
00230808 N11onnxruntime18IExecutionProvider13IKernelLookupE
0023083b NSt6__ndk110__function6__funcIZN11onnxruntimeL28PartitionOnnxFormatModelImplERNS2_5GraphERNS2_11FuncManagerERNS2_21KernelRegistryManagerERNS2_14KernelRegistryERNS2_18IExecutionProviderENS2_16GraphPartitioner4ModeERiNS_8functionIFNS2_6common6StatusES4_RbSC_EEEE3$_2NS_9allocatorISM_EEFSI_S6_RKNS2_12OpKernelInfoERNS_10unique_ptrINS2_8OpKernelENS_14default_deleteIST_EEEEEEE
002309b0 N11onnxruntime14FunctionKernelE
002309d0 ZN11onnxruntimeL28PartitionOnnxFormatModelImplERNS_5GraphERNS_11FuncManagerERNS_21KernelRegistryManagerERNS_14KernelRegistryERNS_18IExecutionProviderENS_16GraphPartitioner4ModeERiNSt6__ndk18functionIFNS_6common6StatusES1_RbS9_EEEE3$_2
00230abb NSt6__ndk110__function6__funcIZN11onnxruntimeL27PartitionOrtFormatModelImplERKNS2_12_GLOBAL__N_115PartitionParamsERNS2_21KernelRegistryManagerERNS2_18IExecutionProviderEE3$_3NS_9allocatorISB_EEFNS2_6common6StatusERNS2_11FuncManagerERKNS2_12OpKernelInfoERNS_10unique_ptrINS2_8OpKernelENS_14default_deleteISM_EEEEEEE
00230bf6 ZN11onnxruntimeL27PartitionOrtFormatModelImplERKNS_12_GLOBAL__N_115PartitionParamsERNS_21KernelRegistryManagerERNS_18IExecutionProviderEE3$_3
00230c85 NSt6__ndk110__function6__funcIZN11onnxruntime11FuncManager8GetFuncsERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERPKNS2_15NodeComputeInfoEE3$_0NS7_ISG_EEFNS2_6common6StatusEPvPK6OrtApiP16OrtKernelContextEEE
00230d63 ZN11onnxruntime11FuncManager8GetFuncsERKNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEERPKNS_15NodeComputeInfoEE3$_0
00230dec NSt6__ndk110__function6__funcIZN11onnxruntime11FuncManager8GetFuncsERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERPKNS2_15NodeComputeInfoEE3$_1NS7_ISG_EEFiPNS2_14ComputeContextEPPvEEE
00230eb3 ZN11onnxruntime11FuncManager8GetFuncsERKNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEERPKNS_15NodeComputeInfoEE3$_1
00230f3c NSt6__ndk110__function6__funcIZN11onnxruntime11FuncManager8GetFuncsERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERPKNS2_15NodeComputeInfoEE3$_2NS7_ISG_EEFvPvEEE
00230fec ZN11onnxruntime11FuncManager8GetFuncsERKNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEERPKNS_15NodeComputeInfoEE3$_2
0023108d N11onnxruntime21KernelTypeStrResolverE
002310b4 N11onnxruntime22IKernelTypeStrResolverE
002310dc N11onnxruntime29OpSchemaKernelTypeStrResolverE
00231110 ktsr
00231184 :Squeeze:1
002311cc com.microsoft:NhwcMaxPool:1
00231224 :Unsqueeze:11
00231270 :Transpose:1
002312c0 :Squeeze:13
00231324 :Identity:14
00231370 :Squeeze:11
002313bc :Unsqueeze:13
002313dc axes
00231430 :Unsqueeze:1
0023147c :Identity:13
002314e0 com.microsoft:QLinearConv:1
0023150c y_scale
002315e4 w_scale
0023160c x_scale
00231640 :Gather:1
002316a4 :Transpose:13
002316f0 :Identity:1
00231738 :Identity:16
00231790 :Gather:11
002317f8 :Gather:13
00231854 Tind
00231874 -+)' 
00231883 NSt6__ndk110__function6__funcIZN11onnxruntime13NodeIndexInfo4InitINS2_15ConstGraphNodesEEEvRKT_mRKNS2_18OrtValueNameIdxMapEEUlRKNS2_7NodeArgEbE_NS_9allocatorISF_EEFvSE_bEEE
00231930 NSt6__ndk110__function6__baseIFvRKN11onnxruntime7NodeArgEbEEE
0023196e ZN11onnxruntime13NodeIndexInfo4InitINS_15ConstGraphNodesEEEvRKT_mRKNS_18OrtValueNameIdxMapEEUlRKNS_7NodeArgEbE_
002319de NSt6__ndk110__function6__funcIZN11onnxruntime13NodeIndexInfo4InitINS2_15ConstGraphNodesEEEvRKT_mRKNS2_18OrtValueNameIdxMapEEUlRKNS2_7NodeArgEbE0_NS_9allocatorISF_EEFvSE_bEEE
00231a8c ZN11onnxruntime13NodeIndexInfo4InitINS_15ConstGraphNodesEEEvRKT_mRKNS_18OrtValueNameIdxMapEEUlRKNS_7NodeArgEbE0_
00231afd NSt6__ndk110__function6__funcIZN11onnxruntime13NodeIndexInfo4InitINS2_10ValidNodesIKNS_6vectorIPKNS2_4NodeENS_9allocatorIS9_EEEEEEEEvRKT_mRKNS2_18OrtValueNameIdxMapEEUlRKNS2_7NodeArgEbE_NSA_ISO_EEFvSN_bEEE
00231bcb ZN11onnxruntime13NodeIndexInfo4InitINS_10ValidNodesIKNSt6__ndk16vectorIPKNS_4NodeENS3_9allocatorIS7_EEEEEEEEvRKT_mRKNS_18OrtValueNameIdxMapEEUlRKNS_7NodeArgEbE_
00231c6c NSt6__ndk110__function6__funcIZN11onnxruntime13NodeIndexInfo4InitINS2_10ValidNodesIKNS_6vectorIPKNS2_4NodeENS_9allocatorIS9_EEEEEEEEvRKT_mRKNS2_18OrtValueNameIdxMapEEUlRKNS2_7NodeArgEbE0_NSA_ISO_EEFvSN_bEEE
00231d3b ZN11onnxruntime13NodeIndexInfo4InitINS_10ValidNodesIKNSt6__ndk16vectorIPKNS_4NodeENS3_9allocatorIS7_EEEEEEEEvRKT_mRKNS_18OrtValueNameIdxMapEEUlRKNS_7NodeArgEbE0_
00231dde 		33	?
00231df2 N11onnxruntime15OpKernelContextE
00231e13 NSt6__ndk120__shared_ptr_emplaceIN11onnxruntime14LibraryHandlesENS_9allocatorIS2_EEEE
00231e6a N11onnxruntime24SequentialPlannerContextE
00231e94 N11onnxruntime25ISequentialPlannerContextE
00231ebf NSt6__ndk110__function6__funcIZN11onnxruntimeL36OuterScopeNodeArgLocationAccumulatorERKNS2_23SequentialExecutionPlanERKNS2_18OrtValueNameIdxMapERKNS2_4NodeERKNS2_11GraphViewerERNS2_14InlinedHashMapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE13OrtMemoryInfoNSJ_INS_4pairIKSL_SM_EEEEEEE3$_5NSJ_IST_EEFNS2_6common6StatusERKNS2_7NodeArgEmEEE
00232020 ZN11onnxruntimeL36OuterScopeNodeArgLocationAccumulatorERKNS_23SequentialExecutionPlanERKNS_18OrtValueNameIdxMapERKNS_4NodeERKNS_11GraphViewerERNS_14InlinedHashMapINSt6__ndk112basic_stringIcNSD_11char_traitsIcEENSD_9allocatorIcEEEE13OrtMemoryInfoNSH_INSD_4pairIKSJ_SK_EEEEEEE3$_5
00232137 NSt6__ndk110__function6__funcIZN11onnxruntimeL36OuterScopeNodeArgLocationAccumulatorERKNS2_23SequentialExecutionPlanERKNS2_18OrtValueNameIdxMapERKNS2_4NodeERKNS2_11GraphViewerERNS2_14InlinedHashMapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE13OrtMemoryInfoNSJ_INS_4pairIKSL_SM_EEEEEEE3$_6NSJ_IST_EEFNS2_6common6StatusERKNS2_7NodeArgEmEEE
00232298 ZN11onnxruntimeL36OuterScopeNodeArgLocationAccumulatorERKNS_23SequentialExecutionPlanERKNS_18OrtValueNameIdxMapERKNS_4NodeERKNS_11GraphViewerERNS_14InlinedHashMapINSt6__ndk112basic_stringIcNSD_11char_traitsIcEENSD_9allocatorIcEEEE13OrtMemoryInfoNSH_INSD_4pairIKSJ_SK_EEEEEEE3$_6
002323af N11onnxruntime31StreamCommandHandleRegistryImplE
002323e0 N11onnxruntime28IStreamCommandHandleRegistryE
0023240e NSt6__ndk110__function6__funcIZN11onnxruntime12SessionState15SetupAllocatorsEvE3$_0NS_9allocatorIS4_EEFNS_10shared_ptrINS2_10IAllocatorEEEi10OrtMemTypeEEE
002324a9 NSt6__ndk110__function6__baseIFNS_10shared_ptrIN11onnxruntime10IAllocatorEEEi10OrtMemTypeEEE
00232506 ZN11onnxruntime12SessionState15SetupAllocatorsEvE3$_0
0023253c NSt6__ndk110__function6__funcIZN11onnxruntime12SessionState24FinalizeSessionStateImplERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEERKNS2_21KernelRegistryManagerEPKNS2_4NodeERKNS2_14SessionOptionsEbRNS2_14InlinedHashMapIS9_mNS7_INS_4pairISA_mEEEEEERKNSL_IS9_13OrtMemoryInfoNS7_INSM_ISA_SR_EEEEEEbE3$_4NS7_ISX_EEFNS2_6common6StatusESB_iRK8OrtValueRKNS2_11OrtCallbackEbbEEE
002326be NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEiRK8OrtValueRKNS2_11OrtCallbackEbbEEE
0023275c ZN11onnxruntime12SessionState24FinalizeSessionStateImplERKNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEERKNS_21KernelRegistryManagerEPKNS_4NodeERKNS_14SessionOptionsEbRNS_14InlinedHashMapIS7_mNS5_INS1_4pairIS8_mEEEEEERKNSJ_IS7_13OrtMemoryInfoNS5_INSK_IS8_SP_EEEEEEbE3$_4
00232880 NSt6__ndk110__function6__funcIZN11onnxruntime25PrepackedWeightsContainer20GetOrCreateAllocatorERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_0NS7_ISC_EEFNS_10unique_ptrINS2_10IAllocatorENS_14default_deleteISF_EEEEsEEE
0023296d ZN11onnxruntime25PrepackedWeightsContainer20GetOrCreateAllocatorERKNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEE3$_0
00232a2a ..........>
00232a7d ]]]]]]]]]]]]]]]]]]
00232d33 &!8G
00232d54 [L@V`@@@@@@@@@@@@@@@@@@@@QN11onnxruntime22DeviceBasedPartitionerE
00232d96 N11onnxruntime17IGraphPartitionerE
00232db9 NSt6__ndk110__function6__funcIZN11onnxruntime11PlannerImpl20ComputeValueLocationEvEUlRKNS2_7NodeArgEmE_NS_9allocatorIS7_EEFNS2_6common6StatusES6_mEEE
00232e50 ZN11onnxruntime11PlannerImpl20ComputeValueLocationEvEUlRKNS_7NodeArgEmE_
00232e99 NSt6__ndk110__function6__funcIZN11onnxruntime11PlannerImpl17ComputeReuseCountEvEUlRKNS2_7NodeArgEmE_NS_9allocatorIS7_EEFNS2_6common6StatusES6_mEEE
00232f2c ZN11onnxruntime11PlannerImpl17ComputeReuseCountEvEUlRKNS_7NodeArgEmE_
00232f72 NSt6__ndk110__function6__funcIZN11onnxruntime11PlannerImpl31OptimizeReusePlanForMultiStreamEvEUlmE_NS_9allocatorIS4_EEFNS_3setImNS_4lessImEENS5_ImEEEEmEEE
0023300d NSt6__ndk110__function6__baseIFNS_3setImNS_4lessImEENS_9allocatorImEEEEmEEE
00233059 NSt6__ndk110__function6__funcIZZN11onnxruntime11PlannerImpl31OptimizeReusePlanForMultiStreamEvENKUlmE_clEmEUlmE_NS_9allocatorIS5_EEFvmEEE
002330e3 NSt6__ndk110__function6__baseIFvmEEE
00233108 ZZN11onnxruntime11PlannerImpl31OptimizeReusePlanForMultiStreamEvENKUlmE_clEmEUlmE_
0023315b ZN11onnxruntime11PlannerImpl31OptimizeReusePlanForMultiStreamEvEUlmE_
002331a1 NSt6__ndk110__function6__funcIZN11onnxruntime11PlannerImpl31OptimizeReusePlanForMultiStreamEvEUlRKNS2_7NodeArgEmE_NS_9allocatorIS7_EEFNS2_6common6StatusES6_mEEE
00233242 ZN11onnxruntime11PlannerImpl31OptimizeReusePlanForMultiStreamEvEUlRKNS_7NodeArgEmE_
00233296 NSt6__ndk110__function6__funcIZN11onnxruntime11PlannerImpl31OptimizeReusePlanForMultiStreamEvEUlmE0_NS_9allocatorIS4_EEFvmEEE
00233314 ZN11onnxruntime11PlannerImpl31OptimizeReusePlanForMultiStreamEvEUlmE0_
0023335b NSt6__ndk110__function6__funcIZN11onnxruntime11PlannerImpl31OptimizeReusePlanForMultiStreamEvEUlmE1_NS_9allocatorIS4_EEFvmEEE
002333d9 ZN11onnxruntime11PlannerImpl31OptimizeReusePlanForMultiStreamEvEUlmE1_
00233420 NSt6__ndk110__function6__funcIZN11onnxruntime11PlannerImpl24GenerateDeallocationPlanEvEUlRKNS2_7NodeArgEmE_NS_9allocatorIS7_EEFNS2_6common6StatusES6_mEEE
002334ba ZN11onnxruntime11PlannerImpl24GenerateDeallocationPlanEvEUlRKNS_7NodeArgEmE_
00233507 NSt6__ndk120__shared_ptr_emplaceIN8nlohmann6detail21output_string_adapterIcNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEENS7_ISA_EEEE
0023359b N8nlohmann6detail21output_string_adapterIcNSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEE
0023360b N8nlohmann6detail23output_adapter_protocolIcEE
002336ca 																
002337ca 000102030405060708091011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798990001020304050607080910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989900010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899
00233a6a U1(\Q
00233a98 mSx@
00233b4a b}$l
00233bb9 ~)p$w
00233c09 11eU%
00233ecb z^KD
00233f9c N11onnxruntime11BarrierStepE
00233fb9 N11onnxruntime23SequentialExecutionPlan13ExecutionStepE
00233ff1 N11onnxruntime12WaitOnEPStepE
0023400f N11onnxruntime16LaunchKernelStepE
00234031 N11onnxruntime24ActivateNotificationStepE
0023405b N11onnxruntime21TriggerDownstreamStepE
00234083 N11onnxruntime23OpKernelContextInternalE
002340ac NSt6__ndk110__function6__funcIZN11onnxruntime14ExecuteThePlanERKNS2_12SessionStateEN3gsl4spanIKiLm18446744073709551615EEENS7_IK8OrtValueLm18446744073709551615EEES9_RNS_6vectorISA_NS_9allocatorISA_EEEERKNS_13unordered_mapImNS_8functionIFNS2_6common6StatusERKNS2_11TensorShapeERK13OrtMemoryInfoRSA_RbEEENS_4hashImEENS_8equal_toImEENSE_INS_4pairIKmSV_EEEEEERKNS2_7logging6LoggerEPKNS2_22DeviceStreamCollectionERKbbbE3$_1NSE_IS1G_EEFvvEEE
0023425f NSt6__ndk110__function6__baseIFvvEEE
00234284 ZN11onnxruntime14ExecuteThePlanERKNS_12SessionStateEN3gsl4spanIKiLm18446744073709551615EEENS4_IK8OrtValueLm18446744073709551615EEES6_RNSt6__ndk16vectorIS7_NSA_9allocatorIS7_EEEERKNSA_13unordered_mapImNSA_8functionIFNS_6common6StatusERKNS_11TensorShapeERK13OrtMemoryInfoRS7_RbEEENSA_4hashImEENSA_8equal_toImEENSC_INSA_4pairIKmST_EEEEEERKNS_7logging6LoggerEPKNS_22DeviceStreamCollectionERKbbbE3$_1
00234410 NSt6__ndk120__shared_ptr_pointerIPvNS_8functionIFvS1_EEENS_9allocatorIvEEEE
0023445c NSt6__ndk18functionIFvPvEEE
00234478 NSt6__ndk110__function6__funcIN11onnxruntime19session_state_utils19ExtDataValueDeleterENS_9allocatorIS4_EEFvPvEEE
002344ea N11onnxruntime19session_state_utils19ExtDataValueDeleterE
00234524 NSt6__ndk110__function6__funcIZN11onnxruntime19session_state_utils33SaveInputOutputNamesToNodeMappingERKNS2_11GraphViewerERNS2_12SessionStateEN3gsl4spanIKPKNS2_7NodeArgELm18446744073709551615EEEE3$_1NS_9allocatorISG_EEFNS2_6common6StatusERSC_mEEE
0023461b ZN11onnxruntime19session_state_utils33SaveInputOutputNamesToNodeMappingERKNS_11GraphViewerERNS_12SessionStateEN3gsl4spanIKPKNS_7NodeArgELm18446744073709551615EEEE3$_1
002346c2 NSt6__ndk110__function6__funcIZN11onnxruntime19session_state_utils33SaveInputOutputNamesToNodeMappingERKNS2_11GraphViewerERNS2_12SessionStateEN3gsl4spanIKPKNS2_7NodeArgELm18446744073709551615EEEE3$_2NS_9allocatorISG_EEFNS2_6common6StatusERSC_mEEE
002347b9 ZN11onnxruntime19session_state_utils33SaveInputOutputNamesToNodeMappingERKNS_11GraphViewerERNS_12SessionStateEN3gsl4spanIKPKNS_7NodeArgELm18446744073709551615EEEE3$_2
00234860 NSt6__ndk110__function6__funcIZN11onnxruntime10IAllocator13MakeUniquePtrIvEENS_10unique_ptrIT_NS_8functionIFvPS6_EEEEENS_10shared_ptrIS3_EEmbPNS2_6StreamENS7_IFvRSE_RNS2_11synchronize12NotificationEEEEEUlPvE_NS_9allocatorISN_EEFvSM_EEE
0023494c ZN11onnxruntime10IAllocator13MakeUniquePtrIvEENSt6__ndk110unique_ptrIT_NS2_8functionIFvPS4_EEEEENS2_10shared_ptrIS0_EEmbPNS_6StreamENS5_IFvRSC_RNS_11synchronize12NotificationEEEEEUlPvE_
00234a1e NSt6__ndk110__function6__funcIZN11onnxruntime18ScheduleDownstreamERNS2_22StreamExecutionContextEmbRKbRNS2_12SessionScopeEE3$_1NS_9allocatorIS9_EEFvvEEE
00234ab6 ZN11onnxruntime18ScheduleDownstreamERNS_22StreamExecutionContextEmbRKbRNS_12SessionScopeEE3$_1
00234b15 N11onnxruntime29TensorAllocatorWithMemPatternE
00234b44 N11onnxruntime16ITensorAllocatorE
00234b66 N11onnxruntime21SimpleTensorAllocatorE
00234bf5 4CRap
00234c23 x|MRW
00234c2d Hn\\s
00234c3b rrr!NSt6__ndk110__function6__funcIZN11onnxruntime5utils35SparseTensorProtoToDenseTensorProtoERKN4onnx17SparseTensorProtoERKNS2_4PathERNS4_11TensorProtoEE3$_0NS_9allocatorISD_EEFvmmEEE
00234cf3 NSt6__ndk110__function6__baseIFvmmEEE
00234d19 ZN11onnxruntime5utils35SparseTensorProtoToDenseTensorProtoERKN4onnx17SparseTensorProtoERKNS_4PathERNS1_11TensorProtoEE3$_0
00234d94 NSt6__ndk110__function6__funcIZN11onnxruntime5utils35SparseTensorProtoToDenseTensorProtoERKN4onnx17SparseTensorProtoERKNS2_4PathERNS4_11TensorProtoEE3$_1NS_9allocatorISD_EEFvmmEEE
00234e48 ZN11onnxruntime5utils35SparseTensorProtoToDenseTensorProtoERKN4onnx17SparseTensorProtoERKNS_4PathERNS1_11TensorProtoEE3$_1
00234ec3 NSt6__ndk110__function6__funcIZN11onnxruntime5utils35SparseTensorProtoToDenseTensorProtoERKN4onnx17SparseTensorProtoERKNS2_4PathERNS4_11TensorProtoEE3$_2NS_9allocatorISD_EEFvmmEEE
00234f77 ZN11onnxruntime5utils35SparseTensorProtoToDenseTensorProtoERKN4onnx17SparseTensorProtoERKNS_4PathERNS1_11TensorProtoEE3$_2
00234ff2 NSt6__ndk110__function6__funcIZN11onnxruntime5utils35SparseTensorProtoToDenseTensorProtoERKN4onnx17SparseTensorProtoERKNS2_4PathERNS4_11TensorProtoEE3$_3NS_9allocatorISD_EEFvmmEEE
002350a6 ZN11onnxruntime5utils35SparseTensorProtoToDenseTensorProtoERKN4onnx17SparseTensorProtoERKNS_4PathERNS1_11TensorProtoEE3$_3
00235123 *K***X
0023512b *K***X
002351a7 +NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_24Attention_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_0NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00235253 ZN11onnxruntime7contrib11GetOpSchemaINS0_24Attention_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_0
002352b0 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_33MultiHeadAttention_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_1NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00235364 ZN11onnxruntime7contrib11GetOpSchemaINS0_33MultiHeadAttention_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_1
002353ca NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_31DecoderAttention_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_2NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023547c ZN11onnxruntime7contrib11GetOpSchemaINS0_31DecoderAttention_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_2
002354e0 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_23FastGelu_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_3NS_9allocatorIS8_EEFbRKNS6_24FunctionBodyBuildContextERKS7_RNS6_13FunctionProtoEEEE
002355ad NSt6__ndk110__function6__baseIFbRKN4onnx24FunctionBodyBuildContextERKNS2_8OpSchemaERNS2_13FunctionProtoEEEE
00235619 ZN11onnxruntime7contrib11GetOpSchemaINS0_23FastGelu_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_3
00235675 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_35RelativePositionBias_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_4NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023572b ZN11onnxruntime7contrib11GetOpSchemaINS0_35RelativePositionBias_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_4
00235793 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_31NGramRepeatBlock_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_5NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00235845 ZN11onnxruntime7contrib11GetOpSchemaINS0_31NGramRepeatBlock_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_5
002358a9 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_34BifurcationDetector_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_6NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023595e ZN11onnxruntime7contrib11GetOpSchemaINS0_34BifurcationDetector_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_6
002359c5 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_27GemmFastGelu_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_7NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00235a73 ZN11onnxruntime7contrib11GetOpSchemaINS0_27GemmFastGelu_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_7
00235ad3 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_28RemovePadding_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_8NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00235b82 ZN11onnxruntime7contrib11GetOpSchemaINS0_28RemovePadding_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_8
00235be3 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_29RestorePadding_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_9NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00235c93 ZN11onnxruntime7contrib11GetOpSchemaINS0_29RestorePadding_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_9
00235cf5 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_40GatedRelativePositionBias_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_10NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00235db1 ZN11onnxruntime7contrib11GetOpSchemaINS0_40GatedRelativePositionBias_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_10
00235f91 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_19Gelu_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_0NS_9allocatorIS8_EEFbRKNS6_24FunctionBodyBuildContextERKS7_RNS6_13FunctionProtoEEEE
0023605a ZN11onnxruntime7contrib11GetOpSchemaINS0_19Gelu_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_0
002360b2 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_24QuickGelu_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_1NS_9allocatorIS8_EEFbRKNS6_24FunctionBodyBuildContextERKS7_RNS6_13FunctionProtoEEEE
00236180 ZN11onnxruntime7contrib11GetOpSchemaINS0_24QuickGelu_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_1
002361dd NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_22Inverse_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_2NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00236286 ZN11onnxruntime7contrib11GetOpSchemaINS0_22Inverse_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_2
002362e1 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_29TorchEmbedding_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_3NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00236391 ZN11onnxruntime7contrib11GetOpSchemaINS0_29TorchEmbedding_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_3
002363f3 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_20Trilu_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_4NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023649a ZN11onnxruntime7contrib11GetOpSchemaINS0_20Trilu_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_4
002364f3 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_26BiasDropout_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_5NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
002365a0 ZN11onnxruntime7contrib11GetOpSchemaINS0_26BiasDropout_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_5
002365ff NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_33BitmaskBiasDropout_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_6NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
002366b3 ZN11onnxruntime7contrib11GetOpSchemaINS0_33BitmaskBiasDropout_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_6
00236719 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_26IsAllFinite_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_7NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
002367c6 ZN11onnxruntime7contrib11GetOpSchemaINS0_26IsAllFinite_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_7
00236825 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_25GridSample_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_8NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
002368d1 ZN11onnxruntime7contrib11GetOpSchemaINS0_25GridSample_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_8
0023692f NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_25BeamSearch_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_9NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
002369db ZN11onnxruntime7contrib11GetOpSchemaINS0_25BeamSearch_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_9
00236a39 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_27GreedySearch_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_10NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00236ae8 ZN11onnxruntime7contrib11GetOpSchemaINS0_27GreedySearch_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_10
00236b49 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_23Sampling_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_11NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00236bf4 ZN11onnxruntime7contrib11GetOpSchemaINS0_23Sampling_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_11
00236c51 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_30MaxpoolWithMask_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_12NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00236d03 ZN11onnxruntime7contrib11GetOpSchemaINS0_30MaxpoolWithMask_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_12
00236d67 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_24FusedConv_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_13NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00236e13 ZN11onnxruntime7contrib11GetOpSchemaINS0_24FusedConv_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_13
00236e71 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_24FusedGemm_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_14NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00236f1d ZN11onnxruntime7contrib11GetOpSchemaINS0_24FusedGemm_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_14
00236f7b NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_25ExpandDims_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_15NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00237028 ZN11onnxruntime7contrib11GetOpSchemaINS0_25ExpandDims_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_15
00237087 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_24Tokenizer_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_16NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00237133 ZN11onnxruntime7contrib11GetOpSchemaINS0_24Tokenizer_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_16
00237191 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_30MatMulInteger16_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_17NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00237243 ZN11onnxruntime7contrib11GetOpSchemaINS0_30MatMulInteger16_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_17
002372a7 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_30TransposeMatMul_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_18NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00237359 ZN11onnxruntime7contrib11GetOpSchemaINS0_30TransposeMatMul_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_18
002373bd NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_26FusedMatMul_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_19NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023746b ZN11onnxruntime7contrib11GetOpSchemaINS0_26FusedMatMul_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_19
002374cb NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_34SparseToDenseMatMul_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_20NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00237581 ZN11onnxruntime7contrib11GetOpSchemaINS0_34SparseToDenseMatMul_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_20
002375e9 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_26MurmurHash3_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_21NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00237697 ZN11onnxruntime7contrib11GetOpSchemaINS0_26MurmurHash3_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_21
002376f7 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_23GatherND_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_22NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
002377a2 ZN11onnxruntime7contrib11GetOpSchemaINS0_23GatherND_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_22
002377ff NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_18Pad_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_23NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
002378a5 ZN11onnxruntime7contrib11GetOpSchemaINS0_18Pad_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_23
002378fd NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_21Unique_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_24NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
002379a6 ZN11onnxruntime7contrib11GetOpSchemaINS0_21Unique_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_24
00237a01 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_28CropAndResize_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_25NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00237ab1 ZN11onnxruntime7contrib11GetOpSchemaINS0_28CropAndResize_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_25
00237b13 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_26NS_9allocatorIS4_EEFvRN4onnx16InferenceContextEEEE
00237b9b ZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_26
00237bd3 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_27NS_9allocatorIS4_EEFbRKN4onnx24FunctionBodyBuildContextERKNS7_8OpSchemaERNS7_13FunctionProtoEEEE
00237c89 ZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_27
00237cc1 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_28NS_9allocatorIS4_EEFvRN4onnx16InferenceContextEEEE
00237d49 ZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_28
00237d81 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_29NS_9allocatorIS4_EEFvRN4onnx16InferenceContextEEEE
00237e09 ZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_29
00237e41 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_30NS_9allocatorIS4_EEFvRN4onnx16InferenceContextEEEE
00237ec9 ZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_30
00237f01 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_31NS_9allocatorIS4_EEFvRN4onnx16InferenceContextEEEE
00237f89 ZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_31
00237fc1 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_32NS_9allocatorIS4_EEFvRN4onnx16InferenceContextEEEE
00238049 ZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_32
00238081 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_33NS_9allocatorIS4_EEFvRN4onnx16InferenceContextEEEE
00238109 ZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_33
00238141 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_34NS_9allocatorIS4_EEFvRN4onnx16InferenceContextEEEE
002381c9 ZN11onnxruntime7contrib22RegisterContribSchemasEvE4$_34
00238213 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_28BiasSplitGelu_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_0NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
002382c2 ZN11onnxruntime7contrib11GetOpSchemaINS0_28BiasSplitGelu_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_0
00238323 NSt6__ndk110__function6__funcIZN11onnxruntime18internal_nhwc_onnx12_GLOBAL__N_132RegisterNHWCSchemaWithActivationERKNS_8functionIFvON4onnx8OpSchemaEEEES8_E3$_1NS_9allocatorISD_EEFvRNS6_16InferenceContextEEEE
002383f3 N11onnxruntime7contrib20NhwcInferenceContextE
00238421 N4onnx16InferenceContextE
0023843b ZN11onnxruntime18internal_nhwc_onnx12_GLOBAL__N_132RegisterNHWCSchemaWithActivationERKNSt6__ndk18functionIFvON4onnx8OpSchemaEEEES6_E3$_1
002384c4 NSt6__ndk110__function6__funcIZN11onnxruntime18internal_nhwc_onnx12_GLOBAL__N_118RegisterNHWCSchemaERKNS_8functionIFvON4onnx8OpSchemaEEEES8_E3$_0NS_9allocatorISD_EEFvRNS6_16InferenceContextEEEE
00238586 ZN11onnxruntime18internal_nhwc_onnx12_GLOBAL__N_118RegisterNHWCSchemaERKNSt6__ndk18functionIFvON4onnx8OpSchemaEEEES6_E3$_0
0023861c NSt6__ndk110__function6__funcIZN11onnxruntime7contrib26NchwcPoolOpSchemaGeneratorERN4onnx8OpSchemaEE3$_0NS_9allocatorIS7_EEFvRNS4_16InferenceContextEEEE
002386b5 ZN11onnxruntime7contrib26NchwcPoolOpSchemaGeneratorERN4onnx8OpSchemaEE3$_0
00238700 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib32NchwcGlobalPoolOpSchemaGeneratorERN4onnx8OpSchemaEE3$_1NS_9allocatorIS7_EEFvRNS4_16InferenceContextEEEE
0023879f ZN11onnxruntime7contrib32NchwcGlobalPoolOpSchemaGeneratorERN4onnx8OpSchemaEE3$_1
002387f0 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib20RegisterNchwcSchemasEvE3$_2NS_9allocatorIS4_EEFvRN4onnx16InferenceContextEEEE
00238875 ZN11onnxruntime7contrib20RegisterNchwcSchemasEvE3$_2
002388aa NSt6__ndk110__function6__funcIZN11onnxruntime7contrib20RegisterNchwcSchemasEvE3$_3NS_9allocatorIS4_EEFvRN4onnx16InferenceContextEEEE
0023892f ZN11onnxruntime7contrib20RegisterNchwcSchemasEvE3$_3
00238964 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib20RegisterNchwcSchemasEvE3$_4NS_9allocatorIS4_EEFvRN4onnx16InferenceContextEEEE
002389e9 ZN11onnxruntime7contrib20RegisterNchwcSchemasEvE3$_4
00238a1e NSt6__ndk110__function6__funcIPFvRN4onnx8OpSchemaEENS_9allocatorIS6_EES5_EE
00238a6a NSt6__ndk110__function6__baseIFvRN4onnx8OpSchemaEEEE
00238a9f PFvRN4onnx8OpSchemaEE
00238ab5 FvRN4onnx8OpSchemaEE
00238aca NSt6__ndk110__function6__funcIZN11onnxruntime7contrib20RegisterNchwcSchemasEvE3$_5NS_9allocatorIS4_EEFvRN4onnx16InferenceContextEEEE
00238b4f ZN11onnxruntime7contrib20RegisterNchwcSchemasEvE3$_5
00238b8d NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_26NhwcMaxPool_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_0NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00238c3a ZN11onnxruntime7contrib11GetOpSchemaINS0_26NhwcMaxPool_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_0
00238c99 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_39QLinearGlobalAveragePool_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_1NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00238d53 ZN11onnxruntime7contrib11GetOpSchemaINS0_39QLinearGlobalAveragePool_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_1
00238dbf NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_33QLinearAveragePool_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_2NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00238e73 ZN11onnxruntime7contrib11GetOpSchemaINS0_33QLinearAveragePool_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_2
00238ed9 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_26QLinearConv_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_3NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00238f86 ZN11onnxruntime7contrib11GetOpSchemaINS0_26QLinearConv_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_3
00238fe5 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib21ConvOpSchemaGeneratorEvE3$_4NS_9allocatorIS4_EEFvRN4onnx8OpSchemaEEEE
00239062 NSt6__ndk110__function6__funcIZZN11onnxruntime7contrib21ConvOpSchemaGeneratorEvENK3$_4clERN4onnx8OpSchemaEEUlRNS5_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00239105 ZZN11onnxruntime7contrib21ConvOpSchemaGeneratorEvENK3$_4clERN4onnx8OpSchemaEEUlRNS2_16InferenceContextEE_
0023916f ZN11onnxruntime7contrib21ConvOpSchemaGeneratorEvE3$_4
002391c0 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_25GivenTensorFill_Onnx_ver1EEEN4onnx8OpSchemaEvE3$_0NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023926c ZN11onnxruntime7contrib11GetOpSchemaINS0_25GivenTensorFill_Onnx_ver1EEEN4onnx8OpSchemaEvE3$_0
002392ca NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_26GivenTensorFill_Onnx_ver10EEEN4onnx8OpSchemaEvE3$_1NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00239377 ZN11onnxruntime7contrib11GetOpSchemaINS0_26GivenTensorFill_Onnx_ver10EEEN4onnx8OpSchemaEvE3$_1
002393d6 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_15Crop_Onnx_ver10EEEN4onnx8OpSchemaEvE3$_2NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00239478 ZN11onnxruntime7contrib11GetOpSchemaINS0_15Crop_Onnx_ver10EEEN4onnx8OpSchemaEvE3$_2
00239583 +NSt6__ndk110__function6__funcIZN11onnxruntime7contrib23QLinearMathDocGeneratorEPKcS5_E3$_0NS_9allocatorIS6_EEFvRN4onnx8OpSchemaEEEE
00239608 NSt6__ndk110__function6__funcIZZN11onnxruntime7contrib23QLinearMathDocGeneratorEPKcS5_ENK3$_0clERN4onnx8OpSchemaEEUlRNS7_16InferenceContextEE_NS_9allocatorISC_EEFvSB_EEE
002396b2 ZZN11onnxruntime7contrib23QLinearMathDocGeneratorEPKcS2_ENK3$_0clERN4onnx8OpSchemaEEUlRNS4_16InferenceContextEE_
00239723 ZN11onnxruntime7contrib23QLinearMathDocGeneratorEPKcS2_E3$_0
00239760 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_29QuantizeLinear_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_1NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00239810 ZN11onnxruntime7contrib11GetOpSchemaINS0_29QuantizeLinear_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_1
00239872 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_31DequantizeLinear_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_2NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00239924 ZN11onnxruntime7contrib11GetOpSchemaINS0_31DequantizeLinear_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_2
00239988 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_26QuantizeBFP_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_3NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00239a35 ZN11onnxruntime7contrib11GetOpSchemaINS0_26QuantizeBFP_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_3
00239a94 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_28DequantizeBFP_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_4NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00239b43 ZN11onnxruntime7contrib11GetOpSchemaINS0_28DequantizeBFP_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_4
00239ba4 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_25MulInteger_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_5NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00239c50 ZN11onnxruntime7contrib11GetOpSchemaINS0_25MulInteger_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_5
00239cae NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_36DynamicQuantizeMatMul_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_6NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00239d65 ZN11onnxruntime7contrib11GetOpSchemaINS0_36DynamicQuantizeMatMul_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_6
00239dce NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_35MatMulIntegerToFloat_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_7NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00239e84 ZN11onnxruntime7contrib11GetOpSchemaINS0_35MatMulIntegerToFloat_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_7
00239eec NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_32QLinearReduceMean_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_8NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
00239f9f ZN11onnxruntime7contrib11GetOpSchemaINS0_32QLinearReduceMean_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_8
0023a004 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_29QLinearSoftmax_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_9NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023a0b4 ZN11onnxruntime7contrib11GetOpSchemaINS0_29QLinearSoftmax_Microsoft_ver1EEEN4onnx8OpSchemaEvE3$_9
0023a116 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_28QLinearConcat_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_10NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023a1c6 ZN11onnxruntime7contrib11GetOpSchemaINS0_28QLinearConcat_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_10
0023a228 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_27QLinearWhere_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_11NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023a2d7 ZN11onnxruntime7contrib11GetOpSchemaINS0_27QLinearWhere_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_11
0023a338 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_20QGemm_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_12NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023a3e0 ZN11onnxruntime7contrib11GetOpSchemaINS0_20QGemm_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_12
0023a43a NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_25QAttention_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_13NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023a4e7 ZN11onnxruntime7contrib11GetOpSchemaINS0_25QAttention_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_13
0023a546 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_32QuantizeWithOrder_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_14NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023a5fa ZN11onnxruntime7contrib11GetOpSchemaINS0_32QuantizeWithOrder_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_14
0023a660 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_34DequantizeWithOrder_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_15NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023a716 ZN11onnxruntime7contrib11GetOpSchemaINS0_34DequantizeWithOrder_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_15
0023a77e NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_29QOrderedMatMul_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_16NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023a82f ZN11onnxruntime7contrib11GetOpSchemaINS0_29QOrderedMatMul_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_16
0023a892 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_41QOrderedLayerNormalization_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_17NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023a94f ZN11onnxruntime7contrib11GetOpSchemaINS0_41QOrderedLayerNormalization_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_17
0023a9be NSt6__ndk110__function6__funcIZN11onnxruntime7contrib11GetOpSchemaINS3_35QLinearConvTranspose_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_18NS_9allocatorIS8_EEFvRNS6_16InferenceContextEEEE
0023aa75 ZN11onnxruntime7contrib11GetOpSchemaINS0_35QLinearConvTranspose_Microsoft_ver1EEEN4onnx8OpSchemaEvE4$_18
0023aaf4 NSt6__ndk110__function6__funcIZN11onnxruntime7contrib21RegisterRangeOpSchemaEON4onnx8OpSchemaEE3$_0NS_9allocatorIS7_EEFvRNS4_16InferenceContextEEEE
0023ab88 ZN11onnxruntime7contrib21RegisterRangeOpSchemaEON4onnx8OpSchemaEE3$_0
0023ac2a z,N11onnxruntime5GraphE
0023ac42 N4onnx28FunctionBodyBuildContextImplE
0023ac68 N4onnx24FunctionBodyBuildContextE
0023ac8b N11onnxruntime20InferenceContextImplE
0023acb1 N11onnxruntime19GraphInferencerImplE
0023acd6 N4onnx15GraphInferencerE
0023acef NSt6__ndk110__function6__funcIPFN11onnxruntime6common6StatusERKNS2_4NodeERNS2_5GraphERKNS_6vectorIPKN4onnx9TypeProtoENS_9allocatorISE_EEEERSH_RKNS8_14ResolveOptionsEENSF_ISP_EESO_EE
0023ada5 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERKNS2_4NodeERNS2_5GraphERKNS_6vectorIPKN4onnx9TypeProtoENS_9allocatorISE_EEEERSH_RKNS8_14ResolveOptionsEEEE
0023ae4d PFN11onnxruntime6common6StatusERKNS_4NodeERNS_5GraphERKNSt6__ndk16vectorIPKN4onnx9TypeProtoENS7_9allocatorISC_EEEERSF_RKNS5_14ResolveOptionsEE
0023aedc FN11onnxruntime6common6StatusERKNS_4NodeERNS_5GraphERKNSt6__ndk16vectorIPKN4onnx9TypeProtoENS7_9allocatorISC_EEEERSF_RKNS5_14ResolveOptionsEE
0023af6a NSt6__ndk110__function6__funcIZN11onnxruntime5Graph7ResolveERKNS3_14ResolveOptionsEE4$_11NS_9allocatorIS7_EEFNS2_6common6StatusERS3_EEE
0023aff2 NSt6__ndk110__function6__baseIFN11onnxruntime6common6StatusERNS2_5GraphEEEE
0023b03e ZN11onnxruntime5Graph7ResolveERKNS0_14ResolveOptionsEE4$_11
0023b07a NSt6__ndk110__function6__funcIZN11onnxruntime5Graph7ResolveERKNS3_14ResolveOptionsEE4$_12NS_9allocatorIS7_EEFNS2_6common6StatusERS3_EEE
0023b102 ZN11onnxruntime5Graph7ResolveERKNS0_14ResolveOptionsEE4$_12
0023b13e NSt6__ndk110__function6__funcIZN11onnxruntime5Graph7ResolveERKNS3_14ResolveOptionsEE4$_13NS_9allocatorIS7_EEFNS2_6common6StatusERS3_EEE
0023b1c6 ZN11onnxruntime5Graph7ResolveERKNS0_14ResolveOptionsEE4$_13
0023b202 NSt6__ndk110__function6__funcIZN11onnxruntime5Graph49PopulateNodeArgToProducerConsumerLookupsFromNodesEvE4$_23NS_9allocatorIS4_EEFvRKNS2_7NodeArgEbEEE
0023b299 ZN11onnxruntime5Graph49PopulateNodeArgToProducerConsumerLookupsFromNodesEvE4$_23
0023b2f4 NSt6__ndk110__function6__funcIZN11onnxruntime14function_utilsL22IOTypeConstraintHelperERKN4onnx13FunctionProtoERNS_10unique_ptrINS4_8OpSchemaENS_14default_deleteIS9_EEEERKNS2_14InlinedHashMapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEiNSI_INS_4pairIKSK_iEEEEEESR_E3$_1NSI_ISS_EEFvRKNS4_9NodeProtoEEEE
0023b431 NSt6__ndk110__function6__baseIFvRKN4onnx9NodeProtoEEEE
0023b468 ZN11onnxruntime14function_utilsL22IOTypeConstraintHelperERKN4onnx13FunctionProtoERNSt6__ndk110unique_ptrINS1_8OpSchemaENS5_14default_deleteIS7_EEEERKNS_14InlinedHashMapINS5_12basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEEiNSG_INS5_4pairIKSI_iEEEEEESP_E3$_1
0023b572 NSt6__ndk110__function6__funcIZN11onnxruntime14function_utils12CreateSchemaERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESB_RKNS2_14InlinedHashMapIS9_PKN4onnx13FunctionProtoENS7_INS_4pairISA_SG_EEEEEERKNS_13unordered_mapIS9_iNS_4hashIS9_EENS_8equal_toIS9_EENS7_INSH_ISA_iEEEEEERKNS2_21SchemaRegistryManagerERKNS2_7logging6LoggerEbE3$_0NS7_IS14_EEFvRNSD_16InferenceContextEEEE
0023b6f9 N4onnx15shape_inference15SymbolTableImplE
0023b723 N4onnx11SymbolTableE
0023b738 ZN11onnxruntime14function_utils12CreateSchemaERKNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEES9_RKNS_14InlinedHashMapIS7_PKN4onnx13FunctionProtoENS5_INS1_4pairIS8_SE_EEEEEERKNS1_13unordered_mapIS7_iNS1_4hashIS7_EENS1_8equal_toIS7_EENS5_INSF_IS8_iEEEEEERKNS_21SchemaRegistryManagerERKNS_7logging6LoggerEbE3$_0
0023b883 N11onnxruntime12FunctionImplE
0023b8a1 N11onnxruntime8FunctionE
0023b8de NSt6__ndk110__function6__funcIZN11onnxruntime11GraphViewerC1ERKNS2_5GraphEPKNS2_15IndexedSubGraphEE3$_0NS_9allocatorISA_EEFbmEEE
0023b95f NSt6__ndk110__function6__baseIFbmEEE
0023b984 ZN11onnxruntime11GraphViewerC1ERKNS_5GraphEPKNS_15IndexedSubGraphEE3$_0
0023b9cc NSt6__ndk110__function6__funcIZN11onnxruntime11GraphViewerC1ERKNS2_5GraphEPKNS2_15IndexedSubGraphEE3$_1NS_9allocatorISA_EEFvPKNS2_4NodeEEEE
0023ba58 NSt6__ndk110__function6__baseIFvPKN11onnxruntime4NodeEEEE
0023ba92 ZN11onnxruntime11GraphViewerC1ERKNS_5GraphEPKNS_15IndexedSubGraphEE3$_1
0023bada NSt6__ndk110__function6__funcIN11onnxruntime11NodeCompareENS_9allocatorIS3_EEFbPKNS2_4NodeES8_EEE
0023bb3c NSt6__ndk110__function6__baseIFbPKN11onnxruntime4NodeES5_EEE
0023bb79 N11onnxruntime11NodeCompareE
0023bb96 NSt6__ndk110__function6__funcIZN11onnxruntime11GraphViewerC1ERKNS2_5GraphEPKNS2_15IndexedSubGraphEE3$_2NS_9allocatorISA_EEFvPKNS2_4NodeEEEE
0023bc22 ZN11onnxruntime11GraphViewerC1ERKNS_5GraphEPKNS_15IndexedSubGraphEE3$_2
0023bc6a NSt6__ndk110__function6__funcIN11onnxruntime19PriorityNodeCompareENS_9allocatorIS3_EEFbPKNS2_4NodeES8_EEE
0023bcd4 N11onnxruntime19PriorityNodeCompareE
0023bcfa NSt6__ndk120__shared_ptr_emplaceIN11onnxruntime21SchemaRegistryManagerENS_9allocatorIS2_EEEE
0023bd57 NSt6__ndk120__shared_ptr_emplaceIN11onnxruntime5ModelENS_9allocatorIS2_EEEE
0023bdaf NSt6__ndk110__function6__funcIZN11onnxruntimeL40SaveRuntimeOptimizationRecordToOrtFormatERN11flatbuffers17FlatBufferBuilderERKNS2_25RuntimeOptimizationRecordERNS3_6OffsetINS2_3fbs25RuntimeOptimizationRecordEEEE3$_1NS_9allocatorISE_EEFjmEEE
0023be9f NSt6__ndk110__function6__baseIFjmEEE
0023bec5 ZN11onnxruntimeL40SaveRuntimeOptimizationRecordToOrtFormatERN11flatbuffers17FlatBufferBuilderERKNS_25RuntimeOptimizationRecordERNS0_6OffsetINS_3fbs25RuntimeOptimizationRecordEEEE3$_1
0023bf7c N11onnxruntime27OnnxRuntimeOpSchemaRegistryE
0023bfa9 N11onnxruntime30IOnnxRuntimeOpSchemaCollectionE
0023bfd9 N4onnx15ISchemaRegistryE
0023bff2 N11onnxruntime21SchemaRegistryManagerE
0023c01a NSt6__ndk110__function6__funcIZ13MlasGemmBatch15CBLAS_TRANSPOSES2_mmmPK22MLAS_SGEMM_DATA_PARAMSmPN11onnxruntime11concurrency10ThreadPoolEE3$_0NS_9allocatorISA_EEFvlEEE
0023c0c2 Z13MlasGemmBatch15CBLAS_TRANSPOSES_mmmPK22MLAS_SGEMM_DATA_PARAMSmPN11onnxruntime11concurrency10ThreadPoolEE3$_0
0023c132 NSt6__ndk110__function6__funcIZ19MlasExecuteThreadedPFvPvlES2_lPN11onnxruntime11concurrency10ThreadPoolEE3$_0NS_9allocatorIS9_EEFvlEEE
0023c1b9 Z19MlasExecuteThreadedPFvPvlES_lPN11onnxruntime11concurrency10ThreadPoolEE3$_0
0023c208 NSt6__ndk110__function6__funcIZ13MlasGemmBatchRK28MLAS_GEMM_QUANT_SHAPE_PARAMSPK27MLAS_GEMM_QUANT_DATA_PARAMSmPN11onnxruntime11concurrency10ThreadPoolEE3$_0NS_9allocatorISC_EEFvlEEE
0023c2be Z13MlasGemmBatchRK28MLAS_GEMM_QUANT_SHAPE_PARAMSPK27MLAS_GEMM_QUANT_DATA_PARAMSmPN11onnxruntime11concurrency10ThreadPoolEE3$_0
0023c33d NSt6__ndk110__function6__funcIZ18MlasSymmQgemmBatchRK28MLAS_GEMM_QUANT_SHAPE_PARAMSPK27MLAS_SYMM_QGEMM_DATA_PARAMSmPN11onnxruntime11concurrency10ThreadPoolEE3$_1NS_9allocatorISC_EEFvlEEE
0023c3f8 Z18MlasSymmQgemmBatchRK28MLAS_GEMM_QUANT_SHAPE_PARAMSPK27MLAS_SYMM_QGEMM_DATA_PARAMSmPN11onnxruntime11concurrency10ThreadPoolEE3$_1
0023c47c NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZ8MlasPool17MLAS_POOLING_KINDmPKlS8_S8_S8_S8_PKfPfPS4_E3$_0EEvSC_lOT_lEUllE_NS_9allocatorISG_EEFvlEEE
0023c53e ZN11onnxruntime11concurrency10ThreadPool19TryBatchParallelForIZ8MlasPool17MLAS_POOLING_KINDmPKlS5_S5_S5_S5_PKfPfPS1_E3$_0EEvS9_lOT_lEUllE_
0023c5d0 38MLAS_QGEMM_SCALE_BIAS_OUTPUT_PROCESSOR
0023c638 N11onnxruntime11concurrency15ThreadPoolTemplINS_3EnvEEE
0023c670 N11onnxruntime11concurrency27ExtendedThreadPoolInterfaceE
0023c6aa N5Eigen19ThreadPoolInterfaceE
0023c6c8 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency15ThreadPoolTemplINS2_3EnvEE10WorkerLoopEiEUlvE_NS_9allocatorIS7_EEFbvEEE
0023c74c NSt6__ndk110__function6__baseIFbvEEE
0023c771 ZN11onnxruntime11concurrency15ThreadPoolTemplINS_3EnvEE10WorkerLoopEiEUlvE_
0023c7bd NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency15ThreadPoolTemplINS2_3EnvEE10WorkerLoopEiEUlvE0_NS_9allocatorIS7_EEFvvEEE
0023c842 ZN11onnxruntime11concurrency15ThreadPoolTemplINS_3EnvEE10WorkerLoopEiEUlvE0_
0023c88f NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency15ThreadPoolTemplINS2_3EnvEE20RunInParallelSectionERNS3_25ThreadPoolParallelSectionENS_8functionIFvjEEEjlEUljE_NS_9allocatorISC_EESA_EE
0023c951 NSt6__ndk110__function6__baseIFvjEEE
0023c976 ZN11onnxruntime11concurrency15ThreadPoolTemplINS_3EnvEE20RunInParallelSectionERNS0_25ThreadPoolParallelSectionENSt6__ndk18functionIFvjEEEjlEUljE_
0023ca08 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency15ThreadPoolTemplINS2_3EnvEE21RunInParallelInternalERNS6_9PerThreadERNS3_25ThreadPoolParallelSectionEjbNS_8functionIFvjEEEEUlvE_NS_9allocatorISE_EEFvvEEE
0023cadc ZN11onnxruntime11concurrency15ThreadPoolTemplINS_3EnvEE21RunInParallelInternalERNS3_9PerThreadERNS0_25ThreadPoolParallelSectionEjbNSt6__ndk18functionIFvjEEEEUlvE_
0023cb7f NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency15ThreadPoolTemplINS2_3EnvEE26ScheduleOnPreferredWorkersERNS6_9PerThreadERNS3_25ThreadPoolParallelSectionERN4absl12lts_2022062313InlinedVectorIiLm11ENS_9allocatorIiEEEEjjNS_8functionIFvjEEEEUlvE_NSE_ISL_EEFvvEEE
0023cc8d ZN11onnxruntime11concurrency15ThreadPoolTemplINS_3EnvEE26ScheduleOnPreferredWorkersERNS3_9PerThreadERNS0_25ThreadPoolParallelSectionERN4absl12lts_2022062313InlinedVectorIiLm11ENSt6__ndk19allocatorIiEEEEjjNSB_8functionIFvjEEEEUlvE_
0023cd74 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool35ParallelForFixedBlockSizeSchedulingEllRKNS_8functionIFvllEEEE3$_0NS_9allocatorISA_EEFvjEEE
0023ce17 ZN11onnxruntime11concurrency10ThreadPool35ParallelForFixedBlockSizeSchedulingEllRKNSt6__ndk18functionIFvllEEEE3$_0
0023ce8a NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool35ParallelForFixedBlockSizeSchedulingEllRKNS_8functionIFvllEEEE3$_1NS_9allocatorISA_EEFvjEEE
0023cf2d ZN11onnxruntime11concurrency10ThreadPool35ParallelForFixedBlockSizeSchedulingEllRKNSt6__ndk18functionIFvllEEEE3$_1
0023cfa0 NSt6__ndk110__function6__funcIZN11onnxruntime11concurrency10ThreadPool17SimpleParallelForElRKNS_8functionIFvlEEEE3$_2NS_9allocatorISA_EEFvllEEE
0023d030 ZN11onnxruntime11concurrency10ThreadPool17SimpleParallelForElRKNSt6__ndk18functionIFvlEEEE3$_2
0023d178 N11onnxruntime7logging14AndroidLogSinkE
0023d1b4 N11onnxruntime12_GLOBAL__N_18PosixEnvE
0023d1db N11onnxruntime3EnvE
0023d1ef N11onnxruntime12_GLOBAL__N_111PosixThreadE
0023d21a N11onnxruntime9EnvThreadE
0023d234 N11onnxruntime12_GLOBAL__N_112PosixEnvTimeE
0023d260 N11onnxruntime7EnvTimeE
0023d278 N11onnxruntime9TelemetryE
0023d295  )2<GQ
0023d37d 	&	5	D	Y	n	
0023d38d 	Invalid
0023d396 Abs (NC, F16)
0023d3a4 Abs (NC, F32)
0023d3b2 Add (ND, F16)
0023d3c0 Add (ND, F32)
0023d3ce Add (ND, QS8)
0023d3dc Add (ND, QU8)
0023d3ea ArgMax Pooling (NHWC, F32)
0023d405 Average Pooling (NHWC, F16)
0023d421 Average Pooling (NHWC, F32)
0023d43d Average Pooling (NHWC, QU8)
0023d459 Bankers Rounding (NC, F16)
0023d474 Bankers Rounding (NC, F32)
0023d48f Ceiling (NC, F16)
0023d4a1 Ceiling (NC, F32)
0023d4b3 Channel Shuffle (NC, X8)
0023d4cc Channel Shuffle (NC, X32)
0023d4e6 Clamp (NC, F16)
0023d4f6 Clamp (NC, F32)
0023d506 Clamp (NC, S8)
0023d515 Clamp (NC, U8)
0023d524 Constant Pad (ND, X8)
0023d53a Constant Pad (ND, X16)
0023d551 Constant Pad (ND, X32)
0023d568 Convert (NC, F16, F32)
0023d57f Convert (NC, F32, F16)
0023d596 Convert (NC, F32, QS8)
0023d5ad Convert (NC, F32, QU8)
0023d5c4 Convert (NC, QS8)
0023d5d6 Convert (NC, QS8, F32)
0023d5ed Convert (NC, QU8)
0023d5ff Convert (NC, QU8, F32)
0023d616 Convolution (NHWC, F16)
0023d62e Convolution (NHWC, F32)
0023d646 Convolution (NHWC, QC8)
0023d65e Convolution (NHWC, QS8)
0023d676 Convolution (NHWC, QU8)
0023d68e Convolution (NCHW, F32)
0023d6a6 Copy (NC, X8)
0023d6b4 Copy (NC, X16)
0023d6c3 Copy (NC, X32)
0023d6d2 Deconvolution (NHWC, F16)
0023d6ec Deconvolution (NHWC, F32)
0023d706 Deconvolution (NHWC, QS8)
0023d720 Deconvolution (NHWC, QU8)
0023d73a Depth To Space (NCHW2NHWC, X32)
0023d75a Depth To Space (NHWC, X8)
0023d774 Depth To Space (NHWC, X16)
0023d78f Depth To Space (NHWC, X32)
0023d7aa Divide (ND, F16)
0023d7bb Divide (ND, F32)
0023d7cc ELU (NC, F16)
0023d7da ELU (NC, F32)
0023d7e8 ELU (NC, QS8)
0023d7f6 Floor (NC, F16)
0023d806 Floor (NC, F32)
0023d816 Fully Connected (NC, F16)
0023d830 Fully Connected (NC, F32)
0023d84a Fully Connected (NC, QS8)
0023d864 Fully Connected (NC, QU8)
0023d87e Global Average Pooling (NWC, F16)
0023d8a0 Global Average Pooling (NWC, F32)
0023d8c2 Global Average Pooling (NWC, QS8)
0023d8e4 Global Average Pooling (NWC, QU8)
0023d906 Global Average Pooling (NCW, F32)
0023d928 HardSwish (NC, F16)
0023d93c HardSwish (NC, F32)
0023d950 Leaky ReLU (NC, F16)
0023d965 Leaky ReLU (NC, F32)
0023d97a Leaky ReLU (NC, QS8)
0023d98f Leaky ReLU (NC, QU8)
0023d9a4 Max Pooling (NHWC, F16)
0023d9bc Max Pooling (NHWC, F32)
0023d9d4 Max Pooling (NHWC, S8)
0023d9eb Max Pooling (NHWC, U8)
0023da02 Maximum (ND, F16)
0023da14 Maximum (ND, F32)
0023da26 Minimum (ND, F16)
0023da38 Minimum (ND, F32)
0023da4a Multiply (ND, F16)
0023da5d Multiply (ND, F32)
0023da70 Multiply (ND, QS8)
0023da83 Multiply (ND, QU8)
0023da96 Negate (NC, F16)
0023daa7 Negate (NC, F32)
0023dab8 PReLU (NC, F16)
0023dac8 PReLU (NC, F32)
0023dad8 Resize Bilinear (NHWC, F16)
0023daf4 Resize Bilinear (NHWC, F32)
0023db10 Resize Bilinear (NHWC, S8)
0023db2b Resize Bilinear (NHWC, U8)
0023db46 Resize Bilinear (NCHW, F32)
0023db62 Sigmoid (NC, F16)
0023db74 Sigmoid (NC, F32)
0023db86 Sigmoid (NC, QS8)
0023db98 Sigmoid (NC, QU8)
0023dbaa Softmax (NC, F16)
0023dbbc Softmax (NC, F32)
0023dbce Softmax (NC, QU8)
0023dbe0 Square (NC, F16)
0023dbf1 Square (NC, F32)
0023dc02 Square Root (NC, F16)
0023dc18 Square Root (NC, F32)
0023dc2e Squared Difference (NC, F16)
0023dc4b Squared Difference (NC, F32)
0023dc68 Subtract (ND, F16)
0023dc7b Subtract (ND, F32)
0023dc8e Subtract (ND, QS8)
0023dca1 Subtract (ND, QU8)
0023dcb4 Tanh (NC, QS8)
0023dcc3 Tanh (NC, QU8)
0023dcd2 Truncation (NC, F16)
0023dce7 Truncation (NC, F32)
0023dcfc Transpose (ND, X8)
0023dd0f Transpose (ND, X16)
0023dd23 Transpose (ND, X32)
0023dd37 Unpooling (NHWC, X32)
0023de7d 7x?2
0023de86 u??Xu?
0023de92 u?*gu?
0023dea6 z?}%}?
0023deb6 ~?):~?
0023dede y?+Zy?
0023deed 7x?F
0023def9 >w?2
0023df02 v?Cpv?
0023df16 u?:zu??Xu?y;u?
0023df42 u?M,u?
0023df49 Fu?*gu?u
0023df5d $v?4cv?
0023df86 y?j9z?
0023df8e z?0O{?
0023df9a |?}%}?
0023dfc8 uNN'u
0023dfce N4onnx7checker15ValidationErrorE
0023e055 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19Constant_Onnx_ver13EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023e0e9 ZN4onnx11GetOpSchemaINS_19Constant_Onnx_ver13EEENS_8OpSchemaEvE3$_0
0023e12d NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_25ConstantOfShape_Onnx_ver9EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023e1c7 ZN4onnx11GetOpSchemaINS_25ConstantOfShape_Onnx_ver9EEENS_8OpSchemaEvE3$_1
0023e211 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17EyeLike_Onnx_ver9EEENS2_8OpSchemaEvE3$_2NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023e2a3 ZN4onnx11GetOpSchemaINS_17EyeLike_Onnx_ver9EEENS_8OpSchemaEvE3$_2
0023e2e5 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_23RandomUniform_Onnx_ver1EEENS2_8OpSchemaEvE3$_3NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023e37d ZN4onnx11GetOpSchemaINS_23RandomUniform_Onnx_ver1EEENS_8OpSchemaEvE3$_3
0023e3c5 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_22RandomNormal_Onnx_ver1EEENS2_8OpSchemaEvE3$_4NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023e45c ZN4onnx11GetOpSchemaINS_22RandomNormal_Onnx_ver1EEENS_8OpSchemaEvE3$_4
0023e4a3 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_27RandomUniformLike_Onnx_ver1EEENS2_8OpSchemaEvE3$_5NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023e53f ZN4onnx11GetOpSchemaINS_27RandomUniformLike_Onnx_ver1EEENS_8OpSchemaEvE3$_5
0023e58b NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_26RandomNormalLike_Onnx_ver1EEENS2_8OpSchemaEvE3$_6NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023e626 ZN4onnx11GetOpSchemaINS_26RandomNormalLike_Onnx_ver1EEENS_8OpSchemaEvE3$_6
0023e671 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_21Multinomial_Onnx_ver7EEENS2_8OpSchemaEvE3$_7NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023e707 ZN4onnx11GetOpSchemaINS_21Multinomial_Onnx_ver7EEENS_8OpSchemaEvE3$_7
0023e74d NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Range_Onnx_ver11EEENS2_8OpSchemaEvE3$_8NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023e7de ZN4onnx11GetOpSchemaINS_16Range_Onnx_ver11EEENS_8OpSchemaEvE3$_8
0023e81f NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_20Bernoulli_Onnx_ver15EEENS2_8OpSchemaEvE3$_9NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023e8b4 ZN4onnx11GetOpSchemaINS_20Bernoulli_Onnx_ver15EEENS_8OpSchemaEvE3$_9
0023e8f9 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_20Bernoulli_Onnx_ver15EEENS2_8OpSchemaEvE4$_10NS_9allocatorIS6_EEFbRKNS2_24FunctionBodyBuildContextERKS5_RNS2_13FunctionProtoEEEE
0023e9b2 ZN4onnx11GetOpSchemaINS_20Bernoulli_Onnx_ver15EEENS_8OpSchemaEvE4$_10
0023e9f8 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19Constant_Onnx_ver12EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023ea8c ZN4onnx11GetOpSchemaINS_19Constant_Onnx_ver12EEENS_8OpSchemaEvE3$_0
0023ead0 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Constant_Onnx_ver1EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023eb63 ZN4onnx11GetOpSchemaINS_18Constant_Onnx_ver1EEENS_8OpSchemaEvE3$_1
0023eba6 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Constant_Onnx_ver9EEENS2_8OpSchemaEvE3$_2NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023ec39 ZN4onnx11GetOpSchemaINS_18Constant_Onnx_ver9EEENS_8OpSchemaEvE3$_2
0023ec7c NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19Constant_Onnx_ver11EEENS2_8OpSchemaEvE3$_3NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023ed10 ZN4onnx11GetOpSchemaINS_19Constant_Onnx_ver11EEENS_8OpSchemaEvE3$_3
0023ed93 NSt6__ndk110__function6__funcIZN4onnx23BinaryLogicDocGeneratorEPKcE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0023ee02 NSt6__ndk110__function6__funcIZZN4onnx23BinaryLogicDocGeneratorEPKcENK3$_0clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
0023ee97 ZZN4onnx23BinaryLogicDocGeneratorEPKcENK3$_0clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
0023eef1 ZN4onnx23BinaryLogicDocGeneratorEPKcE3$_0
0023ef1b NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19BitShift_Onnx_ver11EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023efaf ZN4onnx11GetOpSchemaINS_19BitShift_Onnx_ver11EEENS_8OpSchemaEvE3$_1
0023eff3 NSt6__ndk110__function6__funcIZN4onnx25BinaryBitwiseDocGeneratorEPKcE3$_2NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0023f064 NSt6__ndk110__function6__funcIZZN4onnx25BinaryBitwiseDocGeneratorEPKcENK3$_2clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
0023f0fb ZZN4onnx25BinaryBitwiseDocGeneratorEPKcENK3$_2clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
0023f157 ZN4onnx25BinaryBitwiseDocGeneratorEPKcE3$_2
0023f1b0 NSt6__ndk110__function6__funcIZN4onnx31BinaryLogicDocGenerator_opset12EPKcE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0023f227 NSt6__ndk110__function6__funcIZZN4onnx31BinaryLogicDocGenerator_opset12EPKcENK3$_0clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
0023f2c4 ZZN4onnx31BinaryLogicDocGenerator_opset12EPKcENK3$_0clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
0023f326 ZN4onnx31BinaryLogicDocGenerator_opset12EPKcE3$_0
0023f358 NSt6__ndk110__function6__funcIZN4onnx30BinaryLogicDocGenerator_opset1EPKcE3$_1NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0023f3ce ZN4onnx30BinaryLogicDocGenerator_opset1EPKcE3$_1
0023f3ff NSt6__ndk110__function6__funcIZN4onnx30BinaryLogicDocGenerator_opset7EPKcE3$_2NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0023f475 NSt6__ndk110__function6__funcIZZN4onnx30BinaryLogicDocGenerator_opset7EPKcENK3$_2clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
0023f511 ZZN4onnx30BinaryLogicDocGenerator_opset7EPKcENK3$_2clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
0023f572 ZN4onnx30BinaryLogicDocGenerator_opset7EPKcE3$_2
0023f67e ++++
0023f6d0 NSt6__ndk110__function6__funcIZN4onnx16MathDocGeneratorEPKcE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0023f738 NSt6__ndk110__function6__funcIZZN4onnx16MathDocGeneratorEPKcENK3$_0clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
0023f7c6 ZZN4onnx16MathDocGeneratorEPKcENK3$_0clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
0023f819 ZN4onnx16MathDocGeneratorEPKcE3$_0
0023f83c NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Add_Onnx_ver14EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
0023f8d1 NSt6__ndk110__function6__baseIFvRN4onnx22DataPropagationContextEEEE
0023f915 ZN4onnx11GetOpSchemaINS_14Add_Onnx_ver14EEENS_8OpSchemaEvE3$_1
0023f954 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Sub_Onnx_ver14EEENS2_8OpSchemaEvE3$_2NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
0023f9e9 ZN4onnx11GetOpSchemaINS_14Sub_Onnx_ver14EEENS_8OpSchemaEvE3$_2
0023fa28 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Mod_Onnx_ver13EEENS2_8OpSchemaEvE3$_3NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023fab7 ZN4onnx11GetOpSchemaINS_14Mod_Onnx_ver13EEENS_8OpSchemaEvE3$_3
0023faf6 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Mul_Onnx_ver14EEENS2_8OpSchemaEvE3$_4NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
0023fb8b ZN4onnx11GetOpSchemaINS_14Mul_Onnx_ver14EEENS_8OpSchemaEvE3$_4
0023fbca NSt6__ndk110__function6__funcIPFbRKN4onnx24FunctionBodyBuildContextERKNS2_8OpSchemaERNS2_13FunctionProtoEENS_9allocatorISC_EESB_EE
0023fc4d PFbRKN4onnx24FunctionBodyBuildContextERKNS_8OpSchemaERNS_13FunctionProtoEE
0023fc98 FbRKN4onnx24FunctionBodyBuildContextERKNS_8OpSchemaERNS_13FunctionProtoEE
0023fce2 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Pow_Onnx_ver15EEENS2_8OpSchemaEvE3$_5NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0023fd71 ZN4onnx11GetOpSchemaINS_14Pow_Onnx_ver15EEENS_8OpSchemaEvE3$_5
0023fdb0 NSt6__ndk110__function6__funcIZN4onnx30ElementwiseMultiOpDocGeneratorEPKcE3$_6NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0023fe26 NSt6__ndk110__function6__funcIZZN4onnx30ElementwiseMultiOpDocGeneratorEPKcENK3$_6clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
0023fec2 ZZN4onnx30ElementwiseMultiOpDocGeneratorEPKcENK3$_6clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
0023ff23 ZN4onnx30ElementwiseMultiOpDocGeneratorEPKcE3$_6
0023ff54 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Softmax_Onnx_ver13EEENS2_8OpSchemaEvE3$_7NS_9allocatorIS6_EEFbRKNS2_24FunctionBodyBuildContextERKS5_RNS2_13FunctionProtoEEEE
0024000a ZN4onnx11GetOpSchemaINS_18Softmax_Onnx_ver13EEENS_8OpSchemaEvE3$_7
0024004d NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Softmax_Onnx_ver13EEENS2_8OpSchemaEvE3$_8NS_9allocatorIS6_EEFbRKNS2_24FunctionBodyBuildContextERKS5_RNS2_13FunctionProtoEEEE
00240103 ZN4onnx11GetOpSchemaINS_18Softmax_Onnx_ver13EEENS_8OpSchemaEvE3$_8
00240146 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_21LogSoftmax_Onnx_ver13EEENS2_8OpSchemaEvE3$_9NS_9allocatorIS6_EEFbRKNS2_24FunctionBodyBuildContextERKS5_RNS2_13FunctionProtoEEEE
002401ff ZN4onnx11GetOpSchemaINS_21LogSoftmax_Onnx_ver13EEENS_8OpSchemaEvE3$_9
00240245 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_21LogSoftmax_Onnx_ver13EEENS2_8OpSchemaEvE4$_10NS_9allocatorIS6_EEFbRKNS2_24FunctionBodyBuildContextERKS5_RNS2_13FunctionProtoEEEE
002402ff ZN4onnx11GetOpSchemaINS_21LogSoftmax_Onnx_ver13EEENS_8OpSchemaEvE4$_10
00240346 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15Gemm_Onnx_ver13EEENS2_8OpSchemaEvE4$_11NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002403d7 ZN4onnx11GetOpSchemaINS_15Gemm_Onnx_ver13EEENS_8OpSchemaEvE4$_11
00240418 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17MatMul_Onnx_ver13EEENS2_8OpSchemaEvE4$_12NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002404ab ZN4onnx11GetOpSchemaINS_17MatMul_Onnx_ver13EEENS_8OpSchemaEvE4$_12
002404ee NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15TopK_Onnx_ver11EEENS2_8OpSchemaEvE4$_13NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024057f ZN4onnx11GetOpSchemaINS_15TopK_Onnx_ver11EEENS_8OpSchemaEvE4$_13
002405c0 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Expand_Onnx_ver13EEENS2_8OpSchemaEvE4$_14NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00240653 ZN4onnx11GetOpSchemaINS_17Expand_Onnx_ver13EEENS_8OpSchemaEvE4$_14
00240696 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_24QLinearMatMul_Onnx_ver10EEENS2_8OpSchemaEvE4$_15NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00240730 ZN4onnx11GetOpSchemaINS_24QLinearMatMul_Onnx_ver10EEENS_8OpSchemaEvE4$_15
0024077a NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_24MatMulInteger_Onnx_ver10EEENS2_8OpSchemaEvE4$_16NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00240814 ZN4onnx11GetOpSchemaINS_24MatMulInteger_Onnx_ver10EEENS_8OpSchemaEvE4$_16
0024085e NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Det_Onnx_ver11EEENS2_8OpSchemaEvE4$_17NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002408ee ZN4onnx11GetOpSchemaINS_14Det_Onnx_ver11EEENS_8OpSchemaEvE4$_17
0024092e NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_36NegativeLogLikelihoodLoss_Onnx_ver13EEENS2_8OpSchemaEvE4$_18NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002409d4 ZN4onnx11GetOpSchemaINS_36NegativeLogLikelihoodLoss_Onnx_ver13EEENS_8OpSchemaEvE4$_18
00240a2a NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Einsum_Onnx_ver12EEENS2_8OpSchemaEvE4$_19NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00240abd ZN4onnx11GetOpSchemaINS_17Einsum_Onnx_ver12EEENS_8OpSchemaEvE4$_19
00240b00 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_34SoftmaxCrossEntropyLoss_Onnx_ver13EEENS2_8OpSchemaEvE4$_20NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00240ba4 ZN4onnx11GetOpSchemaINS_34SoftmaxCrossEntropyLoss_Onnx_ver13EEENS_8OpSchemaEvE4$_20
00240bf8 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14DFT_Onnx_ver17EEENS2_8OpSchemaEvE4$_21NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00240c88 ZN4onnx11GetOpSchemaINS_14DFT_Onnx_ver17EEENS_8OpSchemaEvE4$_21
00240cc8 NSt6__ndk110__function6__funcIZN4onnx29CosineSumWindowOpDocGeneratorEPKcE4$_22NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00240d3e NSt6__ndk110__function6__funcIZZN4onnx29CosineSumWindowOpDocGeneratorEPKcENK4$_22clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00240dda ZZN4onnx29CosineSumWindowOpDocGeneratorEPKcENK4$_22clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00240e3b ZN4onnx29CosineSumWindowOpDocGeneratorEPKcE4$_22
00240e6c NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_26MelWeightMatrix_Onnx_ver17EEENS2_8OpSchemaEvE4$_23NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00240f08 ZN4onnx11GetOpSchemaINS_26MelWeightMatrix_Onnx_ver17EEENS_8OpSchemaEvE4$_23
00240f54 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15STFT_Onnx_ver17EEENS2_8OpSchemaEvE4$_24NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00240fe5 ZN4onnx11GetOpSchemaINS_15STFT_Onnx_ver17EEENS_8OpSchemaEvE4$_24
002411c0 NSt6__ndk110__function6__funcIZN4onnx24MathDocGenerator_opset13EPKcE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00241230 NSt6__ndk110__function6__funcIZZN4onnx24MathDocGenerator_opset13EPKcENK3$_0clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
002412c6 ZZN4onnx24MathDocGenerator_opset13EPKcENK3$_0clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00241321 ZN4onnx24MathDocGenerator_opset13EPKcE3$_0
0024134c NSt6__ndk110__function6__funcIZN4onnx24MathDocGenerator_opset_7EPKcE3$_1NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
002413bc NSt6__ndk110__function6__funcIZZN4onnx24MathDocGenerator_opset_7EPKcENK3$_1clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00241452 ZZN4onnx24MathDocGenerator_opset_7EPKcENK3$_1clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
002414ad ZN4onnx24MathDocGenerator_opset_7EPKcE3$_1
002414d8 NSt6__ndk110__function6__funcIZN4onnx34SoftmaxFamilyDocGenerator_opset_11EPKcS4_E3$_2NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00241555 NSt6__ndk110__function6__funcIZZN4onnx34SoftmaxFamilyDocGenerator_opset_11EPKcS4_ENK3$_2clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
002415f8 ZZN4onnx34SoftmaxFamilyDocGenerator_opset_11EPKcS1_ENK3$_2clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00241660 ZN4onnx34SoftmaxFamilyDocGenerator_opset_11EPKcS1_E3$_2
00241698 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Mod_Onnx_ver10EEENS2_8OpSchemaEvE3$_3NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00241727 ZN4onnx11GetOpSchemaINS_14Mod_Onnx_ver10EEENS_8OpSchemaEvE3$_3
00241766 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Pow_Onnx_ver13EEENS2_8OpSchemaEvE3$_4NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002417f5 ZN4onnx11GetOpSchemaINS_14Pow_Onnx_ver13EEENS_8OpSchemaEvE3$_4
00241834 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Pow_Onnx_ver12EEENS2_8OpSchemaEvE3$_5NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002418c3 ZN4onnx11GetOpSchemaINS_14Pow_Onnx_ver12EEENS_8OpSchemaEvE3$_5
00241902 NSt6__ndk110__function6__funcIZN4onnx37ElementwiseMultiOpDocGenerator_opset8EPKcE3$_6NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0024197f NSt6__ndk110__function6__funcIZZN4onnx37ElementwiseMultiOpDocGenerator_opset8EPKcENK3$_6clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00241a22 ZZN4onnx37ElementwiseMultiOpDocGenerator_opset8EPKcENK3$_6clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00241a8a ZN4onnx37ElementwiseMultiOpDocGenerator_opset8EPKcE3$_6
00241ac2 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15Gemm_Onnx_ver11EEENS2_8OpSchemaEvE3$_7NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00241b52 ZN4onnx11GetOpSchemaINS_15Gemm_Onnx_ver11EEENS_8OpSchemaEvE3$_7
00241b92 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16MatMul_Onnx_ver9EEENS2_8OpSchemaEvE3$_8NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00241c23 ZN4onnx11GetOpSchemaINS_16MatMul_Onnx_ver9EEENS_8OpSchemaEvE3$_8
00241c64 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Expand_Onnx_ver8EEENS2_8OpSchemaEvE3$_9NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00241cf5 ZN4onnx11GetOpSchemaINS_16Expand_Onnx_ver8EEENS_8OpSchemaEvE3$_9
00241d36 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_36NegativeLogLikelihoodLoss_Onnx_ver12EEENS2_8OpSchemaEvE4$_10NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00241ddc ZN4onnx11GetOpSchemaINS_36NegativeLogLikelihoodLoss_Onnx_ver12EEENS_8OpSchemaEvE4$_10
00241e32 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_34SoftmaxCrossEntropyLoss_Onnx_ver12EEENS2_8OpSchemaEvE4$_11NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00241ed6 ZN4onnx11GetOpSchemaINS_34SoftmaxCrossEntropyLoss_Onnx_ver12EEENS_8OpSchemaEvE4$_11
00241f2a NSt6__ndk110__function6__funcIZN4onnx32SoftmaxFamilyDocGenerator_opset1EPKcS4_E4$_12NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00241fa6 ZN4onnx32SoftmaxFamilyDocGenerator_opset1EPKcS1_E4$_12
00241fdd NSt6__ndk110__function6__funcIZN4onnx20MathDocGenerator_oldEPKcE4$_13NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0024204a ZN4onnx20MathDocGenerator_oldEPKcE4$_13
00242072 NSt6__ndk110__function6__funcIZN4onnx27MathDocGenerator_old_opset6EPKcE4$_14NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
002420e6 ZN4onnx27MathDocGenerator_old_opset6EPKcE4$_14
00242115 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_13Pow_Onnx_ver7EEENS2_8OpSchemaEvE4$_15NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002421a4 ZN4onnx11GetOpSchemaINS_13Pow_Onnx_ver7EEENS_8OpSchemaEvE4$_15
002421e3 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Gemm_Onnx_ver6EEENS2_8OpSchemaEvE4$_16NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00242273 ZN4onnx11GetOpSchemaINS_14Gemm_Onnx_ver6EEENS_8OpSchemaEvE4$_16
002422b3 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Gemm_Onnx_ver7EEENS2_8OpSchemaEvE4$_17NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00242343 ZN4onnx11GetOpSchemaINS_14Gemm_Onnx_ver7EEENS_8OpSchemaEvE4$_17
00242383 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Gemm_Onnx_ver9EEENS2_8OpSchemaEvE4$_18NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00242413 ZN4onnx11GetOpSchemaINS_14Gemm_Onnx_ver9EEENS_8OpSchemaEvE4$_18
00242453 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16MatMul_Onnx_ver1EEENS2_8OpSchemaEvE4$_19NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002424e5 ZN4onnx11GetOpSchemaINS_16MatMul_Onnx_ver1EEENS_8OpSchemaEvE4$_19
00242527 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14TopK_Onnx_ver1EEENS2_8OpSchemaEvE4$_20NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002425b7 ZN4onnx11GetOpSchemaINS_14TopK_Onnx_ver1EEENS_8OpSchemaEvE4$_20
002425f7 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15TopK_Onnx_ver10EEENS2_8OpSchemaEvE4$_21NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00242688 ZN4onnx11GetOpSchemaINS_15TopK_Onnx_ver10EEENS_8OpSchemaEvE4$_21
002426c9 NSt6__ndk110__function6__funcIZN4onnx34ElementwiseMultiOpDocGenerator_oldEPKcE4$_22NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00242744 NSt6__ndk110__function6__funcIZZN4onnx34ElementwiseMultiOpDocGenerator_oldEPKcENK4$_22clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
002427e5 ZZN4onnx34ElementwiseMultiOpDocGenerator_oldEPKcENK4$_22clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
0024284b ZN4onnx34ElementwiseMultiOpDocGenerator_oldEPKcE4$_22
0024288a NSt6__ndk110__function6__funcIZN4onnx25SoftmaxFamilyDocGeneratorEPKcS4_S4_E3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00242901 NSt6__ndk110__function6__funcIZZN4onnx25SoftmaxFamilyDocGeneratorEPKcS4_S4_ENK3$_0clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
0024299e ZZN4onnx25SoftmaxFamilyDocGeneratorEPKcS1_S1_ENK3$_0clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00242a00 ZN4onnx25SoftmaxFamilyDocGeneratorEPKcS1_S1_E3$_0
00242b68 NSt6__ndk110__function6__funcIZN4onnx21PoolOpSchemaGeneratorEPKcS4_S4_bbE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00242bdd NSt6__ndk110__function6__funcIZZN4onnx21PoolOpSchemaGeneratorEPKcS4_S4_bbENK3$_0clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00242c78 ZZN4onnx21PoolOpSchemaGeneratorEPKcS1_S1_bbENK3$_0clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00242cd8 ZN4onnx21PoolOpSchemaGeneratorEPKcS1_S1_bbE3$_0
00242d08 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_20MaxUnpool_Onnx_ver11EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00242d9d ZN4onnx11GetOpSchemaINS_20MaxUnpool_Onnx_ver11EEENS_8OpSchemaEvE3$_1
00242de2 NSt6__ndk110__function6__funcIZN4onnx23LpPoolOpSchemaGeneratorEPKcE3$_2NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00242e51 NSt6__ndk110__function6__funcIZZN4onnx23LpPoolOpSchemaGeneratorEPKcENK3$_2clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00242ee6 ZZN4onnx23LpPoolOpSchemaGeneratorEPKcENK3$_2clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00242f40 ZN4onnx23LpPoolOpSchemaGeneratorEPKcE3$_2
00242f6a NSt6__ndk110__function6__funcIZN4onnx24RoiPoolOpSchemaGeneratorEPKcE3$_3NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00242fda NSt6__ndk110__function6__funcIZZN4onnx24RoiPoolOpSchemaGeneratorEPKcENK3$_3clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00243070 ZZN4onnx24RoiPoolOpSchemaGeneratorEPKcENK3$_3clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
002430cb ZN4onnx24RoiPoolOpSchemaGeneratorEPKcE3$_3
002430f6 NSt6__ndk110__function6__funcIZN4onnx21ConvOpSchemaGeneratorEPKcE3$_4NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00243163 NSt6__ndk110__function6__funcIZZN4onnx21ConvOpSchemaGeneratorEPKcENK3$_4clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
002431f6 ZZN4onnx21ConvOpSchemaGeneratorEPKcENK3$_4clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
0024324e ZN4onnx21ConvOpSchemaGeneratorEPKcE3$_4
00243276 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_22QLinearConv_Onnx_ver10EEENS2_8OpSchemaEvE3$_5NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024330d ZN4onnx11GetOpSchemaINS_22QLinearConv_Onnx_ver10EEENS_8OpSchemaEvE3$_5
00243354 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_22ConvInteger_Onnx_ver10EEENS2_8OpSchemaEvE3$_6NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002433eb ZN4onnx11GetOpSchemaINS_22ConvInteger_Onnx_ver10EEENS_8OpSchemaEvE3$_6
00243432 NSt6__ndk110__function6__funcIZN4onnx30ConvTransposeOpSchemaGeneratorEPKcE3$_7NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
002434a8 NSt6__ndk110__function6__funcIZZN4onnx30ConvTransposeOpSchemaGeneratorEPKcENK3$_7clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00243544 ZZN4onnx30ConvTransposeOpSchemaGeneratorEPKcENK3$_7clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
002435a5 ZN4onnx30ConvTransposeOpSchemaGeneratorEPKcE3$_7
002435d6 NSt6__ndk110__function6__funcIZN4onnx30GlobalPoolingOpSchemaGeneratorEPKcS4_E3$_8NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0024364f NSt6__ndk110__function6__funcIZZN4onnx30GlobalPoolingOpSchemaGeneratorEPKcS4_ENK3$_8clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
002436ee ZZN4onnx30GlobalPoolingOpSchemaGeneratorEPKcS1_ENK3$_8clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00243752 ZN4onnx30GlobalPoolingOpSchemaGeneratorEPKcS1_E3$_8
00243786 NSt6__ndk110__function6__funcIZN4onnx32GlobalLpPoolingOpSchemaGeneratorEPKcS4_E3$_9NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00243801 NSt6__ndk110__function6__funcIZZN4onnx32GlobalLpPoolingOpSchemaGeneratorEPKcS4_ENK3$_9clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
002438a2 ZZN4onnx32GlobalLpPoolingOpSchemaGeneratorEPKcS1_ENK3$_9clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00243908 ZN4onnx32GlobalLpPoolingOpSchemaGeneratorEPKcS1_E3$_9
0024393e NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_29BatchNormalization_Onnx_ver15EEENS2_8OpSchemaEvE4$_10NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002439dd ZN4onnx11GetOpSchemaINS_29BatchNormalization_Onnx_ver15EEENS_8OpSchemaEvE4$_10
00243a2c NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_31InstanceNormalization_Onnx_ver6EEENS2_8OpSchemaEvE4$_11NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00243acd ZN4onnx11GetOpSchemaINS_31InstanceNormalization_Onnx_ver6EEENS_8OpSchemaEvE4$_11
00243b1e NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_25LpNormalization_Onnx_ver1EEENS2_8OpSchemaEvE4$_12NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00243bb9 ZN4onnx11GetOpSchemaINS_25LpNormalization_Onnx_ver1EEENS_8OpSchemaEvE4$_12
00243c04 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Dropout_Onnx_ver13EEENS2_8OpSchemaEvE4$_13NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00243c98 ZN4onnx11GetOpSchemaINS_18Dropout_Onnx_ver13EEENS_8OpSchemaEvE4$_13
00243cdc NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Flatten_Onnx_ver13EEENS2_8OpSchemaEvE4$_14NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00243d70 ZN4onnx11GetOpSchemaINS_18Flatten_Onnx_ver13EEENS_8OpSchemaEvE4$_14
00243db4 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_25TfIdfVectorizer_Onnx_ver9EEENS2_8OpSchemaEvE4$_15NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00243e4f ZN4onnx11GetOpSchemaINS_25TfIdfVectorizer_Onnx_ver9EEENS_8OpSchemaEvE4$_15
00243e9a NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_27StringNormalizer_Onnx_ver10EEENS2_8OpSchemaEvE4$_16NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00243f37 ZN4onnx11GetOpSchemaINS_27StringNormalizer_Onnx_ver10EEENS_8OpSchemaEvE4$_16
00243f84 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Col2Im_Onnx_ver18EEENS2_8OpSchemaEvE4$_17NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00244017 ZN4onnx11GetOpSchemaINS_17Col2Im_Onnx_ver18EEENS_8OpSchemaEvE4$_17
0024405a NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_29LayerNormalization_Onnx_ver17EEENS2_8OpSchemaEvE4$_19NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002440f9 ZN4onnx11GetOpSchemaINS_29LayerNormalization_Onnx_ver17EEENS_8OpSchemaEvE4$_19
00244148 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_29GroupNormalization_Onnx_ver18EEENS2_8OpSchemaEvE4$_20NS_9allocatorIS6_EEFbRKNS2_24FunctionBodyBuildContextERKS5_RNS2_13FunctionProtoEEEE
0024420a ZN4onnx11GetOpSchemaINS_29GroupNormalization_Onnx_ver18EEENS_8OpSchemaEvE4$_20
00244259 N4onnx12assert_errorE
00244340 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Dropout_Onnx_ver12EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002443d3 ZN4onnx11GetOpSchemaINS_18Dropout_Onnx_ver12EEENS_8OpSchemaEvE3$_0
00244416 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Flatten_Onnx_ver11EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002444a9 ZN4onnx11GetOpSchemaINS_18Flatten_Onnx_ver11EEENS_8OpSchemaEvE3$_1
002444ec NSt6__ndk110__function6__funcIZN4onnx23PoolOpSchemaGenerator_9EPKcS4_S4_E3$_2NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00244561 NSt6__ndk110__function6__funcIZZN4onnx23PoolOpSchemaGenerator_9EPKcS4_S4_ENK3$_2clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
002445fc ZZN4onnx23PoolOpSchemaGenerator_9EPKcS1_S1_ENK3$_2clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
0024465c ZN4onnx23PoolOpSchemaGenerator_9EPKcS1_S1_E3$_2
0024468c NSt6__ndk110__function6__funcIZN4onnx24PoolOpSchemaGenerator_10EPKcS4_S4_biE3$_3NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00244704 NSt6__ndk110__function6__funcIZZN4onnx24PoolOpSchemaGenerator_10EPKcS4_S4_biENK3$_3clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
002447a2 ZZN4onnx24PoolOpSchemaGenerator_10EPKcS1_S1_biENK3$_3clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00244805 ZN4onnx24PoolOpSchemaGenerator_10EPKcS1_S1_biE3$_3
00244838 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19MaxUnpool_Onnx_ver9EEENS2_8OpSchemaEvE3$_4NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002448cc ZN4onnx11GetOpSchemaINS_19MaxUnpool_Onnx_ver9EEENS_8OpSchemaEvE3$_4
00244910 NSt6__ndk110__function6__funcIZN4onnx26LpPoolOpSchemaGenerator_10EPKcE3$_5NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00244982 NSt6__ndk110__function6__funcIZZN4onnx26LpPoolOpSchemaGenerator_10EPKcENK3$_5clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00244a1a ZZN4onnx26LpPoolOpSchemaGenerator_10EPKcENK3$_5clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00244a77 ZN4onnx26LpPoolOpSchemaGenerator_10EPKcE3$_5
00244aa4 NSt6__ndk110__function6__funcIZN4onnx26LpPoolOpSchemaGenerator_11EPKcE3$_6NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00244b16 NSt6__ndk110__function6__funcIZZN4onnx26LpPoolOpSchemaGenerator_11EPKcENK3$_6clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00244bae ZZN4onnx26LpPoolOpSchemaGenerator_11EPKcENK3$_6clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00244c0b ZN4onnx26LpPoolOpSchemaGenerator_11EPKcE3$_6
00244c38 NSt6__ndk110__function6__funcIZN4onnx24ConvOpSchemaGenerator_10EPKcE3$_7NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00244ca8 NSt6__ndk110__function6__funcIZZN4onnx24ConvOpSchemaGenerator_10EPKcENK3$_7clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00244d3e ZZN4onnx24ConvOpSchemaGenerator_10EPKcENK3$_7clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00244d99 ZN4onnx24ConvOpSchemaGenerator_10EPKcE3$_7
00244dc4 NSt6__ndk110__function6__funcIZN4onnx33ConvTransposeOpSchemaGenerator_10EPKcE3$_8NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00244e3d NSt6__ndk110__function6__funcIZZN4onnx33ConvTransposeOpSchemaGenerator_10EPKcENK3$_8clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00244edc ZZN4onnx33ConvTransposeOpSchemaGenerator_10EPKcENK3$_8clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00244f40 ZN4onnx33ConvTransposeOpSchemaGenerator_10EPKcE3$_8
00244f74 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_28BatchNormalization_Onnx_ver9EEENS2_8OpSchemaEvE3$_9NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00245011 ZN4onnx11GetOpSchemaINS_28BatchNormalization_Onnx_ver9EEENS_8OpSchemaEvE3$_9
0024505e NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_29BatchNormalization_Onnx_ver14EEENS2_8OpSchemaEvE4$_10NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002450fd ZN4onnx11GetOpSchemaINS_29BatchNormalization_Onnx_ver14EEENS_8OpSchemaEvE4$_10
0024514c NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Dropout_Onnx_ver10EEENS2_8OpSchemaEvE4$_11NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002451e0 ZN4onnx11GetOpSchemaINS_18Dropout_Onnx_ver10EEENS_8OpSchemaEvE4$_11
00245224 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_28BatchNormalization_Onnx_ver6EEENS2_8OpSchemaEvE4$_12NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002452c2 ZN4onnx11GetOpSchemaINS_28BatchNormalization_Onnx_ver6EEENS_8OpSchemaEvE4$_12
00245310 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Flatten_Onnx_ver1EEENS2_8OpSchemaEvE4$_13NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002453a3 ZN4onnx11GetOpSchemaINS_17Flatten_Onnx_ver1EEENS_8OpSchemaEvE4$_13
002453e6 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Flatten_Onnx_ver9EEENS2_8OpSchemaEvE4$_14NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00245479 ZN4onnx11GetOpSchemaINS_17Flatten_Onnx_ver9EEENS_8OpSchemaEvE4$_14
002454bc NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_28BatchNormalization_Onnx_ver7EEENS2_8OpSchemaEvE4$_15NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024555a ZN4onnx11GetOpSchemaINS_28BatchNormalization_Onnx_ver7EEENS_8OpSchemaEvE4$_15
002455a8 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19RoiAlign_Onnx_ver16EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024563c ZN4onnx11GetOpSchemaINS_19RoiAlign_Onnx_ver16EEENS_8OpSchemaEvE3$_0
00245680 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_28NonMaxSuppression_Onnx_ver11EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024571d ZN4onnx11GetOpSchemaINS_28NonMaxSuppression_Onnx_ver11EEENS_8OpSchemaEvE3$_1
0024576a NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19RoiAlign_Onnx_ver10EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002457fe ZN4onnx11GetOpSchemaINS_19RoiAlign_Onnx_ver10EEENS_8OpSchemaEvE3$_0
00245842 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_28NonMaxSuppression_Onnx_ver10EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002458df ZN4onnx11GetOpSchemaINS_28NonMaxSuppression_Onnx_ver10EEENS_8OpSchemaEvE3$_1
0024592c NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19Optional_Onnx_ver15EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002459c0 ZN4onnx11GetOpSchemaINS_19Optional_Onnx_ver15EEENS_8OpSchemaEvE3$_1
00245a04 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_29OptionalHasElement_Onnx_ver18EEENS2_8OpSchemaEvE3$_2NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00245aa2 ZN4onnx11GetOpSchemaINS_29OptionalHasElement_Onnx_ver18EEENS_8OpSchemaEvE3$_2
00245af0 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_29OptionalGetElement_Onnx_ver18EEENS2_8OpSchemaEvE3$_4NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00245b8e ZN4onnx11GetOpSchemaINS_29OptionalGetElement_Onnx_ver18EEENS_8OpSchemaEvE3$_4
00245bdc NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_29OptionalHasElement_Onnx_ver15EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00245c7a ZN4onnx11GetOpSchemaINS_29OptionalHasElement_Onnx_ver15EEENS_8OpSchemaEvE3$_0
00245cc8 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_29OptionalGetElement_Onnx_ver15EEENS2_8OpSchemaEvE3$_2NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00245d66 ZN4onnx11GetOpSchemaINS_29OptionalGetElement_Onnx_ver15EEENS_8OpSchemaEvE3$_2
00245dee NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_25QuantizeLinear_Onnx_ver13EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00245e88 ZN4onnx11GetOpSchemaINS_25QuantizeLinear_Onnx_ver13EEENS_8OpSchemaEvE3$_0
00245ed2 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_27DequantizeLinear_Onnx_ver13EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00245f6e ZN4onnx11GetOpSchemaINS_27DequantizeLinear_Onnx_ver13EEENS_8OpSchemaEvE3$_1
00245fba NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_32DynamicQuantizeLinear_Onnx_ver11EEENS2_8OpSchemaEvE3$_2NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024605b ZN4onnx11GetOpSchemaINS_32DynamicQuantizeLinear_Onnx_ver11EEENS_8OpSchemaEvE3$_2
002460be NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_25QuantizeLinear_Onnx_ver10EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00246158 ZN4onnx11GetOpSchemaINS_25QuantizeLinear_Onnx_ver10EEENS_8OpSchemaEvE3$_0
002461a2 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_27DequantizeLinear_Onnx_ver10EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024623e ZN4onnx11GetOpSchemaINS_27DequantizeLinear_Onnx_ver10EEENS_8OpSchemaEvE3$_1
00246293 NSt6__ndk110__function6__funcIZN4onnx21ArgReduceDocGeneratorEPKcE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00246300 NSt6__ndk110__function6__funcIZZN4onnx21ArgReduceDocGeneratorEPKcENK3$_0clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00246393 ZZN4onnx21ArgReduceDocGeneratorEPKcENK3$_0clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
002463eb ZN4onnx21ArgReduceDocGeneratorEPKcE3$_0
0024644a NSt6__ndk110__function6__funcIZN4onnx26ReduceDocGenerator_opset12EPKcbE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
002464bd NSt6__ndk110__function6__funcIZZN4onnx26ReduceDocGenerator_opset12EPKcbENK3$_0clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00246556 ZZN4onnx26ReduceDocGenerator_opset12EPKcbENK3$_0clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
002465b4 ZN4onnx26ReduceDocGenerator_opset12EPKcbE3$_0
002465e2 NSt6__ndk110__function6__funcIZN4onnx29ArgReduceDocGenerator_opset12EPKcE3$_1NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00246657 NSt6__ndk110__function6__funcIZZN4onnx29ArgReduceDocGenerator_opset12EPKcENK3$_1clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
002466f2 ZZN4onnx29ArgReduceDocGenerator_opset12EPKcENK3$_1clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00246752 ZN4onnx29ArgReduceDocGenerator_opset12EPKcE3$_1
00246782 NSt6__ndk110__function6__funcIZN4onnx25ReduceDocGenerator_opset1EPKciE3$_2NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
002467f4 NSt6__ndk110__function6__funcIZZN4onnx25ReduceDocGenerator_opset1EPKciENK3$_2clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
0024688c ZZN4onnx25ReduceDocGenerator_opset1EPKciENK3$_2clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
002468e9 ZN4onnx25ReduceDocGenerator_opset1EPKciE3$_2
00246916 NSt6__ndk110__function6__funcIZN4onnx28ArgReduceDocGenerator_opset1EPKcE3$_3NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0024698a NSt6__ndk110__function6__funcIZZN4onnx28ArgReduceDocGenerator_opset1EPKcENK3$_3clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00246a24 ZZN4onnx28ArgReduceDocGenerator_opset1EPKcENK3$_3clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00246a83 ZN4onnx28ArgReduceDocGenerator_opset1EPKcE3$_3
00246ab2 NSt6__ndk110__function6__funcIZN4onnx29ArgReduceDocGenerator_opset11EPKcE3$_4NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00246b27 NSt6__ndk110__function6__funcIZZN4onnx29ArgReduceDocGenerator_opset11EPKcENK3$_4clERNS2_8OpSchemaEEUlRNS2_16InferenceContextEE_NS_9allocatorISA_EEFvS9_EEE
00246bc2 ZZN4onnx29ArgReduceDocGenerator_opset11EPKcENK3$_4clERNS_8OpSchemaEEUlRNS_16InferenceContextEE_
00246c22 ZN4onnx29ArgReduceDocGenerator_opset11EPKcE3$_4
00246c64 NSt6__ndk110__function6__funcIZN4onnx29ReduceDocGenerator_opset13_18EPKcbbS4_NS_8functionIFbRKNS2_24FunctionBodyBuildContextERKNS2_8OpSchemaERNS2_13FunctionProtoEEEEE3$_0NS_9allocatorISG_EEFvRS9_EEE
00246d2b NSt6__ndk110__function6__funcIZZN4onnx29ReduceDocGenerator_opset13_18EPKcbbS4_NS_8functionIFbRKNS2_24FunctionBodyBuildContextERKNS2_8OpSchemaERNS2_13FunctionProtoEEEEENK3$_0clERS9_EUlRNS2_16InferenceContextEE_NS_9allocatorISK_EEFvSJ_EEE
00246e18 ZZN4onnx29ReduceDocGenerator_opset13_18EPKcbbS1_NSt6__ndk18functionIFbRKNS_24FunctionBodyBuildContextERKNS_8OpSchemaERNS_13FunctionProtoEEEEENK3$_0clERS7_EUlRNS_16InferenceContextEE_
00246ecf ZN4onnx29ReduceDocGenerator_opset13_18EPKcbbS1_NSt6__ndk18functionIFbRKNS_24FunctionBodyBuildContextERKNS_8OpSchemaERNS_13FunctionProtoEEEEE3$_0
00246f69 NSt6__ndk110__function6__funcIZN4onnx15RNNDocGeneratorEPKcE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00246fd0 ZN4onnx15RNNDocGeneratorEPKcE3$_0
00247004 NSt6__ndk110__function6__funcIZN4onnx18RNNDocGeneratorOldEPKcE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0024706e ZN4onnx18RNNDocGeneratorOldEPKcE3$_0
00247093 NSt6__ndk110__function6__funcIZN4onnx16RNNDocGenerator1EPKcE3$_1NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
002470fb ZN4onnx16RNNDocGenerator1EPKcE3$_1
0024711e NSt6__ndk110__function6__funcIZN4onnx16RNNDocGenerator2EPKcE3$_2NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00247186 ZN4onnx16RNNDocGenerator2EPKcE3$_2
002471ac #CI@O=L7
002471b5 :FN4onnx16OpSchemaRegistryE
002471d2 NSt6__ndk110__function6__funcIZN4onnx8OpSchema10NumOutputsENS_3setIiNS_4lessIiEENS_9allocatorIiEEEEE3$_2NS7_ISA_EEFbiEEE
0024724b ZN4onnx8OpSchema10NumOutputsENSt6__ndk13setIiNS1_4lessIiEENS1_9allocatorIiEEEEE3$_2
0024729f NSt6__ndk120__shared_ptr_pointerIPN4onnx13FunctionProtoENS_14default_deleteIS2_EENS_9allocatorIS2_EEEE
00247306 NSt6__ndk114default_deleteIN4onnx13FunctionProtoEEE
00247370 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_24SequenceEmpty_Onnx_ver11EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00247409 ZN4onnx11GetOpSchemaINS_24SequenceEmpty_Onnx_ver11EEENS_8OpSchemaEvE3$_0
00247452 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_28SequenceConstruct_Onnx_ver11EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002474ef ZN4onnx11GetOpSchemaINS_28SequenceConstruct_Onnx_ver11EEENS_8OpSchemaEvE3$_1
0024753c NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_25SequenceInsert_Onnx_ver11EEENS2_8OpSchemaEvE3$_2NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002475d6 ZN4onnx11GetOpSchemaINS_25SequenceInsert_Onnx_ver11EEENS_8OpSchemaEvE3$_2
00247620 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_21SequenceAt_Onnx_ver11EEENS2_8OpSchemaEvE3$_3NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002476b6 ZN4onnx11GetOpSchemaINS_21SequenceAt_Onnx_ver11EEENS_8OpSchemaEvE3$_3
002476fc NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_24SequenceErase_Onnx_ver11EEENS2_8OpSchemaEvE3$_4NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00247795 ZN4onnx11GetOpSchemaINS_24SequenceErase_Onnx_ver11EEENS_8OpSchemaEvE3$_4
002477de NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_25SequenceLength_Onnx_ver11EEENS2_8OpSchemaEvE3$_5NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00247878 ZN4onnx11GetOpSchemaINS_25SequenceLength_Onnx_ver11EEENS_8OpSchemaEvE3$_5
002478c2 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_26SplitToSequence_Onnx_ver11EEENS2_8OpSchemaEvE3$_6NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024795d ZN4onnx11GetOpSchemaINS_26SplitToSequence_Onnx_ver11EEENS_8OpSchemaEvE3$_6
002479a8 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_29ConcatFromSequence_Onnx_ver11EEENS2_8OpSchemaEvE3$_7NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00247a46 ZN4onnx11GetOpSchemaINS_29ConcatFromSequence_Onnx_ver11EEENS_8OpSchemaEvE3$_7
00247c74 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15Cast_Onnx_ver13EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00247d04 ZN4onnx11GetOpSchemaINS_15Cast_Onnx_ver13EEENS_8OpSchemaEvE3$_0
00247d44 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15Cast_Onnx_ver13EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
00247dda ZN4onnx11GetOpSchemaINS_15Cast_Onnx_ver13EEENS_8OpSchemaEvE3$_1
00247e1a NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19CastLike_Onnx_ver15EEENS2_8OpSchemaEvE3$_2NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00247eae ZN4onnx11GetOpSchemaINS_19CastLike_Onnx_ver15EEENS_8OpSchemaEvE3$_2
00247ef2 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19CastLike_Onnx_ver15EEENS2_8OpSchemaEvE3$_3NS_9allocatorIS6_EEFbRKNS2_24FunctionBodyBuildContextERKS5_RNS2_13FunctionProtoEEEE
00247fa9 ZN4onnx11GetOpSchemaINS_19CastLike_Onnx_ver15EEENS_8OpSchemaEvE3$_3
00247fed NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Reshape_Onnx_ver14EEENS2_8OpSchemaEvE3$_4NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00248080 ZN4onnx11GetOpSchemaINS_18Reshape_Onnx_ver14EEENS_8OpSchemaEvE3$_4
002480c3 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Shape_Onnx_ver15EEENS2_8OpSchemaEvE3$_5NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00248154 ZN4onnx11GetOpSchemaINS_16Shape_Onnx_ver15EEENS_8OpSchemaEvE3$_5
00248195 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Shape_Onnx_ver15EEENS2_8OpSchemaEvE3$_6NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
0024822c ZN4onnx11GetOpSchemaINS_16Shape_Onnx_ver15EEENS_8OpSchemaEvE3$_6
0024826d NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15Size_Onnx_ver13EEENS2_8OpSchemaEvE3$_7NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002482fd ZN4onnx11GetOpSchemaINS_15Size_Onnx_ver13EEENS_8OpSchemaEvE3$_7
0024833d NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15Size_Onnx_ver13EEENS2_8OpSchemaEvE3$_8NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
002483d3 ZN4onnx11GetOpSchemaINS_15Size_Onnx_ver13EEENS_8OpSchemaEvE3$_8
00248413 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Concat_Onnx_ver13EEENS2_8OpSchemaEvE3$_9NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002484a5 ZN4onnx11GetOpSchemaINS_17Concat_Onnx_ver13EEENS_8OpSchemaEvE3$_9
002484e7 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Concat_Onnx_ver13EEENS2_8OpSchemaEvE4$_10NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
00248580 ZN4onnx11GetOpSchemaINS_17Concat_Onnx_ver13EEENS_8OpSchemaEvE4$_10
002485c3 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Split_Onnx_ver18EEENS2_8OpSchemaEvE4$_11NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00248655 ZN4onnx11GetOpSchemaINS_16Split_Onnx_ver18EEENS_8OpSchemaEvE4$_11
00248697 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Slice_Onnx_ver13EEENS2_8OpSchemaEvE4$_12NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00248729 ZN4onnx11GetOpSchemaINS_16Slice_Onnx_ver13EEENS_8OpSchemaEvE4$_12
0024876b NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Slice_Onnx_ver13EEENS2_8OpSchemaEvE4$_13NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
00248803 ZN4onnx11GetOpSchemaINS_16Slice_Onnx_ver13EEENS_8OpSchemaEvE4$_13
00248845 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_20Transpose_Onnx_ver13EEENS2_8OpSchemaEvE4$_14NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002488db ZN4onnx11GetOpSchemaINS_20Transpose_Onnx_ver13EEENS_8OpSchemaEvE4$_14
00248921 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Scatter_Onnx_ver11EEENS2_8OpSchemaEvE4$_15NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002489b5 ZN4onnx11GetOpSchemaINS_18Scatter_Onnx_ver11EEENS_8OpSchemaEvE4$_15
002489f9 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_20ScatterND_Onnx_ver18EEENS2_8OpSchemaEvE4$_16NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00248a8f ZN4onnx11GetOpSchemaINS_20ScatterND_Onnx_ver18EEENS_8OpSchemaEvE4$_16
00248ad5 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_26ScatterElements_Onnx_ver18EEENS2_8OpSchemaEvE4$_17NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00248b71 ZN4onnx11GetOpSchemaINS_26ScatterElements_Onnx_ver18EEENS_8OpSchemaEvE4$_17
00248bbd NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Gather_Onnx_ver13EEENS2_8OpSchemaEvE4$_18NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00248c50 ZN4onnx11GetOpSchemaINS_17Gather_Onnx_ver13EEENS_8OpSchemaEvE4$_18
00248c93 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Gather_Onnx_ver13EEENS2_8OpSchemaEvE4$_19NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
00248d2c ZN4onnx11GetOpSchemaINS_17Gather_Onnx_ver13EEENS_8OpSchemaEvE4$_19
00248d6f NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_25GatherElements_Onnx_ver13EEENS2_8OpSchemaEvE4$_20NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00248e0a ZN4onnx11GetOpSchemaINS_25GatherElements_Onnx_ver13EEENS_8OpSchemaEvE4$_20
00248e55 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Squeeze_Onnx_ver13EEENS2_8OpSchemaEvE4$_21NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00248ee9 ZN4onnx11GetOpSchemaINS_18Squeeze_Onnx_ver13EEENS_8OpSchemaEvE4$_21
00248f2d NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Squeeze_Onnx_ver13EEENS2_8OpSchemaEvE4$_22NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
00248fc7 ZN4onnx11GetOpSchemaINS_18Squeeze_Onnx_ver13EEENS_8OpSchemaEvE4$_22
0024900b NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_20Unsqueeze_Onnx_ver13EEENS2_8OpSchemaEvE4$_23NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002490a1 ZN4onnx11GetOpSchemaINS_20Unsqueeze_Onnx_ver13EEENS_8OpSchemaEvE4$_23
002490e7 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_20Unsqueeze_Onnx_ver13EEENS2_8OpSchemaEvE4$_24NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
00249183 ZN4onnx11GetOpSchemaINS_20Unsqueeze_Onnx_ver13EEENS_8OpSchemaEvE4$_24
002491c9 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_23SpaceToDepth_Onnx_ver13EEENS2_8OpSchemaEvE4$_25NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00249262 ZN4onnx11GetOpSchemaINS_23SpaceToDepth_Onnx_ver13EEENS_8OpSchemaEvE4$_25
002492ab NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_23DepthToSpace_Onnx_ver13EEENS2_8OpSchemaEvE4$_26NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00249344 ZN4onnx11GetOpSchemaINS_23DepthToSpace_Onnx_ver13EEENS_8OpSchemaEvE4$_26
0024938d NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15Tile_Onnx_ver13EEENS2_8OpSchemaEvE4$_27NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024941e ZN4onnx11GetOpSchemaINS_15Tile_Onnx_ver13EEENS_8OpSchemaEvE4$_27
0024945f NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19Upsample_Onnx_ver10EEENS2_8OpSchemaEvE4$_28NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002494f4 ZN4onnx11GetOpSchemaINS_19Upsample_Onnx_ver10EEENS_8OpSchemaEvE4$_28
00249539 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Resize_Onnx_ver18EEENS2_8OpSchemaEvE4$_29NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002495cc ZN4onnx11GetOpSchemaINS_17Resize_Onnx_ver18EEENS_8OpSchemaEvE4$_29
0024960f NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_21GridSample_Onnx_ver16EEENS2_8OpSchemaEvE4$_30NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
002496a6 ZN4onnx11GetOpSchemaINS_21GridSample_Onnx_ver16EEENS_8OpSchemaEvE4$_30
002496ed NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19Compress_Onnx_ver11EEENS2_8OpSchemaEvE4$_32NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00249782 ZN4onnx11GetOpSchemaINS_19Compress_Onnx_ver11EEENS_8OpSchemaEvE4$_32
002497c7 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17OneHot_Onnx_ver11EEENS2_8OpSchemaEvE4$_33NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024985a ZN4onnx11GetOpSchemaINS_17OneHot_Onnx_ver11EEENS_8OpSchemaEvE4$_33
0024989d NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16IsNaN_Onnx_ver13EEENS2_8OpSchemaEvE4$_34NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024992f ZN4onnx11GetOpSchemaINS_16IsNaN_Onnx_ver13EEENS_8OpSchemaEvE4$_34
00249971 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16IsInf_Onnx_ver10EEENS2_8OpSchemaEvE4$_35NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00249a03 ZN4onnx11GetOpSchemaINS_16IsInf_Onnx_ver10EEENS_8OpSchemaEvE4$_35
00249a45 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Where_Onnx_ver16EEENS2_8OpSchemaEvE4$_36NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00249ad7 ZN4onnx11GetOpSchemaINS_16Where_Onnx_ver16EEENS_8OpSchemaEvE4$_36
00249b19 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18NonZero_Onnx_ver13EEENS2_8OpSchemaEvE4$_37NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00249bad ZN4onnx11GetOpSchemaINS_18NonZero_Onnx_ver13EEENS_8OpSchemaEvE4$_37
00249bf1 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_26ReverseSequence_Onnx_ver10EEENS2_8OpSchemaEvE4$_38NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00249c8d ZN4onnx11GetOpSchemaINS_26ReverseSequence_Onnx_ver10EEENS_8OpSchemaEvE4$_38
00249cd9 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Unique_Onnx_ver11EEENS2_8OpSchemaEvE4$_39NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00249d6c ZN4onnx11GetOpSchemaINS_17Unique_Onnx_ver11EEENS_8OpSchemaEvE4$_39
00249daf NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19GatherND_Onnx_ver13EEENS2_8OpSchemaEvE4$_40NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00249e44 ZN4onnx11GetOpSchemaINS_19GatherND_Onnx_ver13EEENS_8OpSchemaEvE4$_40
00249e89 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Pad_Onnx_ver18EEENS2_8OpSchemaEvE4$_41NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00249f19 ZN4onnx11GetOpSchemaINS_14Pad_Onnx_ver18EEENS_8OpSchemaEvE4$_41
00249f59 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Trilu_Onnx_ver14EEENS2_8OpSchemaEvE4$_42NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
00249feb ZN4onnx11GetOpSchemaINS_16Trilu_Onnx_ver14EEENS_8OpSchemaEvE4$_42
0024a02d NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_24CenterCropPad_Onnx_ver18EEENS2_8OpSchemaEvE4$_43NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024a0c7 ZN4onnx11GetOpSchemaINS_24CenterCropPad_Onnx_ver18EEENS_8OpSchemaEvE4$_43
0024a111 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_24CenterCropPad_Onnx_ver18EEENS2_8OpSchemaEvE4$_44NS_9allocatorIS6_EEFbRKNS2_24FunctionBodyBuildContextERKS5_RNS2_13FunctionProtoEEEE
0024a1ce ZN4onnx11GetOpSchemaINS_24CenterCropPad_Onnx_ver18EEENS_8OpSchemaEvE4$_44
0024a48a NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Cast_Onnx_ver9EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024a519 ZN4onnx11GetOpSchemaINS_14Cast_Onnx_ver9EEENS_8OpSchemaEvE3$_0
0024a558 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Reshape_Onnx_ver13EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024a5eb ZN4onnx11GetOpSchemaINS_18Reshape_Onnx_ver13EEENS_8OpSchemaEvE3$_1
0024a62e NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Reshape_Onnx_ver5EEENS2_8OpSchemaEvE3$_2NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024a6c0 ZN4onnx11GetOpSchemaINS_17Reshape_Onnx_ver5EEENS_8OpSchemaEvE3$_2
0024a702 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Shape_Onnx_ver13EEENS2_8OpSchemaEvE3$_3NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024a793 ZN4onnx11GetOpSchemaINS_16Shape_Onnx_ver13EEENS_8OpSchemaEvE3$_3
0024a7d4 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Shape_Onnx_ver13EEENS2_8OpSchemaEvE3$_4NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
0024a86b ZN4onnx11GetOpSchemaINS_16Shape_Onnx_ver13EEENS_8OpSchemaEvE3$_4
0024a8ac NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15Shape_Onnx_ver1EEENS2_8OpSchemaEvE3$_5NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024a93c ZN4onnx11GetOpSchemaINS_15Shape_Onnx_ver1EEENS_8OpSchemaEvE3$_5
0024a97c NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15Shape_Onnx_ver1EEENS2_8OpSchemaEvE3$_6NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
0024aa12 ZN4onnx11GetOpSchemaINS_15Shape_Onnx_ver1EEENS_8OpSchemaEvE3$_6
0024aa52 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Size_Onnx_ver1EEENS2_8OpSchemaEvE3$_7NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024aae1 ZN4onnx11GetOpSchemaINS_14Size_Onnx_ver1EEENS_8OpSchemaEvE3$_7
0024ab20 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Concat_Onnx_ver11EEENS2_8OpSchemaEvE3$_8NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024abb2 ZN4onnx11GetOpSchemaINS_17Concat_Onnx_ver11EEENS_8OpSchemaEvE3$_8
0024abf4 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Split_Onnx_ver11EEENS2_8OpSchemaEvE3$_9NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024ac85 ZN4onnx11GetOpSchemaINS_16Split_Onnx_ver11EEENS_8OpSchemaEvE3$_9
0024acc6 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Split_Onnx_ver13EEENS2_8OpSchemaEvE4$_10NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024ad58 ZN4onnx11GetOpSchemaINS_16Split_Onnx_ver13EEENS_8OpSchemaEvE4$_10
0024ad9a NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Slice_Onnx_ver11EEENS2_8OpSchemaEvE4$_11NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024ae2c ZN4onnx11GetOpSchemaINS_16Slice_Onnx_ver11EEENS_8OpSchemaEvE4$_11
0024ae6e NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19Transpose_Onnx_ver1EEENS2_8OpSchemaEvE4$_12NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024af03 ZN4onnx11GetOpSchemaINS_19Transpose_Onnx_ver1EEENS_8OpSchemaEvE4$_12
0024af48 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_20ScatterND_Onnx_ver16EEENS2_8OpSchemaEvE4$_13NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024afde ZN4onnx11GetOpSchemaINS_20ScatterND_Onnx_ver16EEENS_8OpSchemaEvE4$_13
0024b024 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_20ScatterND_Onnx_ver13EEENS2_8OpSchemaEvE4$_14NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024b0ba ZN4onnx11GetOpSchemaINS_20ScatterND_Onnx_ver13EEENS_8OpSchemaEvE4$_14
0024b100 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_20ScatterND_Onnx_ver11EEENS2_8OpSchemaEvE4$_15NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024b196 ZN4onnx11GetOpSchemaINS_20ScatterND_Onnx_ver11EEENS_8OpSchemaEvE4$_15
0024b1dc NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_26ScatterElements_Onnx_ver16EEENS2_8OpSchemaEvE4$_16NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024b278 ZN4onnx11GetOpSchemaINS_26ScatterElements_Onnx_ver16EEENS_8OpSchemaEvE4$_16
0024b2c4 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_26ScatterElements_Onnx_ver13EEENS2_8OpSchemaEvE4$_17NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024b360 ZN4onnx11GetOpSchemaINS_26ScatterElements_Onnx_ver13EEENS_8OpSchemaEvE4$_17
0024b3ac NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_26ScatterElements_Onnx_ver11EEENS2_8OpSchemaEvE4$_18NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024b448 ZN4onnx11GetOpSchemaINS_26ScatterElements_Onnx_ver11EEENS_8OpSchemaEvE4$_18
0024b494 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Gather_Onnx_ver11EEENS2_8OpSchemaEvE4$_19NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024b527 ZN4onnx11GetOpSchemaINS_17Gather_Onnx_ver11EEENS_8OpSchemaEvE4$_19
0024b56a NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Gather_Onnx_ver11EEENS2_8OpSchemaEvE4$_20NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
0024b603 ZN4onnx11GetOpSchemaINS_17Gather_Onnx_ver11EEENS_8OpSchemaEvE4$_20
0024b646 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_25GatherElements_Onnx_ver11EEENS2_8OpSchemaEvE4$_21NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024b6e1 ZN4onnx11GetOpSchemaINS_25GatherElements_Onnx_ver11EEENS_8OpSchemaEvE4$_21
0024b72c NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Squeeze_Onnx_ver11EEENS2_8OpSchemaEvE4$_22NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024b7c0 ZN4onnx11GetOpSchemaINS_18Squeeze_Onnx_ver11EEENS_8OpSchemaEvE4$_22
0024b804 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_20Unsqueeze_Onnx_ver11EEENS2_8OpSchemaEvE4$_23NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024b89a ZN4onnx11GetOpSchemaINS_20Unsqueeze_Onnx_ver11EEENS_8OpSchemaEvE4$_23
0024b8e0 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_22SpaceToDepth_Onnx_ver1EEENS2_8OpSchemaEvE4$_24NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024b978 ZN4onnx11GetOpSchemaINS_22SpaceToDepth_Onnx_ver1EEENS_8OpSchemaEvE4$_24
0024b9c0 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_23DepthToSpace_Onnx_ver11EEENS2_8OpSchemaEvE4$_25NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024ba59 ZN4onnx11GetOpSchemaINS_23DepthToSpace_Onnx_ver11EEENS_8OpSchemaEvE4$_25
0024baa2 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Tile_Onnx_ver6EEENS2_8OpSchemaEvE4$_26NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024bb32 ZN4onnx11GetOpSchemaINS_14Tile_Onnx_ver6EEENS_8OpSchemaEvE4$_26
0024bb72 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Resize_Onnx_ver13EEENS2_8OpSchemaEvE4$_27NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024bc05 ZN4onnx11GetOpSchemaINS_17Resize_Onnx_ver13EEENS_8OpSchemaEvE4$_27
0024bc48 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Resize_Onnx_ver11EEENS2_8OpSchemaEvE4$_28NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024bcdb ZN4onnx11GetOpSchemaINS_17Resize_Onnx_ver11EEENS_8OpSchemaEvE4$_28
0024bd1e NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15IsNaN_Onnx_ver9EEENS2_8OpSchemaEvE4$_29NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024bdaf ZN4onnx11GetOpSchemaINS_15IsNaN_Onnx_ver9EEENS_8OpSchemaEvE4$_29
0024bdf0 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17NonZero_Onnx_ver9EEENS2_8OpSchemaEvE4$_30NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024be83 ZN4onnx11GetOpSchemaINS_17NonZero_Onnx_ver9EEENS_8OpSchemaEvE4$_30
0024bec6 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19GatherND_Onnx_ver12EEENS2_8OpSchemaEvE4$_31NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024bf5b ZN4onnx11GetOpSchemaINS_19GatherND_Onnx_ver12EEENS_8OpSchemaEvE4$_31
0024bfa0 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Pad_Onnx_ver11EEENS2_8OpSchemaEvE4$_32NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024c030 ZN4onnx11GetOpSchemaINS_14Pad_Onnx_ver11EEENS_8OpSchemaEvE4$_32
0024c070 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Cast_Onnx_ver6EEENS2_8OpSchemaEvE4$_33NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024c100 ZN4onnx11GetOpSchemaINS_14Cast_Onnx_ver6EEENS_8OpSchemaEvE4$_33
0024c140 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Concat_Onnx_ver4EEENS2_8OpSchemaEvE4$_34NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024c1d2 ZN4onnx11GetOpSchemaINS_16Concat_Onnx_ver4EEENS_8OpSchemaEvE4$_34
0024c214 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Tile_Onnx_ver1EEENS2_8OpSchemaEvE4$_35NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024c2a4 ZN4onnx11GetOpSchemaINS_14Tile_Onnx_ver1EEENS_8OpSchemaEvE4$_35
0024c2e4 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Upsample_Onnx_ver7EEENS2_8OpSchemaEvE4$_36NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024c378 ZN4onnx11GetOpSchemaINS_18Upsample_Onnx_ver7EEENS_8OpSchemaEvE4$_36
0024c3bc NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18Upsample_Onnx_ver9EEENS2_8OpSchemaEvE4$_37NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024c450 ZN4onnx11GetOpSchemaINS_18Upsample_Onnx_ver9EEENS_8OpSchemaEvE4$_37
0024c494 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Resize_Onnx_ver10EEENS2_8OpSchemaEvE4$_38NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024c527 ZN4onnx11GetOpSchemaINS_17Resize_Onnx_ver10EEENS_8OpSchemaEvE4$_38
0024c56a NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15Slice_Onnx_ver1EEENS2_8OpSchemaEvE4$_39NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024c5fb ZN4onnx11GetOpSchemaINS_15Slice_Onnx_ver1EEENS_8OpSchemaEvE4$_39
0024c63c NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Slice_Onnx_ver10EEENS2_8OpSchemaEvE4$_40NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024c6ce ZN4onnx11GetOpSchemaINS_16Slice_Onnx_ver10EEENS_8OpSchemaEvE4$_40
0024c710 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Scatter_Onnx_ver9EEENS2_8OpSchemaEvE4$_41NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024c7a3 ZN4onnx11GetOpSchemaINS_17Scatter_Onnx_ver9EEENS_8OpSchemaEvE4$_41
0024c7e6 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_22DepthToSpace_Onnx_ver1EEENS2_8OpSchemaEvE4$_42NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024c87e ZN4onnx11GetOpSchemaINS_22DepthToSpace_Onnx_ver1EEENS_8OpSchemaEvE4$_42
0024c8c6 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Gather_Onnx_ver1EEENS2_8OpSchemaEvE4$_43NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024c958 ZN4onnx11GetOpSchemaINS_16Gather_Onnx_ver1EEENS_8OpSchemaEvE4$_43
0024c99a NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16Gather_Onnx_ver1EEENS2_8OpSchemaEvE4$_44NS_9allocatorIS6_EEFvRNS2_22DataPropagationContextEEEE
0024ca32 ZN4onnx11GetOpSchemaINS_16Gather_Onnx_ver1EEENS_8OpSchemaEvE4$_44
0024ca74 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_17Squeeze_Onnx_ver1EEENS2_8OpSchemaEvE4$_45NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024cb07 ZN4onnx11GetOpSchemaINS_17Squeeze_Onnx_ver1EEENS_8OpSchemaEvE4$_45
0024cb4a NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19Unsqueeze_Onnx_ver1EEENS2_8OpSchemaEvE4$_46NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024cbdf ZN4onnx11GetOpSchemaINS_19Unsqueeze_Onnx_ver1EEENS_8OpSchemaEvE4$_46
0024cc24 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_16OneHot_Onnx_ver9EEENS2_8OpSchemaEvE4$_47NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024ccb6 ZN4onnx11GetOpSchemaINS_16OneHot_Onnx_ver9EEENS_8OpSchemaEvE4$_47
0024ccf8 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15Split_Onnx_ver2EEENS2_8OpSchemaEvE4$_48NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024cd89 ZN4onnx11GetOpSchemaINS_15Split_Onnx_ver2EEENS_8OpSchemaEvE4$_48
0024cdca NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_13Pad_Onnx_ver2EEENS2_8OpSchemaEvE4$_49NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024ce59 ZN4onnx11GetOpSchemaINS_13Pad_Onnx_ver2EEENS_8OpSchemaEvE4$_49
0024ce98 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19GatherND_Onnx_ver11EEENS2_8OpSchemaEvE4$_50NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024cf2d ZN4onnx11GetOpSchemaINS_19GatherND_Onnx_ver11EEENS_8OpSchemaEvE4$_50
0024cf72 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_15Where_Onnx_ver9EEENS2_8OpSchemaEvE4$_52NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024d003 ZN4onnx11GetOpSchemaINS_15Where_Onnx_ver9EEENS_8OpSchemaEvE4$_52
0024d044 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_14Pad_Onnx_ver13EEENS2_8OpSchemaEvE4$_53NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024d0d4 ZN4onnx11GetOpSchemaINS_14Pad_Onnx_ver13EEENS_8OpSchemaEvE4$_53
0024d12f NSt6__ndk110__function6__funcIZN4onnx21KeepAspectRatioHelperENS2_21KeepAspectRatioPolicyERKNS2_16TensorShapeProtoERKNS_6vectorIlNS_9allocatorIlEEEERSA_E3$_0NS8_ISE_EEFfffEEE
0024d1dd NSt6__ndk110__function6__baseIFfffEEE
0024d203 ZN4onnx21KeepAspectRatioHelperENS_21KeepAspectRatioPolicyERKNS_16TensorShapeProtoERKNSt6__ndk16vectorIlNS4_9allocatorIlEEEERS8_E3$_0
0024d288 NSt6__ndk110__function6__funcIZN4onnx21KeepAspectRatioHelperENS2_21KeepAspectRatioPolicyERKNS2_16TensorShapeProtoERKNS_6vectorIlNS_9allocatorIlEEEERSA_E3$_1NS8_ISE_EEFfffEEE
0024d336 ZN4onnx21KeepAspectRatioHelperENS_21KeepAspectRatioPolicyERKNS_16TensorShapeProtoERKNSt6__ndk16vectorIlNS4_9allocatorIlEEEERS8_E3$_1
0024d3df NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_33ArrayFeatureExtractor_OnnxML_ver1EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024d481 ZN4onnx11GetOpSchemaINS_33ArrayFeatureExtractor_OnnxML_ver1EEENS_8OpSchemaEvE3$_0
0024d4d3 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_19CastMap_OnnxML_ver1EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024d567 ZN4onnx11GetOpSchemaINS_19CastMap_OnnxML_ver1EEENS_8OpSchemaEvE3$_1
0024d5ab NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_26CategoryMapper_OnnxML_ver1EEENS2_8OpSchemaEvE3$_2NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024d646 ZN4onnx11GetOpSchemaINS_26CategoryMapper_OnnxML_ver1EEENS_8OpSchemaEvE3$_2
0024d691 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_26DictVectorizer_OnnxML_ver1EEENS2_8OpSchemaEvE3$_3NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024d72c ZN4onnx11GetOpSchemaINS_26DictVectorizer_OnnxML_ver1EEENS_8OpSchemaEvE3$_3
0024d777 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_24LabelEncoder_OnnxML_ver2EEENS2_8OpSchemaEvE3$_4NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024d810 ZN4onnx11GetOpSchemaINS_24LabelEncoder_OnnxML_ver2EEENS_8OpSchemaEvE3$_4
0024d859 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_28LinearClassifier_OnnxML_ver1EEENS2_8OpSchemaEvE3$_5NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024d8f6 ZN4onnx11GetOpSchemaINS_28LinearClassifier_OnnxML_ver1EEENS_8OpSchemaEvE3$_5
0024d943 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_25SVMClassifier_OnnxML_ver1EEENS2_8OpSchemaEvE3$_6NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024d9dd ZN4onnx11GetOpSchemaINS_25SVMClassifier_OnnxML_ver1EEENS_8OpSchemaEvE3$_6
0024da27 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_34TreeEnsembleClassifier_OnnxML_ver3EEENS2_8OpSchemaEvE3$_7NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024daca ZN4onnx11GetOpSchemaINS_34TreeEnsembleClassifier_OnnxML_ver3EEENS_8OpSchemaEvE3$_7
0024db1d NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_33TreeEnsembleRegressor_OnnxML_ver3EEENS2_8OpSchemaEvE3$_8NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024dbbf ZN4onnx11GetOpSchemaINS_33TreeEnsembleRegressor_OnnxML_ver3EEENS_8OpSchemaEvE3$_8
0024dc11 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_18ZipMap_OnnxML_ver1EEENS2_8OpSchemaEvE3$_9NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024dca4 ZN4onnx11GetOpSchemaINS_18ZipMap_OnnxML_ver1EEENS_8OpSchemaEvE3$_9
0024dce7 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_24LabelEncoder_OnnxML_ver1EEENS2_8OpSchemaEvE3$_0NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024dd80 ZN4onnx11GetOpSchemaINS_24LabelEncoder_OnnxML_ver1EEENS_8OpSchemaEvE3$_0
0024ddc9 NSt6__ndk110__function6__funcIZN4onnx11GetOpSchemaINS2_34TreeEnsembleClassifier_OnnxML_ver1EEENS2_8OpSchemaEvE3$_1NS_9allocatorIS6_EEFvRNS2_16InferenceContextEEEE
0024de6c ZN4onnx11GetOpSchemaINS_34TreeEnsembleClassifier_OnnxML_ver1EEENS_8OpSchemaEvE3$_1
0024decf 9%/IOO
0024dee5 N4onnx15shape_inference19GraphInferencerImplE
0024df14 N4onnx15shape_inference20InferenceContextImplE
0024df43 N4onnx15shape_inference26DataPropagationContextImplE
0024df78 N4onnx22DataPropagationContextE
0024df98 NSt6__ndk110__function6__funcIPFvRN4onnx22DataPropagationContextEENS_9allocatorIS6_EES5_EE
0024dff3 PFvRN4onnx22DataPropagationContextEE
0024e018 FvRN4onnx22DataPropagationContextEE
0024e07f !,7BLWi
0024e0e5 !!0=J[hu
0024e10a FLOATFLOATSGRAPHGRAPHSINTINTSSPARSE_TENSORSPARSE_TENSORSSTRINGSTRINGSTENSORTENSORSTYPE_PROTOTYPE_PROTOSUNDEFINED
0024e1b8 N4onnx14AttributeProtoE
0024e1d0 N4onnx14ValueInfoProtoE
0024e1e8 N4onnx9NodeProtoE
0024e1fa N4onnx17TrainingInfoProtoE
0024e215 N4onnx10ModelProtoE
0024e229 N4onnx22StringStringEntryProtoE
0024e249 N4onnx16TensorAnnotationE
0024e263 N4onnx10GraphProtoE
0024e277 N4onnx19TensorProto_SegmentE
0024e294 N4onnx11TensorProtoE
0024e2a9 N4onnx17SparseTensorProtoE
0024e2c4 N4onnx26TensorShapeProto_DimensionE
0024e2e8 N4onnx16TensorShapeProtoE
0024e302 N4onnx16TypeProto_TensorE
0024e31c N4onnx18TypeProto_SequenceE
0024e338 N4onnx13TypeProto_MapE
0024e34f N4onnx18TypeProto_OptionalE
0024e36b N4onnx22TypeProto_SparseTensorE
0024e38b N4onnx16TypeProto_OpaqueE
0024e3a5 N4onnx9TypeProtoE
0024e3b7 N4onnx18OperatorSetIdProtoE
0024e3d3 N4onnx13FunctionProtoE
0024e3ea N6google8protobuf8internal16InternalMetadata9ContainerINSt6__ndk112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEEEE
0024e467 N6google8protobuf8internal16InternalMetadata13ContainerBaseE
0024e4a4 N6google8protobuf2io15FileInputStreamE
0024e4cb N6google8protobuf2io19ZeroCopyInputStreamE
0024e4f6 N6google8protobuf2io15FileInputStream22CopyingFileInputStreamE
0024e535 N6google8protobuf2io16FileOutputStreamE
0024e55d N6google8protobuf2io16FileOutputStream23CopyingFileOutputStreamE
0024e59e N6google8protobuf2io19CopyingOutputStreamE
0024e5c9 N6google8protobuf2io19OstreamOutputStreamE
0024e5f4 N6google8protobuf2io19OstreamOutputStream26CopyingOstreamOutputStreamE
0024e63b N6google8protobuf2io20ZeroCopyOutputStreamE
0024e667 N6google8protobuf2io18CopyingInputStreamE
0024e691 N6google8protobuf2io25CopyingInputStreamAdaptorE
0024e6c2 N6google8protobuf2io26CopyingOutputStreamAdaptorE
0024e6f4 N6google8protobuf11MessageLiteE
0024e71f PN6google8protobuf14FatalExceptionE
0024e754 00010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899
0024e876 KKKKKKKKKKKKKKKKKKK
0024e88e KKKKK
0024e898 G=`_
0024e8ec DN3re216RepetitionWalkerE
0024e906 N3re26Regexp6WalkerIiEE
0024e9e2 N3re28CompilerE
0024e9f2 N3re26Regexp6WalkerINS_4FragEEE
0024ea13 CC222
0024ea30 +0G+0
0024ea45 Dwg\
0024ea5c ?XXXXXXXaG&N3re217NumCapturesWalkerE
0024ea81 LLLL
0024ea8a 6<LLLLLLLL8L
0024eaa5 QQQQQQ
0024eab0 ''			Ud
0024eac1 N3re214CoalesceWalkerE
0024ead8 N3re26Regexp6WalkerIPS0_EE
0024eaf3 N3re214SimplifyWalkerE
0024eb17 GW/[3k
0024eb2b 	N3re214ToStringWalkerE
0024ff27  * . ` d f o 
0024ffdb  * . ` d f o 
002500c4 d	e	?
00250101  d f p t ~ 
00250115 !%!'!)!,!1!3!M!O!_!
0025012d !&$@$J$`$
00250139 )s+v+
00250155 0 00070<0?0
00250173 1 2_2
00250505 	P	U	c	f	
00250661 -%-'-'-----
00250794 &!&!e
0025086f 0!0)080;0
002508d4 .0/011
002508df 2`2~2`
00250998 Q	T	
002509c3  *0-0
00250aa5 3W3f
00250c39 	9	=	=	P	P	X	a	q	
00250f58 q q 
00250f77 !$!$!&!&!(!(!*!-!/!9!<!?!E!I!N!N!
00250fa9 -%-'-'-----0-g-o-o-
00250fdf -/./.
00250fe7 01050;0<0A0
00251001 1/111
00251a1c q q 
00251a27  *!+!2!2!N!N!`!
002521a7 !/!/!4!4!9!9!<!=!F!I!N!N!
002521c3 !0,_,a,a,e,f,h,h,j,j,l,l,q,q,s,t,v,{,
002522bd -%-'-'-----A
0025262c q	q	F
00252658 q q 
00252663  |,},o-o-/./.
00252673 01050;0;0
00252799 	9	=	=	P	P	X	a	r	
00252a3c 5!8!0-g-
00252a6b 0<0<0A0
00252a81 1/111
00253913 !$!$!&!&!(!(!*!-!0!3!>!?!E!E!
00253935 ,/,`,`,b,d,g,g,i,i,k,k,m,p,r,r,u,u,~,
00253db7 	:	<	>	O	Q	W	b	c	
00253faf -*0/0
00254447 	;	;	>	@	I	L	N	O	
002545a8 .0/0#
002548eb 	:	:	<	<	A	H	M	M	Q	W	b	c	
00254b2f -*0-0
00255044 f	o	
002550c4 p p t y 
002550eb 0!0)080:0
002550f7 1 2)2H2O2Q2_2
00255384 f	o	
00255507 0!0)080:0
00255570 p p t y 
0025557b  P!_!
00255597 1 2)2H2O2Q2_2
00255880 d	e	p	p	
00255919  ' 0 C E Q S ^ } ~ 
00255933 #)#*#h'u'
00255957 ,p-p-
0025595d ...0.O.R.].
00255973 00000=0=0
00255c08 ? @ T T 3
00255c3b .:.;.@.@.].].
00255c4b 00000
00255c84 F F ~ ~ 
00255c8f  	#	#
00255c97 #*#*#i'i'k'k'm'm'o'o'q'q's's'u'u'
00255d07 )#.#.%.%.'.'.).).V.V.X.X.Z.Z.\.\.	0	0
00255da7  : : 
00255dbf .!.!.@
00255de7  9 9 
00255df3 .	.	.
00255dff . . .!
00255e7c d	e	p	p	
00255f0f    ' 0 8 ; > A C G Q S S U ^ 
00255f33 ,p-p-
00255f53 .*...0.9.<.?.A.A.C.O.R.T.
00255f6f 0=0=0
002561e3  E E } } 
002561f7 #)#)#h'h'j'j'l'l'n'n'p'p'r'r't't'
00256267 )".".$.$.&.&.(.(.B.B.U.U.W.W.Y.Y.[.[.
00256438 D D R R z | 
00256461 !#!%!%!'!'!)!)!.!.!:!;!@!D!J!M!O!O!
0025648d #(#+#&$@$J$
002564b5 )s+v+
002564c3 ,P.Q.
002564df 0 0 06070>0?0
002564ff 2*2G2P2P2`2
002569a4 D D R R z | 
002569b7 !@!D!K!K!
002569e7 " #!#|#|#
00256a03 %o&o&
00256a23 *0+D+G+L+)
00256b4d !#!%!%!'!'!)!)!.!.!:!;!J!J!L!M!O!O!
00256b9f #"#(#+#{#}#
00256bb1 #&$@$J$
00256bc9 &n&p&g'
00256bd9 +/+E+F+M+s+v+
00256bef ,P.Q.
00256c0b 0 0 06070>0?0
00256c27 2*2G2P2P2`2
00257010 0-g-o-p-
002570d7  ( ) / / _ _ 
002570f0 ( ( ) )  
00257107  / / _ _ 
00257135 j?$Dsp
00257143 )"8	
00257280 &&&&&&&&&&&T
0025728e '%%%''''''''
0025729b ''''
00257374 gxbaby
00257774 NSt6__ndk18ios_baseE
00257789 NSt6__ndk18ios_base7failureE
002577a6 NSt6__ndk19basic_iosIcNS_11char_traitsIcEEEE
002577d3 NSt6__ndk19basic_iosIwNS_11char_traitsIwEEEE
00257800 NSt6__ndk115basic_streambufIcNS_11char_traitsIcEEEE
00257834 NSt6__ndk115basic_streambufIwNS_11char_traitsIwEEEE
00257868 NSt6__ndk113basic_istreamIcNS_11char_traitsIcEEEE
0025789a NSt6__ndk113basic_istreamIwNS_11char_traitsIwEEEE
002578cc NSt6__ndk113basic_ostreamIcNS_11char_traitsIcEEEE
002578fe NSt6__ndk113basic_ostreamIwNS_11char_traitsIwEEEE
00257930 NSt6__ndk114basic_iostreamIcNS_11char_traitsIcEEEE
00257963 NSt6__ndk119__iostream_categoryE
00257984 NSt6__ndk110__stdinbufIcEE
0025799f NSt6__ndk110__stdinbufIwEE
002579ba NSt6__ndk111__stdoutbufIcEE
002579d6 NSt6__ndk111__stdoutbufIwEE
00257bcb wwwwwwwwww#wwwwwwwwDwwwwwwwwwww
00257bec wwwwwwwwww#wwwwwwwwDwwwwwwwwwww
00257c20 0123456789abcdefABCDEFxX+-pPiInN
00257c41 %I:%M:%S %p%
00258490 NSt6__ndk16locale5facetE
002584a9 NSt6__ndk15ctypeIwEE
002584be NSt6__ndk110ctype_baseE
002584d6 NSt6__ndk17codecvtIcc9mbstate_tEE
002584f8 NSt6__ndk112codecvt_baseE
00258512 NSt6__ndk17codecvtIDsc9mbstate_tEE
00258535 NSt6__ndk17codecvtIDic9mbstate_tEE
00258558 NSt6__ndk114__codecvt_utf8IwEE
00258577 NSt6__ndk17codecvtIwc9mbstate_tEE
00258599 NSt6__ndk16locale5__impE
002585b2 NSt6__ndk114collate_bynameIcEE
002585d1 NSt6__ndk17collateIcEE
002585e8 NSt6__ndk114collate_bynameIwEE
00258607 NSt6__ndk17collateIwEE
0025861e NSt6__ndk15ctypeIcEE
00258633 NSt6__ndk112ctype_bynameIcEE
00258650 NSt6__ndk112ctype_bynameIwEE
0025866d NSt6__ndk18numpunctIcEE
00258685 NSt6__ndk18numpunctIwEE
0025869d NSt6__ndk115numpunct_bynameIcEE
002586bd NSt6__ndk115numpunct_bynameIwEE
002586dd NSt6__ndk17num_getIcNS_19istreambuf_iteratorIcNS_11char_traitsIcEEEEEE
00258724 NSt6__ndk19__num_getIcEE
0025873d NSt6__ndk114__num_get_baseE
00258759 NSt6__ndk17num_getIwNS_19istreambuf_iteratorIwNS_11char_traitsIwEEEEEE
002587a0 NSt6__ndk19__num_getIwEE
002587b9 NSt6__ndk17num_putIcNS_19ostreambuf_iteratorIcNS_11char_traitsIcEEEEEE
00258800 NSt6__ndk19__num_putIcEE
00258819 NSt6__ndk114__num_put_baseE
00258835 NSt6__ndk17num_putIwNS_19ostreambuf_iteratorIwNS_11char_traitsIwEEEEEE
0025887c NSt6__ndk19__num_putIwEE
00258895 NSt6__ndk18time_getIcNS_19istreambuf_iteratorIcNS_11char_traitsIcEEEEEE
002588dd NSt6__ndk19time_baseE
002588f3 NSt6__ndk120__time_get_c_storageIcEE
00258918 NSt6__ndk18time_getIwNS_19istreambuf_iteratorIwNS_11char_traitsIwEEEEEE
00258960 NSt6__ndk120__time_get_c_storageIwEE
00258985 NSt6__ndk115time_get_bynameIcNS_19istreambuf_iteratorIcNS_11char_traitsIcEEEEEE
002589d5 NSt6__ndk118__time_get_storageIcEE
002589f8 NSt6__ndk110__time_getE
00258a10 NSt6__ndk115time_get_bynameIwNS_19istreambuf_iteratorIwNS_11char_traitsIwEEEEEE
00258a60 NSt6__ndk118__time_get_storageIwEE
00258a83 NSt6__ndk18time_putIcNS_19ostreambuf_iteratorIcNS_11char_traitsIcEEEEEE
00258acb NSt6__ndk110__time_putE
00258ae3 NSt6__ndk18time_putIwNS_19ostreambuf_iteratorIwNS_11char_traitsIwEEEEEE
00258b2b NSt6__ndk115time_put_bynameIcNS_19ostreambuf_iteratorIcNS_11char_traitsIcEEEEEE
00258b7b NSt6__ndk115time_put_bynameIwNS_19ostreambuf_iteratorIwNS_11char_traitsIwEEEEEE
00258bcb NSt6__ndk110moneypunctIcLb0EEE
00258bea NSt6__ndk110money_baseE
00258c02 NSt6__ndk110moneypunctIcLb1EEE
00258c21 NSt6__ndk110moneypunctIwLb0EEE
00258c40 NSt6__ndk110moneypunctIwLb1EEE
00258c5f NSt6__ndk117moneypunct_bynameIcLb0EEE
00258c85 NSt6__ndk117moneypunct_bynameIcLb1EEE
00258cab NSt6__ndk117moneypunct_bynameIwLb0EEE
00258cd1 NSt6__ndk117moneypunct_bynameIwLb1EEE
00258cf7 NSt6__ndk19money_getIcNS_19istreambuf_iteratorIcNS_11char_traitsIcEEEEEE
00258d40 NSt6__ndk111__money_getIcEE
00258d5c NSt6__ndk19money_getIwNS_19istreambuf_iteratorIwNS_11char_traitsIwEEEEEE
00258da5 NSt6__ndk111__money_getIwEE
00258dc1 NSt6__ndk19money_putIcNS_19ostreambuf_iteratorIcNS_11char_traitsIcEEEEEE
00258e0a NSt6__ndk111__money_putIcEE
00258e26 NSt6__ndk19money_putIwNS_19ostreambuf_iteratorIwNS_11char_traitsIwEEEEEE
00258e6f NSt6__ndk111__money_putIwEE
00258e8b NSt6__ndk18messagesIcEE
00258ea3 NSt6__ndk113messages_baseE
00258ebe NSt6__ndk18messagesIwEE
00258ed6 NSt6__ndk115messages_bynameIcEE
00258ef6 NSt6__ndk115messages_bynameIwEE
00258f16 NSt6__ndk114codecvt_bynameIcc9mbstate_tEE
00258f40 NSt6__ndk114codecvt_bynameIwc9mbstate_tEE
00258f6a NSt6__ndk114codecvt_bynameIDsc9mbstate_tEE
00258f95 NSt6__ndk114codecvt_bynameIDic9mbstate_tEE
00258fc0 NSt6__ndk115__time_get_tempIcEE
00258fe0 NSt6__ndk115__time_get_tempIwEE
00259000 NSt6__ndk114__shared_countE
0025901c NSt6__ndk119__shared_weak_countE
0025903e St19bad_optional_access
0025910b ]xEc
00259120 00010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899NSt6__ndk112system_errorE
00259202 NSt6__ndk114error_categoryE
0025921e NSt6__ndk112__do_messageE
00259238 NSt6__ndk124__generic_error_categoryE
0025925e NSt6__ndk123__system_error_categoryE
00259283 St18bad_variant_access
002597af <Pcjv
002597de ""i""""""""""""""""""""""""""""{""m
00259802 66666666666666666
00259814 6666666666666tx
00259824 rrrr
00259829 rrrrrrrrrrrrr
00259837 rrrrrrrrrrrr
00259921 	6												
00259a5c  (N12_GLOBAL__N_116itanium_demangle11SpecialNameE
00259a8e N12_GLOBAL__N_116itanium_demangle4NodeE
00259ab6 N12_GLOBAL__N_116itanium_demangle21CtorVtableSpecialNameE
00259af0 N12_GLOBAL__N_116itanium_demangle8NameTypeE
00259b1c N12_GLOBAL__N_116itanium_demangle10NestedNameE
00259b4b N12_GLOBAL__N_116itanium_demangle24ForwardTemplateReferenceE
00259b88 N12_GLOBAL__N_116itanium_demangle14IntegerLiteralE
00259bbb N12_GLOBAL__N_116itanium_demangle8BoolExprE
00259be7 N12_GLOBAL__N_116itanium_demangle16FloatLiteralImplIfEE
00259c1f N12_GLOBAL__N_116itanium_demangle16FloatLiteralImplIdEE
00259c57 N12_GLOBAL__N_116itanium_demangle16FloatLiteralImplIeEE
00259c8f N12_GLOBAL__N_116itanium_demangle13StringLiteralE
00259cc1 N12_GLOBAL__N_116itanium_demangle15UnnamedTypeNameE
00259cf5 N12_GLOBAL__N_116itanium_demangle26SyntheticTemplateParamNameE
00259d34 N12_GLOBAL__N_116itanium_demangle21TypeTemplateParamDeclE
00259d6e N12_GLOBAL__N_116itanium_demangle24NonTypeTemplateParamDeclE
00259dab N12_GLOBAL__N_116itanium_demangle25TemplateTemplateParamDeclE
00259de9 N12_GLOBAL__N_116itanium_demangle21TemplateParamPackDeclE
00259e23 N12_GLOBAL__N_116itanium_demangle15ClosureTypeNameE
00259e57 N12_GLOBAL__N_116itanium_demangle10LambdaExprE
00259e86 N12_GLOBAL__N_116itanium_demangle15IntegerCastExprE
00259eba N12_GLOBAL__N_116itanium_demangle13FunctionParamE
00259eec N12_GLOBAL__N_116itanium_demangle8FoldExprE
00259f18 N12_GLOBAL__N_116itanium_demangle22ParameterPackExpansionE
00259f53 N12_GLOBAL__N_116itanium_demangle10BinaryExprE
00259f82 N12_GLOBAL__N_116itanium_demangle10PrefixExprE
00259fb1 N12_GLOBAL__N_116itanium_demangle8CastExprE
00259fdd N12_GLOBAL__N_116itanium_demangle8CallExprE
0025a009 N12_GLOBAL__N_116itanium_demangle14ConversionExprE
0025a03c N12_GLOBAL__N_116itanium_demangle10DeleteExprE
0025a06b N12_GLOBAL__N_116itanium_demangle13QualifiedNameE
0025a09d N12_GLOBAL__N_116itanium_demangle8DtorNameE
0025a0c9 N12_GLOBAL__N_116itanium_demangle22ConversionOperatorTypeE
0025a104 N12_GLOBAL__N_116itanium_demangle15LiteralOperatorE
0025a138 N12_GLOBAL__N_116itanium_demangle19GlobalQualifiedNameE
0025a170 N12_GLOBAL__N_116itanium_demangle10MemberExprE
0025a19f N12_GLOBAL__N_116itanium_demangle18ArraySubscriptExprE
0025a1d6 N12_GLOBAL__N_116itanium_demangle10BracedExprE
0025a205 N12_GLOBAL__N_116itanium_demangle15BracedRangeExprE
0025a239 N12_GLOBAL__N_116itanium_demangle12InitListExprE
0025a26a N12_GLOBAL__N_116itanium_demangle11PostfixExprE
0025a29a N12_GLOBAL__N_116itanium_demangle7NewExprE
0025a2c5 N12_GLOBAL__N_116itanium_demangle13EnclosingExprE
0025a2f7 N12_GLOBAL__N_116itanium_demangle15ConditionalExprE
0025a32b N12_GLOBAL__N_116itanium_demangle19SizeofParamPackExprE
0025a363 N12_GLOBAL__N_116itanium_demangle13NodeArrayNodeE
0025a395 N12_GLOBAL__N_116itanium_demangle9ThrowExprE
0025a3c2 N12_GLOBAL__N_116itanium_demangle10UUIDOfExprE
0025a3f1 N12_GLOBAL__N_116itanium_demangle27ExpandedSpecialSubstitutionE
0025a431 N12_GLOBAL__N_116itanium_demangle12CtorDtorNameE
0025a462 N12_GLOBAL__N_116itanium_demangle10AbiTagAttrE
0025a491 N12_GLOBAL__N_116itanium_demangle21StructuredBindingNameE
0025a4cb N12_GLOBAL__N_116itanium_demangle9LocalNameE
0025a4f8 N12_GLOBAL__N_116itanium_demangle19SpecialSubstitutionE
0025a530 N12_GLOBAL__N_116itanium_demangle13ParameterPackE
0025a562 N12_GLOBAL__N_116itanium_demangle12TemplateArgsE
0025a593 N12_GLOBAL__N_116itanium_demangle20NameWithTemplateArgsE
0025a5cc N12_GLOBAL__N_116itanium_demangle16StdQualifiedNameE
0025a601 N12_GLOBAL__N_116itanium_demangle20TemplateArgumentPackE
0025a63a N12_GLOBAL__N_116itanium_demangle12EnableIfAttrE
0025a66b N12_GLOBAL__N_116itanium_demangle16FunctionEncodingE
0025a6a0 N12_GLOBAL__N_116itanium_demangle9DotSuffixE
0025a6cd N12_GLOBAL__N_116itanium_demangle12NoexceptSpecE
0025a6fe N12_GLOBAL__N_116itanium_demangle20DynamicExceptionSpecE
0025a737 N12_GLOBAL__N_116itanium_demangle12FunctionTypeE
0025a768 N12_GLOBAL__N_116itanium_demangle13ObjCProtoNameE
0025a79a N12_GLOBAL__N_116itanium_demangle17VendorExtQualTypeE
0025a7d0 N12_GLOBAL__N_116itanium_demangle8QualTypeE
0025a7fc N12_GLOBAL__N_116itanium_demangle15PixelVectorTypeE
0025a830 N12_GLOBAL__N_116itanium_demangle10VectorTypeE
0025a85f N12_GLOBAL__N_116itanium_demangle9ArrayTypeE
0025a88c N12_GLOBAL__N_116itanium_demangle19PointerToMemberTypeE
0025a8c4 N12_GLOBAL__N_116itanium_demangle22ElaboratedTypeSpefTypeE
0025a8ff N12_GLOBAL__N_116itanium_demangle11PointerTypeE
0025a92f N12_GLOBAL__N_116itanium_demangle13ReferenceTypeE
0025a961 N12_GLOBAL__N_116itanium_demangle20PostfixQualifiedTypeE
0025aa01 KKKK6
0025aa80 N10__cxxabiv116__shim_type_infoE
0025aaa1 N10__cxxabiv117__class_type_infoE
0025aac3 N10__cxxabiv117__pbase_type_infoE
0025aae5 N10__cxxabiv119__pointer_type_infoE
0025ab09 N10__cxxabiv120__function_type_infoE
0025ab2e N10__cxxabiv129__pointer_to_member_type_infoE
0025ab5c N10__cxxabiv123__fundamental_type_infoE
0025ab8b N10__cxxabiv120__si_class_type_infoE
0025abb0 N10__cxxabiv121__vmi_class_type_infoE
0025abd6 St9exception
0025abe3 St13bad_exception
0025abf5 St9bad_alloc
0025ac02 St11logic_error
0025ac12 St16invalid_argument
0025ac27 St12length_error
0025ac38 St12out_of_range
0025ac49 St11range_error
0025ac59 St13runtime_error
0025ac6b St14overflow_error
0025ac7e St9type_info
0025ac8b St8bad_cast
0030ab81 zPLR
00373cf1 "@9h
00373de8 h"@9h
00373e81 "@9h
00373fbd "@9h
003740fd "@9h
00374b63 6`.@
003756c1 R@9	
00375920 ?k88w
00375ae3 6`B@
00375b93 7h"@9H
00375bb8 h"@9
00375f81 S@9"
0037696f R!(&
0037745f *!T@
00377bd1 c@9h
00377c21 "@9h
00377c85 c@9h
00377f01 #@9h
00377f31 "@9h
00378165 "@9h
0037860b <amC
00378743 <amC
0037889f <amC
00378b1d "@9h
00378dcd "@9h
003792d2 @9(	
003794cd "@9h
003794f1 "@9h
00379721 "@9h
00379745 "@9h
003797a5 "@9h
003797f9 B@9h
00379bf4 h"@9
00379c3d B@9h
00379de1 "@9h
00379e17 7hB@9
00379e2c hB@9h
00379f79 "@9h
0037a1e5 #@9h
0037a215 "@9h
0037a3e5 #@9h
0037a415 "@9h
0037a5e5 #@9h
0037a615 "@9h
0037a8ef R!@;
0037aed1 "@9h
0037b011 "@9h
0037b337 *!T@
0037b5ef *!T@
0037bdf3 R!`(
0037bf41 "@9h
0037c08d "@9h
0037c1d9 "@9h
0037c351 "@9h
0037c4d5 "@9h
0037c659 "@9h
0037c965 "@9h
0037cb3f 6`.@
0037cb5f 6`"@
0037cbc8 h"@9h
0037d499 #@9t
0037d513 7hB@9
0037d528 hB@9h
0037d575 j68/L
0037d585 #@9t
0037d7f9 B@9h
0037d8fc (C@9
0037d914 (C@9)
0037dc65 j(8v
0037dca8 h"@9h
0037de69 j(8v
0037deac h"@9h
0037e06d j(8v
0037e0b0 h"@9h
0037e9af Rwm$
0037edf7 Rel$
0037ee07 Ral$
0037f14f T@;@
0037fb0b R!  
003805cc +yhxJ	
003805db Rlf$
0038062b RXf$
003806cf R!(#
00380728 +yhxJ	
003809b8 (a@9
003809bf 5(	@
00380d43 R!  
00380e3b RTd$
00381197 R}c$
003811e7 Ric$
0038127b RDc$
003813bb =A	@
0038144b =A	@
0038159b R|b$
003815eb Rhb$
003816f3 *!T@
00381783 *!T@
00381813 *!T@
00381887 *!T@
003818fb *!T@
0038196f *!T@
003819e3 *!T@
00381a57 *!T@
00381acb *!T@
00381b3f *!T@
00381bb3 *!T@
00381c4d CB9h
00381da5 CB9h
00381efd CB9h
00382055 CB9h
003821ad CB9h
00382305 CB9h
0038245d CB9h
003825b5 CB9h
00382715 CB9H
0038280d CB9h
003832a3 R:[$
00383387 *!T@
00383407 *!T@
003836c1 C@9h
0038370b R!46
0038374b R!d6
00383a83 *!T@
00383b03 *!T@
00384a91 B@9(
00384fe7 *!T@
0038525f 7h"A9
0038526f 7hb@9
003852c1 B@9h
003852dc h"A9H
003852e3 6`.@
003852f3 6`"@
003852fc hb@9
00385463 6`.@
003854e0 k"A9h
003854f3 6`.@
0038555b 6`*@
0038559b 6`*@
003857eb Tj.@
003858fb *yW$
00385adf T+Q$
00385c3f oZk@
003860c8 ?k78
00386263 oZk@
00386438 ?k78
00386504 ( @9)
00386524 	S@y
003865f3 TfN$
00386648 	SBy
00386697 =	#\
003867bb 6`J@
003867cb 6`.@
003867db 6`"@
003868b9 kv8h
00386985 B@9h
003869f0 hBC9
003869ff 7h"A9H
00386a0f 7hB@9
00386a3b 6`J@
00386a44 h"A9
00386a4b 6`.@
00386a5b 6`"@
00386a64 hB@9
00386b5d B@9h
00386f74 kC@9l
003870c4 	A@9
003870ec 	A@9
0038711c 	A@9
003872bd ki8JE@9_
0038734d ki8JE@9_
00387607 4hB@9h
00387a6a @9(hh8)
00387c70 	i78	i*8
00387dcd j58h
0038805e @9kq}
00388064 (hh8*hi8)}@
00388161 kv8h
0038831f TtV@
0038851b *!T@
003887f4 h"@9h
00388ae3 *!T@
00388bb8 )ijx?
00388c93 *!T@
00388d68 +ikx
00388d94 *ijx_
00388e5b *!T@
00388fdb *!T@
0038911b o{k@
00389278 )ijx?
00389353 *!T@
00389428 +ikx
00389454 *ijx_
0038951b *!T@
0038969b *!T@
0038a29f T@+@
0038a5a7 Ry>$
0038a5b7 Ru>$
0038a9e8 +ikx
0038aa14 *ijx_
0038aa26 @y?!
0038aadb *!T@
0038ac5b *!T@
0038adef Tt.@
0038aea8 +ikx
0038aed4 *ijx_
0038af9b *!T@
0038b11b *!T@
0038b3bb *!T@
0038b5ac +ikx
0038b5d8 *ijx_
0038b5ea @y?-
0038b69f *!T@
0038b81f *!T@
0038ba10 +ikx
0038ba3c *ijx_
0038ba4e @y?!
0038bb03 *!T@
0038bc83 *!T@
0038bd58 +ikx
0038bd84 *ijx_
0038be4b *!T@
0038bfcb *!T@
0038c14f *!T@
0038c224 +ikx
0038c250 *ijx_
0038c262 @y?-
0038c317 *!T@
0038c497 *!T@
0038c60b *!T@
0038ce30 (a@9
0038ce37 5(	@
0038d513 *!T@
0038d607 Ra2$
0038d92b *!T@
0038da1f R[1$
0038dd0b *!T@
0038ddff Rc0$
0038df83 *!T@
0038e473 *!T@
0038e5d3 *!T@
0038ed63 Tub@
0038f1db Tu"@
0038f631 B@9h
0038f78c kC@9l
0038f8dc 	A@9
0038f904 	A@9
0038f934 	A@9
0038fad5 ki8JE@9_
0038fb65 ki8JE@9_
0038fbdb Ra"@
0038fe39 @@9(
0038fe50 hB@9h
0038ff13 o9k@
0038ff61 #@9h
00390761 ji8JE@9_
00390809 ji8JE@9_
00390ea5 "@9h
003910fd "@9h
00391229 "@9h
00391473 =	i@
0039176d CC9h
003917df R!XB
003919cf R5&$
00391d8f RE%$
00391e8b o)i@
00391ed3 R!0 
00391eeb R!p"
00391f18 hbV9tb
00391f44 hbV9
003921b1 b@9(D
00392227 *!T@
00392255 CC9h
003923e1 CB9h
003924f7 Rk#$
00392667 R!0 
0039267f R!p"
00392765 CC9h
00392975 #F9h
00392985 CC9(
003929bd CC9h
00392a95 "@9h
00392c6d "@9h
00392c91 "@9h
00392ced "@9h
00392d8f *!T@
00392da1 "@9h
00392e1f *!T@
00392e9f *!T@
00392f1f *!T@
00392f9f *!T@
00392faf Rv|$
0039301b *!T@
00393369 #F9H
003935df *!T@
00393629 "@9h
0039364d "@9h
003938a9 k78u
00393ae3 6`6@
00393b19 @@9H
00393bcf 9(h@
00393ec4 h* 9hb 
00393f63 *UG"
00393f72 #9x~
0039409c hbV9h
0039416b 6`.@
0039464d B@9(
00394700 h"@9h
00394778 *iu8
0039484b <h"@9
003948c8 *iv8
00394ed8 h* 9hb 
00394f77 *PC"
00394f86 #9{~
00394fd8 h"@9h
00395023 RYt$
003950a3 *!T@
003951e4 hbV9h
00395267 6`.@
00395654 h* 9 
0039571b *gA"
0039572a #9y~
0039579f Rzr$
0039580b *!T@
00395974 hbV9h
003959fb 6`.@
00395ac9 cA9h
00395cd7 7hbV9h
00395d11 "@9h
00395d70 *iv8
00395e4b =h"E9
00395e64 h"A9
00395e80 hbV9
00395eb8 h"A9
00395ebf 6`.@
0039616d @O9h
00396a2b R! )
00396a9d c@9h
00396aed c@9h
00396c75 c@9h
00397229 B@9h
0039728d #@9h
00397403 RK|$
003978a1 CE9h
00397bf8 ?i(8
00397cb0 ?i(8
00397d68 ?i(8
00397e95 #B9h
00398011 #@9H
003981a3 2Ab#
00398324 h"@9
00398360 h"@9
003985f8 (#@9h
003986b1 #@9h
003986f4 h"@9h
0039890d BO9(
003989e1 "@9h
00398aa5 j48B
00398b00 h"@9h
00398b24 h"@9h
00398b7d #@9h
00398bb5 #@9h
00398bcd #@9h
00398d27 oZk@
00398dc5 #@9h
00398e0d #@9h
00398e70 h"@9h
00399175 c@9h
00399225 c@9h
00399372 \8H	
00399bc9 C@9h
00399f87 <h"@9
00399ffd "`9H
0039a628 ?k78
0039a641 #C9h
0039a899 #C9	
0039a9c6 @y?-
0039acc6 @y_M
0039accf T)%@yi
0039acee @y_U
0039acf7 T))@y)
0039ad1f T)	@y
0039b2df Tl|$
0039b4a5 CC9h
0039b4f1 "`9H
0039b819 CC9h
0039b855 CC9h
0039ba01 CC9h
0039bed9 CC9h
0039c084 h"@9h
0039c14d "@9h
0039cb11 & 9)
0039ceb5 CC9h
0039d452 X8h!
0039db53 Rwb$
0039df4f k$	@
0039e023 k$	@
0039e37d "@9h
0039e3a1 "@9h
0039e681 "@9h
0039e6a5 "@9h
0039ead7 osj@
0039f091 c@9h
0039f12b R)M*
0039f165 c@9h
0039f1f1 c@9h
0039f259 c@9h
0039f311 c@9h
0039f697 *!T@
0039f7df o{k@
0039f901 #@9h
0039fb0b *!T@
0039fd4f oZk@
0039fdd1 #@9h
003a00f0 	!@9
003a0124 h!@9k%
003a01cc 	'`9
003a0446 D9H!
003a0481 CK9h
003a0789 CK9h
003a0818 h"@9h
003a0a74 H!@9J%A
003a0b43 9	SF
003a0be5 "@9h
003a0c09 "@9h
003a0c61 "@9h
003a0e11 cO9h
003a0ea0 H#@9h
003a0f41 "@9h
003a0f65 "@9h
003a0f95 CK9h
003a14c7 R0C$
003a152b *!T@
003a1ab9 cB9h
003a1c69 cB9h
003a1eab 6`>@
003a1fff *!T@
003a2049 "@9h
003a206d "@9h
003a2165  @9h
003a21df 6`F@
003a225b 6`>@
003a22f4 h"@9h
003a2318 h"@9h
003a25f4 (#@9
003a3229 &`9H
003a3793 R!d:
003a379d #@9h
003a39f7 *,4#
003a3a5b 7[:$
003a3b59 j48T
003a3bb3 oZk@
003a3bd9 #@9h
003a3e27 6`2@
003a3ef7 o{k@
003a3f5b R!T2
003a3ff5 #@9h
003a439f Rz7$
003a4880 ( @9
003a4899 R@y`
003a4985 RByh
003a4bbe @9	C
003a4c2a @9	C
003a4c33 9H#@
003a4d49 iw8)	
003a4f5b TtV@
003a5036 @9v.@
003a5077 TtZ@
003a56a8 hB@9t
003a5b67 <`*@
003a5c15 kv8h
003a5c95  A9h
003a5dbf 6`6@
003a5e4f 6`6@
003a5ed8 kbA9h
003a5eeb 6`6@
003a603b TA[@
003a60cc 	i+8	i*8
003a6244 	i+8	i*8
003a6353 7hB@9
003a6368 hB@9h
003a6633 4`"@
003a6647 4`6@
003a672f 4`"@
003a6767 4`2@
003a679b T`2@
003a67f3 4`"@
003a6807 4`6@
003a6953 q`>@
003a6a6f 6hJ@
003a6af3 Rc>@
003a6b1b T`>@
003a6b6b T`B@
003a6ba7 *`>@
003a6bb3 RkN$
003a6d6f T`"@
003a6e1f Th"@
003a6f45 pB9H
003a7331 B@9h
003a73ff TtV@
003a75ad ji8JE@9_
003a7655 ji8JE@9_
003a7a39 ki8JE@9_
003a7ac9 ki8JE@9_
003a7d83 4hB@9h
003a7ee8 kC@9l
003a8038 	A@9
003a8060 	A@9
003a8090 	A@9
003a8231 ki8JE@9_
003a82c1 ki8JE@9_
003a832f Ra"@
003a86e8 kC@9l
003a8838 	A@9
003a8860 	A@9
003a8890 	A@9
003a89c9 B@9h
003a8ba2 4*i"@
003a8c04 ?i(8
003a8c13 Th&C
003a8cec ?i(8
003a8cfb Th&C
003a8e9b ThBA9
003a8f28 ?i(8
003a8f37 Ti"C
003a906c ?i(8
003a907b Th&C
003a909e @yk2B
003a9103 KjB@
003a9128 +	@y)!
003a9139 j+xC
003a913f TybB
003a9148 iFA9
003a929d ju8(
003a92d0 hb@9h
003a93b7 Tm>B)n
003a9505 iq8p	
003a9586 @y?-
003a95cf TJii
003a964e @y?!"ki
003a9657 TI<@
003a969f T)ih
003a97bb Tl>B)n
003a9813 T.ilx.
003a98bb T/im
003a9992 @y?%
003a99df TJii
003a9a42 @y?-
003a9a92 @y?5
003a9ace @y?=
003a9b26 @y?E
003a9b76 @y?M
003a9bbe @y?U
003a9c0e @y?]
003a9c4a @y?]
003a9df7 T+DB)/
003a9faa @zA0
003a9fd3 Tl>B)n
003aa02b T.ilx
003aa097 T0im
003aa1ab TNim
003aa252 @y?%
003aa28e @y?%
003aa2ca @y?-
003aa322 @y?5
003aa372 @y?5
003aa3c2 @y?=
003aa3fe @y?=
003aa44e @y?E
003aa48a @y?E
003aa4da @y?M
003aa516 @y?M
003aa566 @y?U
003aaa68 1jk8
003aaaf0 1jk8
003aac5b Tm>B)n
003aada5 ip8/
003aaeee @y?-
003aaf46 @y?5
003aafa2 @y?=
003aafde @y?=
003ab08b RK}}
003ab177 TiFB)o
003ab1cf TPiox
003ab233 THiq
003ab2bf THia8(
003ab2f7 THiq
003ab383 THia8
003ab3bb THil
003ab483 TnBB)o
003ab4db T/inx
003ab525 	@yq
003ab54b T(ip
003ab5cb T(ia8(
003ab637 T(ik
003ab72b TmBB)n
003ab785 inxO
003ab8f3 T0ioxP
003ab98b T)ik
003aba2b TjFB)o
003aba83 T0iox
003abacd 	@y0
003abb23 T(il
003abbcf TiFB)o
003abc27 Tpiox
003abc8b Thin
003abca9 	@yn
003abdfb Tm>B)n
003abed9 	@y(
003abf4f TJii
003ac067 T+DB)/
003ac0bf T0iox
003ac16f T(in
003ac1fb T(il8h
003ac25f Tm>B)n
003ac2f5 	@yp
003ac4d2 @y?-
003ac562 @y?=
003ac59e @y?E
003ac5a9 !@yh
003ac5f6 @y?M
003ac652 @y?U
003ac68e @y?U
003ac6de @y?]
003ac71a @y?]
003ac76a @y?e
003ac7a6 @y?e
003ac7f6 @y?m
003ac846 @y?u
003ac882 @y?u
003acaa3 Tm>B)n
003acafb Tnimx
003acb39 	@yp
003acb5f Tqio
003acbdf Toiq8o#
003acc17 Tqio
003acc97 Tkil8
003acd22 @y?=
003acd7e @y?E
003acdc6 @y?M
003ace0e @y?U
003ace5e @y?]
003aceae @y?e
003aceea @y?e
003acf3a @y?m
003acf76 @y?m
003acfc6 @y?u
003ad002 @y?u
003ad20f T*DB)/
003ad267 Tpiox
003ad2e7 Thiq
003ad39b Thin
003ad47b Th>B)n
003ad4d3 T.ihx
003ad53b T)ik
003ad559 	@y)
003ad5cf Tkij
003ad61a @y?%
003ad663 TJii
003ad72f TiFB)o
003ad787 Tpiox
003ad7eb Thin
003ad809 	@yn
003ad95b T)DB)/
003ad9b3 Tpiox
003ada17 Thip
003adab3 Thic8
003adaef Tqin
003adba3 6hjt
003adc4b Tm>B)n
003ade1a @y?-
003ade63 TJii
003adebe @y?-
003adf53 T+DB)-
003ae183 T+DB)/
003ae1db T0iox
003ae23f T(iq
003ae2cb T(ib8
003ae303 T(in
003ae38f T(il8
003ae3f7 TiFB)o
003ae44f Tpiox
003ae4b3 Thin
003ae4d1 	@yn
003ae623 T)DB)/
003ae67b Tpiox
003ae6df Thip
003ae77b Thic8
003ae7b7 Tqin
003ae86b 6hjt
003ae913 T)DB)/
003ae96b Tpiox
003ae9cf Thip
003aea6b Thic8
003aeaa7 Tqin
003aeb5b 6hjt
003aebef T+DB)/
003af65f 6`2@
003af6dc kBA9h
003af6ef 6`2@
003af7c7 o9k@
003af7fb R!H$
003afb84 kC@9l
003afcd4 	A@9
003afcfc 	A@9
003afd2c 	A@9
003afecd ki8JE@9_
003aff5d ki8JE@9_
003affeb Ra"@
003b0231 @@9(
003b0237 4`:@
003b0248 hB@9h
003b03a1 ji8JE@9_
003b0449 ji8JE@9_
003b04e9  @9h
003b064d ki8JE@9_
003b06dd ki8JE@9_
003b0743 Ra"@
003b098f 4hB@9h
003b0af4 kC@9l
003b0c44 	A@9
003b0c6c 	A@9
003b0c9c 	A@9
003b0dfb Tt"@
003b1174 ?i(8
003b122c ?i(8
003b12c0 ?i(8
003b12cf Th&C
003b12fb 6iVB
003b1370 ?i(8
003b137f Th&C
003b14b1 B@9h
003b16cd C@9(
003b16e5 B@9h
003b1af5 B@9kB
003b1c13 oZk@
003b2299 B@9h
003b22d4 	a@9i
003b22e5 ku8(
003b2350 	a@9i
003b2361 ku8(
003b239c h"R9h
003b24df Ti2A
003b24f4 *!@9
003b2558 *iu8
003b2610 hbA9
003b268c hbA9H
003b2693 6`6@
003b26a3 6`*@
003b2907 Ti~@
003b2aa3 R( 	
003b2dad j58h
003b30bf *`kh
003b3225 i`8_
003b3265 i)8k
003b3390 *i68*i+8
003b33a8 )iv8?
003b348c +il8*i,8*i(8h
003b34d7 Rji68ji)8
003b34fb =J	@
003b374f <`B@
003b39b4 +ih8J	
003b3a73 4`>@
003b3d83 R)u#
003b3e2d #@9h
003b3fab R)u#
003b4075 #@9h
003b420b R)u#
003b42b5 #@9h
003b4775 "@9h
003b53af o)i@
003b53be @9)A
003b5426 A9JA
003b5709 B@9h
003b573c *iv8
003b57a3 TiZ@
003b57b4 *iv8
003b59fb T`N@
003b5a3f T`B@
003b5a60 h"A9h
003b5a6f 7hb@9
003b5a9f 6`"@
003b5aa8 hb@9h
003b5bec hBA9t
003b5bf7 6`2@
003b5c28 hB@9
003b5d1c (`A9H
003b5d77 6`*@
003b5dd0 hBA9H
003b5e0b 6`&@
003b61c9 i`8_
003b6209 i)8k
003b62fb RJ	C
003b6301 j88l
003b634f 7+{h
003b64e1 i/8)
003b6571 ia8"
003b658d i"8!
003b6971 ji8JE@9_
003b6a19 ji8JE@9_
003b6bb9 ji8JE@9_
003b6c61 ji8JE@9_
003b6f13 TI#@
003b71d7 Ti#@
003b73c2  6i*D
003b73d2 A9k*@
003b7a67 oZk@
003b7bac 	 @9)
003b7c02 A9h!
003b7c54 (C@9h
003b81e0 h"@9h
003b8399 #C9h
003b8749 #@9h
003b8791 "@9h
003b87b5 "@9h
003b87dd cA9h
003b88b9 cA9h
003b8901 cA9(
003b89b8 	 @9
003b8c71 cF9h
003b9293 RcL$
003b954b Th#@
003b9a47 RcL$
003b9b53 Th#@
003b9c7d cF9h
003b9c8e E9hJ
003ba1e1 cF9h
003ba231 cF9h
003ba271 cF9h
003ba2f9 cF9h
003ba339 cF9h
003ba3b1 cF9h
003ba429 cF9h
003ba469 cF9h
003ba50d cF9h
003ba541 cF9h
003ba575 cF9h
003ba5a9 cF9h
003ba65d CD9h
003baead h68B
003bafbd #@9h
003bb021 #@9h
003bb07d  A9h
003bb083 6`.@
003bb0ec Lii8k	
003bb100 	 @9
003bb1d9 #@9h
003bb2f9 #@9(
003bb399 #@9(
003bb619 c@9h
003bb671 c@9h
003bb8d1 CB9h
003bb8f2 @9 !
003bb93a @9?|
003bbab1 CB9h
003bbad2 @9 !
003bbb0a @9?|
003bbd29 CB9H
003bbd65 cA9(
003bbd75 CB9H
003bbdb5 CB9(
003bbe35 CB9(
003bbe45 CB9h
003bbea9  B9h
003bbeaf 6`N@
003bc115 @A9h
003bc11b 6`2@
003bc1eb Th"@
003bc200 iB@9h
003bc24c +ih8J	
003bc443 =hb@9
003bc487 Th&D
003bc528 jkh8)	
003bc61b Ti"B
003bc653 Th"@
003bc7b3 =hb@9
003bc7f7 Th&D
003bc8b1 yixJ	
003bc8d3 Nhb@9
003bc927 Nhb@9
003bc96b Th&D
003bca2b Th&D
003bcae7 Nhb@9
003bcb2b Th&D
003bcc50 Lyixk	
003bcdef 2]x#
003bce63 2@x#
003bce87 27x#
003bd1bb =hb@9
003bd1ff Th&D
003bd2ab =hb@9
003bd4fb Th"@
003bd527 ThBA9
003bd55c hBA9
003bd57f 4hBA9
003bd6a3 Th&D
003bdbac j{hx)	
003bdf9b RiBB9hb
003bdff6 @9?|
003be09f RiBB9hb
003be11e @9?|
003be3c1 c@9H
003be6a1 c@9h
003be741 c@9h	
003be752 Z8(	
003be7c5 c@9H
003be809 c@9(
003be869 c@9h
003be8c1 c@9h
003be95b R	@B9
003bea1a @9?|
003bec05 c@9h
003bed0d #A9h
003bed3a ^8h	
003bede9 c@9H
003bee39 #A9H
003bef55 CA9h
003bf0a6 @9?|
003bf275 c@9h
003bf315 j58"
003bf37d CA9h
003bf3f9 c@9h
003bf41d CA9H
003bf485 CA9H
003bf4e1 c@9h
003bf51c abB9Q
003bf605 {hx)	
003bfa56 @9?|
003bfb7e @9?|
003bfe21 c@9H
003c0101 c@9h
003c01a1 c@9h	
003c01b2 A9(	
003c0225 c@9H
003c0269 c@9(
003c02c9 c@9h
003c0321 c@9h
003c0697 Tiju
003c0a03 6+yj
003c0a27 R(y*
003c0c11 #@9h
003c0dba @9?	
003c0fef 6+ij
003c11db 6+yj
003c11ff R(y*
003c13e9 #@9h
003c15b7 R	@B9
003c16d9 #@9(
003c1779 #@9(
003c18e0 +ih8J	
003c1946 @9?	
003c1a07 9j*@
003c1a4f ROa#
003c1a77 REa#
003c1aa3 R:a#
003c1bb6 @9v.@
003c1bf7 TtZ@
003c1ca0 +ih8J	
003c1ce0 3 @9A
003c1e76 @9_	
003c292e @9?	
003c2ae5 #@9(
003c2b85 #@9(
003c2d73 RL	@
003c2d94 La@9_
003c2dc8 La@9_
003c2e08 -`@9@
003c2e41 a@9L
003c2ec8 Ka@9K
003c2ed8 la@9
003c2eef THa@9
003c2f4c ja@9
003c2f5c La@9l
003c2f6b 9Ha@9
003c2f94 La@9_
003c2fbc ia@9
003c3010 ia@9
003c3071 a@9	
003c30c9 a@9	
003c3346 @9?	
003c3407 9j*@
003c3576 @9?	
003c3637 9j*@
003c379e @9?	
003c385f 9j*@
003c3983 8`B@
003c39ca @9?	
003c3a8b 9j*@
003c3c16 @9?	
003c3cd7 9j*@
003c3e5e @9?	
003c3f1f 9j*@
003c42ad c@9h
003c4305 c@9h
003c4545 #@9h
003c47ad #@9h
003c488e @9?	
003c48d1 iv8)	
003c4931 iv8)	
003c49af RwU#
003c49d7 RmU#
003c4a03 RbU#
003c4a1f R[U#
003c4a3f RSU#
003c4a73 RFU#
003c4ac8 +ih8J	
003c4aef R'U#
003c4c74 +ih8J	
003c4cbf TtZ@
003c4e02 @9?	
003c4faf TtZ@
003c5056 @9?	
003c5203 TtZ@
003c52aa @9?	
003c542f TtV@
003c54d6 @9?	
003c5683 TtZ@
003c5736 @9?	
003c59b3 Ttb@
003c5a92 @9?	
003c5c3f TtZ@
003c5d6a @9?	
003c6165 #@9h
003c6195 "@9h
003c6365 #@9h
003c6395 "@9h
003c69b8 h"@9h
003c6a99 j68w
003c6db3 RvL#
003c6dcf =A	@
003c6e10 h"@9h
003c6e34 h"@9h
003c6e89 "@9h
003c70fb =A	@
003c713c h"@9h
003c7160 h"@9h
003c71b5 "@9h
003c7429 "@9h
003c744d "@9h
003c7484 h"@9h
003c75b9 "@9h
003c75dd "@9h
003c762f RWJ#
003c7ad5 "@9h
003c7c75 "@9h
003c82b9 #	9t
003c82ff R#G#
003c85b1 CH9H
003c8805 CG9h
003c8ca9 CE9h
003c8f07 R!D#
003c90bc (a@9
003c90c3 5(	@
003c93a8 h"@9h
003c9524 h"@9h
003c96bb *!T@
003c974b *!T@
003c97cb *!T@
003c9a75 CE9H
003c9b6d CH9(
003c9c45 CG9h
003c9da5 "@9h
003c9f9d ki8JE@9_
003ca02d ki8JE@9_
003ca093 Ra"@
003ca2e3 4hB@9h
003ca448 kC@9l
003ca598 	A@9
003ca5c0 	A@9
003ca5f0 	A@9
003ca791 ki8JE@9_
003ca821 ki8JE@9_
003ca887 Ra"@
003caad7 4hB@9h
003cac3c kC@9l
003cad8c 	A@9
003cadb4 	A@9
003cade4 	A@9
003cb599 "@9h
003cb7c4 hB@9
003cb991 ji8JE@9_
003cba39 ji8JE@9_
003cbb29 80.	
003cbc1b Ra"@
003cbe5d @@9(
003cc2fb T$7#
003cc75b 6`"@
003ccdf1 2A9`B
003ccf0b 6`*@
003cd31d 80.	
003cd663 TJ2#
003cd848 kC@9l
003cd998 	A@9
003cd9c0 	A@9
003cd9f0 	A@9
003cdb91 ki8JE@9_
003cdc21 ki8JE@9_
003cdc8b Ra"@
003cdf93 4hBA9h
003cdf9b 6`2@
003cdfcc hB@9
003ce2cb Tj @
003ce5eb Tj @
003ce71b <( @
003ce733 =(,@
003ce74b <(0@
003ce7a7 <i*H
003ce7e7 =h&K
003cea3f RS-#
003cedc1 #@9h
003cf45f *!T@
003cf533 Ti"@
003cf9ab R>.#
003cfabf R3)#
003cfb2c (a@9(
003cfb33 5(	@
003d0197 *!T@
003d0367 Th^@
003d058c +ki8JE@9_
003d061c +ki8JE@9_
003d1141 j48`
003d11d0 	 @9
003d1210 	 @9
003d1240 	 @9
003d1657 R!$,
003d16a1 c@9H
003d176d CA9h
003d17a9 "@9h
003d1861 c@9h
003d19c7 <amC
003d1e7b R!\(
003d1f59 j68)
003d20b5 j68I
003d21cd "@9h
003d22ed c@9h
003d2475 k78(
003d24e4 h"@9h
003d2809 "@9h
003d2a8d "@9h
003d2ad1 C@9j
003d2deb Tt.@
003d2f0f o{k@
003d3201 k68C
003d3265 k68b
003d3779 "@9h
003d379d "@9h
003d387d "@9h
003d38a1 "@9h
003d3bd3 *!T@
003d4155 CD9h
003d46ad #B9(
003d4749 C@9(
003d48ad C@9h
003d490d cA9h
003d494d #B9h
003d4975 CC9(
003d49ad CC9h
003d49f5 CC9(
003d4b24 )s@9i
003d4bdb T	=@y*?@y?
003d4beb T	u@9*w@9?
003d4bfb T	q@9
003d5044 )P@9	
003d5277 T9`A):,@y;T@9<P@95
003d52b7 T	=@y?
003d52c3 T	u@9?
003d52cf T	q@9?
003d56be @8)-B
003d5797 R	U	
003d5ab8 ,ij8k	
003d5ac8 KA@9
003d5cb7 R!\6
003d5fa8 hB@9t
003d5fdb R!\6
003d6073 REp#
003d60fb R!\6
003d6173 R!h$
003d618f *5e"
003d61a7 */e"
003d62ad c@9h
003d64a8 h"@9h
003d64cc h"@9h
003d654d #@9h
003d6565 #@9h
003d67a9 #C9H
003d67e9 #@9h
003d6929 cE9H
003d6969 cB9H
003d69dd CD9H
003d6a5d CA9H
003d6cb9 CE9H
003d6cf9 CB9H
003d6d8d #D9H
003d6e0d #A9H
003d6f15 cC9H
003d6f95 c@9H
003d7607 Tt"@
003d7724 Lii8k	
003d77cc Nil8
003d77dc lA@9
003d78bb 7[s!
003d7c6d @@9h
003d7f5d @@9h
003d8079 @@9h
003d82e7 *Y`"
003d8479 ki8JE@9_
003d8509 ki8JE@9_
003d8577 Ra"@
003d88f4 kC@9l
003d8a44 	A@9
003d8a6c 	A@9
003d8a9c 	A@9
003d8b28 hB@9H
003d8ce1 ki8JE@9_
003d8d71 ki8JE@9_
003d8ddb Ra"@
003d9040 hB@9h
003d91a4 kC@9l
003d92f4 	A@9
003d931c 	A@9
003d934c 	A@9
003d95a9 @@9h
003d97b5 ki8JE@9_
003d9845 ki8JE@9_
003d9c0d ji8JE@9_
003d9cb5 ji8JE@9_
003d9de7 Tub@
003d9ec3 Tub@
003da1e5 C@9h
003da295 C@9h
003da331 C@9h
003da3ed C@9h
003da47d C@9h
003da729 C@9H
003dae8d ji8JE@9_
003daf35 ji8JE@9_
003e4331 #@9h
003e434c h"@9h
003e45e5 #@9h
003e4605 "@9h
003e47eb T)W#
003e4bb7 Rt5#
003e5077 R.E#
003e5147 Tx4#
003e525f R!x*
003e53b8 ),B)
003e53c4 ((@)
003e53df R* B
003e543b R=D#
003e5603 TI3#
003e5807 RJC#
003e5a9b T#2#
003e5bc3 R[B#
003e5d1b R!00
003e5d2b R!00
003e5d3b R!00
003e5e8b T'1#
003e65cb 7X8!
003e664b 788!
003e66d7 7=7!
003e68eb 7O7!
003e6fa0 (@@9
003e6fb4 (@@9
003e882f R@7#
003e898f 7hB@9
003e89a4 hB@9h
003e9a03 6`^@
003e9b44 hb@9
003e9bbc hB@9
003e9ef5 B@9h
003ea558 kC@9l
003ea6a8 	A@9
003ea6d0 	A@9
003ea700 	A@9
003ea7c5 B@9kB
003ea86c hB@9h
003ea9c5 ji8JE@9_
003eaa6d ji8JE@9_
003eac29 ki8JE@9_
003eacb9 ki8JE@9_
003ead33 Ra"@
003eb111 ki8JE@9_
003eb1a1 ki8JE@9_
003eb217 Ra"@
003eb5ac +ki8JE@9_
003eb63c +ki8JE@9_
003eb6bb Ra"@
003ebb2d #@9h
003ebd5d ji8JE@9_
003ebe05 ji8JE@9_
003ebfc1 ki8JE@9_
003ec051 ki8JE@9_
003ec324 hB@9h
003ec488 kC@9l
003ec5d8 	A@9
003ec600 	A@9
003ec630 	A@9
003ecc8b *!T@
003ecdab o{k@
003ecf9f *!T@
003ed123 *!T@
003ed297 *!T@
003ed40f *!T@
003ed587 *!T@
003ed6ff *!T@
003ed877 *!T@
003ed9ef *!T@
003edb67 *!T@
003edcdf *!T@
003ede57 *!T@
003edfcf *!T@
003ee147 *!T@
003ee2bf *!T@
003ee437 *!T@
003ee5af *!T@
003ee727 *!T@
003ee89f *!T@
003eea17 *!T@
003eeb8f *!T@
003eed07 *!T@
003eee7f *!T@
003eeff7 *!T@
003ef16f *!T@
003ef2e7 *!T@
003ef45f *!T@
003ef5fb *!T@
003ef767 *!T@
003efb07 *!T@
003efc03 Ra	#
003efd17 *!T@
003efe09 CA9H
003efe3d c@9(
003effe7 *!T@
003f03a7 *!T@
003f08a3 7hB@9
003f08b8 hB@9h
003f0add #@9H
003f0afb Te&#
003f0c6d ki8JE@9_
003f0cfd ki8JE@9_
003f0d4f =		@
003f11cd k:8	
003f11f1 #@9h
003f1218 +ih8J	
003f12f3 *Y+!
003f13fc ?k78
003f1470 ?k78
003f1515 #@9(
003f1555 "@9h
003f1579 "@9h
003f15e9 j68(
003f1611 #@9h
003f19b4 _k88
003f1a20 _k88
003f1a51 CC9(
003f1ab1 CC9(
003f1b91 CC9h
003f1d29 CC9h
003f1e91 CC9h
003f2039 "@9h
003f205d "@9h
003f212d "@9h
003f2151 "@9h
003f2264 h"@9h
003f2308 hB@9t
003f2619 CC9h
003f26b5 CC9h
003f2994 *!@9
003f29f8 *iv8
003f2bab 7hb@9H
003f2be7 6`"@
003f2bf0 hb@9
003f2d51 c@9h
003f33ff =)	@
003f361d "@9h
003f37ad "@9h
003f38f1 "@9h
003f3daf 7hB@9
003f3dc4 hB@9H
003f40db R	(	
003f4205 i`8_
003f4245 i)8k
003f43a0 	i+8	i*8
003f452c +i68+i*8
003f4544 *iv8_
003f45c8 ,i{8m
003f45e3 q+i;8+i(8
003f4614 zi68zi)8
003f4c5f *!T@
003f52dd i*8l
003f5407 6`F@
003f5437 7h"@9h
003f54c0 h"@9
003f5879 ki8JE@9_
003f5909 ki8JE@9_
003f595b =		@
003f5bd7 4hB@9h
003f5d3c kC@9l
003f5e8c 	A@9
003f5eb4 	A@9
003f5ee4 	A@9
003f6211 k:8B
003f626c _k88
003f62c9 k68(
003f65f3 6`F@
003f661f 6`&@
003f682f 9h*_
003f6899 c@9h
003f6925 c@9h
003f6a0d @@9H
003f6a43 4hB@9h
003f6c59 b@9(.
003f6e19 CB9h
003f7021 CB9h
003f751d B@9h
003f75f0 h"@9
003f76fd B@9h
003f7c05 C@9`
003f8374 hB@9t
003f8e39 @J9h
003f8e3f 6`RA
003f90a1 B@9(
003f917d B@9h
003f9607 *!T@
003f975d B@9h
003f97bd B@9h
003f9891 j58hB
003f99b5 80.	
003f9b6d ji8JE@9_
003f9bf9 ji8JE@9_
003f9fa1 ki8JE@9_
003fa031 ki8JE@9_
003fa093 =a"@
003fa335 B@9H
003fa4b5 ki8JE@9_
003fa545 ki8JE@9_
003fa5ab Ra"@
003fb235 #@9h
003fb401 #@9h
003fb47d 80.i
003fb591 80.i
003fb6d1 80.	
003fb7bf 9a"@
003fb9df Rky"
003fbae7 R)y"
003fbf82 A9JA
003fc284 +ki8JE@9_
003fc314 +ki8JE@9_
003fc38b Ra"@
003fc5f8 hB@9h
003fc75c kC@9l
003fc8ac 	A@9
003fc8d4 	A@9
003fc904 	A@9
003fcc59 ki8JE@9_
003fcce9 ki8JE@9_
003fcd3b =		@
003fd519 CE9H5
003fd8e1 #D9h
003fd959 CE9h
003fd9bf kD	@
003fda9d CG9h
003fdba1 CE9H
003fe001 CE9h
003fe125 CE9H
003fe2a5 #G9h
003fe5b5 #B9H
003fe769 "@9h
003fe869 "@9h
003fe899 "@9h
003fea41 "@9h
003fea79 "@9h
003feac5 CE9H
003feb45 CE9h
003fed05 CE9H
003fef7d CE9H
003ff57b TtZ@
003ff8a4 +ih8J	
003ff9a7 Ryi"
003ff9df Rki"
003ffa23 rJU*
003ffa89 C@9(
003ffe57 TtZ@
00400137 Tu^@
00400333 TtV@
004004ff TtV@
00400883 Ttf@
00400e55 B@9h
0040131d c@9h
004016df R+b"
00401735 #@9H
00401a37 *!T@
00401d39 c@9H
00402175 cA9h
004023f9 #@9H
004028cd #A9h
00402b0d #A9h
00402bcd C@9H
00402fd4 +ki8JE@9_
00403064 +ki8JE@9_
004030e3 Ra"@
0040334f 4`J@
00403360 h"A9h
00403367 6`*@
00403370 hB@9h
004034d4 kC@9l
00403624 	A@9
0040364c 	A@9
0040367c 	A@9
00403824 +ki8JE@9_
004038b4 +ki8JE@9_
00403933 Ra"@
00403ca5 ji8JE@9_
00403d4d ji8JE@9_
00404087 Tub@
00404fc1 j38 
004050f8 +ih8J	
004051af RwS"
004051c7 RqS"
0040520f R_S"
00405257 RMS"
004052f7 R%S"
004054df RqW"
0040551f RaW"
0040557f RIW"
004055bf R9W"
004055ff R)W"
004058b5 #@9h
00405a4b Th"@
00405a5f 6h"@
00405a7d WK)?a
00405e0d #@9h
00405f38 	A@9i
004061c8 )`@9
0040622d C@9h
004062a5 C@9h
00406301 C@9h
00406539 C@9h
00406df4 h"@9
00406e13 R!<%
00406e3f R!T$
00406ef1 #@9h
0040723d CA9h
004072df *!T@
004075f7 o9k@
004078c7 *!T@
00407d3b *!T@
00407ee5 ji8JE@9_
00407f8d ji8JE@9_
00408375 ji8JE@9_
0040841d ji8JE@9_
004085d2 A9JA
00408c3b R)e%
00408ecb R)!-
00408fcf RJ1 
0040a14d cE9h
0040a195 CC9h
0040a4f5 #I9h
0040a515 CC9h
0040a893 4`6@
0040a903 TH @
0040aa37 R!t>
0040ac05 cA9h
0040ae05 #@9h
0040aeb9 #@9(
0040b455 ji8JE@9_
0040b4fd ji8JE@9_
0040b6b9 ki8JE@9_
0040b749 ki8JE@9_
0040b7af Ra"@
0040b9f9 @@9(
0040ba10 hB@9h
0040bb74 kC@9l
0040bcc4 	A@9
0040bcec 	A@9
0040bd1c 	A@9
0040c003 TtV@
0040c1d4 +ki8JE@9_
0040c264 +ki8JE@9_
0040c527 4hB@9h
0040c68c kC@9l
0040c7dc 	A@9
0040c804 	A@9
0040c834 	A@9
0040cb9d #@9H
0040ccb5 #@9H
0040d0b5 c@9h
0040d381 #@9H
0040d499 #@9H
0040d775 #@9H
0040d88d #@9H
0040de8f 9(q@
0040df55 #A9(#
0040df5d #D9h#
0040e30b R!h=
0040e399 #A9h
0040e473 *f:"
0040e539 cB9H
0040e781 CC9H
0040e851 CC9H
0040e915 #D9H
0040e9fd cB9h
0040ea61 CC9H
0040eaa5 cB9(
0040eeca @-  (
0040f3b7 *i%*
0040f4a7 Rh#)
0040f6a9 #D9h
0040fac1 A@9H
0040faf9 #A9h
0040fd9d #A9H
0040fdfd CB9h
0040fe35 #A9(
0040fe55 #A9(
004100c5 #A9h
00410225 #B9(
0041070d #A9h
004109db *!T@
00411011 #@9h
00411331 c@9H
00411831 #@9h
00411acb *2,"
00411cdb *bv!
00411ddd #D9H
00411e2d c@9h
00412109 v@9h
004121d6 \8(0
004121de @9h0
00412986 @9H	
00412a59 c@9h
00412b29 c@9h
004133fb R!p"
00413651 ki8JE@9_
004136e1 ki8JE@9_
00413747 Ra"@
00413995 @@9(
004139ac hB@9h
00413b10 kC@9l
00413c60 	A@9
00413c88 	A@9
00413cb8 	A@9
00413e3d ji8JE@9_
00413ee5 ji8JE@9_
004149e1 80.	
00414abd 80.	
00414ef9 80.i
0041507f o)i@
0041508e @9)A
004150fe A9JA
00415453 o)i@
00415462 @9)A
004154ca A9JA
00415785 ki8JE@9_
00415815 ki8JE@9_
0041587b Ra"@
00415acb 4hB@9h
00415c30 kC@9l
00415d80 	A@9
00415da8 	A@9
00415dd8 	A@9
00415f5d ji8JE@9_
00416005 ji8JE@9_
0041611b o{k@
004162f7 TtV@
004164ad CA9JA
004165a5 80.i
00416903 4`6@
004169c7 4`6@
00416b59 #@9(
00416b99 #@9(
00416c2d ii8J	
00416d67 9)a@
00416dab rJU*
00417501 cF9h
004176b9 cF9h
0041774d cC9h
00417775 CD9h
00417bd3 4l}@
00417e21 #F9h
00418091 #F9H
00418fef *!T@
0041919b Tt^@
004196b9 #H9h
00419abd cC9h
0041a059 CA9H
0041a565 CA9h
0041a5cf 6h"@
0041a66f Th"@
0041a71b R!@%
0041a77d c@9h
0041ad65 cJ9h
0041adbd cJ9h
0041ae19 cJ9H
0041aef1 cG9H
0041af2d cG9h
0041afcd cG9h
0041affd cG9h
0041b33d cG9h
0041b85a Y8y#
0041bae5 #B9H
0041bcd1 cG9h
0041bec9 cG9H
0041c0ad cG9(
0041c155 #B9h
0041c1dd cG9H
0041c469 #@9h
0041cf3d #C9h
0041d1e5 #@9h
0041d475 q@)	MA)
0041d6ef *n~	
0041d7ca 	*4+
0041d90b *i~	
0041e089 #A9h
0041e281 9@)<i
0041e28d 1A)U
0041e5a7 T+E@
0041ecf7 T E@
0041f9d1 #C9h
0041fc62 I9hB
0041fd35 #E9h
00420301 #C9h
0042042d #H9h
00420679 CG9(
004206a9 #H9h
00420937 T			
00420dc1 cA9h
00421ac3 Tsb"
00421d49 #@9h
0042219b R!p#
00422215 CA9h
0042232b R!L8
00422475 CA9h
004224fd CA9(
00422665 CA9h
004226ed CA9(
004228bb R!L8
00422a33 R!p#
00422d7f Thjt8
00422e03 R!$&
00422e34 hjt8
0042317b Th'@
0042321d c@9h+
004232fb Th'@
00423433 R!\%
0042366f R!x?
00423735 #A9h
0042378f R~:"
00423813 *!T@
00423827 RX:"
004238ab *!T@
00423b43 R!t9
00423ceb R!x%
00423f1d "@9h
00424186 A9JA
0042436f o{k@
0042437e @9iC
00424777 *!T@
00424921 ji8JE@9_
004249c9 ji8JE@9_
00424b8f o)i@
00424b9e @9)A
00424c12 A9JA
00424f33 Tu^@
004250a3 o{k@
004250b2 @9iC
0042528b o)i@
0042529a @9)A
00425319 CA9JA
00425681 CA9JA
0042590d CA9JA
0042616b o)i@
0042617a @9)A
004261f9 CA9JA
004263ed CA9H
004263fd cB9h
004265e7 R!<%
0042667d cB9(
004266cf TpO"
0042674d CA9(
0042676d CA9(
00426953 *D#!
004269cb 6hVD
00426a07 7(c@9
00426bbf 6hc@9
004275df R!`/
00427669 #@9h
004279ec 	A@9
00427b1f R!H'
00427be3 T+J"
00427d89 #A9h
00427f41 CC9h
004282d1 #@9h
00428782 H-(  
00428921 CC9h
00428a01 #A9h
00428cce K-(  
00428e99 #@9h
00429151 CA9JA
00429482 	kAB
00429795 CB9H
00429935 CB9h
00429cb1 CB9h
00429d65 CB9h
0042a213 R!t>
0042a2c9 #@9h
0042a513 R!`/
0042a995 #C9h
0042b39d CA9JA
0042b89d cA9h
0042bde3 R!t>
0042bfdd #@9J
0042c071 #@9h
0042c0c5 #@9h
0042c631 cA9h
0042cd05 cA9h
0042cd75 cC9h
0042ced9 cC9h
0042d097 Z	}`
0042d225 #@9h
0042d557 R!t>
0042d715 #@9h
0042d77d #A9h
0042d7f5 #A9h
0042dd9b T(}@
0042e26d CD9h
0042e603 T+E@
0042e6e7 TjE@
0042e89b R!t>
0042eae9 #@9h
0042ee97 *!T@
0042f861 cA9h
0042fb63 *!T@
0042fe9b R!t>
0042ff0d #@9h
00430341 CK9h(
004303a1 CE9h
004306b5 CH9h
0043071f T\'"
004307bf 6(#@
00430881 CK9(
00430c0d CC9h
004310bb R!t>
0043132d C@9h
00431871 C@9h
00431c4d cA9h
004324bd CA9h
004329b7 47{<
004329cf Tw{|
00432b69 #A9h
00432c21 #A9h
00432de3 R!t>
00434125 #D9h
004341a5 #A9h
00434425 #A9h
00434581 CB9h
00434635 CB9h
0043488b R!t>
00434a19 #@9J
00434af5 CB9h
00434c67 R!$(
00434d83 R!00
00434db6 P8hH
00434e79 #@9(B
0043517b R!p&
0043540b R!(1
00435679 CB9h
0043569d cA9h
004356b9 #@9(
00435a65 #@9(
00435d7b R!`/
00435ead #@9h
00436491 cK9H
004367f6 A9Wc
00436941 cF9h
00436ae2 +*k}@
00436d61 #B9h
004373bb 6`V@
004373cb 6`>@
004373db 6`&@
0043740b 6`n@
004375e1 C@9h
004379fa B9)il
00437e31 CA9h
00437f57 7hBC9
00437f77 7hB@9
00437f94 hBC9H
00437f9b 6`n@
00437fab 6`V@
00437fbb 6`>@
00437fcb 6`&@
00437fd4 hB@9H
0043814f R!t>
004381f3 4h"@
0043821b 6h"@
00438243 6h&D
00438277 6h&D
00438415 #@9h
004388de @MJA
00439241 j/8-{/
0043966d i`8_
004396ad i)8k
004397d5 j/8-{/
00439970 1i(81i08
00439983 T0ih8
0043998f TPyh
004399e8  ia8"
00439a03 q1i!81i,8A
00439a0f TPy!
00439a1c /i(8
00439a2c /i08
00439be9 r@9H-
00439f2d cA9h
0043a203 *!T@
0043a481 cA9h
0043a5af R!t>
0043a77d #@9h
0043afa7 R!t>
0043b0af R!D:
0043b0e9 #@9h
0043baff R!t>
0043bbb5 #@9h
0043bde3 R!`/
0043be63 RJx!
0043bea7 R9x!
0043bf15 #@9h
0043c697 TKE@
0043c89b R!t>
0043c9dd #@9h
0043cbeb TuZ@
0043d1c5 c@9h
0043d265 c@9h
0043d4b3 R|w!
0043d4f3 Rlw!
0043d533 R\w!
0043d573 RLw!
0043d5b3 R<w!
0043d6e7 R)r!
0043d77f 4h"@
0043d793 6h"@
0043dac3 R!t>
0043df3d c@9H
0043dfb1 #A9h
0043e039 c@9h
0043e2ad ji8JE@9_
0043e355 ji8JE@9_
0043e52f R]s!
0043e56f RMs!
0043e5b3 R<s!
0043e6c7 R1n!
0043e844 {^@)
0043e907 Rgr!
0043e9ab Rxm!
0043e9ff Rcm!
0043f539 cC9h
0043f649 cB9h
0043f9e5 cB9H
0043fa5d cB9h
0043fc3b *!T@
004401ff RJ!2
00440681 CA9(
00440741 CA9h
00440881 CA9h
0044091e 7*h%
00440ad9 "@9h
00440afd "@9h
00440db0 h"@9h
00440f69 CA9h
004410e3 Rph!
00441137 R[h!
0044117f RIh!
004411bf Rsc!
00441203 Rbc!
00441243 6h"@
00441397 R!`/
00441465 #@9h
00441577 RJ!-
00441593 9JQ@
00441617 R]b!
00441755 CA9h
00441809 CA9h
00441b51 cJ9h
00441bb5 cJ9h
00441c21 cJ9h
00441c61 cJ9h
00441c88 :s@9
00441fa5 cJ9H
00442419 CH9(
00442448 +yhxJ	
0044258d CH9H
004426d1 CH9h
0044278d cJ9h
0044284d CH9h
0044292d CH9(
00442e37 6~\!
0044307b rJU*
004430c9 cJ9h
004430d9 CG9h
00443439 CH9h
00443629 cF9h
00443639 CG9h
00443659 CB9h
00443975 cF9h
00443b55 CG9h
00443bbd CH9h
00443d61 cJ9h
00443d99 cJ9(
00444339 #B9h
004443ed #B9h
00444b31 cA9h
00444b55 c@9h
00444bad cA9h
00444d51 #B9h
00444d81 c@9h
00444e07 RaT!
00444ee5 c@9h
00444f51 c@9h
004454a5 #@9H	
004454e3 RpW!
00445523 R`W!
0044556d #@9h
00445e2d yixJ	
00445f01 #F9(
00445f81 #F9(
0044622e A9(=
00446235 #F9h
004465cf RoN!
00446607 RaN!
004467c5 Q	x^
00446819 Q	xI
00446873 rJU*
00446981 CE9h
004469bd CE9h
00446bc5 #F9(
00446be5 #F9(
00446df1 #F9h
00446e15 #F9H
00446eff R#L!
00447413 R!l5
00447771 CB9h
004477a5 CB9h
004477d9 CB9h
0044780d CB9h
0044782b T ! 
00447a1b R!H*
00447bad c@9h
00447c31 c@9(
00448119 #@9h
004481bf R(yh
0044830d #@9h
00448517 9)Q@
00448996 	xj*
004489f7 ReE!
00448ba9 cC9H
00448c29 c@9H
00448cad #A9h
00448cd5 cC9h
00448d55 c@9h
00448dd7 RmD!
004490e7 RoH!
0044912f R]H!
00449461 cA9h
0044992f R!t>
004499b1 #@9h
00449be7 *!T@
00449cb3 R|E!
00449cf3 RlE!
00449d33 R\E!
00449d73 RLE!
00449db3 R<E!
00449df3 R,E!
00449f03 R"@!
0044a545 c@9h
0044a5b1 c@9h
0044a633 RV>!
0044a8bf RyB!
0044a8fb RjB!
0044a93b RZB!
0044a97b RJB!
0044a9bb R:B!
0044b5d7 TI+@
0044b60f T	!I
0044b61f T(	@
0044b6ab TI+@
0044b6e3 T	)I
0044b6f3 T*	@
0044b809 80.	
0044b9cb Th	@
0044ba0f Ti	@
0044bdbb 4	(@
0044be8f *!T@
0044bf0f *!T@
0044bfdf 4	(@
0044c0af *!T@
0044c12f *!T@
0044ca7f RC5!
0044cc60 hB@9t
0044d6e9 80.	
0044d7df =a"@
0044dd4f Ta&@
0044ded5 80.	
0044e214 	A@9	
0044f1b5 ji8JE@9_
0044f25d ji8JE@9_
0044f34f T)kw
0044f389 "@9h
0044f5b3 =)	@
0044f60b R`*!
0044f9c7 *		@
004501f9 "@9_
004502f3 R&'!
004506f7 Tl	@
0045073b Tl	@
00450a8b *!T@
00450dab Rx$!
00450fc5 80.	
004514fd j:8h
00451527 oI}I
00451875 i`8_
004518b5 i)8k
00451a34 *i78*i+8
00451a4c )iw8?
00451ae8 +il8*i,8*i(8h
00451b20 yi78yi)8
00451d9f R{ !
00451edb oZk@
00452059 80.	
00452147 9a"@
0045275d 80.	
00452853 =a"@
00452f8f *!T@
00453c31 C@9h
00453cb1 C@9H
004542e9 ki8JE@9_
00454379 ki8JE@9_
0045441f Ra"@
0045467d @@9h
00454683 4`*@
004546bc hB@9h
00454814 kC@9l
00454964 	A@9
0045498c 	A@9
004549bc 	A@9
00454b41 ji8JE@9_
00454be9 ji8JE@9_
00454e41 ki8JE@9_
00454ed1 ki8JE@9_
00454f77 Ra"@
004551d5 @@9h
004551db 4`*@
00455214 hB@9h
0045536c kC@9l
004554bc 	A@9
004554e4 	A@9
00455514 	A@9
00455699 ji8JE@9_
00455741 ji8JE@9_
0045584f T`"@
00455873 T`"@
004558dc +ih8J	
00455f19 CB9h
00456119 #@9h
00456131 #C9h
0045618d #@9h
004561d4 i"O9`
004564d3 *!T@
0045654f T(	@
00456809 #C9h
0045690b *!T@
00456b4f *!T@
00456d0d #C9h
00456df7 6`jA
00456f4c (#@9h
00456fc0 (#@9h
00456fe4 (#@9h
0045700c hB@9
00457088 (#@9h
004570ac (#@9h
004570dc hB@9(
0045716c (#@9h
00457190 (#@9h
004571b8 hB@9
00457238 h"@9h
0045725c h"@9h
00457298 h"@9h
0045735f *!T@
00457453 6`~@
00457463 6`r@
00457473 6`V@
00457483 6`*@
00457529 c@9h
00457698 	@@9
00457949 #A9h
00457da3 *!T@
004583ff 7hBC9
0045840f 7h"A9H
00458417 7hb@9
00458434 hBC9
0045843b 6`r@
0045844b 6`V@
00458454 h"A9
0045845b 6`*@
00458464 hb@9
004584b0 	 K9
004585da K9j.
00458610 +yhxJ	
004586a3 R!h"
004589e1 aA= 
00458bab Rwe!
00458c8b 7h"K9(
00458c93 7h"J9h
00458c9b 7hbI9h
00458ca3 6`2A
00458cec h"K9(
00458cf3 6`jA
00458cfc h"J9
00458d03 6`JA
00458d0c hbI9
00458f85 "@9h
00458f9d #@9h
00459015 #@9h
00459349 CA9JA
0045983f RRb!
004598a3 *!T@
0045a08d CA9JA
0045a3d2 @MJA
0045a680 	A@9)
0045ab8d 80.	
0045acb3 ThA@9
0045adb3 TiA@9?
0045ae9c hc@9
0045af31 CA9H
0045afc0 hc@9((
0045b091 CA9h
0045b169 CA9h
0045b17d c@9(
0045b211 CA9h
0045b2d9 CA9h
0045b41f RZ[!
0045b49f *!T@
0045b4cf R.[!
0045b547 *!T@
0045b639 CA9H
0045bb85 C@9H
0045bca1 "@9h
0045bd0d "@9h
0045be45 C@9h
0045bfcf RnX!
0045c03b *!T@
0045c134 (`@9
0045c22f R:|@
0045c268 	A@9	
0045c533 Thjt8H
0045c5df R!d+
0045c68b R!`/
0045c6bc hjt8
0045c8c3 R1V!
0045cbb3 T E@
0045cc97 T`E@
0045d0f7 T	@@9?
0045d18b Ra"@
0045d3cb 4hb@9h
0045d524 OA@9
0045d5b0 NA@9
0045d665 B@9h
0045d713 9cs!
0045d8a5 80.	
0045da5d ji8JE@9_
0045dae9 ji8JE@9_
0045df51 ki8JE@9_
0045dfe1 ki8JE@9_
0045e053 Ra"@
0045e39f *!T@
0045e4fc *a@9?
0045e51b Tu"@
0045e78f 9Ha@
0045e8d1 CA9h
0045e8e1 C@9h
0045e939 CB9h
0045e979 C@9h
0045ea3d CA9H
0045eda4 H#@9h
0045ee54 H#@9h
0045eec0 H#@9
0045ef6c H#@9
0045f018 H#@9h
0045f088 H#@9
0045f147 R)!2
0045f180 H#@9h
0045f249 #@9h
0045f2c7 TMyh
0045f2fd #A9h
0045f3f3 *!T@
0045f407 R`K!
0045f46b *!T@
0045f47f RBK!
0045f4eb *!T@
0045f4ff R"K!
0045f563 *!T@
0045f5e3 *!T@
0045f65b *!T@
0045f6d3 *!T@
0045f74b *!T@
0045f8b9 #A9h
0045f903 6`B@
0045f917 6`*@
0045f957 7h"A9
0045f95f 7hb@9
0045f983 6`B@
0045f98c h"A9
0045f993 6`*@
0045f99c hb@9H
0045fbdc (#@9h
0045fdc1 #@9h
0045fdd9 CE9h
0045ff07 T+	@
0045ff7e D9`6A
004601f3 *!T@
00460393 R}G!
004603bf RrG!
00460453 *!T@
0046047b RCG!
0046067a D9(	
004608cf R.F!
00460947 *!T@
0046114f 7hBB9
0046119b 6`f@
004611a4 hBB9
004611ab 6`N@
004611bb 6`6@
0046140d b@9?
0046157b *!T@
00461697 oZk@
004617e4 Lii8k	
00461b82 @MMA
00462261 #@9h
004622cf =+)@
0046234f RkF@
00462445 #@9h
0046258f T+	@
004626d3 Ra2A
00462854 h"@9h
004629ef *!T@
00462bd3 *!T@
00462bfb Rc=!
0046354f 7hBB9
0046359b 6`f@
004635a4 hBB9
004635ab 6`N@
004635bb 6`6@
00463783 Ta.@
00463829 c@9h
0046385b 4h"@
004638e5 "@9h
00463c34 a"C)!|@
00463d78 h"@9h
00463e63 *!T@
00463ef3 *!T@
00463fc7 Rp8!
00464033 *!T@
00464c6d #@9h
00464c91 CC9h
00464d31 #@9h
00464e45 CC9(
00464f35 CC9h
004652cb Ti*@
004653a9 #A9H
00465471 cB9h
004654e8 h"@9h
00465501 C@9h
0046554d C@9h
004655ac h"@9h
00465635 "@9h
004656db T E@
00465b6b *!T@
00465b97 R|1!
00465c13 R]1!
00465c7f *!T@
00465c93 R=1!
00465d27 *!T@
00466174 (#@9h
004661f5 "@9h
004662a0 H#@9h
00466313 9		@
00466365 #C9h
00466409 #C9h
00466469 "@9h
00466486 E9`*
0046650d #C9h
0046669b R!P0
00466719 #C9h
0046677b RJy)
00466833 RJm*
00466879 "@9h
00466896 E9`"
004668f1 "@9h
00466af5 #C9h
00466b0d #E9(
00466b6d #E9(
00466b8b TAN!
00466bfb *!T@
00466c7f *!T@
00466cfb *!T@
00466fe9 #A9H
004672ed cD9h
0046730d #E9h
004676f9 #@9H
00467733 TWK!
00467945 c@9(
00467a45 c@9(
00467c1f TI+@
00467dfd #A9h
004681ad c@9h
00468259 c@9h
004685b9 c@9h
00468747 TRG!
0046900b 6`^@
004694d9 #@9h
00469c93 R=!!
00469d7d #@9(
00469dbd #@9(
00469edd "@9h
0046a23d #@9(
0046a27d #@9(
0046a59d #@9(
0046a5dd #@9(
0046b073 /@ $
0046b0af /@ $
0046b0b7 T @ 
0046b55f Tnzk
0046b5a4 !80.1
0046b667 Tnzk
0046b73b o)i@
0046b74a @9)A
0046b7da A9JA
0046c949 #@9h
0046c969 #@9h
0046c9b5 "@9h
0046c9d5 #@9h
0046cc1d "@9h
0046cc9d "@9h
0046cd19 "@9h
0046cd80 h"@9h
0046ce3b *!T@
0046ceb3 *!T@
0046cf2b *!T@
0046d051 "A9	
0046d13d #@9H
0046d89f T		@
0046d8e7 T		@
0046d973 Tzd@
0046db43 TS2!
0046e5c3 T(yh
0046e727 TMyk
0046efcd CA9H
0046f0f5 CA9h
0046f25d CA9h
0046f317 *!T@
00470867 =	!@
00470c40 +ih8J	
00471964 h"@9h
004725a0 h"@9h
004725f1 "@9h
00472615 "@9h
0047281d C_8{#
004729a9 #@9h
00472bb9 #@9h
00472bd1 #@9h
00473041 i`8_
00473081 i)8k
00473260 	i+8	i*8
00473384 *i78*i+8
0047339c )iw8?
0047344c +il8*i,8*i(8h
0047349c yi78yi)8
00473611 i`8_
00473651 i)8k
0047383d i-8?
00473a10 +i68+i*8
00473a28 *iv8_
00473a98 ,iz8M
00473ab3 q+i:8+i(8
00473ae4 yi68yi)8
00473ee1 #@9h
00473ef9 #@9h
0047405f 9)a@
00474357 9)q@
00474387 R)UE
00474417 9)q@
0047450b R)yE
0047465f 9)Q@
004747e3 9)a@
004748a3 9)Q@
004748d3 R)mE
00474963 9)Q@
00474993 R)uE
00474a57 R)qE
00475c40 *iw8
00475dd8 *iw8
00476f44 *iv8
004785f0 	 @9
00478957 o)mB
00478bc7 9Iq@
00478bfd #@9h
00478e44 	i+8	i*8
00478f61 j58h
0047965b 9Iq@
00479691 #@9h
0047988b RJA!
004798af 9IQ@
004798e5 #@9h
0047a173 9Iq@
0047a1a9 #@9h
0047a409 #@9h
0047a7e5 #@9h
0047a9e7 Ri} 
0047b081 #@9h
0047b27b RJI5
0047b29f 9Iq@
0047b2d5 #@9h
0047b75b 9Iq@
0047b791 #@9h
0047b9e9 #@9h
0047bc41 #@9h
0047be99 #@9h
0047c0ed #@9h
0047c30b 9Ia@
0047c341 #@9h
0047c591 #@9h
0047c7e1 #@9h
0047ca39 #@9h
0047cc57 9Ia@
0047cc8d #@9h
0047ce87 RJY-
0047ceab 9Iq@
0047cee1 #@9h
0047d139 #@9h
0047d35f RJ16
0047d3b1 #@9h
0047d5b3 Rvr 
0047d5ef =)mB
0047dfbc 	 @9
0047e1a7 Ryo 
0047e380 	 @9
0047e4f3 6hJ@
0047e51c 	A@9i
0047e5c0 	 @9
0047e62f RWn 
0047e7fb k$	@
0047e81f 5hJ@
0047e833 6hJ@
0047e8e8 +ih8J	
0047eb18 	 @9
0047ec43 T ya
0047ed0b *!T@
0047efbb 46K@
0047efdf T)#L
0047f167 *!T@
0047f2b5 CC9h
0047f667 9rj 
0047f7a7 *!T@
0047f81f *!T@
0047f897 *!T@
0047f933 *!T@
0047f9ab *!T@
0047fa23 *!T@
0047fa9b *!T@
0047fd81 #B9h
0047ff67 6h&L
00480207 *!T@
004802f3 k$	@
0048035c 	 @9
0048060f R%k 
00480c11 #B9h
00480cb9 cA9h
00480ff5 cA9h
00481271 C@9h
0048148c 	 @9
00481805 #@9h
004819f7 *!T@
00481a6f *!T@
00481aef *!T@
00481ea3 k$	@
00481ec7 5hJ@
00481edb 6h&I
00481f70 	 @9
00482351 CA9h
00482441 c@9h
00482583 *!T@
004825fb *!T@
00482673 *!T@
00482705 c@9h
004829eb k$	@
00482a0f 5hJ@
00482a23 6h&I
00482ab8 	 @9
004830cd #@9h
004831df *!T@
00483257 *!T@
004832cf *!T@
00483347 *!T@
004833bf *!T@
004834fb *!T@
00483853 k$	@
00483877 5hJ@
0048388b 6h&I
004839c8 	 @9
00483a37 RUY 
00483df9 cA9h
00483f7d cA9H
0048412f <h"@9h
00484203 <h"@9h
004844db Rr[ 
00484593 RD[ 
004845d3 R4[ 
00484613 R$[ 
00484649 #A9h
00484681 #A9h
004849cb *!T@
00484cd7 *!T@
00484e4b *!T@
004855a3 rN	@
004855d3 k$	@
00485647 rN	@
00485677 k$	@
0048577d C@9h
0048581b rN	@
0048584b k$	@
004858cf rN	@
004858ff k$	@
00485ccb 6`&@
00486311 ki8JE@9_
004863a1 ki8JE@9_
00486407 Ra"@
0048664d @@9(
00486664 hB@9h
004868a0 kC@9l
004869f0 	A@9
00486a18 	A@9
00486a48 	A@9
00486bb7 9Iq@
004871bf RsK 
00487275 CG9h
004878a7 R!\;
004878e8 h!@9k%
00487b30 h!@9k%
00487bc5 #R9h
00487fa3 *!T@
00488341 "@9h
00488365 "@9h
00488447 Tin@
00488533 Ti2@
00488548 *!@9
004885ac *iu8
00488743 Ti*@
00488754 *iv8
004887b3 <h"@9
0048883f Ti*@
00488850 *iv8
004888af <h"@9h
00488ecf o{k@
00489282 dnc6
004897fa dnc6
00489c6d cB9h
00489dff <h"@9
00489e93 <h"@9h
0048a1cb Rp? 
0048a2b9 cA9h
0048a2cb R0? 
0048a2ef R'? 
0048a421 cA9h
0048a763 <h"@9h
0048a8c1 CA9h
0048a90b RfB 
0048a94b RVB 
0048a98b RFB 
0048ad47 *!T@
0048adc7 *!T@
0048b1ed cB9b
0048b259 cA9h
0048b877 *!T@
0048c00b TkFA
0048c451 c@9(
0048c46d c@9H
0048c6b9 #@9h
0048c8bd #@9h
0048cad5 #@9h
0048ce03 R!8 
0048ce4d #@9h
0048d04d #@9h
0048d1cf <h"@9h
0048d20b R`3 
0048d349 %@9_}
0048d355 !@9_
0048d39d 	@9_
0048d7bb Th&I
0048e389 #J9h
0048e3d0 *!@9
0048e3d7 6 	@
0048e4b1 #J9h
0048e51c *is8
0048e964 *!@9
0048e96b 6 	@
0048e9f4 *iu8
0048ea93 Ti&@
0048eaa4 *iv8
0048eb03 <h"@9
0048eb8f Ti&@
0048eba0 *iv8
0048ebff <h"@9h
0048ef05 ji8JE@9_
0048efad ji8JE@9_
0048f0b9 i`8_
0048f0f9 i)8k
0048f241 i/8+~
0048f24d i.8+
0048f45d ja8"
0048f7fd ki8JE@9_
0048f88d ki8JE@9_
0048f8fb Ra"@
0048fb7c hB@9h
0048fce0 kC@9l
0048fe30 	A@9
0048fe58 	A@9
0048fe88 	A@9
0049025f RK' 
00490a99 CA9JA
00490d89 i`8_
00490dc9 i)8k
00490fa8 	i+8	i*8
004910cc *i78*i+8
004910e4 )iw8?
00491194 +il8*i,8*i(8h
004911e4 yi78yi)8
00491687 RA" 
00491abf R3! 
00491d2c hb@9h
00491ecb R0  
004920fb TkA@
004924a5 80.	
004928e5 b@9h
00492eef TH+@
00493107 R!@6
00493114 h#@9
0049323f Thc@
004933db *!T@
004936bc hb@9H
004937d1 j68h
00493829 i/8,z/
004939c7 <h"@9h
00493b81 b@9h
00493d60 *kh8)	
004940a5 b@9h
00494357 T3	@
004944ff Thn@
00494547 rN	@
00494577 k$	@
004945b1 {hx)	
0049460f T-	@
00494617 rn	@
0049466b 4h&@
004946af 4h.@
004946ef Th:@
0049476b T-	@
00494773 rn	@
00494865 80.	
00494a99 80.	
00494d8d i`8_
00494dcd i)8k
00494ebf RJ	C
00494ec5 j88l
00494f13 7+{h
004950a5 i/8)
00495135 ia8"
00495151 i"8!
004954e5 	@9I
00495539 S	9?
00495576 @9?!
0049564a @9?1
0049568d !@9k
0049571e @9?I
004957da @9?M
0049589e @9?M
004959e3 k$	@
00495a4a @9?M
00495a87 5H'L
00495bb7 9JQ@
00495c09 cG9H
00495c21 #I9h
00495c85 #E9h
00495cf1 #I9h
00495e2a @9?Q
00495ef2 @9?M
00495f7d #I9H
00496032 @9?A
00496116 @9?Q
0049626d #I9H
00496281 CH9H
004962b1 cG9H
00496311 #I9(
004963ef <h"@9h
004966ab 6i#I
00496921 #B9(
004969c5 cD9h
00496a71 #B9h
00496af5 cD9(
00496b31 cD9H
00496b4d cD9h
00496bb3 <h"@9h
00496fcf k$	@
00497415 cB9h
004974ad cB9h
0049755d cB9H
004975e1 cB9(
0049776d ji8J
004978e3 <h"@9h
00497957 RJq@
004979a7 Ry	 
004979fd c@9H
00497fef R!t(
004980f7 R$h 
0049815b *!T@
00498786 M9H	
00498819 #S9H
004988d9 #L9H
00498a9f k$	@
00498bf7 4h"@
004992c5 cF9h
00499301 cF9h
0049988b R!|=
00499963 R!t 
00499acb R!l5
00499c4f R!x!
00499d72 E9H	
0049a2e3 7h"@9
0049a310 h"@9
0049b283 T		@
0049b30b Th"@
0049b73f TT{ 
0049b81f R!$!
0049b93f R!$!
0049c15f R1f%
0049c1ab 9a5C
0049c411 cN9H
0049c431 CL9H
0049c471 cG9H
0049c491 CE9H
0049c645 CO9H
0049c705 CH9H
0049c8df 6h"@
0049ce9f 6(K@
0049d23f 6h"@
0049d30b R!|'
0049d3e3 R!`6
0049d44f R!(!
0049d5cb R!p%
0049d637 R!X=
0049d8ef R!|)
0049d98b R!L"
0049d9ef R!\+
0049ee29 CH9H
0049f1af o	)@
0049f2fd #E9(
0049f64d CH9h
0049f69d #E9(
0049f6f1 #E9H
0049fec7 R!D,
0049ffd3 R!p'
004a05ef 9H}C
004a07e9 #L9H
004a0869 CG9H
004a08a9 #E9H
004a09cb 6(K@
004a0aa5 #H9HQ
004a0ac6 E9HR
004a0acd #E9h
004a14f9 cF9H
004a1683 R!H7
004a1939 #E9(
004a1e41 CC9h
004a1e87 RI-B
004a1f59 CF9h
004a1f81 #G9h
004a2025 CF9h
004a225f RIEC
004a2341 #G9h
004a2359 cE9(
004a23c9 CF9h
004a23d9 cE9(
004a2481 #G9H
004a2675 cE9H
004a27f9 CF9H
004a2a53 6h"@
004a2d35 CC9h
004a3041 CC9h
004a3075 CC9h
004a335f R!@0
004a3b03 R@}C
004a3b91 cD9H
004a3bb1 CB9H
004a3ea5 #B9H
004a3edd #@9h
004a4251 CA9h
004a4555 CA9h
004a4705 CA9h
004a4977 R!\(
004a4b5f R!48
004a5319 c@9h
004a53cf R!h7
004a5463 R!<(
004a5849 c@9h
004a5c8d c@9h
004a5d37 R!h>
004a5dc3 Th"@
004a635d C@9h
004a6987 oi-B
004a69b7 9-9C
004a6a7a P9H?
004a6a9a N9H@
004a6c96 P9(;
004a6c9d CP9h;
004a6cb6 N9(<
004a6cbe N9h<
004a6d23 o	)@
004a7013 T	)@
004a70a7 6h#@
004a74cf R!H$
004a75bb R!D(
004a79c3 T	!@
004a7d1f R!,?
004a801b Th#@
004a82b1 #D9H
004a8459 CP9H
004a8645 CP9H
004a87c1 CP9H
004a92d3 6HK@
004a9a5f xD,B
004a9cbd CT9H	
004a9cdd #R9H
004a9d1d CM9H
004a9d3d #K9H
004a9d7d CF9H
004a9dd1 #U9H
004a9e51 cP9H
004a9e91 #N9H
004a9f11 cI9H
004a9f51 #G9H
004a9fef T	)@
004aa097 6(K@
004aacef Th#@
004aaf7d #A9h
004aafb9 #A9h
004ab273 r@9C
004ab4eb Th#@
004ab791 #A9h
004ab895 #A9h
004aba57 <h"@9h
004abcbf RH9C
004abe15 CM9H
004abfe7 T	)@
004ac25d #N9(M
004ac266 M9hM
004ac27e L9(N
004ac286 K9hN
004ac29e I9(O
004ac2a6 H9hO
004ac2ca F9y"
004ac32f T	)@
004ac515 cB9(Z
004ac51e B9hZ
004ac52d #C9h
004acb11 cE9h
004acbfd #N9(
004acc2d cL9h
004acc6d CJ9h
004accd2 F9y"
004ace17 R!,?
004acfa7 R!@:
004ad055 cB9(
004ad085 #C9h
004ad10d #C9H
004ad131 cB9H
004ad171 #C9(
004ad2f1 CJ9H
004ad711 CA9H
004adf27 TZ1 
004ae836 @y	%
004ae90e @y	%
004ae9e6 @y	%
004afa75 cL9h
004b0022 M9H!
004b02b7 6HK@
004b0435 CN9H
004b05d7 T)	@
004b06c7 Rc +
004b087b Rcx+
004b0915 #K9h
004b0a07 Rc +
004b0a6f Rc +
004b0acb Rc +
004b0b1d cD9h
004b0c2f 6HK@
004b0dd3 Rcx+
004b0e3b Rcx+
004b0ea3 Rcx+
004b0f0b Rcx+
004b0fb3 Rc +
004b101b Rc +
004b1083 Rcx+
004b10eb Rcx+
004b1153 Rc +
004b11bb Rcx+
004b1223 Rcx+
004b129b Rcx+
004b1303 Rcx+
004b136b Rcx+
004b13d3 Rcx+
004b14a6 D9h	
004b17d5 cD9H
004b19bb <h"@9h
004b1c15 c@9h
004b1cef Tpyn
004b233b <hb@
004b2367 9)Q@
004b2737 RJe%
004b2772 	9	.B
004b2797 r(YB
004b27e7 Rj}C
004b2a5e S9HI
004b2a7d CQ9HJ
004b2a9d #O9HK
004b2abe L9HL
004b2add CJ9HM
004b2afd #H9HN
004b2b1e E9HO
004b2df6 S9(:
004b2dfe R9h:
004b2e16 P9(;
004b2e1d cP9h;
004b2e36 N9(<
004b2e3e M9h<
004b2e56 L9(=
004b2e5e K9h=
004b2e76 I9(>
004b2e7d cI9h>
004b2e96 G9(?
004b2e9e F9h?
004b2eb6 E9(@
004b2ef6 	9o(
004b30b6 L9H2
004b30d5 CJ9H3
004b30f5 #H9H4
004b3116 E9H5
004b32de K9H)
004b32fd cI9H*
004b331e F9H+
004b333e D9H,
004b3371 cT9H
004b33b1 #R9H
004b3431 cM9H
004b3471 #K9H
004b34f1 cF9H
004b3565 CQ9h
004b35a5 #O9h
004b3625 CJ9h
004b3665 #H9h
004b36e9 cM9H
004b3729 #K9H
004b37a9 cF9H
004b3aa7 7h#@
004b3ce2 D9(G
004b3d47 Th#@
004b429f Th#@
004b4477 7h#@
004b45d3 7h#@
004b4b89 cA9h
004b4bf1 cA9H
004b4ced cA9H
004b54c3 R@EC
004b554b 9)-B
004b5635 #H9H
004b5675 CC9H
004b56e9 cF9H
004b5729 #D9H
004b5887 R@YB
004b5996 E9H 
004b59b5 CC9H!
004b5d89 cF9H
004b5dc9 #D9H
004b5eb7 T(K@
004b5efb Th"@
004b60a5 CA9h
004b62dd CA9h
004b63cb R!|+
004b64bf Th"@
004b6b05 C@9h
004b6f75 ji8JE@9_
004b701d ji8JE@9_
004b71bd C@9h
004b7369 zjx*
004b77d5 #@9h
004b7809 #@9h
004b813d CE9h
004b8195 cD9h
004b81c9 #F9h
004b8351 #F9(
004b8401 CE9h
004b8411 #F9(
004b8465 #F9h
004b86cf R	y9
004b895d #M9)
004b8bd5 CK9H
004b8d05 CE9H
004b93c1 CE9H
004b9517 =)ih
004b9589 CE9h
004b971d CE9h
004b9747 R	y:
004b9873 =)ih
004b9ac5 CE9h
004b9aef R	y;
004b9cb5 #G9H
004b9da9 CE9H
004b9ebf *!T@
004ba029 CE9H
004ba065 cL9H
004ba1b9 CE9H
004ba2cd CE9H
004ba397 <h"@9h
004ba3ff <h"@9h
004ba9ab 5)#I
004baab1 CB9h
004baba9 CB9h
004babe9 cA9h
004bac21 cA9h
004badeb <h"@9h
004bb573 k$	@
004bb9ec (#@9
004bba4d CC9H
004bbbd5 CC9h
004bbcf5 CC9(
004bbe87 <h"@9h
004bbf07 T*)@
004bc09f 5hK@
004bc66f TjGA
004bc9f3 k$	@
004bcc89 CB9h
004bcd0d #C9h
004bcd45 CB9H
004bcdf5 #C9H
004bce32 B9h	
004bce89 CB9(
004bd043 <h"@9h
004bd256 	K	K@
004bd336 	K)K@
004bd49b 6(K@
004bd4c3 7(K@
004bd7df TjFA
004bd9ee 	KIK@
004bda15 C@9h
004bdaca 	K)K@
004bdb39 C@9h
004bdba5 C@9\
004bdc2d C@9h
004bdd09 C@9h
004bdd3d C@9h
004bddc5 C@9h
004be12a 	KIK@
004be35b k$	@
004be5cb k$	@
004be6b9 cC9h
004be7b5 #B9H
004be869 cC9H
004beba7 <h"@9h
004bf40b 9kQ@
004bf445 cA9H
004bf45d #B9h
004bf4d9 #B9H
004bf52f 6hK@
004bf70d #B9h
004bf7c1 cC9h
004bf7c9 #B9(
004bf7e9 cA9h
004bf829 #B9(
004bf8f3 <h"@9h
004bfba7 TjFA
004bfd23 TK)@
004bfdc0 	 @9
004bff5c ?k78
004c043b *!T@
004c0547 *!T@
004c0739 #@y9
004c077a @y)	
004c08df Th:@
004c0a09 8a.!8a.B8a.c8a.
004c0a2a ?m)A
004c0a54 M%@x
004c0efb *!T@
004c0f7b *!T@
004c1093 Th:@
004c11bd 8a.!8a.B8a.c8a.
004c11de ?m)A
004c1208 M%@x
004c16af *!T@
004c172f *!T@
004c181e 	ka0
004c1847 Th:@
004c1971 8a.!8a.B8a.c8a.
004c1992 ?m)A
004c19bc M%@x
004c1e9b *!T@
004c1f1b *!T@
004c2033 Th:@
004c215c !8a.
004c2161 8a.B8a.
004c2170 !8a.!
004c2182 ?m)A
004c21ac M%@x
004c251b *!T@
004c259b *!T@
004c26cd #@y9
004c270e @y)	
004c29c1 s@ys
004c2adc C8a.B8an#
004c2b4c C8a.B8an#
004c31e3 *!T@
004c3263 *!T@
004c3413 *!T@
004c35af *!T@
004c374b *!T@
004c38e7 *!T@
004c3a83 *!T@
004c3c1f *!T@
004c3dbb *!T@
004c3f57 *!T@
004c40f3 *!T@
004c428f *!T@
004c4495 C@9h
004c46df Th&L
004c4e38 	 A9	
004c5105 CC9h
004c541d CC9h
004c5461 CC9h
004c5535 CC9h
004c587b *!T@
004c5b37 <h"@9h
004c5b9f <h"@9h
004c5fab 5hK@
004c600f 5ic@
004c6ba7 Th'L
004c6db3 k$	@
004c6e9b Tjc@
004c794b 7HK@
004c795f 6HK@
004c7977 THK@
004c7b0d cE9h
004c7c5d #C9h
004c7d31 #J9h
004c7e39 cE9H
004c7e9d cE9(
004c807d #J9h
004c8afb 6h'L
004c8ba5 CG9h
004c8c7b k$	@
004c8d41 CG9h
004c8e05 CG9h
004c8ec1 CG9h
004c91c1 CG9h
004c9211 cF9@
004c9313 7hK@
004c9327 6hK@
004c933f ThK@
004c9449 #D9H
004c94e5 cC9h
004c9609 cF9)
004c97b5 #D9H
004c97e5 CG9H
004c9805 CG9H
004c982d cF9H
004c99c3 <h"@9h
004c9a2b <h"@9h
004ca08f k$	@
004ca283 k$	@
004ca581 CA9(
004ca5fd cC9h
004ca709 CB9H
004ca7e1 cC9H
004caa47 <h"@9h
004caf3f 9kQ@
004caf7d CB9h
004cb447 <h"@9h
004cb727 6;{@
004cb817 k$	@
004cb88f 4h/@
004cb973 k$	@
004cb9af T	#L
004cb9bf Th+@
004cbc2d cM9h
004cbcae Ai	H@
004cbccb T<#L
004cbd3e Ai	`@
004cbe2f 9kQ@
004cbe89 CL9h
004cc26d cM9H
004cc2e1 #K9H
004cc40f *!T@
004cc483 *!T@
004cc4b9 CR9h
004cc505 #K9h
004cc535 cM9h
004cc58a [85a
004cc6d9 CD9(
004cc6f1 CL9h
004cc719 CD9(
004cc749 CL9h
004cc97f Ti&@
004cc990 *iv8
004cc9ef <h"@9
004cca7b Ti&@
004cca8c *iv8
004ccaeb <h"@9h
004cccb4 *A@9
004ccf23 T: @
004ccfb7 5z"@
004cd487 R)S	
004cd5d5 i`8_
004cd615 i)8k
004cd709 j58h
004cd760 	i+8
004cd76c 	i*8
004cd783 =		@
004cd920 *i78*i+8
004cd938 )iw8?
004cd9d4 +il8*i,8*i(8h
004cda0f <*	@
004cda44 zi78zi)8
004cda57 =+	@
004cdd8f *!T@
004cde07 *!T@
004ce088 +ih8J	
004ce41f *!T@
004ce45c h"@9h
004ce581 "@9H
004ce625 "@9h
004ce9a5 ki8JE@9_
004cea35 ki8JE@9_
004cea93 =		@
004ceabf Ra"@
004cef4f 6HK@
004cf4fb =)Q@
004cf561 #F9h
004cf805 #D9h
004cf8a5 cC9h
004cf929 CE9h
004cfe2f Ti"I
004cfe6d #A9h
004d017b *!T@
004d04ca A9H	
004d0677 *!T@
004d0bb3 *!T@
004d0d6f <h"@9h
004d0e29 i`8_
004d0e69 i)8k
004d0f57 o)	C
004d0f5d j;8k
004d0f8c li.8li-8k
004d1a53 TuZ@
004d1c0b TuZ@
004d1e85 #@9h
004d1f0b <K}	
004d26d1 C@9h
004d2b4f TH_@
004d30f5 cC9h
004d32b7 T)(A
004d33c1 CB9h
004d3441 #^);	@
004d362d CB9h
004d3705 cC9h
004d378d cC9h
004d37b9 cC9h
004d37f5 CA9h
004d398b *!T@
004d4295 cA9(
004d450d C@9(
004d452d cA9h
004d45ed cA9(
004d46f1 cA9h
004d47cf R	{u
004d4af3 rN	@
004d4b23 k$	@
004d4bef Th'@
004d4c0f *h#@
004d4c1f Th+@
004d4dad cA9h
004d4dca Z8JA
004d4ec5 cA9h
004d4fb9 cA9(ih
004d5011 cA9h
004d5319 CA9h
004d53cb R*{{
004d54fb TyJ@
004d55ab <hb@
004d55d9 CA9h
004d5901 c@9h
004d5c0b ThJ@
004d5c5f ThJ@
004d5cab ThJ@
004d5cf7 ThJ@
004d5eb5 CB9h
004d6593 T		@
004d665a ]8H	
004d66ed c@9h
004d69e9 CC9h
004d6c75 CC9h
004d6d19 cB9h
004d6d29 CC9h
004d6d6d CC9h
004d6e71 CC9h
004d6f3b RJy)
004d72e6 B9!I
004d73ad CC9h
004d74db T		@
004d7a17 R! -
004d81ab <hR@
004d81e7 <h*@
004d82ab <h"@9h
004d8365 i`8_
004d83a5 i)8k
004d8560 *i,8
004d858c *i(8`
004d8670 ,i48,i*8
004d8688 *it8_
004d8708 .iy8-
004d8723 q,i98,i/8
004d8770 Wi48Wi)8
004d8899 i`8_
004d88d9 i)8k
004d89c7 o)	C
004d89cd j;8k
004d89fc li.8li-8k
004d96f7 <h"@9
004d97bf <h"@9h
004d9a4c +ih8J	
004d9c04 	 @9
004d9d01 CA9h
004d9d75 #@9h
004d9db1 CA9(
004d9e01 #@9h
004d9e53 R!X%
004d9f33 k$	@
004da510 	 @9
004da80b Th&@
004daa53 6`&@
004dac33 *!T@
004daecb T6yx
004db562 	*C	@
004dbb64 	i+8	i*8
004dc4d4 *i,8
004dc4e4 *i+8
004dcaa9 "@9h
004dcaf5 "@9h
004dcdb5 i`8_
004dcdf5 i)8k
004dcf10 *i78*i+8
004dcf28 )iw8?
004dcfd8 +il8*i,8*i(8h
004dd030 yi78yi)8
004dd1ad i`8_
004dd1ed i)8k
004dd3f5 jb8C
004dd415 j-8a
004ddcb9 i`8_
004ddcf9 i)8k
004dde08 ,i48,i*8
004dde20 *it8_
004dde90 .iy8-
004ddeab q,i98,i/8
004ddefc Wi48Wi)8
004de17f TIo@
004de263 6@[@
004de28f R 9 
004de329 cB9(
004de45c 	 @9
004de681 "A9(
004de87b TjFA
004de917 R!|+
004de947 R!|+
004deb71 #A9h
004ded8f <h"@9h
004df1e1 #B9H
004df245 #B9H
004df3ed cC9h
004df4a3 6 #@
004df4c5 #B9H
004df4db 6 #@
004df4e9 #B9(
004df529 #B9H
004df587 6 #@
004df7cf <h"@9h
004dfa64 H@@9
004dfb33 *!T@
004dfcaf *!T@
004dff21 #D9	
004dffb9 CB9	
004e00c5 cC9h
004e0359 CB9(
004e0361 #D9h
004e046d CB9h
004e0559 CB9(
004e0639 #D9H
004e0933 *!T@
004e09f9 #D9(
004e0a19 #D9(
004e0a3d #D9H
004e0ac1 #D9(
004e0ae1 #D9(
004e0b01 #D9(
004e0b61 #D9h
004e0c3b ** I
004e0d77 *!T@
004e101f oZk@
004e1233 *!T@
004e159b T	-B)5
004e17af *!T@
004e1857 ** L
004e1993 *!T@
004e1bc7 6h'I
004e1c17 6hK@
004e1dd1 CA9h
004e204b <h"@9h
004e25f3 *!T@
004e2a89 C@9(
004e2b20 	 @9
004e2f15 jz8	
004e2f29 j:89
004e2ff5 #@9h
004e30e9 #@9(
004e33a7 rk}F
004e384d cK9h
004e38ad #I9h
004e38cd cH9h
004e398d CC9h
004e3e49 #I9h
004e3e69 cH9h
004e3ee9 CC9h
004e4aa4 hB@9
004e512d CC9H
004e546f <h"@9h
004e61ad #@9h
004e668b 9Jq@
004e66bb <kEF
004e67af 9JQ@
004e6827 <kIF
004e6963 9(q@
004e698b R)QF
004e6b5d c@9H
004e6ba4 hB@9
004e6ccf R9Q@
004e6d1b <)QF
004e7247 6`"@
004e7250 hb@9(
004e751f R		@
004e774b R		@
004e7b2b TvbL
004e8847 qi"@
004e8863 R(yw
004e8893 Ti*@
004e89db 4h&@
004e8b0f q$	@z
004e8c91 	Cza
004e8ccf Ti"@
004e961e @MJA
004e9b3d #I9h
004e9b5d cH9h
004e9bbd #F9h
004e9bfd cA9h
004e9c1d #B9h
004e9c7d cD9h
004e9c9d #E9h
004e9d44 hB@9
004e9e95 cA9(
004e9ef1 #E9h
004e9f39 cD9h
004e9fd5 cA9(
004ea1f5 cA9h
004ea215 #B9h
004ea2b8 hB@9
004ea37d cA9(
004ea3fd cA9(
004ea58d cA9h
004ea630 hB@9
004ea6d5 cA9h
004ea751 cA9H
004ea8c0 hB@9
004eaad8 hB@9
004eacfc hB@9
004eaf1c hB@9
004eb134 hB@9
004eb3ab *!T@
004eb6da @9h#@
004eb747 Tjg@
004eb931 cA9h
004ebbf1 i`8_
004ebc31 i)8k
004ebe00 *i,8*i+8
004ebefc ,i58,i*8
004ebf14 *iu8_
004ebf94 .iy8/
004ebfaf q,i98,i/8
004ebfbf TKy9
004ebff0 Xi58Xi)8
004ec205 ki8JE@9_
004ec295 ki8JE@9_
004ec54f 4hB@9h
004ec6b4 kC@9l
004ec804 	A@9
004ec82c 	A@9
004ec85c 	A@9
004ec9e1 ji8JE@9_
004eca89 ji8JE@9_
004ecc29 ji8JE@9_
004eccd1 ji8JE@9_
004ecea7 Tu^@
004ed46a 	K)K@
004ed4eb k$	@
004ed6e9 cF9h
004ed819 CB9(
004ed839 cC9h
004ed919 cC9(
004eda65 cC9H
004edb3f <h"@9h
004edd1c 	A@9)
004edd9d CA9J
004eddf1 CA9h
004ee24d CA9(
004ee40f k$	@
004ee4a4 	 @9
004ee8d4 (G@9
004ee8db 6({@
004eea79 cA9H
004eebf5 cA9h
004ef339 C@9h
004ef47f R@}C
004ef4e3 r -B
004ef5a5 CE9H
004ef5c5 #C9H
004ef679 cA9H
004ef751 CA9h
004ef785 CA9h
004ef801 CA9h
004efcb3 R 9C
004f0033 9`}C
004f014d #F9H
004f01e1 cD9H
004f0221 CB9H
004f030f k$	@
004f047d #@9h
004f04b5 #@9h
004f058d CA9(
004f0595 #B9h
004f05cd CA9(
004f070f RH}C
004f07e1 CB9(
004f08d1 CB9H
004f09b1 #C9h
004f09c1 CB9(
004f0a05 #C9H
004f0a39 CB9H
004f0f63 <h"@9h
004f1377 <h"@9h
004f1a43 6`Z@
004f1a7f ThB@
004f1a94 	a@9i
004f1aa5 kv8(
004f1b0f <h"@9
004f1f43 Rln@
004f210d i`8_
004f214d i)8k
004f2241 j58h
004f2488 *i88*i+8
004f24a0 )ix8?
004f2550 ,ik8*i+8*i(8h
004f2590 {i88{i)8
004f2720 	 @9
004f2ec5 c@9h
004f2fcc hB@9
004f37dd j68h
004f3835 i/8,z/
004f3b39 i`8_
004f3b79 i)8k
004f3c6b RJ	C
004f3c71 j88l
004f3cbf 7+{h
004f3e51 i/8)
004f3ee1 ia8"
004f3efd i"8!
004f4168 +ki8JE@9_
004f41f8 +ki8JE@9_
004f4273 Ra"@
004f4521 TOi\
004f478f *!T@
004f480b *!T@
004f4a7f y@@D
004f4d05 "@9(
004f4e0d "@9H
004f4f73 *!T@
004f5281 &@9i
004f53ef *!T@
004f5551 j@9?	
004f56d7 4)!@
004f572d n@9H
004f5907 5)#K
004f5dfc 	E@9)
004f5e13 Ti{|
004f5fa1 !@9(
004f5fd3 9)!@
004f6227 T+-@
004f6633 *!T@
004f6d0f T*g@
004f6d5d CL9)
004f6f95 CJ9h
004f70d7 =I	@
004f717d "@9h
004f71a1 "@9h
004f7325 cK9h
004f7365 #J9h
004f7535 #J9H
004f7b13 R!d4
004f7c5f k$	@
004f7cf3 k$	@
004f7d2b Rc,5
004f7e13 Rc,5
004f7eb9 CB9h
004f7fbf Rc,5
004f80f9 cE9H
004f84bf <h"@9h
004f8585 `@9h
004f85d4 hb@9h
004f8713 =K1@
004f88af =K1@
004f8b0b o)i@
004f8b1a @9)A
004f8b96 B9JA
004f904c +ki8JE@9_
004f90dc +ki8JE@9_
004f94a8 hB@9h
004f960c kC@9l
004f975c 	A@9
004f9784 	A@9
004f97b4 	A@9
004f9a7f 4hB@9h
004f9f68 kC@9l
004fa0b8 	A@9
004fa0e0 	A@9
004fa110 	A@9
004fa295 ji8JE@9_
004fa33d ji8JE@9_
004fa44d ji8JE@9_
004fa5cd ji8JE@9_
004fa675 ji8JE@9_
004fac81 CM9h
004fafef 6j.L
004fb2ab *H'L
004fb2bf TjFA
004fb6e7 9kQ@
004fb849 CC9h
004fb8e0 hB@9
004fbb89 cD9H
004fbeab k$	@
004fbef3 ThJ@
004fbfe7 rN	@
004fc017 k$	@
004fc097 rN	@
004fc0c7 k$	@
004fc16f rN	@
004fc19f k$	@
004fc2a3 k$	@
004fc2ef ThJ@
004fc303 6hJ@
004fc3ef <h"@9h
004fc559 #@9(
004fc5df 6h&I
004fc6e5 cA9h
004fc7f9 cA9h
004fc855 #@93
004fc891 #@9h
004fc8bd cA9J!
004fcdf8 	 @9
004fd7d0 hB@9u
004fd85b 6`b@
004fd9c2 B9i^@
004fda3a B9i^@
004fdc85 "@9h
004fde11 "@9h
004fde35 "@9h
004fe010 h"@9h
004fe029 cB9h
004fe0db *!T@
004fe15f *!T@
004fe245 cB9h
004fe32d cB9H
004fe5ed #B9h
004fe75d "@9h
004fe887 *!T@
004feb2d #B9h
004fecd7 4I#I
004feef9 #@9h
004ff3c4 ?k78
004ff3eb =)	@
004ff977 <h"@9h
005002bd ki8JE@9_
0050034d ki8JE@9_
005003b3 Ra"@
00500603 4hB@9h
00500768 kC@9l
005008b8 	A@9
005008e0 	A@9
00500910 	A@9
0050140f *!T@
005014e9 cA9h
00501670 	A@9
00501748 	A@9i
00501bfc 	A@9
00501d0c 	A@9
00501dd7 *!T@
00501e8b *!T@
00501fb8 	A@9I
0050215c 	A@9	
0050245f *!T@
00502b13 Thz@
0050352b 4I_@
005040e3 *!T@
005045f9 #@9h
005048fd j48 
00504ee5 cB9h
00504fd3 *!T@
005052f5 cB9h
005053df 6m&@
00505733 *!T@
005057cb *!T@
0050593d CB9h
00505c7b *!T@
00505d17 *!T@
00505da3 *!T@
00505e49 CB9h
00505f71 CB9h
005060c1 CB9H
00506369 CB9h
00506565 cA9h
00506748 ?k"8
0050677d CB9h
0050683d CB9h
00506af1 cA9(
00506b61 CB9h
00507161 #@9h
005071f9 #@9h
00507677 *!T@
0050798b *		@
00507ac7 k$	@
00507cc6 @yj.
00508673 Ri2@
00508acb oZk@
00508d9f =a"@
0050964f TtV@
0050976f oZk@
00509b09 C@9h
00509ca9 C@9h
00509cb9 cB9h
00509fa7 <h"@9
0050a06f <h"@9h
0050a3b3 Tjzi
0050ab67 ThF@9
0050b103 nBX ncX nB(
0050b263 nBX ncX nB(
0050b345 A@9(
0050b463 nBX ncX nB(
0050b8f1 j48h
0050bb35 3@y`
0050bdc4 hb@9
0050c148 ?k78
0050c327 k$	@
0050c50f Tvzu
0050c538 	 @9
0050ca50 hB@9t
0050cd5c (a@9
0050cd6b 6 	@
0050d508 hb@9
0050d593 T8yw
0050d64f T7yv
0050d8fb TJ3@
0050d960 	a@9)
0050dec0 	a@9)
0050e50b T*iw
0050e6a0 i"@y`
0050e7be [8H	
0050eb34 	a@9
0050ed98 	a@9)
00510a38 	a@9	
005111ff R!8+
0051136b R!8+
00511cb7 TH{y
0051288c 	 @9
005128e0 	 @9
005157cf T		@
005157ef T		@
005161c3 o{k@
00516b51 ji8JE@9_
00516bf9 ji8JE@9_
005173fd c@9h
0051755d c@9h
005175c0 	 @9
00517979 C@9H
00517b21 C@9h
00517b81 C@9h
00517f35 c@9h
00518213 Tnyi
0051829f T+yl
00518765 CB9h
00518ef9 !@9h
0051988f TYsL
00519d71 80.+
0051b15b *!T@
0051b614 jj58
0051b79f =a"@
0051bde3 TuZ@
0051bf9b TuZ@
0051c313 TuZ@
0051c73f Tt.@
0051ce49 80.	
0051d1e9 80.	
0051dd85 "@9h
0051de18 h"@9h
0051df2b T)kx
0051df69 "@9h
0051dffc h"@9h
0051e414 h"@9h
0051e438 h"@9h
0051e4a9 "@9h
005220d7 *!T@
005227c7 *!T@
00523243 *!T@
00523717 o)=G
0052380f *!T@
00523f2f o)QG
00524027 *!T@
005249e3 o)iG
00524adb *!T@
00524c1f <!d N
00524ca4 !d NBd N!
00524d30 !d NBd N
00524f5b <!d N
00524fe0 !d NBd N!
0052506c !d NBd N
005253d7 *!T@
00525d7b *!T@
00525e3d  C-	
00526307 *!T@
00526763 *!T@
00526f93 *!T@
005274f3 *!T@
00527db3 *!T@
0052820b *!T@
005288eb *!T@
00528b97 N9W7O
00528c93 n @ 
00528dc7 n @ 
00529117 N9W7O
00529213 n @ 
00529347 n @ 
005299bf *!T@
00529c27 T	 A
00529ee0 	(C-5
0052a603 rAE@
0052a8f5 "@9h
0052a969 "@9h
0052ab0b *!T@
0052ab83 *!T@
0052ad93 *!T@
0052ae8f r6 @
0052aebd #@9h
0052af98 h"@9h
0052b035 "@9h
0052b059 "@9h
0052b143 *!T@
0052b1c3 *!T@
0052b35d "@9h
0052b381 "@9h
0052b3ec h"@9h
0052b8f4 H#@9h
0052b918 H#@9h
0052b940 	-B)
0052b953 Tt}@
0052bb18 h"@9h
0052be71 "@9h
0052be95 "@9h
0052c0bc h"@9h
0052c2a1 #@9h
0052c2c5 #@9h
0052c3ed #@9h
0052c411 #@9h
0052c4d4 h"@9h
0052c835 C@9H
0052cb44 h"@9h
0052cdcf *!T@
0052d2ef <	#z
0052d44b TiF@
0052d4f7 *!T@
0052da57 7h"A9
0052da5f 7hb@9
0052da8f 6`Z@
0052da9f 6`B@
0052daa8 h"A9
0052daaf 6`*@
0052dab8 hb@9h
0052dd0f 7h"A9
0052dd17 7hb@9
0052dd53 6`B@
0052dd5c h"A9
0052dd63 6`*@
0052dd6c hb@9
0052df83 T`R@
0052e6c9 CA9JA
0052e941 CA9JA
0052ece3 oZk@
0052ee9f Tt.@
0052f0c3 =*!	
0052f677 TaR@
0052fbaf <) I
0052fbd7 )) L
0052fd93 *!T@
0052fedd "@9h
00530057 *!T@
00530117 *!T@
00530daf RY!	
005316d3 T`"@
00531875 "@9h
00531899 "@9h
00531b0c h"@9h
00531bcb *!T@
00531dcb *!T@
00531e4b *!T@
00531f21 `B9J
00531f32 B9	H
00531f73 5	\@
0053201b *!T@
00533269 "@9h
00533373 Toyh
00533504 h"@9h
005336dd "@9h
0053379d cA9h!
00533d70 	`B9
00533e05 "@9h
00533e29 "@9h
00533e94 h"@9h
00533f53 *!T@
00534043 TiF@
005340ef *!T@
00534841 CA9JA
00534d83 Ra"@
00534fc7 4`"@
00535342 @y)/@y
00535352 A9)W@9
00535362 A9)S@9
0053544c h"@9h
00535505 #@9h
0053568f =*!	
00535913 TJ		
005365c3 *!T@
00536725 "@9h
00536798 h"@9h
00536857 *!T@
005368cf *!T@
00536b74 h#@9
0053705b *!T@
00537325 #@9h
005373d0 h"@9h
005374d9 "@9h
005374fd "@9h
00537597 *!T@
0053762f *!T@
00537794 h"@9h
00537ac5 "@9h
00537ae9 "@9h
00537d8c h"@9h
0053865c h"@9h
0053943c 	/@y
0053944a A9	W@9
0053945a A9	S@9
0053956d #@9h
0053a1c7 T(K@
0053a2c3 T	 @
0053a4b7 *!T@
0053a577 *!T@
0053a705 "@9h
0053a817 *!T@
0053a973 T)?@
0053b3cb *!T@
0053b61d #@9h
0053b6b0 h"@9h
0053b6f5 "@9h
0053b719 "@9h
0053b7d7 *!T@
0053b857 *!T@
0053bcd5 CA9(
0053bd69 CA9(
0053be15 CA9(
0053be69 CA9(
0053bf30 h"@9h
0053c1d0 (#@9h
0053c1f4 (#@9h
0053c881 CB9h
0053ca38 h"@9h
0053d6cb *!T@
0053ea29 CA9JA
0053f0d1 "@9h
0053f145 "@9h
0053f275 #@9h
0053f30d "@9h
0053f48b *!T@
0053f503 *!T@
0053f62f *!T@
0053f6d7 *!T@
0053f8f3 *!T@
0053f9ef r6 @
0053fa1d cA9h
0053fb5c h"@9h
0053fc2d "@9h
0053fc51 "@9h
0053fd87 *!T@
0053fe07 *!T@
0053ff89 "@9h
0053ffad "@9h
0054002d "@9h
00540051 "@9h
005400bc h"@9h
005404b5 "@9h
005404d9 "@9h
005405f5 "@9h
005409af 6`6@
00540b60 h"@9h
00540e10 (#@9h
00540e34 (#@9h
00540f28 H#@9h
00540f4c H#@9h
005410fc h"@9h
00541379 #@9h
0054139d #@9h
00541486 	K*}@
0054150d #@9h
00541531 #@9h
00541596 	K*}@
0054160c h"@9h
005419d4 h"@9h
00541d0b *!T@
00542161 cA9(
00542171 "@9h
0054222b *!T@
00542483 *!T@
00542cd3 7h"A9
00542cdb 7hb@9
00542d0b 6`Z@
00542d1b 6`B@
00542d24 h"A9
00542d2b 6`*@
00542d34 hb@9h
00542e6f 7h"A9
00542e77 7hb@9
00542eb3 6`B@
00542ebc h"A9
00542ec3 6`*@
00542ecc hb@9
005437d9 CA9JA
00543b98 	 @9
005440b5 "@9h
005441af *!T@
0054422f *!T@
005443c8 +ih8J	
0054444e @y_@
00544555 #@9(
0054466c +yhxJ	
00544d73 *!T@
00544deb *!T@
00544e6b *!T@
0054537b oZk@
005455a9 #A9h
005455e5 #@9H
00545671 #@9(
00545691 #@9(
00545923 T   
005459c7 T@{v
00545a3b TA{h
0054684f TH! 
00546857 T@A 
00546a4f T 9(
00546d21 C@9H
00546ea9 C@9H
005471e1 "@9h
00547205 "@9h
005475b1 "@9h
00547619 "@9h
00547681 "@9h
005476d3 *)E(
005476eb S)}	K
00547735 "@9h
005477bd "@9h
00547831 #A9h
005478d7 *!T@
0054794f *!T@
005479c7 *!T@
00547a53 *!T@
00547acb *!T@
00547d65 "@9h
00547dc5 "@9h
00547e2d "@9h
00547e7f *)E(
00547e97 S)}	K
00547ee1 "@9h
00547f69 "@9h
00547fdd #A9h
00548083 *!T@
005480fb *!T@
00548173 *!T@
005481ff *!T@
00548277 *!T@
005484fd "@9h
00548565 "@9h
005485cd "@9h
0054861f *)E(
00548637 S)}	K
00548681 "@9h
00548753 *!T@
005487cb *!T@
00548857 *!T@
00548a2d "@9h
00548a8d "@9h
00548af5 "@9h
00548b47 *)E(
00548b5f S)}	K
00548ba9 "@9h
00548c7b *!T@
00548cf3 *!T@
00548d7f *!T@
00548f1b rJy"
00548f5d "@9h
00548fc5 "@9h
00549017 *)E(
0054902f S)}	K
00549079 "@9h
00549157 *!T@
005491e3 *!T@
005492fc hb@9
00549523 oZk@
0054979f T   
00549843 T@{v
005498bb TA{h
00549fc9 #@9h
0054a2ad "@9h
0054a399 "@9h
0054a3bd "@9h
0054a475 "@9h
0054a499 "@9h
0054a551 "@9h
0054a575 "@9h
0054a62d "@9h
0054a651 "@9h
0054a709 "@9h
0054a72d "@9h
0054a794 h"@9h
0054a86d C@9H
0054aa71 C@9h
0054afc1 C@9h
0054bacd "@9h
0054bb31 "@9h
0054bbfb *!T@
0054c512 ?m)A
0054c66f *!T@
0054c6ef *!T@
0054cb33 *!T@
0054cbb3 *!T@
0054cdb7 <Bd NBl!N
0054ce38 Bd Ncd N"l"N#l#N
0054cf9f *!T@
0054d01f *!T@
0054d21f <Bd nBl!n
0054d2a0 Bd ncd n"l"n#l#nb
0054d2f4 Bd ."l".
0054d407 *!T@
0054d487 *!T@
0054d8f3 *!T@
0054d973 *!T@
0054dddf *!T@
0054de5f *!T@
0054f211 C@9h
0054f289 "@9h
0054f2ad "@9h
0054f2c5 C@9h
0054f507 R	y9
0054f782 B9(	
0054fd15 #A9h
00550219 cD9H
0055026d cA9H
0055047f 6`6@
0055059b T5{i
005507bb *!T@
00550b33 *!T@
00550be7 *!T@
00550c9b *!T@
0055100f Toyl
005511cf 6`.@
00551513 *!T@
0055164f Toyl
005517b9 C@9h
00551831 "@9h
00551855 "@9h
0055186d C@9h
00551aaf R	y9
00551d2a B9(	
005522bd #A9h
005526b1 cD9H
00552705 cA9H
00552917 6`6@
00552bfb *!T@
00552caf *!T@
00552d63 *!T@
00552e8b Toyl
00552ef7 6`F@
00552f00 hBA9
00553031 C@9h
005530a9 "@9h
005530cd "@9h
005530e5 C@9h
00553327 R	y9
005535a2 B9(	
00553b35 #A9h
00553f29 cD9H
00553f7d cA9H
0055418f 6`6@
00554473 *!T@
00554527 *!T@
005545db *!T@
00554703 Toyl
00554865 C@9h
005548dd "@9h
00554901 "@9h
00554919 C@9h
00554b5b R	y9
00554dd6 B9(	
00555369 #A9h
0055575d cD9H
005557b1 cA9H
005559c3 6`6@
00555ca7 *!T@
00555d5b *!T@
00555e0f *!T@
00555f37 Toyl
00556737 *!T@
00556869 SA9h
005568e9 SA9(
0055705b T,	@
005572a3 ^!("
005572af ^!(#
005572bf N!($
005572c7 ^!("
005572cf ^!(#
005572db ^!($
0055760a "N1"
0055775f T!yj
00557783 ^!("
0055778f ^!(#
0055779f N!($
005577a7 ^!("
005577af ^!(#
005577bb ^!($
005584bb Th~`
005584eb KW}@
005589c7 6I!@
00559b43 T`	@
0055a1f7 T@	@
0055a422 2N7	
0055a42e 3N5Y
0055a437 =rM@
0055a43e 1Nt	
0055a44a 'NrM
0055aa4e <Nc	
0055aa5a <Na	
0055ab5a $Ng@@
0055ab6e !Ng@
0055afe6 <N!	
0055ba03 ORLA
0055ba2f ORLB
0055ba57 ORLC
0055bdf1 Wi-1
0055be15 Wk-2
0055be35 Wm-3
0055beb9 Ow-8
0055c58b T zg
0055c65b T zg
0055c67f T zg
0055c6db T zg
0055c7db T zg
0055c997 T@xd
0055cf37 n/	@
0055cff6 2nSi
0055d083 ^B(9
0055d0ab ^c(8
0055d0b7 ^!(1
0055d0d3 ^c(<
0055d113 ^!(2
0055d423 ^c(1
0055d443 ^B(3
0055d457 ^c(5
0055d46b ^!('
0055d47f ^c(1
0055d48b ^!(8
0055d49b ^c(2
0055d4a7 ^!(5
0055d4bb ^!('
0055d4cb ^B(1
0055d4d7 ^!(%
0055d4ef ^!(3
0055d6d3 ^B(#
0055d6db ^!(%
0055d6e7 ^B(&
0055d6ef ^!(0
0055d6fb =B(1
0055d706 $nB(#
0055d70e 'n!(%
0055d71b ^B($
0055d727 ^!(#
0055d733 ^!(&
0055d73b ^B('
0055d8bf ^!("
0055d8cb ^!(#
0055d8d2 %n!(&
0055d8db ^!("
0055d8e3 ^!(#
0055d8ef ^!($
0055da8a 0N5YA
0055da96 1N3Q
0055daa6 &N5Y
0055dab6 $N0E
0055daef Ti8@
0055dbcf Ti8@
0055dc0e 0N2MA
0055dc32 #N1IA
0055dc3e %N'A
0055dc46 $N1I
0055dc6b Ti8@
0055dcc6 #N0	
0055dcf7 Ti8@
0055dd6b Ti8@
0055ddcb Ti8@
0055debb ^c($
0055dec7 ^c(%
0055dee2 &nc($
0055deef ^c(%
0055defb ^c(&
0055df97 6I!@
0055ebe3 TQ@@
0055f178 h"@9h
0055f488 Lii8k	
005606a0 h"A9h
005606a7 6`.@
00560700 hb@9
00560774 hB@9h
005607e4 hB@9h
00560941 "@9h
00560a2f *!T@
00560bed ii8_
00560cff 6`.@
00560d3c ib@9
00560e2c hb@9
00560f6f 6`.@
00560fc0 ( A9h
00560fc7 6`.@
00561024 hb@9
00561887 o{k@
00561c8b *!T@
00561d0b *!T@
00561d8b *!T@
00561e0b *!T@
00562607 *!T@
00562687 *!T@
00562707 *!T@
00562787 *!T@
00562e3b *!T@
00562ebb *!T@
00562f3b *!T@
00562fbb *!T@
00563763 *!T@
005637e3 *!T@
00563863 *!T@
005638e3 *!T@
00563ceb *!T@
00563e07 TH{a
00563e53 Ti @
0056451b *!T@
0056495f *!T@
00564f8b *!T@
0056514b T-yl
00565207 *!T@
00565505 CA9JA
0056688f nBX nB(
00566c7b T	x{
00567043 *!T@
005670e3 *!T@
0056738b o)i@
005673eb THk{
005678e7 *[i)
00567d3f =)Y 
00567d86 X8(-
00567e4f TH{w
00567f47 TH{w
00568ed2 A9JA
005691af Tt.@
0056954f TtV@
005696df TvR@
0056a55d CB9h
0056a6b7 *!T@
0056a737 *!T@
0056a7db *!T@
0056a873 *!T@
0056aa75 CB9h
0056b297 Tk{i
0056b6f3 Tk{i
0056be29 CD9H
0056c1bd CH9H
0056c271 cG9H
0056c417 *!T@
0056c497 *!T@
0056c553 *!T@
0056c5ff *!T@
0056c6af *!T@
0056c989 CD9H
0056caa9 CH9h
0056cab9 #I9h
0056d911 CB9h
0056da6b *!T@
0056daeb *!T@
0056db8f *!T@
0056dc27 *!T@
0056de29 CB9h
0056e64b Tk{i
0056eaa7 Tk{i
0056f1dd CD9H
0056f571 CH9H
0056f625 cG9H
0056f7cb *!T@
0056f84b *!T@
0056f907 *!T@
0056f9b3 *!T@
0056fa63 *!T@
0056fd3d CD9H
0056fe5d CH9h
0056fe6d #I9h
00570c89 CB9h
00570de3 *!T@
00570e63 *!T@
00570f07 *!T@
00570f9f *!T@
005711a1 CB9h
005719c3 Tk{i
00571e1f Tk{i
00572555 CD9H
005728e9 CH9H
0057299d cG9H
00572b43 *!T@
00572bc3 *!T@
00572c7f *!T@
00572d2b *!T@
00572ddb *!T@
005730b5 CD9H
005731d5 CH9h
005731e5 #I9h
00574001 CB9h
0057415b *!T@
005741db *!T@
0057427f *!T@
00574317 *!T@
00574519 CB9h
00574d3b Tk{i
00575197 Tk{i
005758cd CD9H
00575c61 CH9H
00575d15 cG9H
00575ebb *!T@
00575f3b *!T@
00575ff7 *!T@
005760a3 *!T@
00576153 *!T@
0057642d CD9H
0057654d CH9h
0057655d #I9h
0058c964 +ih8J	
0058ca19 C@9h
0058cab4 Lii8k	
0058cbb5 C@9h
0058cc60 Lii8k	
0058cd61 C@9h
0058ce0c Lii8k	
0058cf0d C@9h
0058cfb8 Lii8k	
0058d0b9 C@9h
0058d64b *!T@
0058d6cb *!T@
0058dd73 *!T@
0058ddf3 *!T@
0058e0ff =)	@
0058e158 kim8_
0058e290 kim8_
0058e8fb =)	@
0058e954 kim8_
0058ea8c kim8_
0058ed9f =)	@
0058fcab *!T@
0058fd2b *!T@
0058fdab *!T@
0058fe9b =)	@
00590a31 cD9H
00591d0f =)	@
0059218b T	,@
00592d64 HyhxT
00593027 T ksx
00593034 @ksx
00593059 j3xs
005935c7 *!T@
00593677 *!T@
005937a0 	!D9
00593804 	!D9
00593a0f *!T@
00593dbb =)	@
0059462f =)	@
00594e6f =)	@
005956e3 =)	@
005963c3 =)	@
00596c37 =)	@
00597477 =)	@
00597ceb =)	@
005989cb =)	@
00599237 =)	@
00599a6f =)	@
0059a2e3 =)	@
0059b177 =)	@
0059b9eb =)	@
0059c22b =)	@
0059c277 T	,@
0059c2c7 T	,@
0059c317 T	,@
0059c46b =)	@
0059c4b7 T	,@
0059c507 T	,@
0059c557 T	,@
0059cb8c hB@9
0059cdaf *!T@
0059d444 hB@9
0059d667 *!T@
0059dcd4 hB@9
0059def7 *!T@
0059e67c hB@9
0059e8a3 *!T@
0059e956 OK)	@
0059ec12 QKk	@
0059ef40 hB@9
0059f163 *!T@
0059f808 hB@9
0059fa2f *!T@
005a00ac hB@9
005a01db o)-B
005a02d3 *!T@
005a0a00 hB@9
005a0b2f o)EB
005a0c27 *!T@
005a0d18 +%@xJ
005a0e9c +%@x
005a1054 hB@9
005a1183 o)]B
005a127b *!T@
005a16a8 hB@9
005a17d7 o)uB
005a18cf *!T@
005a215c hB@9
005a237f *!T@
005a2a14 hB@9
005a2c37 *!T@
005a32a4 hB@9
005a34c7 *!T@
005a3c3c hB@9
005a3e5f *!T@
005a44f4 hB@9
005a4717 *!T@
005a4fb4 hB@9
005a51d7 *!T@
005a561c hB@9
005a583f *!T@
005a5d64 hB@9
005a5f87 *!T@
005a63cc hB@9
005a64f7 o)-C
005a65ef *!T@
005a6b14 hB@9
005a6c3f o)AC
005a6d37 *!T@
005a73f4 hB@9
005a751f o)UC
005a7617 *!T@
005a7d8c hB@9
005a7eb7 o)iC
005a7faf *!T@
005a83f4 hB@9
005a851f o)}C
005a8617 *!T@
005a8d8c hB@9
005a8faf *!T@
005a92ac hB@9
005a94cf *!T@
005a9a74 hB@9
005a9c97 *!T@
005aa6cc hB@9
005aa8ef *!T@
005ab5af *!T@
005ab62f *!T@
005ab6af *!T@
005abf9b *!T@
005ac01b *!T@
005ac09b *!T@
005ac257 =)	@
005acc03 =)	@
005adbbf =)	@
005adc73 nc(a
005add4b nc(a
005ade33 n!(a
005adfab =)	@
005ae4ef =)	@
005ae5a3 NB(a
005ae67b NB(a
005ae763 N!(a
005ae8db =)	@
005aef47 =)	@
005aeffb nc(a
005af0d3 nc(a
005af1bb n!(a
005af333 =)	@
005af877 =)	@
005af92b NB(a
005afa03 NB(a
005afaeb N!(a
005afc63 =)	@
005b02cf =)	@
005b0873 =)	@
005b0927 nB(a
005b09ff nB(a
005b0ae7 n!(a
005b0c5f =)	@
005b107b =)	@
005b112e $Nc(a
005b1206 "Nc(a
005b12ee $N!(a
005b1467 =)	@
005b151a dNc(
005b1602 bNc(
005b16fa dN!(
005b1e4b =)	@
005b1efe "nc(a
005b1fd6 $nc(a
005b20be "n!(a
005b2237 =)	@
005b22ea bnc(
005b23d2 dnc(
005b24ca bn!(
005b2653 =)	@
005b2707 NB(a
005b27df NB(a
005b28c7 N!(a
005b2a3f =)	@
005b30ab =)	@
005b315e $nc(a
005b3236 "nc(a
005b331e "n!(a
005b3497 =)	@
005b354a dnc(
005b3632 bnc(
005b372a bn!(
005b38b3 =)	@
005b3967 NB(a
005b3a3f NB(a
005b3b27 N!(a
005b3c9f =)	@
005b45e5 "@9h
005b473b *!T@
005b4a39 0bn$
005b4a52 AN!(!
005b4ba3 /C0cnD0dn
005b4d59 0anc
005b4d6a AN!(!
005b5237 *!T@
005b52af *!T@
005b54e1 "@9h
005b5637 *!T@
005b5cff TI		
005b5f47 *!T@
005b5fbf *!T@
005b61f1 "@9h
005b6347 *!T@
005b6c57 *!T@
005b6ccf *!T@
005b6e5b =)	@
005b759f =)	@
005b7ccb =)	@
005b83f7 =)	@
005b8b23 =)	@
005b9267 =)	@
005b9993 =)	@
005ba0bf =)	@
005ba89d X n!X n`
005bab0d X n!X n
005bad31 X n!X n
005baf55 X n!X n
005bb15d X n!X n`
005bb3cd X n!X n
005bb5f1 X n!X n
005bb815 X n!X n
005bb96b =)	@
005bc0af =)	@
005bc7db =)	@
005bcf07 =)	@
005bd633 =)	@
005bdd77 =)	@
005be4a3 =)	@
005bebcf =)	@
005bf2fb =)	@
005bfa3f =)	@
005c016b =)	@
005c0897 =)	@
005c0fc3 =)	@
005c1707 =)	@
005c1e33 =)	@
005c255f =)	@
005c35db Nc@b
005c3652 %NBT>Of
005c3d0f Nc@b
005c3dbf Nc@b
005c3e6f Nc@b
005c3f1f NB@b
005c3f8a %N%T>OC
005c5369 cB9H
005c545f *!T@
005c550b *!T@
005c5649 CA9h
005c58b9 #C9H
005c590d #D9H
005c59c9 c@9h
005c5ab1 c@9h
005c5af5 c@9h
005c5b0d c@9h
005c61d3 *!T@
005c626b *!T@
005c6387 7hBC9
005c63d4 hBC9
005c63db 6`n@
005c63eb 6`V@
005c63fb 6`6@
005c67ef *!T@
005c68d7 Tk"@
005c6907 TkJ@
005c692b T+y(
005c6a97 *!T@
005c6c1b o{k@
005c6e2f *!T@
005c730b *!T@
005c7565 CA9JA
005c7745 CA9JA
005c7a8f *!T@
005d12df T(D@y)
005d1990 Lii8k	
005d1ab1 "@9h
005d5267 T(D@y)
005d57fc Lii8k	
005d591d "@9h
005d8caf *!T@
005d94bf *!T@
005daeae a~`~
005dbb4e a^8{
005dcfb8 #yhx
005dd090 cynx]
005dd664 #yhx
005dd73c cynxU
005ddcc8 #yhx
005ddda0 cynx]
005ddf9a a~%r
005de370 #yhx
005de448 cynxN
005de4fa @yM	
005de5fe @ym	
005de822 @yM	
005de96c #ih8
005dea44 cin8^
005df030 #ih8
005df108 cin8Y
005df6a4 #ih8
005df77c cin8^
005dfd64 #ih8
005dfe3c cin8Q
005dfeee @9,	
005dfffe @9l	
005e022e @9L	
005e03bb *!T@
005e0985 CF9h
005e0a6d CF9h
005e0bef 7h"D9h
005e0bff 7hbB9h
005e0c38 h"D9
005e0c4f 6`r@
005e0c58 hbB9h
005e0c68 hbB9
005e0c6f 6`R@
005e0c7f 6`:@
005e0c8f 6`"@
005e0da3 6`6@
005e1437 *!T@
005e27ed "@9h
005e2a2d "@9h
005e2a51 "@9h
005e2a79 #@9(
005e2ae1 "@9h
005e2b05 "@9h
005e2bb9 #@9(
005e2c9b *!T@
005e2d13 *!T@
005e2d8b *!T@
005e2e39 #@9H
005e3050 h"@9h
005e36cd "@9h
005e3f03 *!T@
005e4bcb Rsj@
005e4c1f R!@=
005e4d67 T {h
005e510f Tx.@
005e51c9 #@9h
005e5af1 "@9h
005e75c1 "@9h
005e75dd c@9h
005e7631 "@9h
005e764d c@9h
005e769d "@9h
005e76bd c@9h
005e7715 "@9h
005e7731 c@9h
005e7747 RJ!,
005e7789 "@9h
005e77a5 c@9h
005ea28f Tj&@xJ=
005eb6e5 "@9h
005ebecd "@9h
005ec545 "@9h
005ecd2d "@9h
005ed67f R!@=
005edbdf *Hxy
005ee6b1 "@9h
005ee725 "@9h
005ee7e7 *!T@
005ee85f *!T@
005ee8d7 *!T@
005eebed "@9h
005eecab *!T@
005ef1e5 "@9h
005ef25d "@9h
005ef2d9 "@9h
005ef3a3 *!T@
005ef41b *!T@
005ef493 *!T@
005efeef 6 !@
005f093b 6 !@
005f26fb kzz-
005f274f Tnzj
005f2773 Tozm
005f279f Tmzj
005f27e7 Tpz*
005f28a3 Tazp
005f28c7 Tbz`
005f28f3 T`zp
005f293b Tcz0
005f2a4b Tlzi
005f2a6f Tmzk
005f2a9b Tkzi
005f2ae3 Tnz)
005f2f53 4aN6
005f314f T   
005f316f T@ !
005f31d7 T@ !
005f3353 T   
005f33ab T   
005f33d7 T   
005f34eb T   
005f350b T@ !
005f3653 T   
005f37b7 T@ !
005f3833 T@ !
005f3893 T   
005f38bf T   
005f398b T   
005f3aa4 +ih8J	
005f3b07 T   
005f3b27 T@ !
005f3c27 T   
005f3c5f T   
005f3c7f T@ !
005f3dcf T   
005f3f5b T   
005f3f7b T@ !
005f407b T@ !
005f4083 T@  
005f409b T@  
005f40bf T@  
005f4104 Lii8k	
005f4147 T   
005f4167 T@ !
005f42d3 T   
005f42f3 T@ !
005f4393 T@ !
005f439b T@  
005f43b3 T@  
005f444b T   
005f447f T@  
005f48eb kzz-
005f493f Tnzj
005f4963 Tozm
005f498f Tmzj
005f49d7 Tpz*
005f4a93 Tazp
005f4ab7 Tbz`
005f4ae3 T`zp
005f4b2b Tcz0
005f4c3b Tlzi
005f4c5f Tmzk
005f4c8b Tkzi
005f4cd3 Tnz)
005f5143 4aN6
005f533f T   
005f535f T@ !
005f53c7 T@ !
005f5543 T   
005f559b T   
005f55c7 T   
005f56db T   
005f56fb T@ !
005f5843 T   
005f59a7 T@ !
005f5a23 T@ !
005f5a83 T   
005f5aaf T   
005f5b7b T   
005f5c94 +ih8J	
005f5cf7 T   
005f5d17 T@ !
005f5e17 T   
005f5e4f T   
005f5e6f T@ !
005f5fbf T   
005f614b T   
005f616b T@ !
005f626b T@ !
005f6273 T@  
005f628b T@  
005f62af T@  
005f62f4 Lii8k	
005f6337 T   
005f6357 T@ !
005f64c3 T   
005f64e3 T@ !
005f6583 T@ !
005f658b T@  
005f65a3 T@  
005f663b T   
005f666f T@  
005f66fb *Hxx
005f69d7 *Hxz
005f717f 6 !@
005f767b kzz-
005f76cf Tnzj
005f76f3 Tozm
005f771f Tmzj
005f7767 Tpz*
005f7823 Tazp
005f7847 Tbz`
005f7873 T`zp
005f78bb Tcz0
005f79cb Tlzi
005f79ef Tmzk
005f7a1b Tkzi
005f7a63 Tnz)
005f7ed3 4aN6
005f80cf T  `
005f80ef T@ a
005f8157 T@ a
005f82d3 T  `
005f832b T  `
005f8357 T  `
005f846b T  `
005f848b T@ a
005f85d3 T  `
005f8737 T@ a
005f87b3 T@ a
005f8813 T  `
005f883f T  `
005f890b T  `
005f8a24 +ih8J	
005f8a87 T  `
005f8aa7 T@ a
005f8ba7 T  `
005f8bdf T  `
005f8bff T@ a
005f8d4f T  `
005f8edb T  `
005f8efb T@ a
005f8ffb T@ a
005f9003 T@ `
005f901b T@ `
005f903f T@ `
005f9084 Lii8k	
005f90c7 T  `
005f90e7 T@ a
005f9253 T  `
005f9273 T@ a
005f9313 T@ a
005f931b T@ `
005f9333 T@ `
005f93cb T  `
005f93ff T@ `
005f986f kzz-
005f98c3 Tnzj
005f98e7 Tozm
005f9913 Tmzj
005f995b Tpz*
005f9a17 Tazp
005f9a3b Tbz`
005f9a67 T`zp
005f9aaf Tcz0
005f9bbf Tlzi
005f9be3 Tmzk
005f9c0f Tkzi
005f9c57 Tnz)
005fa0c7 4aN6
005fa2c3 T  `
005fa2e3 T@ a
005fa34b T@ a
005fa4c7 T  `
005fa51f T  `
005fa54b T  `
005fa65f T  `
005fa67f T@ a
005fa7c7 T  `
005fa92b T@ a
005fa9a7 T@ a
005faa07 T  `
005faa33 T  `
005faaff T  `
005fac18 +ih8J	
005fac7b T  `
005fac9b T@ a
005fad9b T  `
005fadd3 T  `
005fadf3 T@ a
005faf43 T  `
005fb0cf T  `
005fb0ef T@ a
005fb1ef T@ a
005fb1f7 T@ `
005fb20f T@ `
005fb233 T@ `
005fb278 Lii8k	
005fb2bb T  `
005fb2db T@ a
005fb447 T  `
005fb467 T@ a
005fb507 T@ a
005fb50f T@ `
005fb527 T@ `
005fb5bf T  `
005fb5f3 T@ `
005fba57 k|z+
005fbaa7 Tnzj
005fbacb Tozm
005fbaf7 Tmzj
005fbb3f Tpz*
005fbb77 Toyn
005fbb9b Tpy|
005fbbd7 Tqzn
005fbbfb T`zp
005fbc27 Tpzn
005fbc6f Taz.
005fbd83 Tlzi
005fbda7 Tmzk
005fbdd3 Tkzi
005fbe1b Tnz)
005fc28f 4aN6
005fcde4 +ih8J	
005fd444 Lii8k	
005fdc23 k|z+
005fdc73 Tnzj
005fdc97 Tozm
005fdcc3 Tmzj
005fdd0b Tpz*
005fdd43 Toyn
005fdd67 Tpy|
005fdda3 Tqzn
005fddc7 T`zp
005fddf3 Tpzn
005fde3b Taz.
005fdf4f Tlzi
005fdf73 Tmzk
005fdf9f Tkzi
005fdfe7 Tnz)
005fe45b 4aN6
005fefb0 +ih8J	
005ff610 Lii8k	
005ffe3f Tnzk
005ffe63 Tozm
005ffe8f Tmzk
005ffed7 Tpz+
005fff93 Tazp
005fffb7 Tbz`
005fffe3 T`zp
0060002b Tcz0
00600143 Tlzi
00600167 Tmzk
00600193 Tkzi
006001db Tnz)
0060064f 4aN6
006011b0 +ih8J	
0060182c Lii8k	
00602073 Tnzk
00602097 Tozm
006020c3 Tmzk
0060210b Tpz+
006021c7 Tazp
006021eb Tbz`
00602217 T`zp
0060225f Tcz0
00602377 Tlzi
0060239b Tmzk
006023c7 Tkzi
0060240f Tnz)
00602883 4aN6
006033e4 +ih8J	
00603a60 Lii8k	
00605ce5 "@9h
00605f35 #@9h
00605f59 #@9H
00605ff1 #@9(
00606499 CA9h
006064a9 #@9h
0060673b T )@
006067ef T )@
0060691b *!T@
00606c87 *!T@
00606e1f T )@
00606ed7 T )@
00607007 *!T@
0060737b *!T@
006076ef *!T@
00607a3f *!T@
00607c0d "@9h
00607c25 #A9h
00607d4d "@9h
00607d65 #A9h
00607e41 "@9h
00607e59 #A9h
00608033 *!T@
006080ab *!T@
00608123 *!T@
006081a3 *!T@
00608e6b 6`:@
006090b1 #@9h
006090e3 RJU>
00609125 #@9h
00609195 #@9h
00609205 "@9h
00609403 *!T@
0060947b *!T@
006094f3 *!T@
0060956b *!T@
006095e3 *!T@
006096bf 6`:@
00609a08 kC@9l
00609b58 	A@9
00609b80 	A@9
00609bb0 	A@9
0060a051 ki8JE@9_
0060a0e1 ki8JE@9_
0060a147 Ra"@
0060a397 4hB@9h
0060a4fb Ra"@
0060a73f 4hb@9h
0060a899 ji8JE@9_
0060a941 ji8JE@9_
0060b441 "@9h
0060b4fb *!T@
0060bab1 "@9h
0060bb6b *!T@
0060c235 "@9h
0060c2ef *!T@
0060c9b5 "@9h
0060ca6f *!T@
0060ce29 "@9h
0060cee3 *!T@
0060d275 "@9h
0060d32f *!T@
0060d987 7I#A
0060dab7 T(/@
0060dadc jyhx)	
0060e24f T G@
0060e287 T G@
0060e32b T G@
0060e363 T G@
0060e55b *!T@
0060e61b *!T@
0060ea7f *!T@
0060eeb1 "@9h
0060eeef RJ-+
0060ef31 "@9h
0060f023 *!T@
0060f2fd "@9h
0060f4c7 *!T@
006102ff 9)a@
00610349 "@9h
0061037d c@9h
006103d9 c@9h
00610709 "@9h
00610729 #@9h
00610a95 "@9h
00610ab5 #@9h
00610e21 "@9h
00610e41 #@9h
00611187 9)a@
006111d1 "@9h
00611205 c@9h
00611261 c@9h
00611591 "@9h
006115b1 #@9h
0061191d "@9h
0061193d #@9h
006119ab 6`:@
00611be5 #@9h
00611c55 #@9h
00611cc5 "@9h
00611e8b *!T@
00611f03 *!T@
00611f7b *!T@
0061202f 6`:@
006121a3 Ra"@
006126cf *!T@
00612763 *!T@
0061284f *!T@
006128df 6`&@
0061298f 6`>@
006129a3 6`2@
00612adb 7hBA9H
00612b00 hBA9
00612b07 6`2@
00612b17 6`&@
00612c80 !80.,
0061335c !80.(
0061369f 4hb@9h
006139f7 *!T@
00613ce5 #@9h
00613d63 *!T@
00613d75 #@9h
00613df3 *!T@
00613edb *!T@
00613f5b 6`6@
006140bf 6`*@
006143e9 ki8JE@9_
00614479 ki8JE@9_
006144df Ra"@
0061472f 4hB@9h
00614894 kC@9l
006149e4 	A@9
00614a0c 	A@9
00614a3c 	A@9
00614bc1 ji8JE@9_
00614c69 ji8JE@9_
00614f01 #@9h
00614f7f *!T@
00614f91 #@9h
0061500f *!T@
006150f7 *!T@
0061520b 6`6@
0061521b 6`*@
0061530f 6`*@
006153b3 6`*@
00615d09 #@9h
00615d87 *!T@
00615d99 #@9h
00615e17 *!T@
00615eff *!T@
00615f7f 6`*@
00616027 6`6@
00616103 6`*@
006161a7 6`*@
00616274 !80.,
006163fc !80.(
00616c0b *!T@
00616c9f *!T@
00616d8b *!T@
00616e1b 6`&@
00616ecb 6`>@
00616edf 6`2@
00616f13 7hBA9H
00616f38 hBA9
00616f3f 6`2@
00616f4f 6`&@
00617455 #@9h
006174d3 *!T@
006174e5 #@9h
00617563 *!T@
0061764b *!T@
006176cb 6`6@
006176db 6`*@
006177a7 6`*@
00617ba5 #@9h
00617c23 *!T@
00617c35 #@9h
00617cb3 *!T@
00617d9b *!T@
00617e1b 6`*@
00617ec3 6`6@
00617f9f 6`*@
00618043 6`*@
00618ae1 "@9h
00618afd #@9h
00618b2f 8)a@
00618c75 #@9(
00618c95 #@9h
00618d21 #@9h
00618ddd #@9h
00618df3 R)M<
00618e39 #@9h
00618e91 "@9h
00618ea9 #@9h
00618f8f *!T@
00619039 #@9h
00619099 #@9h
006191f9 "@9h
006195c5 #A9h
00619687 T@E@
006197a7 *!T@
00619a0b *!T@
00619a50 +yhxJ	
00619b57 = @ 
00619cbf T A!
00619e43 = @ 
0061a5bc h"@9h
0061a701 "@9h
0061a873 *!T@
0061a8e7 *!T@
0061a95b *!T@
0061b11d #@9h
0061b291 #@9h
0061b301 "@9h
0061b319 #@9h
0061b375 "@9h
0061b38d #@9h
0061b48f *!T@
0061b507 *!T@
0061b733 TY#A9H
0061be65 "@9h
0061be7d CA9h
0061bf51 #@9h
0061bf8d #@9h
0061bfa1 #@9h
0061c08f *!T@
0061c13d #@9(
0061c269 "@9h
0061c339 "@9h
0061c35d "@9h
0061c401 "@9h
0061c425 "@9h
0061c4c9 "@9h
0061c4ed "@9h
0061c591 "@9h
0061c5b5 "@9h
0061c689 #@9H1
0061cddb oZk@
0061cf75 #@9h-
0061d38a bn!ha
0061d76a aNBha
0061d896 aN!ha
0061d94a aNBha
0061dca1 #@9(/
0061ed49 "@9h
0061ed7b R)U>
0061f07b *!T@
0061f0fb *!T@
0061f53f TQyp
0061fd05 "@9h
0061fd37 R)U>
00620037 *!T@
006200b7 *!T@
006204b7 TQyp
00620751 "@9h
00620783 R)U>
00620a83 *!T@
00620b03 *!T@
00620f03 TQyp
0062119d "@9h
006211cf R)U>
006214cf *!T@
0062154f *!T@
00621f97 *!T@
006220c7 *!T@
006220fd CA9H
00622f7f *!T@
006230af *!T@
006230e5 CA9H
00623c6f *!T@
00623d9f *!T@
00623dd5 CA9H
0062494b *!T@
00624a7b *!T@
00624ab1 CA9H
006258f3 8)a@
00625ab5 "@9h
00625b29 "@9h
00625bb7 R)M<
00625bf5 "@9h
00625c29 "@9h
00625df3 Tl.L
00625e23 Ti"I
00625e3b Ti"L
00625f4b *!T@
00625fc3 *!T@
0062603b *!T@
006260b3 *!T@
0062612b *!T@
006261a3 *!T@
0062621b *!T@
00626625 c@9(
00626645 c@9h
006266c1 "@9h
006266d9 c@9h
0062675d c@9h
006267cf *!T@
00626a76 ?m)A
00626afe !^@E
00626bec h"@9h
00627093 *3}@
0062751d xaN"
00627533 ^ (`
00627548 AxaN
0062766d xaN"
00627683 ^ (`
00627698 AxaN
00627f4b n @ 
006281f7 ^ @ 
006283eb T(a@9
00628743 Tkzx
006287af Tkzh
006287bf Tlzh
006288b3 Tkzx
0062891f Tkzh
0062892f Tlzh
00628983 Tkzh
00628aff ~   
00628ddf T@%@
00628de4 Ua@9
00628e2b Ra"	
00628f5f R %@
0062903b R#)@
006290b3 Ra"	
00629c11 "@9h
00629c2d #@9h
00629ca9 #@9h
00629e1d #@9h
00629e7d #@9h
00629e95 #@9h
00629ef1 #@9h
00629f09 #@9h
00629f6d "@9h
00629f89 #@9h
0062a0d3 *!T@
0062a14b *!T@
0062a1c3 *!T@
0062a53c h"@9h
0062a8f5 "@9h
0062a9ab *!T@
0062c5d7 =)	@
0062c7a3 R)5!
0062c94b R)q#
0062cd65 #F9h
0062cd95 CG9h
0062cdd5 #I9H	
0062cf89 #O9h
0062cfb9 CP9h
0062cfe9 cQ9h
0062d4a5 #F9H
0062d506 J9H 
0062d56d #O9h
0062d629 CP9H
0062dbbd %A9J
0062dcd5 %A9J
0062e10b =)	@
0062e2d5 "@9h
0062e33b R)5!
0062e4df R)q#
0062e799 #D9h
0062e7c9 CE9h
0062e809 #G9H	
0062e9bd #M9h
0062e9ed CN9h
0062eaad CS9h
0062eeb5 cF9(
0062eec5 #G9(
0062ef16 J9(#
0062ef4d #M9h
0062ef6d CN9H
0062efee R8H	
0062f235 CE9h
0062f275 cF9(
0062f2a5 #G9(
0062f3cd #M9(
0062f4c5 ii8J	
0062f97f Tl/@
0062f9df T*/@
0062f9ff Tj.@
0062fa13 Th'@
0062fa3b TH%@
006300a3 T "A9
00630b0b *!T@
00630b83 *!T@
00630bfb *!T@
00630c73 *!T@
00630ceb *!T@
00630d63 *!T@
00630ddb *!T@
00630e53 *!T@
00630ecb *!T@
00630f43 *!T@
00630fbb *!T@
00631033 *!T@
006310ab *!T@
0063112b *!T@
00631a8e _x_}>
00631d94 ($@)
00631da7 JW}@
006321e8 OAB)
00632278 N=B)
006322e4 ($@)
006322f7 JW}@
0063306c hkh8*
00635888 dJ@z3
00635f5b 9   
00635f61 Y@z 
00635fef q ( 
00636160 Hkh8*
0063786f 9   
00637903 q ( 
00637a74 Hkh8*
00638918 Lii8k	
00638929  A9)
00638941  A9H
0063895d $A9h
00638981  A9H
006389a4 	 A9)
006389c9 ii8J	
00638a0b T	$A9i
00638a41  A9H
00638a5d $A9h
00638a85  A9I
00638a9d  A9h
00638ab9 $A9h
00638b15 $A9h
00638b71 $A9h
00638b99  A9)
00638bcd $A9h
00638c15  A9*
00638c45  A9*
00638c75  A9*
00638ca5  A9*
00638cd5  A9*
00638d05  A9*
00638d4f T`"@
006394bb n @ 
006396ef *!T@
006398e3 *!T@
00639ab7 *!T@
0063a773 T`"@
0063a7df n @ 
0063a887 r`"@
0063a913 T`"@
0063a94f T`"@
0063aa24 +yhxJ	
0063adbb T A!
0063ae3b T 8)
0063ae4f rJ) 
0063b108 	1@9
0063b712 @MJA
0063c27b T`"@
0063c9bf n @ 
0063d147 q ( 
0063d477 oa"@
0063d4e3 n @ 
0063d58f r`"@
0063d61b oa"@
0063d65b /a"@
0063e2c7 T`"@
0063e2ee @9   
0063e2f5 Y@z(
0063e317 R`"@
0063e34b 9   
0063e350 $Y@z 
0063e383 R`"@
0063e3b7 9   
0063e3bc $Y@z 
0063e53f Rh>@
0063ead7 n @ 
0063ec27 /AE@
0063ed2b *!T@
0063ee7f 4 jk
0063eeff *!T@
0063f087 9   
0063f08c $Y@z 
0063f34b 9   
0063f351 Y@zh
0063f641 M@8k
0063f68b q ( 
0063f9ff Ob"@
0063fa63 n @ 
0063fb0b r`"@
0063fbc3 T`"@
006408e7 T`"@
0064090e @9   
00640937 R`"@
0064096b 9   
006409a3 R`"@
006409d7 9   
00640b5f Rh>@
006410f7 n @ 
006412bb 4 jk
0064133b *!T@
006414c3 9   
00641787 9   
00641a7d M@8k
00641ac7 q ( 
00641e3b Ob"@
00641e9f n @ 
00641f47 r`"@
00641fff T`"@
00642f51 BB9H
00643158 h"@9h
00643e00 hkh8*
00644b73 T`"@
006452b4 l1@9
00645349 1@9m
0064535b T   
00645390 )1@9)
006453b7 R)1@9
006454f7 *!T@
00645714 +ih8J	
006458f7 T E@
006459c3 T E@
006459d7 T A!
00645a43 RJ) 
00645ae7 r G@
006465c4 l1@9,
006465ce @9`	@
006466f7 *!T@
0064786b =)	@
00647a37 R)5!
00647bdf R)q#
00647ff9 #F9h
00648029 CG9h
00648069 #I9H	
0064821d #O9h
0064824d CP9h
0064827d cQ9h
00648739 #F9H
0064879a J9H 
00648801 #O9h
006488bd CP9H
00648e51 %A9J
00648f69 %A9J
0064939f =)	@
00649569 "@9h
006495cf R)5!
00649773 R)q#
00649a2d #D9h
00649a5d CE9h
00649a9d #G9H	
00649c51 #M9h
00649c81 CN9h
00649d41 CS9h
0064a149 cF9(
0064a159 #G9(
0064a1aa J9(#
0064a1e1 #M9h
0064a201 CN9H
0064a282 R8H	
0064a4c9 CE9h
0064a509 cF9(
0064a539 #G9(
0064a661 #M9(
0064a759 ii8J	
0064ac2b Tl.@
0064ac7b TJ/@
0064ac87 T*/@
0064acbb Th&@
0064acdb TH%@
0064ad1b TH'@
0064b17b 9M;@
0064b37b T bA9
0064be0b *!T@
0064be83 *!T@
0064befb *!T@
0064bf73 *!T@
0064bfeb *!T@
0064c063 *!T@
0064c0db *!T@
0064c153 *!T@
0064c1cb *!T@
0064c243 *!T@
0064c2bb *!T@
0064c333 *!T@
0064c3ab *!T@
0064c42b *!T@
0064ca96 _x_}>
0064cb50 ($@)
0064cb63 JW}@
0064cfa4 OAB)
0064d034 N=B)
0064d0a0 ($@)
0064d0b3 JW}@
0064de2c hkh8*
0064f4fb q @b
00650643 T*!@9
00650654 dJ@z3
00650d23 9  `
00650d29 Y@z 
00650db7 q!(`
00650f2c Hkh8*
00651f5f T*!@9
0065263f 9  `
006526d3 q!(`
00652848 Hkh8*
006536db 4	 @
006536f4 Lii8k	
00653705 `A9)
0065371d `A9H
00653739 dA9h
0065375d `A9H
00653780 	`A9)
00653787 4	 @
006537a5 ii8J	
006537e7 T	dA9i
0065381d `A9H
00653839 dA9h
00653861 `A9I
00653879 `A9h
00653895 dA9h
006538f1 dA9h
0065394d dA9h
00653975 `A9)
006539a9 dA9h
006539f1 `A9*
00653a21 `A9*
00653a51 `A9*
00653a81 `A9*
00653ab1 `A9*
00653ae1 `A9*
00653b2b T`"@
006543eb *!T@
006545df *!T@
00654714 1"@9
006547b3 *!T@
00654f52 a~!iy
00655353 T`z6
006553a7 Taz6
00655474 +yhxJ	
0065562c *!@9
0065565c )!@9
00655698 *!@9)A
00655700 	!@9
00655740 h#@9
00655784 	#@9
0065578b 9!@b
006557c8 	!@9
00655830 	!@9
006558db T 8(
0065591b Ti#@9h#
0065595c 	!@9
006559d0 (#@9
00656b53 T`"@
00657937 q!(`
00657d0b T`z6
00657d5f Taz6
006589c7 T`"@
006589ed "@9  `
006589f5 Y@z(
00658a1b R`"@
00658a4c 	!@9
00658a53 9  `
00658a58 $Y@z 
00658a8f R`"@
00658ac0 	!@9
00658ac7 9  `
00658acc $Y@z 
00658c53 Rh>@
00659337 T+!@9+
006593af /*!@9J
00659427 *!T@
0065955c 1"@9
00659575  @9@
0065957b 4 jk
006595fb *!T@
00659780 	!@9
00659787 9  `
0065978c $Y@z 
00659a44 (!@98!
00659a4b 9  `
00659a51 Y@zh
00659d18 H!@9
00659d30 H!@9h
00659d70 	!@9
00659d8b q!(`
0065a1a6 !.)	
0065afc3 T`"@
0065afe9 "@9  `
0065b017 R`"@
0065b048 	!@9
0065b04f 9  `
0065b08b R`"@
0065b0bc 	!@9
0065b0c3 9  `
0065b24f Rh>@
0065b974 1"@9
0065b98d  @9@
0065b993 4 jk
0065ba13 *!T@
0065bb98 	!@9
0065bb9f 9  `
0065be5c (!@98!
0065be63 9  `
0065c130 H!@9
0065c148 H!@9h
0065c188 	!@9
0065c1a3 q!(`
0065c5be !.)	
0065d605 BB9H
0065d617 T yv
0065d820 h"@9h
0065e29c hkh8*
0065f007 T`"@
0065f548 +ih8J	
0065f61f T@	i
0065fc25 !@9+
0065fc88 la@9
0065fd1d a@9m
0065fd2f T  `
0065fd64 )a@9)
0065fd8b R)a@9
0065fecb *!T@
006609ac la@9,
006609b6 @9`	@
006609e3 /*!@9!
00660adf *!T@
00661c53 =)	@
00661e1f R)5!
00661fc7 R)q#
006623e1 #F9h
00662411 CG9h
00662451 #I9H	
00662605 #O9h
00662635 CP9h
00662665 cQ9h
00662b21 #F9H
00662b82 J9H 
00662be9 #O9h
00662ca5 CP9H
00663239 %A9J
00663351 %A9J
00663787 =)	@
00663951 "@9h
006639b7 R)5!
00663b5b R)q#
00663e15 #D9h
00663e45 CE9h
00663e85 #G9H	
00664039 #M9h
00664069 CN9h
00664129 CS9h
00664531 cF9(
00664541 #G9(
00664592 J9(#
006645c9 #M9h
006645e9 CN9H
0066466a R8H	
006648b1 CE9h
006648f1 cF9(
00664921 #G9(
00664a49 #M9(
00664b41 ii8J	
00664ffb Tl/@
0066505b T*/@
0066507b Tj.@
0066508f Th'@
006650b7 TH%@
0066571f T "A9
00666187 *!T@
006661ff *!T@
00666277 *!T@
006662ef *!T@
00666367 *!T@
006663df *!T@
00666457 *!T@
006664cf *!T@
00666547 *!T@
006665bf *!T@
00666637 *!T@
006666af *!T@
00666727 *!T@
006667a7 *!T@
00667530 hkh8*
00669d4c dJ@z3
0066a41f 9   
0066a425 Y@z 
0066a4b3 q ( 
0066a624 Hkh8*
0066bd33 9   
0066bdc7 q ( 
0066bf38 Hkh8*
0066cddc Lii8k	
0066ce29  A9h
0066ce5c 	 A9
0066ce81 ij8k	
0066cee9  A9i
0066cf29  A9	
0066cfa9  A9I
0066d19b T`"@
0066d907 n @ 
0066db3b *!T@
0066dd2f *!T@
0066dee3 *!T@
0066e947 T`"@
0066e9b3 n @ 
0066ea5b r`"@
0066eae7 T`"@
0066eb23 T`"@
0066f6ef T`"@
0066fe33 n @ 
006705bb q ( 
006708eb oa"@
00670957 n @ 
00670a03 r`"@
00670a8f oa"@
00670acf /a"@
0067173b T`"@
00671762 @9   
00671769 Y@z(
0067178b R`"@
006717bf 9   
006717c4 $Y@z 
006717f7 R`"@
0067182b 9   
00671830 $Y@z 
006719b3 Rh>@
00671f4b n @ 
0067209b /AE@
0067219f *!T@
006722f3 4 jk
00672373 *!T@
006724fb 9   
00672500 $Y@z 
006727bf 9   
006727c5 Y@zh
00672ab5 M@8k
00672aff q ( 
00672e73 Ob"@
00672ed7 n @ 
00672f7f r`"@
00673037 T`"@
00673d5b T`"@
00673d82 @9   
00673dab R`"@
00673ddf 9   
00673e17 R`"@
00673e4b 9   
00673fd3 Rh>@
0067456b n @ 
0067472f 4 jk
006747af *!T@
00674937 9   
00674bfb 9   
00674ef1 M@8k
00674f3b q ( 
006752af Ob"@
00675313 n @ 
006753bb r`"@
00675473 T`"@
006763c5 BB9H
006765cc h"@9h
00677050 hkh8*
00677dc3 T`"@
00678504 l1@9
00678599 1@9m
006785ab T   
006785e0 )1@9)
00678607 R)1@9
00678747 *!T@
006790bc l1@9,
006790c6 @9`	@
006791ef *!T@
0067a363 =)	@
0067a52f R)5!
0067a6d7 R)q#
0067aaf1 #F9h
0067ab21 CG9h
0067ab61 #I9H	
0067ad15 #O9h
0067ad45 CP9h
0067ad75 cQ9h
0067b231 #F9H
0067b292 J9H 
0067b2f9 #O9h
0067b3b5 CP9H
0067b949 %A9J
0067ba61 %A9J
0067be97 =)	@
0067c061 "@9h
0067c0c7 R)5!
0067c26b R)q#
0067c525 #D9h
0067c555 CE9h
0067c595 #G9H	
0067c749 #M9h
0067c779 CN9h
0067c839 CS9h
0067cc41 cF9(
0067cc51 #G9(
0067cca2 J9(#
0067ccd9 #M9h
0067ccf9 CN9H
0067cd7a R8H	
0067cfc1 CE9h
0067d001 cF9(
0067d031 #G9(
0067d159 #M9(
0067d251 ii8J	
0067d70b Tl/@
0067d76b T*/@
0067d78b Tj.@
0067d79f Th'@
0067d7c7 TH%@
0067de2f T "A9
0067e897 *!T@
0067e90f *!T@
0067e987 *!T@
0067e9ff *!T@
0067ea77 *!T@
0067eaef *!T@
0067eb67 *!T@
0067ebdf *!T@
0067ec57 *!T@
0067eccf *!T@
0067ed47 *!T@
0067edbf *!T@
0067ee37 *!T@
0067eeb7 *!T@
0067fc40 hkh8*
0068245c dJ@z3
00682b2f 9   
00682b35 Y@z 
00682bc3 q ( 
00682d34 Hkh8*
00684443 9   
006844d7 q ( 
00684648 Hkh8*
006854ec Lii8k	
0068551e !^   
00685539  A9h
0068556c 	 A9
00685591 ij8k	
006855f9  A9i
0068561a !^   
00685639  A9	
0068565a !^   
0068569a !^   
006856b9  A9I
006856da !^   
0068571a !^   
0068574e !^   
00685782 !^   
006857b6 !^   
006857ea !^   
0068581e !^   
00685852 !^   
006858ab T`"@
00686017 n @ 
0068624b *!T@
0068643f *!T@
006865f3 *!T@
00687057 T`"@
006870c3 n @ 
0068716b r`"@
006871f7 T`"@
00687233 T`"@
00687dff T`"@
00688543 n @ 
00688ccb q ( 
00688ffb oa"@
00689067 n @ 
00689113 r`"@
0068919f oa"@
006891df /a"@
00689e4b T`"@
00689e72 @9   
00689e79 Y@z(
00689e9b R`"@
00689ecf 9   
00689ed4 $Y@z 
00689f07 R`"@
00689f3b 9   
00689f40 $Y@z 
0068a0c3 Rh>@
0068a65b n @ 
0068a7ab /AE@
0068a8af *!T@
0068aa03 4 jk
0068aa83 *!T@
0068ac0b 9   
0068ac10 $Y@z 
0068aecf 9   
0068aed5 Y@zh
0068b1c5 M@8k
0068b20f q ( 
0068b583 Ob"@
0068b5e7 n @ 
0068b68f r`"@
0068b747 T`"@
0068c46b T`"@
0068c492 @9   
0068c4bb R`"@
0068c4ef 9   
0068c527 R`"@
0068c55b 9   
0068c6e3 Rh>@
0068cc7b n @ 
0068ce3f 4 jk
0068cebf *!T@
0068d047 9   
0068d30b 9   
0068d601 M@8k
0068d64b q ( 
0068d9bf Ob"@
0068da23 n @ 
0068dacb r`"@
0068db83 T`"@
0068ead5 BB9H
0068ecdc h"@9h
0068f760 hkh8*
006904d3 T`"@
00690c14 l1@9
00690ca9 1@9m
00690cbb T   
00690cf0 )1@9)
00690d17 R)1@9
00690e57 *!T@
006917cc l1@9,
006917d6 @9`	@
006918ff *!T@
00692595 "@9h
006926f7 *!T@
006927ab *!T@
0069286f *!T@
00692a77 *!T@
00692dc3 *!T@
006930c5 CA9JA
00694533 *!T@
00694ef1 #A9H
00695313 *!T@
006954f3 Tt.@
006957bf *!T@
0069599f Tt.@
0069613d #@9h
0069629d cB9h
00696385 #A9h
006969a9 #@9h
00696a6f Tj&A
00696b3f Tj&A
00696bb7 TMyh
00696bd3 Tj&D
00696c83 *!T@
00696cfb *!T@
00696d7b *!T@
00696df3 *!T@
0069703f o)i@
0069704e @9)A
006970cd CA9JA
00697fd5 "@9h
00698059 "@9h
006980ab R)92
006980ed "@9h
0069818d "@9h
006981c4 hb@9
00698267 *!T@
006983d8 eb@9
006989cf RAyk
00698a87 TAyk
00698d2a #NC@
00698d73 ^B($
00698d7f ^B(%
00698d87 NB('
00698d8e %nB($
00698d9b ^B(%
00698da7 ^B(&
00698e03 ^B($
00698e0f ^B(%
00698e17 NB('
00698e1e %nB($
00698e2b ^B(%
00698e37 ^B(&
006996a1 c@9_
0069a1bb *!T@
0069a87d #@9h
0069add5 "@9h
0069ae59 "@9h
0069aeab R)92
0069aeed "@9h
0069af8d "@9h
0069afc4 hb@9
0069b067 *!T@
0069b554 hb@9
0069b56c hb@9
0069b7cb RAyk
0069b87b TAyk
0069bb0f ^B(d
0069bb16 enB(f
0069bb1f ^B(d
0069bf7c Ha@9H
0069c35d a@9_
0069ce3b *!T@
0069da42 K9j!
0069dead cE9h
0069df1d #K9H
0069e241 #K9H
0069e753 rkE	
0069e7c5 #@9H
0069e925 #@9H
0069ea9e A9JA
0069f681 cH9h
006a0163 rkE	
006a0251 cA9h
006a053b <	#@
006a0781 #D9(
006a07c1 #D9(
006a0895 cC9h
006a08a5 #D9h
006a09db 7`:@
006a0a13 6`Z@
006a0a23 6`B@
006a0d9f o{k@
006a2079 "@9h
006a242e @8DE@
006a2667 *!T@
006a27f7 *!T@
006a2877 *!T@
006a2a3f *!T@
006a2cb9 "@9h
006a306e @8DE@
006a32a7 *!T@
006a343b *!T@
006a34bb *!T@
006a3669 "@9h
006a3c6f *!T@
006a3ef9 "@9h
006a44ff *!T@
006a50f9 "@9h
006a51b3 *!T@
006a53fb *!T@
006a5a83 TAiy
006a5bdf ^c(!
006a5beb ^b("
006a5bf3 NB(%
006a5bfa #nA(!
006a5c07 ^!(#
006a5c13 ^!($
006a5c83 ^c(!
006a5c8f ^b("
006a5c97 NB(%
006a5c9e #nA(!
006a5cab ^!(#
006a5cb7 ^!($
006a60e9 #@9h
006a62cd #@9h
006a639f o{k@
006a643d #@9h
006a6535 #@9h
006a65d7 o{k@
006a6675 #@9h
006a68ed "@9h
006a69a7 *!T@
006a6f85 "@9h
006a6ff5 "@9h
006a70af *!T@
006a7127 *!T@
006a97ac h"@9h
006a97d0 h"@9h
006a983c h"@9h
006a99f0 h"@9h
006a9a14 h"@9h
006a9f51 "@9h
006a9fb9 "@9h
006aa0c9 "@9h
006ab571 "@9h
006ab5cd "@9h
006ab697 *!T@
006ab70f *!T@
006ab787 *!T@
006aba9b ^!("
006abaa7 ^!(#
006abab7 N!($
006ababf ^!("
006abac7 ^!(#
006abad3 ^!($
006abb1f T(  
006abd57 ^!("
006abd63 ^!(#
006abd72 #n!($
006abd7b ^!("
006abd83 ^!(#
006abd8f ^!($
006ac049 "@9h
006ac0a5 "@9h
006ac16f *!T@
006ac1e7 *!T@
006ac25f *!T@
006ac573 ^!(b
006ac583 N!(c
006ac58b ^!(b
006ac5d7 T( `
006ac80f ^!(b
006ac81e bn!(c
006ac827 ^!(b
006ad017 *!T@
006ad515 "@9h
006ad595 "@9h
006ad609 "@9h
006ad694 h"@9h
006ad73b *!T@
006ad7b3 *!T@
006ad82b *!T@
006ad8a3 *!T@
006ad91b *!T@
006ad993 *!T@
006ada0b *!T@
006ae33a @9	@
006af93d 	@9_
006af94a @9_1
006af956 @9_E
006afa50 h"@9h
006afb07 *!T@
006afb9f 7hBB9
006afbd4 hBB9
006afbdb 6`N@
006afbeb 6`6@
006b04fa Y8h5
006b07b5 CB9H
006b0837 =,	@
006b0e03 <i6@
006b0f7a @9Y	
006b13ff T A 
006b14cb <iN@
006b18fb T A 
006b1b0d "@9h
006b1bc7 *!T@
006b20a2 C9H%
006b2195 CB9H
006b21b7 =,	@
006b2535 CB9H
006b27f3 <i6@
006b2987 / A 
006b2a8f <iF@
006b2d2b / A 
006b2dc6 a^u#
006b2f13 <iV@
006b309f Ty&@
006b30ab Tj.A
006b3233 ThR@
006b329b / A 
006b3382 a^8#
006b346b ThR@
006b3771 "@9h
006b3841 "@9h
006b3865 "@9h
006b3909 "@9h
006b392d "@9h
006b39d1 "@9h
006b39f5 "@9h
006b3a99 "@9h
006b3abd "@9h
006b3e1f <h7@
006b3fdb TiCC9jo@
006b4029 CC9(%
006b4097 TiCC9jo@
006b40c0 kCC9lo@
006b411b =,	@
006b4133 =O	@
006b44c9 CC9(
006b4655 CC9h
006b46a1 CC9(
006b46c1 CC9(
006b473b <i6@
006b4917 T @ 
006b49ab T @ 
006b4caf Tb{~
006b520b Tazj
006b5217 T @ 
006b52b3 T	L@
006b548a Y8(8
006b56ae @9)	
006b56d9 CB9h$
006b56ea V8(%
006b57eb =,	@
006b5d15 CB9h
006b5e03 <i6@
006b5fe3 T @`
006b6077 T @`
006b68eb Tazj
006b68f7 T @`
006b6993 T	L@
006b6b6a Y8(8
006b6d8e @9)	
006b6db9 CB9h$
006b6dca V8(%
006b6ecb =,	@
006b73f5 CB9h
006b74e3 <i6@
006b762b R.i+8
006b76cf R"i*8J
006b7b1c Di-8
006b7eb7 T	H@
006b7f0b T	H@
006b8028 &i*8(
006b807f T	L@
006b8252 Y8(8
006b8476 @9)	
006b84a1 CB9h$
006b84b2 V8(%
006b85b3 =,	@
006b8add CB9h
006b8bcb <i6@
006b8d14 ,i+8
006b8d99 ip8_
006b8db7 *"i*8J
006b91fc Pi,8
006b9597 T	H@
006b95eb T	H@
006b9708 %i*8(
006b975f T	L@
006b9a03 *h~@
006b9ae7 R`!@
006b9bbb o(%A
006b9cb3 Te|@
006b9e43 *!T@
006b9ebb *!T@
006b9f33 *!T@
006ba0e1 "@9h
006ba185 "@9h
006ba25b *!T@
006ba2d3 *!T@
006ba34b *!T@
006ba3c3 *!T@
006ba43b *!T@
006ba4b3 *!T@
006ba84f /  (
006ba857 T 8)
006ba93e @yJ=
006ba953 /  (
006ba95b T"8)
006bab95 "@9h
006bac05 "@9h
006bacc7 *!T@
006bad3f *!T@
006baf6d #@9h
006bafc1 "@9h
006bb03d "@9h
006bb143 T A!
006bb16f /@ )
006bb177 TA8(
006bb18d "@9h
006bb22b T A!
006bb281 "@9h
006bb31f T A!
006bb34f T !!
006bb357 T!8(
006bb395 "@9h
006bb433 T A!
006bb463 T !!
006bb46b T!8(
006bb4a9 "@9h
006bb54f T B!
006bb593 =A(!
006bb5b2 !^   
006bb5bb T "!
006bb5c7 =!8"
006bb639 X nP
006bb66d "@9h
006bb713 T B!
006bb757 =A(!
006bb776 !~   
006bb77f T "!
006bb78b =!8"
006bb7fd X nP
006bb831 "@9h
006bb8cf T A!
006bb8fa !^   
006bb903 T !!
006bb90b T!8(
006bb949 "@9h
006bb9e7 T A!
006bba0e !~   
006bba17 T !!
006bba1f T!8(
006bba5d "@9h
006bbafb T A!
006bbb2b T !!
006bbb33 T!8(
006bbb71 "@9h
006bbc0f T A!
006bbc36 !~   
006bbc3f T !!
006bbc47 T!8(
006bbc85 "@9h
006bbfa5 #@9h
006bbfc9 #@9h
006bc0bb RjB@9h
006bc23c jB@9j
006bc4b0 h"@9h
006bc4ff RjB@9h
006bc517 RjB@9h
006bc597 *!T@
006bc617 *!T@
006bc697 *!T@
006bc717 *!T@
006bc797 *!T@
006bc817 *!T@
006bc897 *!T@
006bcde0 hb@9h
006bce60 *iu8
006bd101 "@9h
006bd125 "@9h
006bd5e8 h"@9h
006be7cf Ti2@
006be7e0 *iv8
006be848 *iv8
006beca1 CA9JA
006bedff Rln@
006befc9 i`8_
006bf009 i)8k
006bf128 *i78*i+8
006bf140 )iw8?
006bf1f0 +il8*i,8*i(8h
006bf240 zi78zi)8
006bf847 T*E@
006bfb61 i`8_
006bfba1 i)8k
006bfc95 j58h
006bfcf9 i)8h
006bfeb0 *i68*i+8
006bfec8 )iv8?
006bff90 +il8*i,8*i(8h
006bffe0 yi68yi)8
006c0f11 #B9h
006c1059 "@9h
006c107d "@9h
006c1095 #B9h
006c1109 "@9h
006c112d "@9h
006c1145 #B9h
006c11b9 "@9h
006c11dd "@9h
006c11f5 #B9h
006c121f RkY2
006c1269 "@9h
006c128d "@9h
006c12a5 #B9h
006c132d "@9h
006c1351 "@9h
006c1369 #B9h
006c1499 "@9h
006c14bd "@9h
006c14d5 #B9h
006c1507 RJ)4
006c155d "@9h
006c1581 "@9h
006c1599 #B9h
006c1601 "@9h
006c1625 "@9h
006c163d #B9h
006c1780 h"@9h
006c18ab *!T@
006c197f *!T@
006c1a27 *!T@
006c1aa7 *!T@
006c1b27 *!T@
006c1ba7 *!T@
006c1c43 *!T@
006c1cc3 *!T@
006c1d5f *!T@
006c1ddf *!T@
006c1e9f *!T@
006c1f1f *!T@
006c1fbb *!T@
006c207b *!T@
006c213b *!T@
006c21e7 *!T@
006c22b3 *!T@
006c2333 *!T@
006c282f *!T@
006c2a33 *!T@
006c2c3f R7S@
006c2c6b T7S@
006c2caf T(#@
006c2df3 TMyl
006c2e03 T-'@
006c2e8f T E@
006c2fb7 T E@
006c31bf T(7@
006c424b T,	@
006c42f3 T,	@
006c4783 Tm	@
006c4803 TV	@
006c4a5f T,	@
006c4b1f T,	@
006c547d #@9(
006c551d #@9(
006c562d #@9(
006c56cd #@9(
006c592b *!T@
006c59a3 *!T@
006c5c25 #@9H
006c5f0f TJ{y
006c6037 TI{y
006c62cb TA8!
006c62df Ta(!
006c690b *!T@
006c6b8d "@9h
006c6c5b *!T@
006c7589 #@9(
006c75cd #@9h
006c75e5 #@9h
006c7769 "@9h
006c7822 gn&4
006c78b6 d.%4
006c79d9 "@9h
006c7a55 "@9h
006c7acd "@9h
006c7b49 "@9h
006c7bd9 "@9h
006c7f8f *!T@
006c83c1 "@9h
006c898f TH  
006c8c32 A-!{p
006c8dae D-!{a
006c8e12 ~-!{a
006c946d "@9h
006cb945 B@9(
006cb9fb *!T@
006cc981 cH9(
006cca8f *!T@
006ccb0f *!T@
006ccd49 cH9H
006cd357 *!T@
006cd5ce O-?	
006cd61f R 8#
006cd63f RA8!
006cdd30 ;ih8
006cdf0c (A@98-@
006cdf83 9iZO
006ce1a3 *!T@
006ce223 *!T@
006cef95 #@9h
006cf9b7 <HQ@
006cfa05 "@9h
006cff5f Rjyj
006d0a1b *+}@
006d1463 T(,@
006d18d8 ,kl8,i+8k
006d1cfb 95 @
006d1e57 *!T@
006d2034 Hii8h
006d20ff *!T@
006d217f *!T@
006d21ff *!T@
006d227f *!T@
006d25b3 *!T@
006d2633 *!T@
006d26b3 *!T@
006d2ac7 <i^@
006d2d23 ohJ@
006d2dbb 9iZ@
006d3213 9iN@
006d3317 Ti*M
006d345f Rl.@
006d3ab4 Oi-8
006d3c87 T)(@
006d3f03 <HQ@
006d3f51 "@9h
006d44ab Rjyj
006d4f67 *+}@
006d59af T(,@
006d5e24 ,kl8,i+8k
006d6247 95 @
006d63a3 *!T@
006d6530 Hii8h
006d65fb *!T@
006d667b *!T@
006d66fb *!T@
006d677b *!T@
006d6aaf *!T@
006d6b2f *!T@
006d6baf *!T@
006d6f27 <i^@
006d7183 ohJ@
006d7783 Ti*M
006d78cb Rl.@
006d79d7 yjV@
006d7f24 Oi-8
006d9205 "@9h
006d921d #@9h
006d970f *!T@
006d985b *!T@
006d98e7 *!T@
006d9acd "@9h
006d9ae5 #@9h
006d9fc5 "@9h
006d9fdd #@9h
006da41f *!T@
006da711 "@9h
006da729 #@9h
006dad45 "@9h
006dad5d #@9h
006daf2f Rkm@
006db8f8 (A@9
006db8ff q(-@
006dbab3 =I)@
006dbd03 9Hii8	
006dbd86 B9H-
006dbe10 (ih8
006dbe1b 9(i|
006dc037 *!T@
006dc0b7 *!T@
006dc137 *!T@
006dc1b7 *!T@
006dc237 *!T@
006dc2b7 *!T@
006dcfb8 +ih8J	
006dda34 (i<8
006de3df *!T@
006de52b *!T@
006de5ab *!T@
006de85b *!T@
006de8db *!T@
006debeb *!T@
006dec6b *!T@
006df157 *!T@
006df1d7 *!T@
006df8c7 6`6@
006dfeb8 +ih8J	
006e16e8 +ih8J	
006e2eac +ih8J	
006f2c07 T	h@
006f2c13 T	0@
006f2cab *!T@
006f2d23 *!T@
006f2d9b *!T@
006f2e8f RJ]7
006f2edb *!T@
006f336f Tn6@
006f3813 TjV@
006f3887 q(yh
006f399f TuR@
006f3fef *!T@
006f414f *!T@
006f41cf *!T@
006f4513 *;*	
006f4550 +ih8J	
006f4875 @@9h
006f48c1 @@9h
006f490d @@9h
006f4959 @@9h
006f4a71 @@9h
006f4c47 *n(	
006f539b T+5J
006f53ef T'5@
006f547f T$U@
006f55bd @@9h
006f5efb T+1J
006f5f53 T,5@
006f5f73 T5M@
006f6685 @@9h
006f685b *i!	
006f6f9b T+5J
006f6fef T'5@
006f7077 T$U@
006f71b5 @@9h
006f7acf T+1J
006f7b27 T,5@
006f7b47 T5M@
006f8255 @@9h
006f8ee5 @@9h
006fa131 @@9h
006fa282 U8(	
006fa28a X8h	
006fa782 "N"@
006fa79b T@  
006fa973 = ( 
006fabb3 Ti#J
006fac33 Th7@
006facf3 /{O@
006faed9 @@9h
006fc515 @@9h
006fc565 @@9h
006fc6b6 U8(	
006fc6be X8h	
006fcbbf T@ `
006fcd97 = (`
006fcfd7 Ti#J
006fd057 Th7@
006fd117 /{O@
006fd561 @@9h
006ff94b T+5J
006ff99f T'5@
006ffa2f T$U@
006ffb6d @@9h
00700ccb T#xb
00700d6b T"xf
00701263 Rfyq
007021bf T*yl
0070237b T+1J
007023d3 T,5@
007023ff T5M@
00702639 @@9h
0070360b T#xb
007036bf T"xf
00703b9b Ta	@
00703c5f Tl	@
00703e0f T/	@
00704bdb T	xk
00704deb T$M@
00704edf T1Q@
00704ef7 T/U@
00705039 @@9h
007073f7 T+5J
0070744b T'5@
007074db T$U@
00707c79 @@9h
00708240 !d#N
00708249 d!N_
007083dd d"N!d#Na
007083e9 d!N?
00708461 d"N!d#Na
0070846d d!N?
00708ca5 i*8J
00708d9d d"N!d#N
00708e31 d"N!d#NA
00708ef1 d"N!d#N!
00708f95 d"N!d#NA
00708fa1 d!N_
007093bd i+8k
0070943d d"N!d#Na
00709449 d!N?
00709553 =!d"Nbd$N!d"N
007095c8 Ni+8k
00709649 d"N!d#Na
00709f89 i58h
0070a14a @9?	
0070a1b4 !d#N
0070a261 d"N!d#Na
0070a2e5 d"N!d#Na
0070a519 jj8c
0070a5bc @d Nad!NA
0070a670 ;i!8	i@
0070a67f T	m@
0070a821 @@9h
0070ade8 !d#n
0070adf1 d!n_
0070af85 d"n!d#na
0070af91 d!n?
0070b009 d"n!d#na
0070b015 d!n?
0070b84d i*8J
0070b945 d"n!d#n
0070b9d9 d"n!d#nA
0070ba99 d"n!d#n!
0070bad9 d!.a
0070baf5 hs8s
0070bb3d d"n!d#nA
0070bb49 d!n_
0070bbc1 hy89
0070bcf8 nil8
0070bf65 i+8k
0070bfe5 d"n!d#na
0070bff1 d!n?
0070c0fb =!d"nbd$n!d"n
0070c170 Ni+8k
0070c1f1 d"n!d#na
0070cb31 i58h
0070ccf2 @9?	
0070cd5c !d#n
0070ce09 d"n!d#na
0070ce8d d"n!d#na
0070d0c5 jj8c
0070d168 @d nad!nA
0070d1bc  d .a
0070d1dc *i|8
0070d21c ;i!8	i@
0070d22b T	m@
0070dd5d @@9h
0070ebbf T+5J
0070ec1b T'5@
0070eca3 T$U@
0070ede1 @@9h
0070f97e ?)B 
0070fc73 T,-J
0070fcd7 T+5@
0070fcf7 T6M@
00710401 @@9h
00711253 T+5J
007112af T'5@
00711337 T$U@
007116d9 @@9h
00713153 T+5J
007131a7 T'5@
00713237 T$U@
00713375 @@9h
007144d3 T#xb
00714573 T"xf
00714a6b Rfyq
0071505b T*yl
00715213 T+1J
0071526b T,5@
00715297 T5M@
007154d1 @@9h
007164a3 T#xb
00716557 T"xf
00716a33 Ta	@
00716af7 Tl	@
00716ca7 T/	@
007170fb T	xk
0071730b T$M@
007173ff T1Q@
00717417 T/U@
00717559 @@9h
00718fa7 T+5J
00718ffb T'5@
0071908b T$U@
00719829 @@9h
00719df0 !l#N
00719df9 l!N_
00719f8c @l Nal!Na
00719f99 l!N?
0071a010 @l Nal!Na
0071a01d l!N?
0071a855 i*8J
0071a94d l"N!l#N
0071a9e0 @l Nal!NA
0071aa9f <@l Nal!N!
0071ab44 @l Nal!NA
0071ab51 l!N_
0071af6d i+8k
0071afec @l Nal!Na
0071aff9 l!N?
0071b103 =!l"Nbl$N!l"N
0071b178 Ni+8k
0071b1f8 @l Nal!Na
0071b39e @9?	
0071b408 !l#N
0071b4b4 @l Nal!Na
0071b538 @l Nal!Na
0071b76d jj8c
0071b810 @l Nal!NA
0071b8c4 ;i!8	i@
0071b8d3 T	m@
0071ba75 @@9h
0071c03c !l#n
0071c045 l!n_
0071c1d8 @l nal!na
0071c1e5 l!n?
0071c220  l .
0071c25c @l nal!na
0071c269 l!n?
0071c2a4  l .
0071c2d2 (kh1
0071c2f6 (kh1
0071caa1 i*8J
0071cb99 l"n!l#n
0071cc2c @l nal!nA
0071cc70  l .
0071cc92 7k72
0071cceb <@l nal!n!
0071cd2c  l .a
0071cd49 hs8s
0071cd90 @l nal!nA
0071cd9d l!n_
0071cdf4  l .
0071ce15 hy89
0071cf4c nil8
0071d1b9 i+8k
0071d238 @l nal!na
0071d245 l!n?
0071d288  l .
0071d2ba 1k10
0071d34f =!l"nbl$n!l"n
0071d3c4 Ni+8k
0071d444 @l nal!na
0071d494  l .
0071d5e6 @9?	
0071d650 !l#n
0071d6fc @l nal!na
0071d744  l .
0071d780 @l nal!na
0071d7c8  l .
0071d7f6 *kj1
0071d81a *kj1
0071d9b5 jj8c
0071da58 @l nal!nA
0071daac  l .a
0071dacc *i|8
0071dad6 ;k[1
0071db0c ;i!8	i@
0071db1b T	m@
0071e64d @@9h
0071ef9b T+5J
0071efef T'5@
0071f073 T$U@
0071f1b1 @@9h
0071fc2b T+1J
0071fc83 T,5@
0071fca3 T5M@
0071fee9 @@9h
007209d3 T$EF
007209f3 T#M@
00720ac7 T0Q@
00720adf T.U@
00721ce1 @@9h
007225ff T+5J
00722653 T'5@
007226d7 T$U@
00722815 @@9h
00723127 T+1J
0072317f T,5@
0072319f T5M@
007233d9 @@9h
00723cc7 T+5J
00723d1b T'5@
00723d9f T$U@
00724609 @@9h
00724659 @@9h
007247ed "@9h
007248b5 "@9h
0072493d "@9h
007249b9 "@9h
00724a93 *!T@
00725673 T$EF
00725693 T&M@
00725727 T0Q@
0072573f T.U@
00725be7 T$EF
00725c07 T&M@
00725c9b T0Q@
00725cb3 T.U@
00725de9 @@9h
00726a47 T$EF
00726a67 T'M@
00726afb T0Q@
00726b13 T.U@
00726fc3 T$EF
00726fe3 T'M@
00727077 T0Q@
0072708f T.U@
007271c9 @@9h
00727e27 T%EF
00727e47 T$M@
00727e70 eif8
00727ed7 T0Q@
00727eef T.U@
0072839b T%EF
007283bb T$M@
007283e4 eif8
0072844b T0Q@
00728463 T.U@
0072859d @@9h
00728ee0 ljk8
007291f7 T%EF
00729217 T$M@
00729240 eif8
007292a7 T0Q@
007292bf T.U@
0072976b T%EF
0072978b T$M@
007297b4 eif8
0072981b T0Q@
00729833 T.U@
00729b05 @@9h
0072a763 T$EF
0072a783 T&M@
0072a817 T0Q@
0072a82f T.U@
0072acd7 T$EF
0072acf7 T&M@
0072ad8b T0Q@
0072ada3 T.U@
0072b46d @@9h
0072c0cb T$EF
0072c0eb T&M@
0072c17f T0Q@
0072c197 T.U@
0072c63f T$EF
0072c65f T&M@
0072c6f3 T0Q@
0072c70b T.U@
0072c841 @@9h
0072d49f T$EF
0072d4bf T'M@
0072d553 T0Q@
0072d56b T.U@
0072da1b T$EF
0072da3b T'M@
0072dacf T0Q@
0072dae7 T.U@
0072ddb9 @@9h
0072ea17 T$EF
0072ea37 T&M@
0072eacb T0Q@
0072eae3 T.U@
0072ef8b T$EF
0072efab T&M@
0072f03f T0Q@
0072f057 T.U@
0072f59d "@9h
0072f625 "@9h
0072f6a1 "@9h
0072f793 *!T@
0073038f T!yl
0073051b T+5J
0073056f T'5@
007305f3 T$U@
007312bf T*yl
0073146f T+1J
007314c7 T,5@
007314e7 T5M@
00732113 T!yl
0073229f T+5J
007322f3 T'5@
00732377 T$U@
00732ff3 T*yk
0073320f T$M@
007332ef T1Q@
00733307 T/U@
007346fd "@9h
00734720 h"@9h
00734877 Sk}@
00734e0f *i		
0073520c h"@9h
007357c1 #@9h
007357f3 RJM#
00735835 #@9h
007358cd #@9h
0073590f Rka,
00735aa5 #@9h
00735cbd "@9h
00735e13 *!T@
00735e93 *!T@
00735f47 *!T@
00735ffb *!T@
0073607b *!T@
00736103 *!T@
007362fa ]8x"
007367e7 Tt"@
00736a3b Tt"@
0073707f Ti~A
0073755d *B)k}@
0073756e 	kB}
00737c36 @9			
007380c2 @9J	
0073820f Tu		
007386ff T(ys
0073870f Qj~@
00738ae7 *!T@
00738b7f *!T@
00738c13 *!T@
00738c87 *!T@
00739457 4i"@
00739523 4i"@
00739623 5i"@
00739683 4i"@
00739717 5i"Bi6}
00739783 Ti"@
00739973 TM,@
00739ab3 TK}@
00739fdf *!T@
0073a3ff */~@
0073a657 *!T@
0073a6cf *!T@
0073a747 *!T@
0073a7bf *!T@
0073a98f *!T@
0073ab3b *!T@
0073ac07 */~@
0073ae5f *!T@
0073aed7 *!T@
0073af4f *!T@
0073afc7 *!T@
0073c6d0 h"@9h
0073c6f1 #B9h
0073c74c h"@9h
0073c769 #B9h
0073c77f R)5:
0073c7d1 "@9h
0073c7e9 #B9h
0073c859 "@9h
0073c89b Rka,
0073c92d #B9h
0073c985 #B9h
0073c9e5 #B9h
0073ca49 "@9h
0073ca61 #B9h
0073cd6f *!T@
0073cde7 *!T@
0073ce8b *!T@
0073cf03 *!T@
0073cf83 *!T@
0073d095 #B9(
0073d0bd #B9h
0073d34f T(	@
0073d407 Rxn	
0073d43f Rjn	
0073d477 R\n	
0073d528 H#@9h
0073d54c h"@9h
0073e034 h"@9h
0073e6ed C@9h
0073ef3b T(	@
0073eff3 R}g	
0073f02b Rog	
0073f063 Rag	
0073f114 H#@9h
0073f138 h"@9h
0073fc20 h"@9h
007406ad CA9JA
00740d6c h"@9h
007410c3 T(;@
00741108 (CB9)O@
0074211b TKA!
00742a31 cE9(
00742a71 cB9(
00742af7 9)Q@
00742b51 cB9H
00742bd8 (#@9h
00742c5c h#@9h
00742c8f R)5:
00742ccc h#@9h
00742d0b ThBB9iN@
00742d81 CD9h
00742dd1 cB9(
00742ec5 #A9h
00742f75 #A9h
00742f8b RJa,
00742fcc h#@9h
00743040 H#@9h
007431db *!T@
00743253 *!T@
007432cb *!T@
00743343 *!T@
007433bb *!T@
00743433 *!T@
007434b3 *!T@
00743651 CD9h
00743669 #C9(
00743709 #C9(
00743793 6`R@
00743824 	@B9
00743833 6`R@
00744b91 ki8JE@9_
00744c21 ki8JE@9_
00744cc7 Ra"@
00744f25 @@9h
00744f2b 4`*@
00744f64 hB@9h
007450bc kC@9l
0074520c 	A@9
00745234 	A@9
00745264 	A@9
007453e9 ji8JE@9_
00745491 ji8JE@9_
0074564d ki8JE@9_
007456dd ki8JE@9_
00745743 Ra"@
00745cbf TJ	@
00745cf3 TM}@
00745fc3 TJ	@
007462da gn&4
0074636e d.%4
007463de @9@.
007468b6 @9#|@
007469bf *!T@
00746a37 *!T@
00746c4c qC@9
00746efb *!T@
00746f73 *!T@
00746feb *!T@
00747063 *!T@
007471a7 -`  
007471c3 T@  
0074723b T"@ 
00747753 -`  
0074776f T@  
007478bb r	u~
00747a83 -`  
00747a9f T@  
00747beb r	u~
00747df7 7	u~
00747eaf -`  
00747ecb T@  
0074802f r	u~
0074825b 7	u~
0074833b -`  
00748357 T@  
007484bf O	u~
007494cf qJYA
007494e7 T(@ 
00749603 qJaA
0074961b T(@ 
00749737 qJeA
0074974f T(@ 
0074986b qJmA
00749883 T(@ 
0074999f qJuA
007499b7 T(@ 
00749ad3 qJyA
00749aeb T(@ 
00749c07 qJ}A
00749c1f T(@ 
00749d53 T(@ 
00749e77 qJYA
00749e8f T(@ 
00749fd3 qJaA
00749feb T(@ 
0074a12f qJeA
0074a147 T(@ 
0074a28b qJmA
0074a2a3 T(@ 
0074a3e7 qJuA
0074a3ff T(@ 
0074a543 qJyA
0074a55b T(@ 
0074a69f qJ}A
0074a6b7 T(@ 
0074a813 T(@ 
0074a957 qJYA
0074a96f T(@ 
0074aab3 qJaA
0074aacb T(@ 
0074ac0f qJeA
0074ac27 T(@ 
0074ad6b qJmA
0074ad83 T(@ 
0074aec7 qJuA
0074aedf T(@ 
0074b023 qJyA
0074b03b T(@ 
0074b17f qJ}A
0074b197 T(@ 
0074b2f3 T(@ 
0074b43b qJYA
0074b453 T(@ 
0074b5b3 qJaA
0074b5cb T(@ 
0074b72b qJeA
0074b743 T(@ 
0074b8a3 qJmA
0074b8bb T(@ 
0074ba1b qJuA
0074ba33 T(@ 
0074bb93 qJyA
0074bbab T(@ 
0074bd0b qJ}A
0074bd23 T(@ 
0074be9b T(@ 
0074c0f6 A9JA
0074c8cd ki8JE@9_
0074c95d ki8JE@9_
0074cc17 4hB@9h
0074cd7c kC@9l
0074cecc 	A@9
0074cef4 	A@9
0074cf24 	A@9
0074d0c5 ki8JE@9_
0074d155 ki8JE@9_
0074d40f 4hB@9h
0074d574 kC@9l
0074d6c4 	A@9
0074d6ec 	A@9
0074d71c 	A@9
0074d8a1 ji8JE@9_
0074d949 ji8JE@9_
0074dae9 ji8JE@9_
0074db91 ji8JE@9_
0074dcfb Tu^@
0074df17 9)q@
0074e1f5 c@9(
0074e21d CB9h
0074e235 cC9(
0074e245 #D9h
0074e38d #D9h
0074e495 c@9(
0074e515 cC9(
0074e589 #D9H
0074e605 #A9(
0074e695 cC9(
0074e6c5 #D9(
0074e715 cC9(
0074e875 c@9(
0074e89d CB9h
0074e8b5 cC9(
0074e975 cC9(
0074ead7 ** @
0074ec8a @9)=A
0074ecd7 Th&@
0074f094 j&Cih&
0074f0df 4i"@
0074f2a3 5h*@
0074f2af Ti"@
0074f2c8 h&Cib
0074f33c h&Cib
0074f5e3 T(8@
0074fdcf =)	@
0074fea7 =)	@
0074ff37 4@cB
0074ff9b 4@3B
0074ffa7 TA7B
00750007 4I'@
0075006f 4@kB
007500d7 4@;B
007500e3 TA?B
00750143 7	q}
007501c7 4@KB
007501d3 TAOB
00750247 4@sB
007502af 4@CB
007502bb TAGB
007503d7 =)	@
00750473 7	q}
00750543 7	q}
007506ff *!T@
00750837 *!T@
007508ff =<l@
00750afd .C))
0075146b TI		
007517f3 =<l@
00751a1d O!)w}
007524eb TI		
007537cc h"@9h
0075385f *!T@
00753a8d "@9h
00753b09 "@9h
00753bd7 *!T@
00754a0d "@9h
00754a25 #@9h
00754b4c +ih8J	
00755a41 #@9(
0075604b *!T@
007564d1 "@9h
00756545 "@9h
00756660 Lii8k	
007566cd #@9h
00756b6b 49}~
00756df7 *!T@
00756edb *!T@
007573f7 49}}
00757683 *!T@
00757767 *!T@
00757c83 49}~
00757f0f *!T@
00757ff3 *!T@
0075850f 49}}
0075879b *!T@
0075887f *!T@
007590a7 *!T@
0075918b *!T@
00759387 Tsza
0075ad61 cB9H
0075aea5 cB9h
0075aed1 cB9h
0075af85 cB9H
0075b30d cB9H
0075b379 cB9(
0075b399 cB9(
0075b4eb T;	@
0075b5ef T;	@
0075b6af T;	@
0075b76f T;	@
0075bcce F9h1
0075c627 *!T@
0075c6a7 *!T@
0075c727 *!T@
0075c7a7 *!T@
0075c827 *!T@
0075c8a7 *!T@
0075c927 *!T@
0075c9a7 *!T@
0075ca27 *!T@
0075caa3 *!T@
0075cb1f *!T@
0075cb9b *!T@
0075d001 "@9h
0075d075 "@9h
0075d0ed "@9h
0075d2b1 "@9h
0075d38b Th.@
0075d3b0 +ih8J	
0075d493 *!T@
0075dc9f /a{`
0075de97 n B 
0075df93 R'@ 
0075dfb3 *'@ 
0075e03b nDl$
0075e05f nG@ 
0075e0bf nf@ 
0075e253 nE@ 
0075e97b /`"$
0075eb87 nFl&
0075ebab nE@ 
0075ec0b nFl&
0075eca7 /`"4
0075eccb n`B 
0075ed9b nCB 
0075ef5f Td@!
0075f053 nBl%
0075f123 nbB 
0075f1a7 /@ "
0075f203 n@B 
0075f38f n B 
0075f48b R'@ 
0075f4ab *'@ 
0075f533 nDl$
0075f557 nG@ 
0075f5b7 nf@ 
0075f74b nE@ 
0075ff87 /a{`
0076027b n  a
0076033b nEle
00760347 /dld
00760393 nEle
00760443 n  a
007604ef /&nf
007604fb nAna
00760bbb /`"d
00760bdb n  a
00760d97 nFlf
00760da3 /glg
00760e17 nFlf
00760e9f /`"t
00760ebf n` c
00760ecb nCnc
00760f4b /  a
007610fb /`"d
0076111b n` c
00761227 nBle
007612df n  a
007612eb nAna
0076136b /` c
00761617 n  a
007616d7 nEle
007616e3 /dld
0076172f nEle
007617df n  a
0076188b /&nf
00761897 nAna
007619f0 (ih8*ij8+ik8)il8
00762c9f Th.@
00762cc4 +ih8J	
00762da7 *!T@
00762f2b Th.@
00762f50 +ih8J	
00763037 *!T@
00763371 "@9h
0076348b 9Jq@
007634c5 "@9h
00763661 "@9h
00763811 "@9h
00763b51 "@9h
00763def = @`
00763e99 "@9h
007640db = @`
0076417d "@9h
0076455a 	N(<
00764b5a aNI<
00764c95 "@9h
00764f0e qN(<
00765153 ^ @`
00765222 rN!(
0076530d "@9h
0076555b = @`
00765609 "@9h
00765853 = @`
007658fd "@9h
00765cda 	N(<
007662da aNI<
00766415 "@9h
0076668e qN(<
007668d3 ^ @`
007669a2 rN!(
00766a8d "@9h
00766cdb = @`
00766d89 "@9h
00766fd3 = @`
0076707d "@9h
007672cd "@9h
007673d5 "@9h
007673f9 "@9h
007674b5 "@9h
007674d9 "@9h
00767595 "@9h
007675b9 "@9h
00767675 "@9h
00767699 "@9h
00767755 "@9h
00767779 "@9h
00767835 "@9h
00767859 "@9h
00767915 "@9h
00767939 "@9h
007679f5 "@9h
00767a19 "@9h
00767ad5 "@9h
00767af9 "@9h
00767bb5 "@9h
00767bd9 "@9h
00767ff7 nsja
00768005 jaN1ja
0076800e 0nQjaN1
00768113 *!T@
00768193 *!T@
007686ff *!T@
0076877f *!T@
00768bbc oi08
00768c93 *!T@
00768d13 *!T@
007690f1 z)xq
00769103 T0>@
0076914d h#x9
00769179 i1x1
0076924f *!T@
007692cf *!T@
007696c3 T0~@
0076980f *!T@
0076988f *!T@
00769dbb *!T@
00769e3b *!T@
0076a278 oi08
0076a34f *!T@
0076a3cf *!T@
0076a7ad z)xq
0076a7bf T0>@
0076a809 h#x9
0076a835 i1x1
0076a90b *!T@
0076a98b *!T@
0076ad7f T0~@
0076aecb *!T@
0076af4b *!T@
0076b477 *!T@
0076b4f7 *!T@
0076bbc7 *!T@
0076c00b N!(a
0076c33e !^@E
0076c82a ?m)A
0076c96f S  "
0076cbc6 ?m)A
0076d132 ?m)A
0076d1e2 ?m)A
0076d5e2 ?m)A
0076d9af N!X nBX n!(
0076e4e7 N!(a
0076e5de !~@E
0076f077 N!X nBX n!(a
0076f4da ?m)A
0076f652 ?m)A
0076f94a aNBha
0076f97a 0/M<
007707be bN!(!
007707d2 ?m)A
007707f0 K%@x
00770c35 %@x)
00770cb4 K%@8)
00770e84 K%@8)
00771017 NB@a
00771362 bN!(!
00771376 ?m)A
00771394 K%@x
00771440 K%@x)
007714fc K%@x)
007715ac K%@x)
0077163a @yJ!
00771678 K%@x)
0077174c K%@x)
007717d9 %@x)
00771858 K%@8)
007718eb RL%@x
007719a4 K%@x)
00771a28 K%@8)
00771c0a anBha
00771c3a 0/M<
00771d27 Nc@a
00771d2c C@aNC
00771e7a @}J	
0077272b Nc@a
00772730 C@aNC
0077287e @}J	
0077333f Nc@a
00773344 C@aNC
007733a7 NrE@
007735e8 K%@x
00773a97 Nc@a
00773a9c C@aNC
00773aff NrE@
00773d40 K%@x
00773dc8 K%@x)
00773e58 K%@x)
00773ee4 K%@x)
00773f7d %@x)
00774008 K%@x)
007740a8 K%@x)
00774138 K%@x)
007741bc K%@x)
00774255 %@x)
007742e0 K%@x)
00774436 bN!(!
0077444a ?m)A
00774796 bN!(!
0077489d 8a.!8a.
007748e5 8an#8a.!8anB
00774941 8an#8a.!8anB
0077495b NB(a
007749a9 8a.!8a.
007749ed 8a.!8a. 
00774a91 8an#8a.!8anB
00774aed 8an#8a.!8anB
00774b07 NB(a
00774b90 S:a.R
00774c1b RN%@x
007759d6 @y J
00775baf N9Cg
00775bbd Z nYCgN
00775bc5 Z ns
00776597 *!T@
0077663b *!T@
00776845 #B9H
00776b1b *!T@
00776b9b *!T@
00777135 #@9h
007771ad #@9h
0077721d "@9h
007772e7 *!T@
0077735f *!T@
007773d7 *!T@
007774a7 6`&@
007774fb 7hB@9H
00777537 6`&@
00777540 hB@9
00777593 7hB@9
007775d7 6`&@
007775e0 hB@9
00777dcf *!T@
00777e4f *!T@
00777ecf *!T@
00777ef1 CC9h
007786bb T`zv
00778839 c@9;
00778a49 iw8H
00778ca3 *!T@
00778edd "@9h
00778ef5 #@9h
007796d1 CB9(
007798ea Z8HN
007799d9 CC9(
00779c19 CC9(
00779d4d CC9H
00779dd9 "@9h
00779ee9 "@9?
00779f07 R,yj
0077a367 *!T@
0077a413 *!T@
0077a4bf *!T@
0077a9d7 5hks
0077aadc h"@9h
0077aca0 Lih8k	
0077ae43 *!T@
0077b080 h"@9h
0077be2d cB9(
0077bf8f *!T@
0077c00f *!T@
0077c101 cB9h
0077c263 Tj"A
0077c26b R7+	
0077c293 Ti"@
0077c2eb Ti"A
0077c32f Tj"A
0077c337 R4+	
0077c3f3 *!T@
0077c95b *!T@
0077cd9d cB9(
0077ceff *!T@
0077cf7f *!T@
0077d2db *!T@
0077d853 *!T@
0077db3d cB9(
0077dc9f *!T@
0077dd1f *!T@
0077e07b *!T@
0077e5eb *!T@
0077e8d5 cB9(
0077ea37 *!T@
0077eab7 *!T@
0077ee13 *!T@
0077f38b *!T@
0077f675 cB9(
0077f7d7 *!T@
0077f857 *!T@
0077fbaf *!T@
00780117 *!T@
007828d3 Rpzi
00783c4f Rpzi
00784bb7 Rpzi
00785af7 Rpzi
00786a63 Rpzi
007879cb Rpzi
00788933 Rpzi
00789873 Rpzi
0078a7df Rpzi
0078b747 Rpzi
0078c6af Rpzi
0078d5ef Rpzi
0078e526 ^8hQ
0078e70b Roy,
0078eaef Roy,
0078ece3 Roy,
0078eeef Roy,
0078f109 "@9h
0078f121 #@9h
0078f181 "@9h
0078f199 #@9h
00790a6c h"@9h
00790b2b *!T@
00790e82 A9JA
00791887 TLyh
00791897 Tmyh
00791989 C@9h
00791c97 9*yh
00791d44 myjx
00791e57 9*yh
00791f04 myjx
0079248d #A9h
0079253c h"@9h
00792f09 "@9h
00792fcb *!T@
007934be @9V		
007934d3 Rh"@
00793527 Rh"@
00793547 Ti&@
007937fb R)i	
00793c37 TMym
0079414f TMymx
0079419c Oyox/y,x
0079466b T,il8
00794671 i+8k
007946c9 i+8k
00794b6a @9L @
00794b9b TNyn
007950af Rh"@
007950ff Rh"@
0079511b Ti&@
00795623 TMym
00795b33 TMymx
00795b7c Oyox/y,x
00796047 T,il8
0079604d i+8k
007960a1 i+8k
00796542 @9L @
0079656f TNyn
00797e8f =!	A
007982d7 *!T@
00798570 h"@9h
0079858d #@9h
00798bbf T:{x
00798e9b TV}@
00799267 RJe>
00799321 "@9h
007996f3 *!T@
0079978b *!T@
00799a2e 2-(}
00799d7f *!T@
00799e2f *!T@
00799f57 <i>@
0079a913 TS9(
0079aa97 T3;=
0079aad7 TS;=
0079ab17 T?;=
0079af7b T3;8
0079b03f Th9<
0079b10b Ts9<
0079b1f7 Ts9<
0079b2c7 Ts9<
0079c267 T(/@
0079c41d "@9h
0079ca75 "@9h
0079d115 "@9h
0079d139 "@9h
0079d1ff *!T@
0079d27f *!T@
0079d5da !NB(a
0079d692  NB(a
0079d726 !NB(a
0079d767 R@E@
0079d8de aNB(
0079d9aa aNB(
0079da4e aNB(
0079e55b RL%@x
0079e5e3 oB4`nc4`nB(!
0079e5fe ?m)A
0079e7f7 N!X nBX n!(a
0079ea23 N!X nBX n!(
0079f131 "@9h
0079f149 CA9h
0079f703 Rayl
0079f7bb Tayl
0079f9e2 #NC@
0079fa2b ^B($
0079fa37 ^B(%
0079fa3f NB('
0079fa46 %nB($
0079fa53 ^B(%
0079fa5f ^B(&
0079fabb ^B($
0079fac7 ^B(%
0079facf NB('
0079fad6 %nB($
0079fae3 ^B(%
0079faef ^B(&
0079fc5b R @ 
007a0283 T!8 
007a032e "N"@
007a037f ^!(#
007a038b ^!($
007a0393 N!(&
007a039a $n!(#
007a03a7 ^!($
007a03b3 ^!(%
007a041b ^!(#
007a0427 ^!($
007a042f N!(&
007a0436 $n!(#
007a0443 ^!($
007a044f ^!(%
007a052e #NC@
007a1f3f *!T@
007a1feb *!T@
007a2aff *!T@
007a2bab *!T@
007a32cb *!T@
007a3377 *!T@
007a3a97 *!T@
007a3b43 *!T@
007a426b *!T@
007a4317 *!T@
007a6f65 "@9h
007a76ab <()@
007a79eb T	hs
007a7acb T	ht
007a7d85 8J)*
007a7da1 ,H),
007a8891 "@9h
007a8c67 T	((
007a8fdb <()@
007a931b T	hs
007a93fd 8J)*
007a9419 ,H),
007a9895 "@9h
007aa349 "@9h
007aa71f T	((
007aae05 "@9h
007ab54b <()@
007ab88b T	hs
007ab971 8J)*
007ab98d ,H),
007ac295 "@9h
007ac9db <()@
007acd1b T	hs
007ace01 8J)*
007ace1d ,H),
007ad2c5 "@9h
007adb0d "@9h
007adee7 T	((
007ae25b <()@
007ae59b T	hs
007ae67d 8J)*
007ae699 ,H),
007aeb59 "@9h
007af2a3 <()@
007af5e3 T	hs
007af6c9 8J)*
007af6e5 ,H),
007affed "@9h
007b0835 "@9h
007b19b7 TMyi
007b1a27 TMyi
007b1ab1 #@9h
007b1b60 h2C9
007b351c kjj8J
007b3524 kj)8)
007b3eae E9h*
007b5273 r3ij
007b5476 E9(|
007b5bfb r4ij
007b5e39 CM9h
007b5ebc h"@9h
007b5ee0 h"@9h
007b5f92 E9H#
007b61d7 r3ij
007b6449 CM9h
007b649d cD9H
007b6a9b *!T@
007b6b1b *!T@
007b6ba7 *!T@
007b6c27 *!T@
007b6ca7 *!T@
007b6d27 *!T@
007b6da7 *!T@
007b6e23 *!T@
007b6e9f *!T@
007b6fb7 *!T@
007b7d49 cD9H
007b7e63 Th&@
007b7f53 Th&@
007b7fe3 7hb@9
007b8018 hb@9
007b8063 7hb@9
007b80a0 hb@9H
007b8215 "@9h
007b8289 "@9h
007b8425 "@9h
007b8bae @MMA
007b9323 6`.@
007b940f Toyl
007b941b Tn>H
007b9430 nBA9o.@
007b9f27 *!T@
007ba011 @@9h
007ba061 @@9h
007ba3af *!T@
007ba4cb *!T@
007ba54b *!T@
007ba5fb *!T@
007ba6ab *!T@
007ba8d5 "@9h
007bac23 *!T@
007bd550 )C@9h
007bd614 +ih8J	
007bd628 (C@9
007bd6e0 (C@9
007bd718 (C@9
007bd750 (C@9
007bd788 (C@9
007bd7c0 (C@9
007bd7f8 (C@9
007bd830 (C@9
007bd868 (C@9
007bd8a0 (C@9
007bd8d8 (C@9
007bd910 (C@9
007bd948 (C@9
007bd980 (C@9
007bda5f *!T@
007be68b RZ#	
007c0abd "@9h
007c0b29 "@9h
007c0c0f *!T@
007c0c87 *!T@
007c0d1f *!T@
007c0db7 *!T@
007c0e43 *!T@
007c115b *!T@
007c12f7 *!T@
007c1493 *!T@
007c162f *!T@
007c17cb *!T@
007c1967 *!T@
007c1b03 *!T@
007c1c9f *!T@
007c1e3b *!T@
007c1fd7 *!T@
007c2173 *!T@
007c2f01 "@9h
007c2f33 R)a5
007c2f6d "@9h
007c303f *!T@
007c311d `@9h
007c316d `@9h
007c3609 "@9h
007c362d "@9h
007c366c h"@9h
007c3f79 CA9JA
007c4159 CA9JA
007c44ad "@9h
007c45cd "@9h
007c45f1 "@9h
007c46b5 "@9h
007c46d9 "@9h
007c479d "@9h
007c47c1 "@9h
007c4885 "@9h
007c48a9 "@9h
007c496d "@9h
007c4991 "@9h
007c4a55 "@9h
007c4a79 "@9h
007c4b3d "@9h
007c4b61 "@9h
007c4c25 "@9h
007c4c49 "@9h
007c4d0d "@9h
007c4d31 "@9h
007c4df5 "@9h
007c4e19 "@9h
007c4edd "@9h
007c4f01 "@9h
007c4fc5 "@9h
007c4fe9 "@9h
007c50ad "@9h
007c50d1 "@9h
007c5195 "@9h
007c51b9 "@9h
007c56a7 Tnyi
007c5a77 Tnyi
007c5e4b Tnyi
007c6223 Tnyi
007c661b Tnyi
007c66cf Rl	@
007c6cb3 Tnyi
007c7083 Tnyi
007c7457 Tnyi
007c782f Tnyi
007c7c27 Tnyi
007c82bf Tnyi
007c868f Tnyi
007c8a63 Tnyi
007c8e3b Tnyi
007c9233 Tnyi
007c98cb Tnyi
007c9c9b Tnyi
007ca06f Tnyi
007ca447 Tnyi
007ca83f Tnyi
007caed7 Tnyi
007cb2a7 Tnyi
007cb67b Tnyi
007cba53 Tnyi
007cbe4b Tnyi
007cbeff Rl	@
007cc4e3 Tnyi
007cc8b3 Tnyi
007ccc87 Tnyi
007cd05f Tnyi
007cd457 Tnyi
007cd50b Rl	@
007cdaef Tnyi
007cdb44 Myix)
007cdebf Tnyi
007cdf14 Myix)
007ce293 Tnyi
007ce301 j,x`
007ce66b Tnyi
007ce6d9 j,x`
007cea63 Tnyi
007ceab4 Myix)
007ceac1 z,x@
007ceb55 %@xJ
007cf0fb Tnyi
007cf150 Myix)
007cf4cb Tnyi
007cf520 Myix)
007cf859 %@x_
007cf89f Tnyi
007cf8f4 Nyix)
007cf90d j,x`
007cfc31 %@x_
007cfc77 Tnyi
007cfccc Nyix)
007cfce5 j,x`
007d006f Tnyi
007d00c0 Myix)
007d00cd z,x@
007d0161 %@xJ
007d0758 Lii8)
007d0761 jk8?
007d0b24 Lii8)
007d0b2d jk8?
007d16bc Lii8)
007d16c9 j+8`
007d1d54 Lii8)
007d1d5d jk8?
007d2120 Lii8)
007d2129 jk8?
007d24f1 jk8Mii8)
007d28c5 jk8Mii8)
007d2cb8 Lii8)
007d2cc5 j+8`
007d42a3 Tnyi
007d42f4 Myix)
007d4301 z,x@
007d4399 %@xJ
007d5c33 Tnyi
007d5c84 Myix)
007d5c91 z,x@
007d5d29 %@xJ
007d660f Tnyi
007d6660 Mii8)
007d6669 jl8?
007d69db Tnyi
007d6a2c Mii8)
007d6a35 jl8?
007d758b Tnyi
007d75dc Mii8)
007d75e9 j,8@
007d82ff T?{(
007d8727 T?{(
007d8b4f T?{(
007d9f8f RJa5
007d9fe1 "@9h
007da462 A9JA
007da701 "@9h
007da809 "@9h
007da82d "@9h
007da8dd "@9h
007da901 "@9h
007da9b1 "@9h
007da9d5 "@9h
007daa85 "@9h
007daaa9 "@9h
007dab59 "@9h
007dab7d "@9h
007dac2d "@9h
007dac51 "@9h
007dad01 "@9h
007dad25 "@9h
007dadd5 "@9h
007dadf9 "@9h
007daea9 "@9h
007daecd "@9h
007daf7d "@9h
007dafa1 "@9h
007db051 "@9h
007db075 "@9h
007db125 "@9h
007db149 "@9h
007db1f9 "@9h
007db21d "@9h
007db2cd "@9h
007db2f1 "@9h
007dbb8c +ih8J	
007dbc43 T E@
007dbd4f T E@
007dc7ac +ih8J	
007dd3cc +ih8J	
007de024 +ih8J	
007dec7c +ih8J	
007ded33 T+E@
007dee3f T+E@
007df88c +ih8J	
007df943 T+E@
007dfa4f T+E@
007e049c +ih8J	
007e0553 T+%@xL
007e065f T+%@xL
007e0709 lbN!lcN
007e07d5 dbN!dcN
007e1094 +ih8J	
007e114b T+%@xL
007e1257 T+%@xL
007e1301 lbn!lcn
007e1328 ,%@x
007e13cd dbn!dcn
007e13f4 ,%@x
007e1c88 +ih8J	
007e1f95 l"N!l#N
007e202d d"N!d#N
007e29bc +ih8J	
007e2cc9 l"n!l#n
007e2d61 d"n!d#n
007e3708 +ih8J	
007e43d4 +ih8J	
007e509c +ih8J	
007e5da4 +ih8J	
007e5dcf R)ya
007e5ec3 R)ya
007e694d "@9h
007e6969 #@9v
007e69c1 "@9h
007e8101 #A9h
007e8259 #A9h
007e8281 #A9h
007e8299 #A9h
007e85cf RMyz
007e9481 CA9h
007e9897 RJa6
007e9a41 cF9(
007e9a77 T		@
007e9a94 Lyixk	
007e9c01 cF9(
007ea261 cB9H
007ea4d5 #C9H
007ea71d cF9h
007ea8ad #@9h
007ea90c (#@9h
007ea96d "@9h
007eaa67 *!T@
007eaae7 *!T@
007ead03 o)mE
007eae9b o)mE
007eaf4f o)mE
007eb547 *!T@
007eb5eb Th"@
007eb6c3 Toyl
007eb6cf Tn>H
007eb6e4 nBA9o.@
007eb8bc Lii8k	
007eb8de @9hj686
007eb98e @yhz7x
007ebbab *!T@
007ebd1f *!T@
007ebe93 *!T@
007ec007 *!T@
007ecd1b T		@
007ece9d C@9h
007ed0b1 b@9(
007ed434 h"@9h
007ed4f3 *!T@
007ed765 "@9h
007edcc7 T	hs
007ede93 <J}	
007ee3af Th2@
007ee793 <k}	
007ef513 R yh
007ef533 kIxk
007f06af T	hs
007f087b <J}	
007f0dc3 <k}	
007f1b27 R yh
007f1b47 kIxk
007f323e !^  "
007f32f3 4h~@
007f39f7 *!T@
007f3fd1 "@9h
007f404d "@9h
007f4171 "@9h
007f4253 *!T@
007f4759 CA9JA
007f494e A9JA
007f526d #@9h
007f5409 "@9h
007f5529 @@9h
007f5579 @@9h
007f57af *!T@
007f582f *!T@
007f5d87 *!T@
007f5f89 CA9JA
007f6714 h"@9
007f68bc i"@9h
007f6ccd sA96
007f6d78 +ih8J	
007f6f57 *!T@
007f6fd7 *!T@
007f7484 Lyixk	
007f7507 9piq
007f7717 ypiq
007f79b7 *!T@
007f7a2b *!T@
007f7a9f *!T@
007f7b13 *!T@
007f7dab T-xj
007f7db7 T.ym
007f7e49 "@9h
007f7f67 TH,@
007f80ab TMyk
007f8473 q+ki
007f84b3 T+ki
007f87af *!T@
007f8827 *!T@
007f88a3 *!T@
007f895f *!T@
007f89df *!T@
007f8d37 Tpyl
007f8d43 TQ{p
007f8df1 "@9h
007f8e15 "@9h
007f8e64 h"@9h
007f8fa7 *!T@
007f920b oZk@
007f9301 c@9h
007f93b9 c@9h
007f93e1 c@9(
007f9421 c@9(
007f9809 `@9h
007f9859 `@9h
007f9a77 *!T@
007f9e11 cA9h
007f9f05 "@9h
007fa0bb *!T@
007fb85b *!T@
007fbb25 "@9h
007fbbef *!T@
007fbf34 Lii8k	
007fbff5 C@9h
007fc094 hG@9
007fc1a7 T   
007fc534 xC@9JU
007fcb1b T   
007fcb5b TL-B
007fcb83 T   
007fd40f Rh!	
007fdf4c hG@9
007fe3e8 xC@9JU
007fea0f TL-B
007ff2c3 Rh!	
007fff9b R|#	
008002a9 C@9JU
0080059a @9Nk,83
008008b3 TL-B
0080111f RH!	
0080208f R)A@9
008030c3 Rh!	
00803d01 "@9h
00803d79 "@9h
00804427 T   
0080445f T   
0080505c ikt8	
008050d4 hkt8[
00805118 hkt8[
0080590b Tw&@
00806e1f *!T@
00806e97 *!T@
00806f17 *!T@
00806f97 *!T@
00807235 @@9h
00807285 @@9h
008073f9 "@9h
008074b7 *!T@
008082df *(@ 
008084b7 T !.
008087cf ~Ai(
008087db T\i(
00808967 *(@ 
00808b3f T !.
00808c56 	ki)
00808e51 )	K?
00808e73 ZMi(
00808e87 T5i(
008092a1 &B9)
008092a9 *B9)
00809615 "B9h
00809729 c@9h
00809939 c@9H
00809a31 CA9h
00809abd CA9h
0080a1a1 CB9H
0080a205 3B9)
0080a355 /B9	c
0080a40c +ih8J	
0080a427 Thb@
0080a48b Thb@
0080a5cb Ti"@
0080a707 Ti"A
0080a732 @9JA
0080aa1b q#}@
0080abb5 CB9h
0080ac0b q#}@
0080af35 CB9(
0080af55 CB9(
0080b0a3 TM	@
0080b3dc A	@-
0080b51f Tnyj
0080b5ab TJ	@
0080b687 Tj	@
0080b853 T`yn
0080b863 T?{.
0080b8eb Th	@
0080c75d gt)Z
0080c9ad gt)Z
0080dff3 /@!(
0080e17b /@!)
0080e7b7 T@!.
0080ea7b T-yx
0080f437 / L 
0080f5d7 3(}@
0080f77b T`!-
0080faeb T@yh
0081143f T"zi
00812c13 / L 
00812edb T@!/
008130cf Ti"B
008133d3 ~Ai(
008133df T[i(
00813643 <i6@
00813717 T	 @
0081384b T` "
00813853 TW`F
00813baf /  "
00813c1c !80.-
00813d06 A-)}
00813e3c !80.(
00814398 !80.(
008146e1 @@9h
008149c9 80.	
00814b31 80.	
00814e4b =a"@
0081507c !80.(
0081563d &B9)
00815645 *B9)
008159b1 "B9h
00815ac5 c@9h
00815cd5 c@9H
00815dcd CA9h
00815e59 CA9h
008162ed CB9H
00816560 +ih8J	
0081657b Thb@
008165a1 2B9i
008165df Thb@
00816651 2B9I
008166a5 2B9I
0081671f Ti"@
0081685b Ti"A
00816886 @9JA
00816b6f q#}@
00816d09 CB9h
00816d5f q#}@
00817089 CB9(
008170a9 CB9(
008171eb TM	@
00817544 A	@-
008176af Tnyj
00817747 TJ	@
0081781f Tj	@
008179e7 T`yn
008179f7 T?{.
00817a73 Th	@
008188a1 gt)Z
00818af1 gt)Z
0081a7f6 !^  "
0081ac0a !^  "
0081afa2 !^  "
0081bf7f T	 @
0081c106 !^&jn
0081c59b <i6@
0081c673 T	 @
0081c7ab T` "
0081c7b3 TW`F
0081cbc9 &B9)
0081cbd1 *B9)
0081cf3d "B9h
0081d051 c@9h
0081d261 c@9H
0081d359 CA9h
0081d3e5 CA9h
0081d879 CB9H
0081daec +ih8J	
0081db07 Thb@
0081db2d 2B9)
0081db6b Thb@
0081dbdd 2B9)
0081dc31 2B9)
0081dcab Ti"@
0081dde7 Ti"A
0081de12 @9JA
0081e0fb q#}@
0081e295 CB9h
0081e2eb q#}@
0081e615 CB9(
0081e635 CB9(
0081e773 TM	@
0081eb08 A	@-
0081ed53 Tn	@
0081ee37 Tp	@
0081efdf T`yn
0081efef T?{.
0081fe45 gt)Z
00820095 gt)Z
008213fb / L 
0082159f 3(}@
0082173b T`!-
00821870 *c@9
00821a68 (c@9
00821aa7 T@yh
00822dd3 8#F@
008234ce @9(i*8J
008234f3 T	(@
008236b0 .i-8
00823777 Th&A
00823a2f 8bhq
0082415c Li+8k
00824255 h#8c
00824400 Ki)8)
0082492b / L 
0082498b <i6@
00824a63 T	 @
00824b34 Ni-8
00824f2f /  "
0082521d &B9)
00825225 *B9)
00825591 "B9h
008256a5 c@9h
008258b5 c@9H
008259ad CA9h
00825a39 CA9h
00825ecd CB9H
00825f31 3B9i
00826140 +ih8J	
0082615b Thb@
008261bf Thb@
008262ff Ti"@
0082643b Ti"A
00826466 @9JA
0082674f q#}@
008268e9 CB9h
0082693f q#}@
00826c69 CB9(
00826c89 CB9(
00826dc7 TM	@
0082715c A	@-
008273a7 Tn	@
0082748b Tp	@
00827633 T`yn
00827643 T?{.
00828499 gt)Z
008286e9 gt)Z
0082a3ee @8#F@
0082aaea @9(i*8J
0082ab0f T	(@
0082accc .i-8
0082ad93 Th&A
0082b778 Li+8k
0082b839 hc8E}
0082b871 h#8c
0082ba1c Ki)8)
0082bcd9 hd8sjd8)id8
0082bf5f <i6@
0082c037 T	 @
0082c108 Ni-8
0082c255 ic<C
0082c2b5 in<@
0082df4d CF9h
0082e3c7 T	8@
0082e3e8 )ip8
0082e6f8 Uil8
0082ea30 Uil8
0082f41f T	4@
0082ff5f T	4@
00832cff T)kx
00832d3d "@9h
00832dd0 h"@9h
00832ed3 T)kx
00832f11 "@9h
00832fa4 h"@9h
008330a7 T)kx
008330e5 "@9h
008331b4 h"@9h
008339ee i))}@
0083424d "@9h
0083429b 9Ja@
008342cd "@9h
00834349 "@9h
0083436e @9`&
008343c1 "@9h
008343de @9`*
008343f7 R)e,
0083442d "@9h
008344b9 "@9h
0083458b *!T@
00834f2e B9)!
008350d1 CA9,
008353f3 *)}@
0083542f *	}@
008354e7 *)}@
008358f3 *I}@
00835d2f *L}@
00835dab KC|@
00835e13 q!( 
00835f27 <iF@
00836dbb RhS	
00836df3 RZS	
00836e2b RLS	
00836e7f R7S	
00836ea7 R-S	
00837177 RyR	
008371cb RdR	
008371f3 RZR	
0083722b RLR	
0083757f RwQ	
00837744 ,ij8k	
00837807 T		@
00837963 R~P	
008379f7 RYP	
008379fd C@9h
00837abf Rj|@
00837d82 A9JA
0083811d "@9h
008381e3 *!T@
0083825b *!T@
0083881f =)	@
00838bf7 *	 D
0083969f R/I	
0083997f RwH	
008399a7 RmH	
008399cf RcH	
00839a03 RVH	
00839a43 RFH	
00839a77 R9H	
00839abb R(H	
0083a023 T(	@
0083a197 T<	@
0083a331 "@9h
0083a359 "@9h
0083a3b7 RAz	
0083b558 h"@9h
0083c6c7 Tk	@
0083c98b Rt<	
0083c9c3 Th	@
0083ca3f RG<	
0083cd3d "@9h
0083cd5d #B9h
0083cdc9 "@9h
0083cde1 #B9h
0083ce51 "@9h
0083ce93 Rka,
0083cf25 #B9h
0083cf7d #B9h
0083cfdd #B9h
0083d041 "@9h
0083d059 #B9h
0083d35b *!T@
0083d3d3 *!T@
0083d477 *!T@
0083d4ef *!T@
0083e741 'Di(}
0083e913 *!T@
0083eafb Tf*@
0083eb93 Tk&@
0083ec4b *!T@
0083ef64 "xaN!xa
0083ef70 cxaN!
0083ef7a `n!ha
0083ef8a `nAhaNdhaN!
0083f033 Rg		
0083f1b7 ** @
0083f505 @F9H
0083f533 Rhn@
0083f59f 6i"W
0083f5d8 hBF9H
0083f5f7 ReF@
0083f607 Rhn@
0083f6df Ti}	
0083f94a @9)=A
0083f96c *AF9h
0083fea0 j&Cih&
0083feeb 4i"@
008400af 5h2@
008400bb Ti"@
008400d4 h&CibB
00840148 h&CibB
008402df T`NA
00840407 T(8@
00840a4b =8L@
00840e71 CI9h
00841083 TK		
00841117 TI		
00841703 =)	@
008417df =)	@
0084186f 4`WC
0084193f 4i'@
008419a3 4`_C
00841a77 7	q}
00841afb 4`#C
00841b07 Ta'C
00841b7b 4`gC
00841d0f =)	@
00841e13 7	q}
00841ee7 7	q}
008421bd CC9H
008421dd CC9H
008428ed "@9h
008429fb *!T@
00842d77 Ry#	
0084310f T yh
00843a3f ^!("
00843a4b ^!(#
00843a53 <!($
00843a5e $n!("
00843a67 ^!(#
00843a6f ^!("
00843a77 ^!($
00843c62 "N"@
00843ca7 ^!("
00843cb3 ^!(#
00843cbb <!($
00843cc6 $n!("
00843ccf ^!(#
00843cd7 ^!("
00843cdf ^!($
00843eea !n"@
00843f2b ^!("
00843f37 ^!(#
00843f3f <!($
00843f4a $n!("
00843f53 ^!(#
00843f5b ^!("
00843f63 ^!($
00844056 "N"@
0084409b ^!("
008440a7 ^!(#
008440af <!($
008440ba $n!("
008440c3 ^!(#
008440cb ^!("
008440d3 ^!($
00844e37 TS$@
00844e9f TS(@
0084516b TPD@
0084534d "@9h
0084545b *!T@
00845972 p~Ayk
00845cdb T yh
0084699b ^!(b
008469a6 bn!(d
008469af ^!(b
00846ac3 ^!(b
00846ace bn!(d
00846ad7 ^!(b
00846c17 ^!(b
00846c22 bn!(d
00846c2b ^!(b
00846ecf ^!(b
00846eda bn!(d
00846ee3 ^!(b
008473b2 snYi
008473ba tnTi
008473ff ^c(x
00847407 ^B(t
0084740f ^!(q
008476ea gn0G@
0084770b ^c(p
00847717 =c(g
00847723 ^B(r
00847733 ^c(g
00847757 ^B(p
0084775f ^c(q
0084776b ^B(g
0084796b ^B(c
00847973 ^!(e
0084797e gnB(p
0084798b ^B(d
00847993 ^!(e
00847ac3 ^!(b
00847aca en!(c
00847ad3 ^!(b
00847e77 6I!@
00847e97 Rk}L
0084899b T@4@
008489d3 TDD@
00848a07 T@4@
00848a8f TU0@
00848ad3 TLd@
00848c17 TDD@
00848c83 TDD@
00848cdf TQ0@
00848da3 TO@@
008493b3 =sQ@
008493ba rNu	
008493c6 pNsQ
008493f2 dNG	
008498e1 AAm"
00849909 ABm"
0084a14b ^c(v
0084a153 ^B(x
0084a15b ^!(y
0084a16a pnc(g
0084a17a snB(t
0084a193 ^c(w
0084a19f ^!(f
0084abcf *!T@
0084b943 r@E@
0084dae1 C@9h
0084e41b R(*	
0084e713 *!T@
0084e888 	(D-U
0084ed73 *!T@
0084f253 r@E@
0084fe21 "@9h
0085003b TH$A
008500b3 TJ$A
00850303 TJ$A
008505d6 @MjB
00850fe5 "@9h
008510ab *!T@
00851123 *!T@
00851467 *!T@
008514df *!T@
00851557 *!T@
00851817 *!T@
00851b53 9Ja@
00851b89 "@9h
00851c09 "@9h
00851cdb *!T@
00851d53 *!T@
00851dcb *!T@
00851e43 *!T@
00851ebb *!T@
00852097 Tj>@
0085251b *!T@
00852593 *!T@
00852bdf T(%@
00852ecf TK)A
0085347d "@9h
008534b8 hB@9
0085353a gn&4
008535ce d.%4
00853623 ThB@9j
00853663 4hB@9j
008536ed "@9h
008538fd @@9h
0085394d @@9h
00853a88 h#@9h
00853b78 h"@9h
00853caf TK	@
008540f3 TL}	
00854167 ^y}@
0085438f ^a}@
0085487f o)mE
00855185 "@9h
008551e9 "@9h
008552a3 *!T@
0085531b *!T@
008554f9 "@9h
008555b3 *!T@
00855bc7 *!T@
00855c87 *!T@
00855eca A9JA
008562b1 "@9h
0085632f *!T@
008564bd "@9h
0085673d #@9h
008567a9 "@9h
00856c80 hB@9
0085770d "@9h
00857771 "@9h
0085782b *!T@
008578a3 *!T@
0085a63f TM	@
0085a763 ^!(b
0085a773 N!(c
0085a77b ^!(b
0085acbb TAyi
0085acdf ^!(b
0085acef N!(c
0085acf7 ^!(b
0085b9eb Th~`
0085ba17 K7}@
0085beeb 6I!@
0085bf0b Rk}L
0085da43 T@xd
0085de8e gN4UA
0085de9a pN2M
0085deaa eN4U
0085deba cN'A
0085def3 Ti8@
0085dfc7 Ti8@
0085e006 gN1IA
0085e02a bN0EA
0085e03e cN0E
0085e063 Ti8@
0085e09e fN0	
0085e0be bN'	
0085e0ef Ti8@
0085e163 Ti8@
0085e25b ^B(c
0085e26a cnB(e
0085e273 ^B(c
0085eb73 TQ@@
0085fec0 +%@xJ
008602e4 K%@x
0086073f Tfymx
008607a3 S!( 
00860cab Tc|@
00860d40 Ehdx
00860d49 h$xFh$x!
00860d93 Th;@
0086118e @y!8
008613ec  i<x)
008613f7 T i|x
008616e1 ygxtJ
008617be @y[K
00861832 @y[K
00861862 @y[K
00861896 @y[K
00861a9f 6I!@
008624a2 @ydH
00862a43 yi&@x
00862bb3 TPD@
00862c05 &@x1
00862c0c  x/x
00862d37 TY`@
00862eab xj'@x
00862eb3 x*'@x
00862f74 %&@x
00862f7c %x0x
00863427 S~	@ym
00863bae 	*1=
00864026 	*1=
008645af *B(!
00864606 @yg8
008657cb Rm!@y
008657d3 St%@yq)@yl8
008657e4 x-@y?
00865a2b RB(!
008669ee @yh1@y
008669f7 S~5@yq9@yl8
00866a08 a=@y
00866b8e 	*/I
00867ba0 lA@y
00867bad %@yeE@y
00867bb7 SqI@y
00867bc4 xM@y
00867f96 	*:I
00868dac n+@y
00868db3 Ra/@y
00868dbb RmQ@y
00868dc3 ScU@yqY@y8;
00868dd4 t]@y
0086925b RB(!
00869fb0 .1@y!5@yma@y
00869fbf S~e@yqi@y8;
00869fd0 tm@y
0086b148 oq@ylu@y
0086b15d =@yqy@y
0086b167 St}@y8;
0086b556 	*:I
0086ba6f RB(!
0086c485 7;)l
0086c4f7 S~	@y`
0086cda3 RB(!
0086d4b5 Gy)1
0086d6d3 RB(!
0086db96 	*1=
0086f036 	*1I
0086f4ba 	*1I
0086f93e 	*1I
0086fdc2 	*1I
00870246 	*1I
008706ca 	*1I
00870b4e 	*1I
00871382 	*0=
008715e5 y+xk
0087168e 	r(	
00871ce6 	*,=
00871f22 	*.=
0087215e 	*.=
00872b99 ![x\I
0087349a [x0;
008735be 	*.=
008737ea 	*.=
00873a1a 	*,=
00873ea2 	*.=
008740de 	*.=
00874316 	*.=
00874792 	*.=
008749e2 	*.=
00874c0e 	*.=
008752e2 	**=
0087550e 	**=
0087573a 	**=
00875992 	*.=
00875bca 	**=
00875dfa 	*.=
00876676 	*I}
00876a66 	*.=
00876ca2 	*.=
008777d1 z)xk
0087783b TIkjx,I
00877853 2mijx
00877878 mijx
008778b0 mijx
0087796e 	*,=
00877cd9 	@yl
00878ac1 zix!
00878b8e @ynH
00878bb2 @ynH
00878bea @ynH
0087904b S ( 
0087917b S ( 
00879557 T		@
00879592 	*	{(xh
008795a7 Th&@
00879614 	{hx*I
00879648 	{hx*I
0087979e @y+I
00879897 R!( 
008798b7 qM @
00879bc6 @y(=
00879f4f R]<@
0087a050 iy*x
0087a136 @y+I
0087a15e @y+I
0087a196 @y+I
0087a24e 	*I=
0087ac3a @yII
0087ac6e @yII
0087acae @yII
0087ad8e 	*I=
0087b257 rB( 
0087b286 	*i=
0087c308 iy*x
0087c3b2 @yII
0087c4e2 	*I=
0087c5be @yII
0087c5ee @yII
0087c62a @yII
0087c6fa 	*I=
0087c7d6 @y)H
0087c806 @y)H
0087c842 @y)H
0087c912 	*)<
0087c9ee @y)J
0087ca1e @y)J
0087ca5a @y)J
0087cb3a 	*	>
0087d3c4 	z*x
0087d42e @yiJ
0087d54e 	*i>
0087d62a @y	K
0087d65a @y	K
0087d696 @y	K
0087dca4 Ix!x
0087dfd8 cxaxdH
0087e09e @y(=
0087e453 2 ( 
0087f722 u)C|
0088057a 	**=
0088078b TMhjx
008809d1 hjx0H
008809ea @yqH
00880a12 @yqH
00880a4a @yqH
00880c32 @yCH
00880e5a @yCH
00881082 @yCH
00881284 (hxx
008812b0  h8x
008813e6 @yPH
0088140e @yPH
00881446 @yPH
0088162e @y"H
00881856 @y"H
00881b41 hjx.J
00881b5a @y/H
00881b82 @y/H
00881bba @y/H
0088209e 	*)x>x
008823e0 *x~xKI
00882410 *x~xKI
00882443 S*x~xKI
00882482 	*,I
00882567 6I!@
00882f71 ylxly*xJ
00883850 kyjxlI
00883966 @ylI
00883c0b **y,x
00883c1b T+ylx`I
00885131 #@9h
008854b1 "@9h
008854d1 #@9h
00885525 "@9h
00885541 #@9h
00885594 h"@9h
008855b1 #@9h
008856e7 o)i@
008856f6 @9)A
00885775 CA9JA
00885c62 \8H&
00886259 #C9h
008868dd #C9h
00887191 #C9h
008871c5 #@9h
008871e8 h"@9h
00887a49 #C9h
00887a7d #@9h
00887aa0 h"@9h
00888219 #C9h
0088824d #@9h
00888270 h"@9h
008882e0 h"@9h
00888309 #C9h
0088833d #@9h
00888360 h"@9h
00888aad #C9h
00888ae1 #@9h
00888b04 h"@9h
0088a6c7 =U	@
0088a919 CB9H
0088aacd CB9h
0088ab01 CB9(
0088ab21 CB9(
0088b17b <iF@
0088b9fd "@9h
0088ba6d "@9h
0088bb27 *!T@
0088bb9f *!T@
0088c04e @9B 
0088c05b J!~	
0088c064 1FA*1~
0088c0cb T"|B
0088c12a @9"<
0088c177 JkAKJk}
0088c180 k5KJk}	
0088c188 kAKJ
0088c1ab Rk}B
0088c1e8 BDC*B|
0088c2c7 *!T@
0088c347 *!T@
0088c3bf *!T@
0088c5bd "@9h
0088c631 "@9h
0088c9f3 *!T@
0088ca6b *!T@
0088cd43 *!T@
0088cdbb *!T@
0088ce51 c@9h
0088d5c5 #C9h
0088d653 *!T@
0088d6cb *!T@
0088db19 CA9H
0088dbef *!T@
0088dc67 *!T@
0088dcf9 CA9h
0088dd66 @9	@
0088deb9 haNE
0088df34 0jaN
0088dfda aN0jaNq
0088dfe3 NRja
0088dff6 $n2jaNQ
0088e085 haN'
0088e587 *!T@
0088e5ff *!T@
0088f545 @@9h
0088f595 @@9h
0088f6ab 9JQ@
0088f6dd "@9h
0088f797 *!T@
0088f931 "@9h
0088f9ad "@9h
0088fa67 *!T@
0088fae7 *!T@
0088fb5f *!T@
0088fd31 "@9h
0088fdaf *!T@
0088ff28 hb@9
0088ffd3 *!T@
008903e5 "@9h
00890447 T		@
008904bd "@9h
008905fd "@9h
00890713 RiB@
00890787 *!T@
008907ff *!T@
008909c7 *!T@
00890a3f *!T@
00890ab7 *!T@
00890b2f *!T@
00890ecf Th&B
00890f57 Ti"@
00891047 <i.@
00891bb2 Z8h7
00891f93 8)}@
008925af Ti/@
00892bab Tw	@
00892bbb T)/@
00892cd7 *)?@
00893499 bD9?
008934b1 fD9?
00893f9a A9JA
008948af *!T@
00894bdb =)	@
00894efd CG9(
00894f25 CC9h
00894f5d CG9(
008952bf Th>@
008952cc (ih8
0089549f *!T@
008963d7 o)5A
0089648f o)9A
00896547 o)9A
008969c3 *!T@
00897483 Ti2@
008974ab Toyp
0089756f Tqyp
00897633 Tpyp
00897723 Tlyp
0089773f Tiyp
0089776b TiB@
008978a7 Tk6@
00897b7f x,y+
0089801f 6I!@
00898c53 TQ@@
00899127 Tq	@
00899467 =qI@
0089aef1 XCmA
0089b5a7 7h"B9H
0089b5af 7hbA9
0089b5ec h"B9
0089b5f3 6`J@
0089b5fc hbA9
0089b603 6`2@
0089b667 7h"B9
0089b66f 7hbA9
0089b6b4 h"B9
0089b6bb 6`J@
0089b6c4 hbA9
0089b6cb 6`2@
0089bef7 *!T@
0089c22f 7h"B9H
0089c237 7hbA9
0089c274 h"B9
0089c27b 6`J@
0089c284 hbA9
0089c28b 6`2@
0089c2ef 7h"B9
0089c2f7 7hbA9
0089c33c h"B9
0089c343 6`J@
0089c34c hbA9
0089c353 6`2@
0089cb7f *!T@
0089d1b7 TH/@
0089d457 T	m@
0089d6e3 T	)@
0089d6f7 R;}@
0089de1b =)	@
0089e2d7 =)	@
0089e6d6 @M'	
0089e87e @M%	
0089eb83 NDD@
0089ef0e @M'	
0089f0b6 @M%	
0089f3bb NDD@
0089fc19 "@9h
008a043d "@9h
008a2167 =)	@
008a2475 CH9h
008a253d CC9h
008a25d3 *!T@
008a2653 *!T@
008a26d3 *!T@
008a2753 *!T@
008a27d3 *!T@
008a2853 *!T@
008a2974 Iii8
008a2b4a K-"`@
008a2c1c 	!D9
008a2c80 	!D9
008a2e8b *!T@
008a34d3 =)	@
008a37e1 CH9h
008a38a9 CC9h
008a393f *!T@
008a39bf *!T@
008a3a3f *!T@
008a3abf *!T@
008a3b3f *!T@
008a3bbf *!T@
008a3ce0 Iii8
008a3eb6 K-"`@
008a3fe7 =)	@
008a406c Iii8
008a4242 K-"`@
008a4373 =)	@
008a43f8 Iii8
008a45ce K-"`@
008a46cb Ti"B
008a47c3 2	i9
008a4867 2	i9
008a4a93 *!T@
008a4b27 *!T@
008a4ba7 *!T@
008a4f63 2Ii(
008a4fee 	k!"
008a537d "@9h
008a5423 *!T@
008a54b3 *!T@
008a558b *!T@
008a616f TiC@9j
008a6365 cB9H
008a653b *!T@
008a65bb *!T@
008a663b *!T@
008a66bb *!T@
008a6e3b 9JQ@
008a6e75 "@9h
008a7a08 (hh8)hi8*hj8+hk8H
008a7a3c (hh8H
008a7db7 *!T@
008a7e37 *!T@
008a7ebb *!T@
008a7f3b *!T@
008a81f7 NET8O*
008a8323 *!T@
008a83a3 *!T@
008a8427 *!T@
008a84a7 *!T@
008a87b4 	DD9I
008a8b35 BD9h
008a91c9 BD9+
008a942d kC9	
008a966d {C9	
008a98bb *!T@
008a993b *!T@
008a99bb *!T@
008a9a3b *!T@
008a9c59 CE9h
008a9f41 CH9H
008a9fbe I9(3
008aa119 CH9h
008aa325 BD9j
008aa55d CD9H
008aa85d BD99
008aafab *!T@
008ab02b *!T@
008ab0ab *!T@
008ab12b *!T@
008ab6d3 9JQ@
008ab70d "@9h
008ab83b NfT8OK
008ac01d i)8)
008ac384 -i(8
008ac3f7 /Ayp
008ac467 <iF@
008ac9e8 *i(8
008acb5f <i>@
008acec8 ci)8	
008ad3da @9K}
008ad454 *i(8
008ad68b Tj'H
008adc78 hi*8
008ae2c9 R@=B
008ae2ce !~!("
008ae2e9 i)8)
008ae629 P@=!
008ae648 ,i(8
008ae6bb /Ayo
008ae72b <iF@
008aec88 bR@=B
008aec8e !~!("
008aeca8 *i(8
008aee1f <i>@
008af161 P@=!
008af180 Bi)8	
008af68e @9K}
008af6e1 S@=B
008af6e6 !~!("
008af700 *i(8
008afeed P@=!
008aff10 hi)8
008b006d CA9h
008b00d5 "@9h
008b00f9 "@9h
008b0111 CA9h
008b017c a"E)!|@
008b021f Th&A
008b030c h"@9h
008b03c7 *!T@
008b0443 *!T@
008b0d6b T[{7
008b0deb T,yl
008b15a2 @9N}
008b161f T(  
008b17c7 T(  
008b1bf3 Th&A
008b1d5f *!T@
008b1ddf *!T@
008b200f Th/@
008b2312 A9@ 
008b2589 cI9(	
008b2592 H9h	
008b25a9 #F9(
008b2699 #J9h
008b26a9 cI9(
008b26e9 #F9(
008b27af *!T@
008b282f *!T@
008b28af *!T@
008b292f *!T@
008b33b2 @9*i@
008b3405 7?)a
008b3704 	ii8i
008b37a3 T0im8
008b381c /im8
008b3821 io8k
008b392e @9Ni@
008b39b5 in8)
008b3a40 Uil8
008b3d78 Uil8
008b4ba4 h"@9h
008b4c63 5(/@
008b4e1c (ih8
008b528f *!T@
008b530f *!T@
008b538f *!T@
008b540f *!T@
008b548f *!T@
008b550f *!T@
008b558f *!T@
008b5beb *!T@
008b7005 "@9h
008b70cb *!T@
008b7143 *!T@
008b738f TtN@
008b7a13 ^!("
008b7a4b ^!(0
008b7a56 $n!(%
008b7a67 ^!($
008b7a83 ^!('
008b7b93 ^!("
008b7bbb ^!(0
008b7bcb ^!(&
008b7beb ^!(%
008b7bfb ^!(#
008b7ceb ^!("
008b7d1b ^!(0
008b7d26 $n!(%
008b7d37 ^!($
008b7d53 ^!('
008b7e03 ^!("
008b7e2b ^!(0
008b7e3b ^!(&
008b7e57 ^!(%
008b7e63 ^!(#
008b83e5 "@9h
008b84ab *!T@
008b8523 *!T@
008b876f TtN@
008b8dee bn!(b
008b8e1a cn!(e
008b8e2b ^!(c
008b8f52 bn!(b
008b8f7e cn!(e
008b8f8f ^!(c
008b9066 bn!(b
008b908a cn!(e
008b909b ^!(c
008b9765 #@9h
008b9789 #@9h
008b97bf RJU'
008b9808 (#@9h
008b982c (#@9h
008b98c4 (#@9h
008b98e8 (#@9h
008b9961 "@9h
008b9985 "@9h
008b9a5d CA9h
008b9b98 h"@9h
008b9c09 CA9J
008b9d6b *!T@
008b9deb *!T@
008b9e6b *!T@
008b9eeb *!T@
008b9f6b *!T@
008b9feb *!T@
008ba06b *!T@
008ba0eb *!T@
008ba3e5 CA9h
008ba5f0 	A@9
008ba741 B@9(
008ba7a9 iz8H
008ba7cd iz8(
008ba7d2 86		
008ba879 B@9H
008bab05 hj8k
008bab0a ?6l	
008bab65 hk8J
008bab99 hj8k
008baeae ?6l	
008baf42 ?6l	
008bb3a1 C@9j	
008bb569 A@9(
008bbc76 ?6l	
008bbce2 ?6		
008bbe9c 	A@9
008bbf45 #B9H
008bc0c1 A@9(
008bc0e5 A@9J'@
008bc834 hb@9h
008bc9b7 TtV@
008bcb1b Tt.@
008bcf5d "@9h
008bcfd9 "@9h
008bd050 h"@9h
008bd113 *!T@
008bd18b *!T@
008bd203 *!T@
008bd5b8 h"@9h
008bd755 #@9(
008bd7b1 "@9h
008bd7f2 M)o:
008bd8e1 "@9h
008bd935 #@9(
008bd989 #@9h
008bd9e9 cA9h
008bda7b *!T@
008bdafb *!T@
008bdb7b *!T@
008bdbfb *!T@
008bdc41 #@9(
008bdc61 #@9(
008bddb8 h"@9h
008bde37 r6 @
008bf39f *!T@
008bf41f *!T@
008bf49f *!T@
008bf51f *!T@
008bf59f *!T@
008bf61f *!T@
008bfddd #@9h
008bfe1f RJ%"
008bfe59 #@9h
008bfed1 #@9h
008bff51 #@9h
008bff93 R)A7
008bffcd #@9h
008c0031 %D)?
008c019d #@9(
008c080d "@9h
008c0831 "@9h
008c091d "@9h
008c0941 "@9h
008c0ed8 h"@9h
008c15d1 #@9h
008c1613 RJ%"
008c164d #@9h
008c16c5 #@9h
008c1745 #@9h
008c1787 R)A7
008c17c1 #@9h
008c1825 %D)?
008c1991 #@9(
008c2001 "@9h
008c2025 "@9h
008c2111 "@9h
008c2135 "@9h
008c26cc h"@9h
008c3380 h"@9h
008c376d "@9h
008c3791 "@9h
008c3e5b *!T@
008c4b74 h"@9h
008c4f61 "@9h
008c4f85 "@9h
008c564f *!T@
008c67c0 hB@9
008c6980 hbA9
008c8de3 T	 A
008c90ff T)e@
008c92bd '7)	
008ca7cb T)e@
008ca989 '7)	
008cb42b T	 A
008cb681 "@9h
008cb6f9 "@9h
008cb77d "@9h
008cb7f9 "@9h
008cb82f R)u%
008cb871 "@9h
008cb8ed "@9h
008cb923 RJ5	
008cb965 "@9h
008cb982 @9hn
008cbb2b *!T@
008cbd3f *!T@
008cbdef *!T@
008cbe7b *!T@
008cbf27 *!T@
008cbfc7 *!T@
008cc057 *!T@
008cc0e3 *!T@
008cc26f oZk@
008cc797 *!T@
008cc94f TWg@
008ccc8f Tmii8
008cd033 *!T@
008cd35b Rhk88
008cda0f T_y0
008cda64 hkx8
008cdb4c )!@9I
008cdc2f *!T@
008cdca7 *!T@
008cdd1f *!T@
008cdd97 *!T@
008cde0f *!T@
008cdf5b Ti;@
008cdf67 Ti?@
008cdf6c )ix8	
008ce3c3 Tj+@
008ce5b7 *!T@
008ce62f *!T@
008ce9d7 =a*@
008cfd07 T.xk
008cfe6f *!T@
008d00a9 C@9h
008d0557 T*xi
008d0663 *!T@
008d102f Th~@
008d1143 Th~@
008d21e3 *!T@
008d2337 TI|@
008d2973 *!T@
008d2b0b T)#@
008d2cff *!T@
008d2e97 T)#@
008d308b *!T@
008d3223 T)#@
008d33ef *!T@
008d3747 Tmi(
008d38f6 	*9}@
008d3d5b *!T@
008d4287 *!T@
008d4347 4)(@
008d439b T@ye
008d445b T@yo
008d4572 @-!("
008d4dc8 +ih8J	
008d5754 +ih8J	
008d5cba =-`G
008d5d1a =-`D
008d5dba =-`?
008d611e =-@$
008d61a2 =-  
008d622c ,ij8k	
008d73cc myjx
008d7bc1 "@9h
008d7d25 "@9h
008d7da1 "@9h
008d7e18 h"@9h
008d7edb *!T@
008d7f53 *!T@
008d7fcb *!T@
008d83f7 *!T@
008d8477 *!T@
008d85e3 r6 @
008d8615 CI9h
008d8649 w	9J
008d8651 C	9	
008d8679 CI9h
008d86d3 =*I@
008d907f *!T@
008d90ff *!T@
008d917f *!T@
008d91ff *!T@
008d927f *!T@
008d98d3 RJ%"
008d9edc h"@9h
008da238 (#@9h
008da25c (#@9h
008da348 (#@9h
008da36c (#@9h
008da3f0 Kii8
008dac9f RJ%"
008db2a8 h"@9h
008db604 (#@9h
008db628 (#@9h
008db714 (#@9h
008db738 (#@9h
008db7bc Kii8
008dd4eb T	 @
008dd857 TOyi
008dd86d ii8O
008dec7b T	 @
008defe7 TOyi
008deffd ii8O
008dfab1 "@9h
008dfb2d "@9h
008dfba9 "@9h
008dfbdf R)u%
008dfc21 "@9h
008dfc9d "@9h
008dfcd3 RJ5	
008dfd15 "@9h
008dfd32 @9hn
008dfec7 *!T@
008dffeb *!T@
008e007b *!T@
008e012b *!T@
008e01b7 *!T@
008e1324 hB@9h
008e13eb *(	@
008e171f *(	@
008e1980 H$A)
008e2149 "@9h
008e21c5 "@9h
008e223c h"@9h
008e22ff *!T@
008e2377 *!T@
008e23ef *!T@
008e26f0 h"@9h
008e27b9 "@9h
008e286f *!T@
008e28ef *!T@
008e2a5b r6 @
008e2a8d CI9h
008e2ac1 w	9J
008e2ac9 C	9	
008e2af1 CI9h
008e2b4b =*I@
008e34f7 *!T@
008e3577 *!T@
008e35f7 *!T@
008e3677 *!T@
008e36f7 *!T@
008e3d4b RJ%"
008e4414 h"@9h
008e4770 (#@9h
008e4794 (#@9h
008e4880 (#@9h
008e48a4 (#@9h
008e4928 Kii8
008e51fb RJ%"
008e58c4 h"@9h
008e5c20 (#@9h
008e5c44 (#@9h
008e5d30 (#@9h
008e5d54 (#@9h
008e5dd8 Kii8
008e7873 R	}	
008e78a7 /kF@
008e7d07 TOyi
008e7d1d ii8O
008e8443 R	}	
008e8477 /kF@
008e88d7 TOyi
008e88ed ii8O
008e8b45 "@9h
008e8bc1 "@9h
008e8c3d "@9h
008e8c73 R)u%
008e8cb5 "@9h
008e8d31 "@9h
008e8dad "@9h
008e8e1d "@9h
008e8e99 "@9h
008e8f15 "@9h
008e8f85 "@9h
008e8fa2 @9`~
008e8ff9 "@9h
008e9037 RJ5	
008e9079 "@9h
008e9096 @9hn
008e920f *!T@
008e9467 T)	@
008e947b T	,@
008e99e8 	 Di
008e9e0f Th~@
008ea97d #@9h
008eb3e9 "Di!
008ebc33 *!T@
008ebcab *!T@
008ebe9b T	$@
008ec451 #@9H
008ed11f 2	OB
008ed143 2	OB
008ed441 #@9h
008edc6f r7}@
008edebc )!Di!
008ee79f *!T@
008eef29 #@9h
008ef874 	 Di
008efe9b *!T@
008f0269 CA9H
008f04db T+	@
008f0781 i`8_
008f07c1 i)8k
008f08e9 i/8p
008f08f1 i.8c	@
008f1a11 #@9h
008f25bf 9Ja@
008f25f9 "@9h
008f262b R)m9
008f2669 "@9h
008f26e5 "@9h
008f30c0 	`@y
008f3105 "I)?
008f33fd #@9h
008f35d1 a	*i
008f3851 #@9h
008f38be )kA	
008f38fb *)}@
008f3c56 A9JA
008f493f *!T@
008f4d3b *!T@
008f599b *!T@
008f5f35 cA9h
008f5f69 cA9h
008f6019 "@9h
008f60b5 #B9h
008f671b *!T@
008f6a13 Rt#	
008f6bff *!T@
008f6c77 *!T@
008f6ceb *!T@
008f6f61 CC9h
008f70d9 CC9h
008f7369 CC9h
008f74f5 CC9h
008f76d5 CC9h
008f78cd CC9h
008f7a8d CC9h
008f7cd7 TI	@
008f7cdc (a@9
008f7ce3 5(	@
008f7ea3 =)Q@
008f8095 CC9h
008f8265 CC9h
008f83cf R!0)
008f8441 CC9h
008f8615 CC9h
008f87d9 CC9h
008f890b *!T@
008f8987 *!T@
008f8d85 cE9h
008f8f77 *!T@
008f91ef *!T@
008f9447 *!T@
008f95b5 rQ9h
008f9943 R!( 
008f996b R!H-
008f99d5 CB9h
008f9bdb *!T@
008f9c4f *!T@
008f9cc3 *!T@
008f9fdf *!T@
008fa05f *!T@
008fa2af *!T@
008fa42b *!T@
008fa647 *!T@
008fa6bf *!T@
008fa8db *!T@
008fabe3 *!T@
008fac8f *!T@
008fad03 *!T@
008fad77 *!T@
008fadeb *!T@
008fb23b o9k@
008fb277 R!d6
008fb29f R!d6
008fb2c7 R!d6
008fb2ef R!d6
008fb317 R!d6
008fb33f R!d6
008fb367 R!d6
008fb38f R!d6
008fb3b7 R!d6
008fb77f *!T@
008fb7f3 *!T@
008fb867 *!T@
008fb8db *!T@
008fc238 	 @9
008fc8fb *!T@
008fc9d3 Tu^@
008fcb43 Tu^@
008fcff7 *!T@
008fd06f *!T@
008fd135 80.i
008fd2ab oZk@
008fd729 80.	
008fd81f =a"@
008fda7d 80.	
008fdec3 Ta&@
008fdf65 80.i
008fe0a5 80.	
008fea11 #@9h
008fea55 `@9h
008fed01 CA9h
008ff0b5 CA9h
008ff2ff T.4@
008ff32f T/4@
008ff383 T,8@
008ff7c7 *!T@
008ffb3d c@9h
008ffbdd c@9h
008ffd71 c@9H
008ffe15 c@9h
008fff9d c@9h
00900035 c@9h
00900087 T(+@
009001d1 c@9H
009001f5 c@9h
00900399 c@9h
009003eb T(+@
00900535 c@9H
009006c5 c@9h
00900783 TtV@
00900887 R)iE
00900977 R)qE
00900a67 R)yE
00900d67 *!T@
00900ea3 Tm	@
00900f54 ,ij8k	
00901093 *!T@
009011e7 Ti*@
009012bf *!T@
00901337 *!T@
0090143b Th*@
0090152b *!T@
009015a3 *!T@
0090175f Th*@
0090186b *!T@
009018e3 *!T@
00901a93 Th*@
00901b9f *!T@
00901c17 *!T@
00901cdb T)(@
00901ce7 T	)@
00901dc7 *!T@
00901e3f *!T@
00901eef T)(@
00901efb T	)@
00901ffb *!T@
00902073 *!T@
00902193 *!T@
0090238b *!T@
0090bf7f *!T@
0090c00b *!T@
0090c570 Lyixk	
0090cb94 Lyixk	
0090d877 RJ	G
00910ba0 J{hx)	
00911077 *!T@
0091173d 80.	
00911cd3 oZk@
00911e25 80.i
00912b8f RJ	G
009136cf RJ	G
00913b0b *!T@
009142d7 *!T@
009149af RJ	G
009151f3 *!T@
00916f67 *!T@
009170a7 *!T@
009172a4 	<@y
009172b3 T	t@9
009172c3 T	p@9
009173f3 *!T@
00917693 Rh.@
009176af Tj2@
009182ed cA9h
00918344 h"@9h
0091849d cA9h
00918a55 c@9H
00918b15 c@9H
00918cbc h"@9h
00918ce0 h"@9h
00918d39 #@9h
00918d71 #@9h
00918d89 #@9h
0091913f *!T@
00919220 	@A9
0091922f 6`.@
009195b3 *!T@
00919627 *!T@
009199bf *!T@
0091a21b *!T@
0091a293 *!T@
0091a57d #@9h
0091a6ef *!T@
0091a891 c@9H
0091aa43 *!T@
0091acaf T*	@
0091b235 #B9h
0091b3cf *!T@
0091b8ad #@9h
0091bb0b TiN@
0091bb5c iBA9
0091bb6b 6`.@
0091be33 TH#@
0091bec2 A))}J
0091c257 R!4<
0091c6b9 #@9(
0091c6d9 #@9(
0091c6f5 "@9h
0091ca11 c@9h
0091cb1b *!T@
0091ce4d CA9h
0091cec1 CA9h
0091ced2 @9H+
0091cf91 iy8)	
0091d50b *!T@
0091d58b *!T@
0091d60f *!T@
0091d8a3 Tpyj
0091d9d3 R!x9
0091dd6b R!< 
0091ddc1 "@9h
0091de67 *!T@
0091e6db Ti#@
0091e80d "@9h
0091e9fc /i,8/i08(
0091ee35 i`8_
0091ee75 i)8k
0091ef98 +i68+i*8
0091efb0 *iv8_
0091f020 ,iz8M
0091f03b q+i:8+i(8
0091f06c yi68yi)8
0091f1a1 j58h
0091f1f5 i)8h
0091f4cb *`kh
0091f631 i`8_
0091f671 i)8k
0091f79c *i68*i+8
0091f7b4 )iv8?
0091f898 +il8*i,8*i(8h
0091f8bb =*	@
0091f8fb Rji68ji)8
0091fc53 *)}@
00920071 *B)J}@
00920079 80.J	
0092014d >@y	=@y?
0092015b T	u@9
00920161 v@9?
0092016b T	q@9
00920171 r@9?
0092019f TvR@
0092029b SJ}@
00920531 C@9h
00920aa1 #@9h
00920baf *!T@
00921fdf TMA@
0092281f R!8<
009228d1 cA9h
00922c63 *!T@
009230f1 j/8-{/
00923259 j98h
009232b1 i.8l
009236ed i`8_
0092372d i)8k
00923855 j/8-{/
009239f0 1i(81i08
00923a03 T0ih8
00923a0f TPyh
00923a68  ia8"
00923a83 q1i!81i,8A
00923a8f TPy!
00923a9c /i(8
00923aac /i08
00923bad i`8_
00923bed i)8k
00923ce1 j:8l
00923d15 i.8l
00924368 	!@9
009243dd CA9h
00924501 cC9H
00924599 CA9H
00924cfd "@9h
00924d21 "@9h
00924dc0 h"@9h
009252f3 6`>@
0092538b 6($D
0092560b *!T@
009258af T(	@
00925991 j58h
009288bf *!T@
00928dd9 ji8JE@9_
00928e81 ji8JE@9_
00928fcd "@9h
009292ba A9JA
0092959b oZk@
009295aa @9IC
0092976f TtV@
00929a99 #@9h
00929d3d C@9h
0092a223 oH!@9J%A
0092a4b9 #B9h
0092a4d9 cE9(
0092a805 cA9H
0092a90d "@9h
0092b6f5 c@9h
0092b9d9 ji8JE@9_
0092ba81 ji8JE@9_
0092bc3d ki8JE@9_
0092bccd ki8JE@9_
0092bd5f =a"@
0092c0c0 kC@9l
0092c210 	A@9
0092c238 	A@9
0092c268 	A@9
0092c2d7 4`j@
0092c377 6`"@
0092c380 hB@9
0092c687 k$	@
0092c6ef rn&@
0092c71f k$	@
0092c759 &C)h*C)
0092cb91 j58t
0092cc15 j58t
0092ccbd j58h
0092cd45 j58h
0092cdf1 j58h
0092ce79 j58h
0092d187 *)#H
0092d44b RJ|`
0092d4d3 *!T@
0092d679 ji8JE@9_
0092d721 ji8JE@9_
0092d8e4 +ki8JE@9_
0092d974 +ki8JE@9_
0092d9f7 <a"@
0092dc41 @@9(
0092dc58 hB@9h
0092ddbc kC@9l
0092df0c 	A@9
0092df34 	A@9
0092df64 	A@9
0092e10c +ki8JE@9_
0092e19c +ki8JE@9_
0092e6a0 4LC)
0092e8c7 R!p'
0092e9ab T43@
0092ecdb T)yh
0092efdb *!T@
0092f0eb *!T@
0092f37f r+$D
0092f3d5 #A9h
0092f481 #A9h
0092f6bd c@9h
0092f849 #A9h
0092f8f4 _k88
0092fa51 -C)_
0092fc70 h"@9h
0092ff99 #@9h
0092ffed #@9(
009307ed #@9h
009308f5 #@9h
00930abf Thzh
00930b05 #@9h
00930b29 #@9h
00930be1 "@9h
00930c05 "@9h
00930cf9 C@9(
00930d19 C@9(
00930d34 h"@9h
00930eb7 oZk@
00930ec6 @9IC
00930f48 	!@9
00930f7c 	!@9
00931109 C@9h
009311e5 C@9H
00931205 C@9h
00931349 ji8JE@9_
009313f1 ji8JE@9_
009315ad ki8JE@9_
0093163d ki8JE@9_
009318f1 @@9h
00931910 hB@9h
00931954 hB@9
00931a98 kC@9l
00931be8 	A@9
00931c10 	A@9
00931c40 	A@9
00932581 js8(
00932ca1 ju8(
00933728 (a@9
0093372f 5(	@
00933859 AA9h
009339fc ?i(8
009342e8 ?i(8
0093448c ?i(8
009346c0 ?i(8
00934858 ?i(8
00934ad4 ?i(8
00934f84 ?i(8
0093511c ?i(8
00935528 ?i(8
0093571f 4h&@
0093578c ?i(8
0093579b Th"@
009357ab Rj*@
009357cb 4h&@
00935840 ?i(8
0093584f Th"@
0093585f Rj*@
009358db 4h&@
00935948 ?i(8
00935957 Th"@
00935967 Rj*@
00935987 4h&@
009359fc ?i(8
00935a0b Th"@
00935a1b Rj*@
00935aa3 T4	@yt
00935c97 TI	@yi4
00935caa @yu5
00935d8b TI	@y	
00935e1c kkhx
009360cd "@9h
00936219 ju8(
00936599 i+8h
00936ae7 Rln@
00936cb1 i`8_
00936cf1 i)8k
00936de5 j58h
00937094 *i88*i+8
009370ac )ix8?
0093715c +iv8*i68*i(8h
0093719c {i88{i)8
00937497 o)i@
009374a6 @9)A
00937521 CA9JA
009377a9 j58h
0093784b <I%@
00937a30 hb@9
00937a67 R)	T
00937db5 i`8_
00937df5 i)8k
00937e77 T-	@
00937e7f rn	@
00937f1f rN	@
0093808c *i68*i+8
009380a4 )iv8?
00938138 +i{8*i;8*i(8h
00938178 zi68zi)8
009382cb o{k@
0093856b o)i@
0093857a @9)A
009385dd CA9JA
009387b4 ?i(8
009387c3 Th&@
00938840 ?i(8
009388f0 ?i(8
009388ff Th&C
00938a3c J	@yk	@y
00938ae4 )	@y
00938b60 )	@y
00938b88 )	@y
00938bd8 )	@y
00938c78 J	@yk	@y
00938d50 )	@y
00938dc0 )	@y
00938e34 )	@y
00938e5c )	@y
00938eb0 )	@y
00938f2c +ih8J	
00938f70 J	@yk	@y)
009390bc )	@yJ	@y
0093910c )	@y
0093919c J	@yk	@y
00939220 J	@y	
00939228 )	@y
00939318 J	@yk	@y
00939390 J	@yk	@y
00939408 J	@yk	@y
00939504 J	@yk	@y
00939584 J	@yk	@y
009395fc J	@yk	@y
00939674 J	@yk	@y
009397b4 )	@yJ	@y)
00939828 )	@y
00939838 J	@y
009398f4 +ih8J	
0093992c J	@yk	@y)
00939a0c )	@yJ	@yI
00939a80 )	@y
00939a90 J	@y
00939c84 J	@yk	@y
00939d2c )	@y
00939da8 )	@y
00939dd0 )	@y
00939e20 )	@y
00939ec0 J	@yk	@y
00939f98 )	@y
0093a008 )	@y
0093a07c )	@y
0093a0a4 )	@y
0093a0f8 )	@y
0093a174 +ih8J	
0093a1b8 J	@yk	@y)
0093a304 )	@yJ	@y
0093a354 )	@y
0093a3e4 J	@yk	@y
0093a468 J	@y	
0093a470 )	@y
0093a560 J	@yk	@y
0093a5d8 J	@yk	@y
0093a650 J	@yk	@y
0093a74c J	@yk	@y
0093a7cc J	@yk	@y
0093a844 J	@yk	@y
0093a8bc J	@yk	@y
0093a9fc )	@yJ	@y)
0093aa70 )	@y
0093aa80 J	@y
0093ab3c +ih8J	
0093ab74 J	@yk	@y)
0093ac54 )	@yJ	@yI
0093acc8 )	@y
0093acd8 J	@y
0093ae68 ?i(8
0093aeec ?i(8
0093aefb Th&C
0093af1f Kj"@
0093af88 ,`@9	
0093afc3 r*$B
0093b07b rJ	@
0093b507 o)i@
0093b516 @9)A
0093b579 CA9JA
0093b8ab <H1@
0093bb23 <	0@
0093bcc5 cA9(
0093bce5 #@9h
0093bd25 cA9(
0093be39 cA9(
0093be59 cA9(
0093c13f *!T@
0093c291 FZ*:
0093c2ad B[*9
0093c350 \ky8{
0093c3b9 !@9E
0093c3f7 J ~	
0093c46b rmAKJi
0093c474 JAJJ
0093c480 )AIJJ}
0093c497 rk5KJJ5JJ
0093c4a1 5HJk}
0093c4a8 )5IJJ}
0093c4b8 kAKJJAJJ
0093c4c1 AHJK
0093c4c8 )AIJk
0093cc87 6`&@
0093d50e @MJA
0093d767 *!T@
0093da9b *!T@
0093db93 QkAC
0093dc03 R!p$
0093e108 	 @9
0093e121  @9	
0093e174 h"@9h
0093e330 +ih8J	
0093e4cc +ih8J	
0093e4df R	A@9)
0093e61f R	A@9)
0093e9a4 +ih8J	
0093eca3 *!T@
0093ed23 *!T@
0093f19b *!T@
0093f34f *!T@
0093f757 *!T@
0093f84f Th*@
0093f8a3 Th.@
0093f8f7 Th2@
0093fa97 *!T@
0093fdc9 "@9h
009401f5 #@9h
009403d5 #@9H
00941215 #@9h
00941acf T		@
00941d7f TJY	
00941e8b *!T@
00941f03 *!T@
00942863 T(		
009429dd j98h
00942b9d i`8_
00942bdd i)8k
00942cd9 j:8l
00942d19 i-8l	@
00942e87 RJ	C
00942f65 ia8"
00942f8b T-@	
009430d9 j58h
00943124 	i+8
0094312c 	i*8
00943143 7({v
0094339f T		@
00943519 i`8_
00943559 i)8k
0094367c *i68*i+8
00943694 )iv8?
00943760 -il8
0094377f q/i,8/i.8a
0094378b TIyv
009437a7 RKi68Ki)8
00943b4f *!T@
00943bcf *!T@
00943c6f *!T@
00943d0b *!T@
00943e03 *)q@
00944463 *!T@
009444e3 *!T@
00944583 *!T@
0094461f *!T@
00944717 *)M@
00944e68 	 @9
00944ef1 "@9h
009454e3 *!T@
009456f9 B@9h
00945759 B@9h
00945829 j88(
0094595d 80.	
00945b15 ji8JE@9_
00945ba1 ji8JE@9_
00945e33 Rln@
00945ffd i`8_
0094603d i)8k
00946164 *i88*i+8
0094617c )ix8?
0094622c +iv8*i68*i(8h
0094626c {i88{i)8
009465ef R!$,
00946649 cA9h
00946674 (#@9
00946709 cA9(
00946cf0 h"R9
00946ed5 q@9	
009471b8 	!@9
009473ab TI	@
009473b0 (a@9
009473b7 5(	@
009474f7 T`3@
00947807 6`&@
009478d5 B@9h
00947954 	a@9i
00947965 ju8(
00947ba3 Tmm@y
00947ccf RSKB
00947cdb 9h"@
00947e2d cB9h
00947f4b TH#A
00948212 @9kq}
00948218 (hh8*hi8)}@
0094863e @9kq}
00948644 (hh8*hi8)}@
00948a6a @9kq}
00948a70 (hh8*hi8)}@
00948e73 TH#A
00949029 cB9h
009492a1 #@9h
009492c5 #@9h
00949315 "@9h
00949470 h"@9h
009495cf Tl	@
00949613 Tl	@
009496b7 *!T@
00949bd8 	 R9
0094a327 Th+J
0094a4d6 @9kq}
0094a4dc (hh8*hi8)}@
0094a710 h"@9
0094a97e G9hG
0094a983 4h'C
0094ac5d cI9(
0094acaf 6sKB
0094adc8 H!@9J%A
0094ae6e @9kq}
0094ae74 (hh8*hi8)}@
0094b0e6 @9n^@
0094b277 Th_@
0094b42a @9kq}
0094b435 ji8)}@
0094b495 cE9h
0094b4f1 #F9h
0094b81d #F9h
0094b983 *!T@
0094ba03 *!T@
0094ba9f *!T@
0094bcc1 #F9h
0094c003 9h"R9i
0094c153 Tli@9
0094c15f Tlm@9
0094c1b0 Kk@9
0094c1bb TKo@9
0094c54d CA9H
0094cb0b *!T@
0094cddb *!T@
0094d05b *!T@
0094d56b R:KB
0094d8df 4H#@
0094da0d CC9h
0094db98 *is8
0094dbf0 *is8
0094dc59 CC9h
0094dc83 TH#@
0094dd80 hB@9
0094e033 TH#@
0094e285 CC9h
0094e2af TH#@
0094e2d5 CC9h
0094e485 #E9h
0094e7ea @9kq}
0094e7f0 (hh8*hi8)}@
0094ebe4 H#@9(
0094ee04 h"@9h
0094ee1e C9hL
0094ee36 W8(L
0094ef9c (#R9
0094f147 T /C
0094f1b3 6 _@
0094f678 *iv8
0094f8bf *!T@
0094f937 *!T@
0094fc44 *iu8
0094fcd8 *iu8
0094fe11 CA9h
0094fee3 *!T@
0094ffc0 	 Z9
009500d7 T)/@
00950881 ji8JE@9_
00950929 ji8JE@9_
00950cab Rm:@
00951025 i`8_
00951065 i)8k
00951244 	i+8	i*8
00951368 *i78*i+8
00951380 )iw8?
00951430 +il8*i,8*i(8h
00951480 yi78yi)8
00951940 h#@9
009519ad c@9h
00952075 ki8JE@9_
00952105 ki8JE@9_
0095216b Ra"@
00952424 hB@9h
00952580 kC@9l
009526d0 	A@9
009526f8 	A@9
00952728 	A@9
009529d5 ji8JE@9_
00952a7d ji8JE@9_
00952c39 ki8JE@9_
00952cc9 ki8JE@9_
00952d8b Ra"@
00953014 hB@9h
00953178 kC@9l
009532c8 	A@9
009532f0 	A@9
00953320 	A@9
00953823 =a"@
00953ac1 j58h
00953ddf =I	@
00953e45 "@9h
00953f0b Rln@
009540d5 i`8_
00954115 i)8k
00954234 *i78*i+8
0095424c )iw8?
009542fc ,ik8*i+8*i(8h
0095435c zi78zi)8
0095460f =I	@
00954675 "@9h
009547d5 kv8H
009549c4 oio8
00954b4b R	 	
009550a1 c@9H
0095511d c@9h
00955155 c@9h
009551fb Rln@
009553c5 i`8_
00955405 i)8k
009554f9 j58h
009557a4 *i88*i+8
009557bc )ix8?
0095586c +iv8*i68*i(8h
009558ac {i88{i)8
00955acc 0ip8
00955c61 i`8_
00955ca1 i)8k
00955e85 i*8/
00955fdc +i68+i*8
00955ff4 *iv8_
00956064 ,iz8M
0095607f q+i:8+i(8
009560b0 yi68yi)8
009562a8 ,4A)+,@y
009562b4 )T@9*P@9	
009564e7 =a"@
00956c51 i`8_
00956c91 i)8k
00956d8d j:8l
00956dcd i-8l	@
00956f3b RJ	C
00957019 ia8"
0095703f T-@	
009571a1 i`8_
009571e1 i)8k
00957309 j/8-{/
009574a4 @i)8@i18)
009574b7 TQii8?
0095751c Aib8C
00957530 @i"8?
00957537 q@i#8
0095754c Pi)8
00957554 Pi 8
009577f9 i`8_
00957839 i)8k
00957961 i/8,z/
00957b05 i/8)
00957b89 ia8"
00957ba5 i"8!
00957e45 i`8_
00957e85 i)8k
00958064 	i+8	i*8
009581a0 *i88*i+8
009581b8 )ix8?
00958268 +il8*i,8*i(8h
009582a8 zi88zi)8
009585ee A9JA
00958a6d ji8JE@9_
00958b15 ji8JE@9_
00958f2f <a"@
009593bd B@9h
00959541 ki8JE@9_
009595d1 ki8JE@9_
009598a4 hB@9h
00959a08 kC@9l
00959b58 	A@9
00959b80 	A@9
00959bb0 	A@9
00959ef9 "@9h
0095a06a A9JA
0095a28b TtV@
0095a9a1 ji8JE@9_
0095aa49 ji8JE@9_
0095acb1 ki8JE@9_
0095ad41 ki8JE@9_
0095ada7 Ra"@
0095aff1 @@9h
0095b010 hB@9h
0095b054 hB@9
0095b198 kC@9l
0095b2e8 	A@9
0095b310 	A@9
0095b340 	A@9
0095b4e1 ki8JE@9_
0095b571 ki8JE@9_
0095b5fb <a"@
0095b845 @@9h
0095b9a8 kC@9l
0095baf8 	A@9
0095bb20 	A@9
0095bb50 	A@9
0095bcd5 ji8JE@9_
0095bd7d ji8JE@9_
0095be7b T iu
0095bf53 *!T@
0095c34a @9kq}
0095c350 (hh8*hi8)}@
0095c92d "@9h
0095c9f7 *!T@
0095cae7 Rh"	
0095cb47 Rs"	
0095d493 *!T@
0095d507 *!T@
0095d58f *!T@
0095da07 *		@
0095dfa2 @9kq}
0095dfa8 (hh8*hi8)}@
0095e23c (AA9)-@
0095e4ab rhAA9I
0095e6e7 Rk	C
0095eafe @9kq}
0095eb04 (hh8*hi8)}@
0095ed63 8J	C
0095ef97 T{R@
0095f098 nin8
0095f943 TwR@
0095fdbe @9kq}
0095fdc4 (hh8*hi8)}@
0096019f *!T@
0096030b *!T@
0096040f *!T@
00960655 "@9h
009608f9 "@9h
00960a0b 9 !C
0096156b =hz@
00961593 Tin@
00961607 TiZ@
0096165b 6`B@
00961a0c /io8
00962016 @9kq}
0096201c (hh8*hi8)}@
00962399 CB9h
009623af 9)c@
00962471 CB9h
009624cc *is8
00962524 *is8
0096260b *!T@
009627e8 	iv8
00962834 	it8
009628b5 j58h
00962b30 *iu8
009630c6 @9?	
009633a3 *H%C
0096343d C@9h
009634f5 CA9h
009636ef *!T@
00963b99 #C9h
00963f8d #@9h
00964a8e @9?	
00964be9 #@9h
00964e69 #J9h
009655c9 CI9h
00965e84 iB@9h
00965eac iB@9h
00965f3d #C9h
00965fd1 CI9H
00966014 	`A9
00966098 iB@9
00966653 Tt.@
009666cb TtV@
0096684b *!T@
009669db *!T@
00966afb Tl	@
00966b3f Tl	@
00966bf7 *!T@
009670db *V}@
00967357 *		@
009673d3 *		@
009674f7 *!T@
00967e15 i`8_
00967e55 i)8k
00967f49 j:8l
00967f7d i.8l
0096836d #@9h
0096859b *!T@
00968e81 CE9JA
00968ee5 #C9(
00968f60 hB@9u
00969057 *!T@
009690e9 #C9h
00969125 #C9H
0096937b *		@
0096945b *!T@
009695cd C@9h
0096978d ji8JE@9_
00969835 ji8JE@9_
00969cb5 i`8_
00969cf5 i)8k
00969de9 j:8l
00969e1d i.8l
0096a1f9 i`8_
0096a239 i)8k
0096a32d j58h
0096a408 	i,8
0096a440 	i*8
0096a568 +i68+i*8
0096a580 *iv8_
0096a5f4 ,i{8m
0096a60f q+i;8+i(8
0096a643 Rji68ji)8'
0096a861 i`8_
0096a8a1 i)8k
0096abd9 ia8"
0096ad99 i`8_
0096add9 i)8k
0096aec9 j:8l
0096aef8 li.8li-8l
0096b125 iq8 
0096b155 i18l
0096b18d i18l
0096b283 TtV@
0096b3ab TtV@
0096b5d8 nin8
0096b62d i 8z.@
0096c157 Rh#)
0096c46f *!T@
0096c4e3 *!T@
0096c557 *!T@
0096c5cb *!T@
0096c647 *!T@
0096c6bf *!T@
0096c73b *!T@
0096d26b o(]@
0096d9af *!T@
0096dc1b *!T@
0096dd2f T9yh
0096dd6f TYyi
0096de03 T8yh
0096e19f *!T@
0096e2b7 *	)@
0096e3f7 *!T@
0096e4df T*)@
0096e54b T-	@
0096e553 rn	@
0096e74d i`8_
0096e78d i)8k
0096e881 j:8l
0096e8b5 i.8l
0096edfb TuZ@
0096fa68 (#@9
0096fbf4 (#@9
0096fddf T:yh
0096fe30 (#@9
0096fe97 R!X)
0097004f T:yh
009700a0 (#@9
00970137 T:yh
00970188 (#@9
00970213 Raim
0097035b R!X)
00970397 R!p*
00970683 TJo@
009709cf R!X)
009713a1 i`8_
009713e1 i)8k
009714d5 j58h
009715b4 *i,8
009715e8 *i+8
00971718 +i68+i*8
00971730 *iv8_
009717a4 ,i{8m
009717bf q+i;8+i(8
009717f3 Rji68ji)8'
00971c7d "@9H
00971f81 "@9h
00972433 oHq@
00973023 oHq@
0097312f oHq@
0097366b T(/@
00973677 T(+@
00974000 	@@9
00974575 i`8_
009745b5 i)8k
009746a9 j:8l
009746dd i.8l
00974a79 i`8_
00974ab9 i)8k
00974bad j:8l
00974be1 i.8l
00974fdb TvR@
00975097 Tt.@
00975425 CB9h
00975446 @9 !
00975549 cA9h
00975559 CB9h
0097557a @9 !
00975611 CB9h
00975761 CB9H
0097579d cA9(
009757ad CB9H
009757ed CB9(
0097586d CB9(
0097587d CB9h
009758e1  B9h
009758e7 6`N@
00975af1 @A9h
00975af7 6`2@
00975be3 Th"@
00975bf8 iB@9h
00975c44 +ih8J	
00975e3b =hb@9
00975eaf Th&D
00975f51 kh8)	
0097605b Ti"B
00976093 Th"@
009761f3 =hb@9
00976267 Th&D
00976321 yixJ	
00976343 Nhb@9
00976397 Nhb@9
00976437 Th&D
00976523 Th&D
009765df Nhb@9
0097666b Th&D
00976750 Lyixk	
00976d1b =hb@9
00976d8f Th&D
00976e3b =hb@9
009770a3 Th"@
009770cf ThBA9
00977104 hBA9
00977127 4hBA9
0097724b Th&D
009775e0 jkh8)	
00977a9b RiBB9hb
00977b43 RiBB9hb
00977b8d c@9h
00977e1d c@9H
009780fd c@9h
0097819d c@9h	
009781ae Z8(	
00978221 c@9H
00978265 c@9(
009782c5 c@9h
0097831d c@9h
00978571 CA9h
00978901 j58b
00978a35 c@9h
00978a59 CA9H
00978ac1 CA9H
00978b1d c@9h
00978bb9 kh8)	
0097916d c@9h
009793fd c@9H
009796dd c@9h
0097977d c@9h	
0097978e A9(	
00979801 c@9H
00979845 c@9(
009798a5 c@9h
009798fd c@9h
00979a68 Lii8k	
00979d37 rN	@
00979d7d !@9) @9
0097a24d #@9h
0097a66e _8`"
0097a7f7 Tvf@
0097a8e7 Tvf@
0097aa77 *)%5
0097aa90 +ih8J	
0097ab12 I9i:A
0097abaa I9i:A
0097abff R!D!
0097ac9a I9i:A
0097ad0a I9i:A
0097ad66 I9i:A
0097ae37 R!\+
0097ae6b qi:A
0097af56 @9iF
0097af78 j{hx
0097b086 @9iF
0097b0db R!`%
0097b467 R)5E
0097b476 @9iF
0097b48f R)5E
0097b49e @9iF
0097b501 ynx.
0097b525 yjx(
0097b56c Jyhx
0097b5ba I9i:A
0097b6cc Jyhx
0097b85d ynx.
0097b881 yjx(
0097b8c6 I9i:A
0097b930 Nynx.
0097b94b THykx(
0097b9fe I9i:A
0097bb23 6`:A
0097bc84 Jit8+kj8
0097bce1 ih8)	
0097bd55 i(8H
0097bde1 i*8(
0097bebb Rc4:
0097c22d CB9h
0097c279 CB9h
0097c30d CA9H
0097c54d ynx.
0097c569 yjx(
0097c6d5 5A)t
0097c813 *5|@
0097c85f K5|@
0097cc71 hm8_
0097d099 #@9h
0097d153 *!T@
0097d5c5 #@9h
0097dbf9 "@9h
0097dc1d "@9h
0097dd43 R! 4
0097de39 cA9k
0097e05d #@9h
0097e095 cA9h
0097e121 cI9h
0097e140 h"@9h
0097e6b7 *!T@
0097e8f9 cA9h
0097eb91 cA9(
0097ebe7 6 5@
0097ec0d CC9`
0097ec99 cA9(
0097ee9c h"@9h
0097eec0 h"@9h
0097eed9 #@9h
0097ef71 B@9H5
0097f00b R)i@
0097f2ff x`"@
0097f337 <`&@
0097f34f <)q@
0097f37b R)]#
0097f3a3 <`*@
0097f4cd cI9H
0097f50d cF9H
0097f54d cC9H
0097f5fd cC9h
0097f60d CB9h
0097f61c hbA9
0097f623 7hb@9(
0097f664 hb@9(
0097f6c1 CH9H
0097f741 CE9H
0097f7c1 CA9H
0097f825 CB9h
0097f875 cI9(
0097f8b5 cF9(
0097f8f5 cC9h
0097f915 cI9(
0097f945 CH9h
0097f995 cF9(
0097f9c5 CE9h
0097fa15 cC9(
0097fa55 CA9h
0097fadd CA9h
0097fe3d CC9h
0098003f T	/@
0098014f T*	@
0098093c hB@9h
0098099d C@9h
00980b25 `@9h
0098101d CI9h
00981221 "@9h
009812b4 I/@y
009812c2 A9IW@9
009812d2 A9IS@9
009815b1 CI9(
00981b14 *is8
00981c3b Rcd/
00981dc9 CI9h
00981efb =)9@
009820bf Rcd/
009822bf Rcd/
00982481 CI9h
009825e5 CI9(	
00982615 CI9h
009828f1 CI9h
009829aa @9)	@
00982bb6 @9)	@
00982d65 CI9h
00982dd5 "@9h
00982fb9 "@9h
00983139 CI9h
009831bb *!T@
0098323b *!T@
00983971 j98h
009839c9 i.8l
00983b9d j/8-{/
00983f12 @9kq}
00983f18 (hh8*hi8)}@
0098449b R!h:
00984867 Tk2@
00984914 ai"8
0098491c ai#8#
00984926 @8)A
00984ac5 C@9h
00984cd3 *!T@
009854bd i`8_
009854fd i)8k
009855f1 j:8l
00985625 i.8l
00985d75 "@9h
00986059 "@9h
00986f75 CA9h
0098703d CA9H
00987677 *!T@
00987713 *!T@
00987913 *!T@
00987bd5 #@9h
00987dbd #A9h
00987e65 #@9(
00987e85 #@9(
009880e9 c@9H
00988219 c@9(
00988239 c@9(
0098829f 5h*@
0098851b *!T@
0098859b *!T@
00988ded #A9(
00988e2d #@9h
00988ead #A9(
00988f21 #@9(
00988f41 #@9(
00989087 *!T@
00989123 *!T@
009892a9 cA9(
00989355 cA9H
00989429 cA9(
009894ad cA9h
009894c9 cA9(
00989589 cA9(
009896a1 cA9(
009896c1 cA9(
00989b65 #@9h
00989ed1 #A9H
0098a039 #A9(
0098a059 #A9(
0098a1ab Rx&@
0098a30f *!T@
0098a3a3 *!T@
0098aad3 *!T@
0098ab6f *!T@
0098ad1e [8(&
0098adfa \8h	
0098b6c5 #@9h
0098b869 c@9h
0098bb21 c@9(
0098bb41 c@9(
0098bea7 *!T@
0098bf3b *!T@
0098c325 #A9(
0098c365 #@9h
0098c3e5 #A9(
0098c485 #@9(
0098c4a5 #@9(
0098c6dd C@9h
0098d4fb o)i@
0098d50a @9)A
0098d589 CA9JA
0098d6ef o)i@
0098d6fe @9)A
0098d77d CA9JA
0098dd5b oZk@
0098e32f o)i@
0098e33e @9)A
0098e3bd CA9JA
0098e5db T	q@9
0098e815 q@9k
0098e833 9)q@9
0098e879 #O9(
0098e8f9 #O9(
0098eac8 +ih8J	
0098f6c1 #O9(
0098f6e1 #O9(
0098fea3 T++@
009903cf T++@
00990903 T++@
00990d40 	q@9
00990e39 CG9h
00990f87 4)#@
00991250 	q@9
009913eb *!T@
00991477 *!T@
009915d0 (hc8
009915dc (xcx
00991680 	q@9_#
009918fa A9h	
009918ff 4i#@
00991ebc 	q@9i
00992324 )q@9Jm1
00992a74 +yhxJ	
009930c1 #K9(
009930e1 #K9(
00994557 *!T@
00994733 *!T@
00994849 "@9h
009948c5 "@9h
00994ac3 R!P5
00994b25 CA9h
00994b7c h#@9h
00994bfb *!T@
00994d90 (#@9h
00994db4 (#@9h
00994ee9 "@9h
00994f44 (#@9h
00994fc7 *!T@
0099513c h"@9h
00995160 h"@9h
00995179 #@9h
0099590b *!T@
00995bff *!T@
00995ebf *!T@
009960f3 *!T@
0099633f *!T@
00996a1f =h>@
0099701e A))}J
00997083 5	/@
0099723b Rij	
00997ed7 *`kh
00998039 i`8_
00998079 i)8k
00998179 j58h
009981bc 	i+8l
009981c4 	i*8
009983b0 *i68*i+8
009983c8 )iv8?
009984a8 +il8*i,8*i(8h
009984eb Rji68ji)8
00998d00 	iv8
00998d4c 	it8
00998dcd j58h
009993ab *!T@
009995b7 *!T@
009997a7 *!T@
00999de0 ma@9k
0099a051 #@9(
0099a827 *)5.
0099a830 +ih8J	
0099ad13 oZk@
0099af6b Th&@
0099afa3 Tt"@
0099b08b T((@
0099b0ff T-	@
0099b107 rn	@
0099b5b5 #@9h
0099b76d C@9H
0099b955 #@9h
0099bb0d C@9H
0099bc13 8	 @
0099bca1 C@9H
0099bd63 8	 @
0099bdf1 C@9H
0099bf1d C@9h
0099c0c5 C@9h
0099c2e5 #@9h
0099c471 C@9H
0099c615 #@9h
0099c7cd C@9H
0099c9b5 #@9h
0099cb6d C@9H
0099cd55 #@9h
0099cee1 C@9H
0099cfd7 N!(a
0099d19d #@9h
0099d267 T	 @
0099d435 #@9h
0099d4ff T	 @
0099d6ac +ih8J	
0099d844 +ih8J	
0099dd9d cB9+}
0099def5 #A9H
0099e0d4 H#@9
0099e1d1 "@9h
0099e201 cB9h
0099e367 *!T@
0099e529 cB9h
0099e7b5 C@9(
0099e884 _k98
0099ea99 C@9h
0099eecd ij8)	
0099f2dd #@9h
0099f7ff T{"C)
0099fa0c +yhxJ	
0099fc97 6K	@
0099fcbb 4H'@
009a0085 "C)_
009a0099 "C)_
009a0278 ?k78V
009a02b4 Lii8k	
009a030d "@9h
009a0331 "@9h
009a03ad "@9h
009a03d1 "@9h
009a048d CA9h
009a04b9 "@9h
009a0559 "@9h
009a057d "@9h
009a05f5 "@9h
009a0619 "@9h
009a0775 CA9H
009a086c Lii8k	
009a0931 #@9h
009a13f0 Lii8k	
009a146f T"#@
009a151b T9;@
009a1ea3 T({s
009a1f1f R	y3
009a22ab *!T@
009a2323 *!T@
009a27c8 +ih8J	
009a2adb *!T@
009a30a4 (hc8
009a30c0 (xcx
009a3219 C@9h
009a3251 C@9h
009a327d C@9h
009a4589 #@9h
009a4cfd CA9JA
009a4e20 Hih8hi)8
009a4ec0 Hyhxhy)x
009a5847 RJ54
009a5981 C@9h
009a5ac3 TH,@
009a5b44 +ih8J	
009a5d8f TH,@
009a5e20 +ih8J	
009a60fb T-xl
009a64a1 "@9h
009a654b *!T@
009a6a63 6`Z@
009a6a83 6`>@
009a6ccb *!T@
009a6d6f *!T@
009a7493 T	!@
009a7541 CA9h
009a7c03 *!T@
009a7c99 C@9h
009a7f87 TU'@
009a8385 "@9h
009a83a9 "@9h
009a8710 h"@9h
009a894f R9#	
009a9121 "@9h
009a94cf *!T@
009a9547 *!T@
009a9a95 "@9h
009a9ab9 "@9h
009aa6cc ,ij8k	
009aa6dc KA@9
009aa7bd ii8J	
009aa7cc *A@9
009aa865 ii8J	
009aa874 *A@9
009aa8db T		@
009aae88 ,ij8k	
009aae98 KA@9
009ab589 ii8J	
009ab598 *A@9
009ab631 ii8J	
009ab640 *A@9
009abba1 ii8J	
009abbb0 *A@9*
009abc65 ii8J	
009abc74 *A@9
009abe51 ii8J	
009abe60 *A@9
009b01cf Th*@
009b0855 #A9h
009b08b1 c@9H
009b0955 c@9h
009b0985 #A9h
009b0ba2 @9K9
009b0c89 "@9h
009b0e2a @9l9
009b0efd "@9h
009b105c h"@9h
009b13cc ,ij8k	
009b13dc KA@9
009b155c ,ij8k	
009b156c KA@9
009b1851 #@9h
009b18c4 ,ij8k	
009b18d4 KA@9k
009b1bf5 yixJ	
009b1c04 *A@9*
009b1c9d yixJ	
009b1cac *A@9
009b1d19 D@9h
009b2795 #A9h
009b2e7d #A9(
009b2edd #A9(
009b386f RJ!,
009b3949 yixJ	
009b3958 *A@9
009b398a @9(M
009b39f1 yixJ	
009b3a00 *A@9jI
009b4af1 yixJ	
009b4b00 *A@9
009b4b32 @9(5
009b4b9d yixJ	
009b4bac *A@9J1
009b56a3 T*E@
009b5787 TKE@
009b5893 TLE@
009b59f8 ,yjxk	
009b5a08 KA@9
009b5a3a @9H&
009b5a6b T)	@
009b5ddd C@9h
009b6984 ,ij8k	
009b6994 KA@9
009b69f7 T)	@
009b9259 C@9h
009b93d9 C@9h
009b9635 CE9H
009b9675 CB9H
009b9709 #D9H
009b9789 #A9H
009b9891 cC9H
009b9911 c@9H
009bae25 C@9h
009bae85 #A9h
009baf2d C@9h
009baf59 #A9h
009bb091 CB9H
009bb125 #A9H
009bb1ed c@9H
009bb551 c@9h
009bb595 c@9h
009bb5b5 c@9h
009bc385 c@9h
009bc451 c@9H
009bc82d c@9h
009bc881 c@9h
009bc8e5 c@9H
009bd039 C@9h
009bd099 #A9h
009bd141 C@9h
009bd16d #A9h
009be8cd C@9h
009be92d #A9h
009be9dd C@9h
009bea09 #A9h
009bf00d #@9h
009bf061 #@9h
009bf401 C@9h
009bf461 #A9h
009bf509 C@9h
009bf535 #A9h
009bf7a1 #@9h
009bf7e9 #@9h
009bfb35 c@9h
009bfb79 c@9h
009bfb99 c@9h
009bfbfd c@9H
009bfe81 #H9h
009bfff9 cG9h
009c19e1 CB9h
009c1a81 cC9h
009c1ac9 #D9h
009c1b11 #A9h
009c1b49 CE9h
009c1c05 CF9h
009c1c9d #A9h
009c1d45 #D9(
009c1dcd CE9("
009c1de5 CE9h!
009c1e0e E9h 
009c1e75 CF9("
009c1e8d CF9h!
009c1eb6 F9h 
009c1f45 #A9h
009c20ad cC9h
009c2125 #D9h
009c220d CE9H
009c2321 cG9h
009c2361 #H9h
009c2409 CB9H
009c2469 cC9H
009c273f T*yz
009c27fb rN	@
009c282b k$	@
009c2ec5 c@9h
009c33dc ,ij8k	
009c33ec KA@9
009c3bf4 ,ij8k	
009c3c04 KA@9K
009c3eb0 ,ij8k	
009c3ec0 KA@9+
009c427f Th*@
009c46d8 ,ij8k	
009c46e8 KA@9
009c4978 ,ij8k	
009c4988 KA@9
009c5a04 ,ij8k	
009c5a14 KA@9
009c6101 ii8J	
009c6110 *A@9
009c61a9 ii8J	
009c61b8 *A@9
009c6229 #@9h
009c6289 #@9h
009c683c ,ij8k	
009c684c KA@9
009c6e38 ,ij8k	
009c6e48 KA@9
009c7894 ,ij8k	
009c78a4 KA@9
009c7a5d ii8J	
009c7a6c *A@9
009c7b05 ii8J	
009c7b14 *A@9j
009c7d1b TH}@
009c843c ,ij8k	
009c844c KA@9K
009c878b q9ih
009c922c ,ij8k	
009c923c KA@9
009c93b5 ii8J	
009c93c4 *A@9
009c945d ii8J	
009c946c *A@9J
009c9505 ii8J	
009c9514 *A@9
009c95ad ii8J	
009c95bc *A@9
009ca0bc ,ij8k	
009ca0cc KA@9
009cab49 #@9H
009cac05 CA9H
009caea9 CA9H
009caf0d cB9h
009cb144 ,ij8k	
009cb154 KA@9
009cb4d4 ,yjxk	
009cb4e4 KA@9
009cb516 @9H)
009cb523 R)}2
009cbe00 ,ij8k	
009cbe10 KA@9
009cc358 ,ij8k	
009cc368 KA@9
009cc8ac ,ij8k	
009cc8bc KA@9
009cd1d9 C@9h
009cd21d C@9h
009cd961 ii8J	
009cd970 *A@9J
009cda09 ii8J	
009cda18 *A@9
009cebc4 	A@9I
009cebeb Th*@
009ceee8 	A@9
009cef0f TH(@
009ceff3 Q	M9
009d0f7d #B9h
009d0fc5 cA9h
009d0ffd CC9h
009d10e5 #E9h
009d11bd cD9h
009d1215 #G9h
009d124d C@9h
009d1325 cD9h
009d13dd #G9( 
009d13e6 G9h 
009d1465 cA9h
009d14e5 #B9h
009d161d CC9H
009d166d cD9h
009d16ed #E9h
009d17dd #G9(
009d182d C@9h
009d18c5 cD9h
009d1ac8 ,ij8k	
009d1ad8 KA@9K
009d21b4 ,ij8k	
009d21c4 KA@9
009d2938 ,ij8k	
009d2948 KA@9
009d2b6d #@9h
009d2bc3 Thjz
009d2e81 #@9h
009d33c5 c@9h
009d3409 c@9(
009d3441 c@9h
009d41f9 c@9h
009d4251 c@9h
009d42b1 c@9h
009d4735 #@9h
009d47a8 ,ij8k	
009d47b8 KA@9k
009d4b71 #@9h
009d50bd #@9h
009d5175 #@9h
009d57a3 RB$!
009d5935 C@9h
009d5de7 R!<,
009d60d7 R!<,
009d63b7 R!<,
009d667f R!<,
009d68df R!<,
009d6cdf R!<,
009d6cf5 C@9h
009d6d55 #A9h
009d6df5 C@9(
009d6e05 #A9h
009d70bf R!<,
009d7387 R!<,
009d76c3 R!<,
009d7977 R!<,
009d7c43 R!<,
009d7f83 R!<,
009d8213 R!<,
009d8503 R!<,
009d87f7 R!<,
009d8af3 R!<,
009d8ddb R!<,
009d90c3 R!<,
009d94c7 R!<,
009d94dd C@9h
009d953d #A9h
009d95c9 C@9(
009d95d9 #A9h
009d987f R!<,
009d9c2c ,ij8k	
009d9c3c KA@9
009da8a4 ,ij8k	
009da8b4 KA@9
009dad08 ,ij8k	
009dad18 KA@9
009dc614 +ih8J	
009dc797 *_|	
009dc8ec ,ij8k	
009dc8fc KA@9
009e09d9 c@9h
009e0a1d c@9h
009e0a3d c@9h
009e0aa1 c@9H
009e49a9 c@9h
009e4a3d c@9h
009e4b97 =!	@
009e4e25 C@9h
009e4e7d C@9(
009e4e9d C@9(
009e4ebd C@9(
009e50f1 ii8J	
009e5100 *A@9
009e5199 ii8J	
009e51a8 *A@9J	
009e528f 7n<	
009e52bb 7D<	
009e549c ,ij8k	
009e54ac KA@9
009e5660 ,ij8k	
009e5670 KA@9
009e57bf 7";	
009e5823 7	;	
009e5908 ,ij8k	
009e5918 KA@9
009e594a @9h	
009e5be8 ,ij8k	
009e5bf8 KA@9k
009e5eb3 7e9	
009e5fd1 ii8J	
009e5fe0 *A@9
009e6079 ii8J	
009e6088 *A@9J	
009e64e0 ,yjxk	
009e64f0 KA@9
009e6522 @9h#
009e66cb 7_7	
009e66f7 757	
009e7144 ,ij8k	
009e7154 KA@9
009e7201 D@9H
009e720d #@9h
009e7291 #@9H
009e771c *kh8)	
009e772c 	A@9)
009e77ed C@9h
009e79eb 7x2	
009e7eef Th*@
009e8391 kh8)	
009e83a0 	A@9i
009e8785 ii8J	
009e8794 *A@9
009e882d ii8J	
009e883c *A@9
009e88ad #@9h
009e890d #@9h
009e8d4c ,ij8k	
009e8d5c KA@9
009e8e83 7q-	
009e9304 ,ij8k	
009e9314 KA@9
009e9429 D@9h
009ea5c0 +yhxJ	
009ea63f T!9h
009ead97 6	d@
009eada6 @9)	@
009eaecf 6	d@
009eaede @9)	@
009eaf03 T	 @
009eb007 6	d@
009eb016 @9)	@
009eb03b T	8@
009eb13f 6	d@
009eb14e @9)	@
009eb26f 6	d@
009eb27e @9)	@
009eb2a3 T	D@
009eb41d yixJ	
009eb42c *A@9*"
009eb4e5 ii8J	
009eb4f4 *A@9
009ec65d yixJ	
009ec66c *A@9
009ec705 yixJ	
009ec714 *A@9
009ec746 @9H'
009ec787 R)e,
009ec881 #@9h
009ec8a7 T;	@
009eca25 ii8J	
009eca34 *A@9*
009ecad5 D@9h
009ecf2d #@9h
009ed5d8 ib@9
009ed6d4 	A@9i
009edf07 4l)@
009edfa0 kA@9
009ee269 #<)@
009ee464 HC@9
009ee494 HC@9(
009ee4f9 A@9H	
009ee7bb q`	Iz!
009eeadb R!4$
009ef237 Th.@
009ef30c (WH9
009ef383 6K	@
009ef45b Th:@
009ef467 Ti"@
009ef48f 6K	@
009ef5d7 T ya
009ef667 *!T@
009ef8f7 T`Z@
009efb60 (cD9
009efed0 ?i(8
009eff8c ?i(8
009f0048 ?i(8
009f0134 ?i(8
009f0204 ?i(8
009f02c0 ?i(8
009f037c ?i(8
009f0434 ?i(8
009f04e8 ?i(8
009f059c ?i(8
009f0ebe @y?%
009f0eea @y?-
009f0f0e @y?-
009f0f36 @y?=
009f0f62 @y?A
009f0f8a @y?A
009f0f95 !@yJ
009f101a @y_e
009f1023 T)1@y
009f12a5 CJ9h
009f12e6 @y?u
009f1386 @y?m
009f1391 5@yH
009f150d CJ9h
009f155e @y?]
009f17d3 6YG@
009f1edb TL}~
009f2097 TlE@
009f21a3 TLE@
009f22d7 T(	@yH
009f2366 @y?%
009f243b T)	@y
009f2585 C@9H
009f2a23 Th:@
009f31d5 B@9h
009f3375 C@9h
009f39d1 #@9h
009f42b3 *!T@
009f4478 h"@9(
009f457c (C@9h
009f49ff R!P 
009f4af9 CB9(
009f4b4c HC@9h
009f4bf4 	A@9i
009f4cf4 hB@9
009f4deb *!T@
009f4e73 *!T@
009f4f13 *!T@
009f5027 *!T@
009f50c7 *!T@
009f5bc3 Th^A
009f5c81 CA9H
009f5caf 4jB	
009f5d1d CA9h
009f5f8d CA9H
009f631c hB@9t
009f6344 hB@9t
009f636c hB@9t
009f64ab *!T@
009f654b *!T@
009f69b5 B@9h
009f6ab4 *iu8
009f6d4b Th.A
009f6d8f Ti:A
009f6e97 Th:A
009f7727 T(yu
009f7773 y.1I
009f7aff T(yv
009f7b27 TJyk
009f865c (C@94
009f8e17 *!T@
009f92fc *ih8
009f9363 R+i(8
009f96d9 ji8)
009fb0c4 h#@9h
009fb0e8 h#@9h
009fb182 @9)(@
009fb1b4 H#@9h
009fb434 h"@9h
009fb72b *!T@
009fbc7d CE9H
009fbcbd CC9H
009fc0dd CE9H
009fc11d CC9H
009fc22c h"@9h
009fc3d7 4	)@
009fc3f5 ii8J	
009fc45f 4K)@
009fc59d CE9H 
009fc751 CD9H
009fc771 CB9H
009fc824 JA@9*
009fc8cb 4	)@
009fc987 4	)@
009fc9d1 CC9(-
009fcaa1 cG9h
009fcb27 4	)@
009fcb8b 4	)@
009fcbcc 	A@9
009fcc88 	A@9
009fcd44 	A@9
009fce52 R9%YB
009fcec1 CD9(
009fcef5 A@9H
009fcf54 h"@9h
009fcf7d cG9H
009fd174 hB@9t
009fd229 CE9H
009fd269 CC9H
009fd29a A9h-
009fd371 CC9H
009fd43d CE9H
009fd4d9 CB9H
009fd4e9 cA9H
009fd6dd CD9(
009fd799 CD9H
009fd8d1 `A9H
009fd92b 6`*@
009fdcac h"@9h
009fdcd0 h"@9h
009fdce9 C@9h
009fde88 *A@9
009fdebc *A@9
009fdf6b *!T@
009fe44f 4	)@
009fe498 	A@9I
009fe50f T+ih
009feb05 CF9H
009fedc0 	1D9I
009fedd2 B8++B
009fedd8 )c@9-
009feeb8 H3A9H
009ff20d cK9h
009ff278 hB@9t
009ff2a0 hB@9t
009ff2c8 hB@9t
009ff350 h"@9h
009ff760 h"@9h
009ff784 h"@9h
009ff79d #@9h
009ff8a4 	1D9i
009ff9bd #@9h
009ff9d5 #@9h
009ffc9b 6`*@
009ffec1 #@9h
009ffed9 #@9h
00a00551 bJ9h
00a0095d !I9h
00a00a98 (C@9H
00a00da1 cA9(
00a00ed9 bJ9(
00a010a4 hB@9t
00a010cc hB@9t
00a010f4 hB@9t
00a01698 h"@9h
00a01715 "@9h
00a01739 "@9h
00a01888 JQH9_
00a018b1 RH9h
00a01bb0 hB@9t
00a01c37 *!T@
00a01f6b *!T@
00a0200b 5hb@
00a02241 B@9h
00a025af *!T@
00a0262f *!T@
00a0275b 6	)\)?
00a027dd CA9h
00a028c1 CA9h
00a02975 CA9H
00a02acf *!T@
00a02ded CA9(
00a02e0d CA9(
00a030a5 #A9h
00a044cc ?i(8
00a045a4 ?i(8
00a04660 ?i(8
00a04718 ?i(8
00a047ec ?i(8
00a048a4 ?i(8
00a04960 ?i(8
00a04a1c ?i(8
00a04ad4 ?i(8
00a0506f R!p"
00a054eb k$	@
00a055db R!p"
00a058bb *!T@
00a05aeb TvBA
00a05b6b TvZA
00a05e07 *!T@
00a05e31 #@9(
00a05e91 #@9(
00a05f48 	TH9
00a061eb *!T@
00a0636b Tt6A
00a0639f TtBA
00a067a3 TtZB
00a0689b R!@5
00a06a25 cA9h
00a071f7 7tZB
00a072d0 hC@9
00a072ef R!@5
00a07355 cA9h
00a073e4 hC@9
00a0755f *!T@
00a075fb *!T@
00a07d70 (`@9
00a07de9 1D9(
00a07e7f *!T@
00a080e0 hB@9v
00a08108 hB@9v
00a081d3 *!T@
00a084e0 x_E)
00a084fb T(yw
00a08603 TwcE)
00a08748 hB@9t
00a08770 hB@9t
00a087ef *!T@
00a08867 *!T@
00a08c8b r-	@
00a08cbb k$	@
00a08da3 r-	@
00a08dd3 k$	@
00a095ad #B9h
00a09a14 hB@9
00a09c58 hB@9u
00a09cc8 hB@9u
00a09dbb *!T@
00a0a233 4h*A
00a0a27e @9H	
00a0a36b Rh"	9i*
00a0a417 *!T@
00a0aad5 B@9h
00a0ab80 *iu8
00a0ae9b R!D)
00a0b1fb T(	@y
00a0b41f R!\)
00a0b4d1 CB9h
00a0b7a9 CB9h
00a0b958 _k98
00a0b9be @y?-
00a0ba4b T(%@y
00a0baf6 @y_%
00a0bb64 		@y?5
00a0bc5e @y?-
00a0bde2 A9('
00a0bde9 CC9h'
00a0be0a @y_5
00a0be16 @y		
00a0be5c j	@y_
00a0bf3e @y?=
00a0c0d6 @y?E
00a0c0e1 !@y(
00a0c1f2 A9H	
00a0c24a @y?U
00a0c27b T)	@y
00a0c39d #D9h
00a0c461 CC9(
00a0c481 CC9(
00a0ce8c h"@9h
00a0ceb0 h"@9h
00a0cec9 #@9h
00a0d2f3 T`Z@
00a0d529 ki8JE@9_
00a0d5b9 ki8JE@9_
00a0d61f Ra"@
00a0d86f 4hB@9h
00a0d9d4 kC@9l
00a0db24 	A@9
00a0db4c 	A@9
00a0db7c 	A@9
00a0dd01 ji8JE@9_
00a0dda9 ji8JE@9_
00a0e1dc ?i(8
00a0e260 ?i(8
00a0e26f Th&C
00a0e293 Kj"@
00a0e2ef ThBA9
00a0e37c ?i(8
00a0e38b Ti"C
00a0e5a3 4h&@
00a0e610 ?i(8
00a0e61f Th"@
00a0e62f Rj*@
00a0e64f 4h&@
00a0e6c4 ?i(8
00a0e6d3 Th"@
00a0e6e3 Rj*@
00a0e7ef o)i@
00a0e7fe @9)A
00a0e882 A9JA
00a0e99f T-)@
00a0e9ab T--@
00a0ec97 R  	
00a0f0b7 TuZ@
00a0f0df TvV@
00a0f499 "@9h
00a0f4c0 h"@9h
00a0f87f TtV@
00a0fe57 o)i@
00a0fe66 @9)A
00a0fec9 CA9JA
00a10080 ?i(8
00a10104 ?i(8
00a10113 Th&C
00a10137 Kj"@
00a10200 ?i(8
00a10284 ?i(8
00a10293 Th&C
00a102b7 Kj"@
00a10380 ?i(8
00a10404 ?i(8
00a10413 Th&C
00a10437 Kj"@
00a10500 ?i(8
00a10584 ?i(8
00a10593 Th&C
00a105b7 Kj"@
00a10680 ?i(8
00a10704 ?i(8
00a10713 Th&C
00a10737 Kj"@
00a10800 ?i(8
00a10884 ?i(8
00a10893 Th&C
00a108b7 Kj"@
00a11087 TvR@
00a11227 TvV@
00a113f9 ji8JE@9_
00a114a1 ji8JE@9_
00a11c14 +ki8JE@9_
00a11ca4 +ki8JE@9_
00a11d1b Ra"@
00a11f6f 4hB@9h
00a120d4 kC@9l
00a12224 	A@9
00a1224c 	A@9
00a1227c 	A@9
00a1237b TtV@
00a124a7 o)i@
00a124b6 @9)A
00a12535 CA9JA
00a12945 ki8JE@9_
00a129d5 ki8JE@9_
00a12a43 Ra"@
00a12d1f TtV@
00a13001 ji8JE@9_
00a130a9 ji8JE@9_
00a13405 ki8JE@9_
00a13495 ki8JE@9_
00a13503 Ra"@
00a13757 4hB@9h
00a138bc kC@9l
00a13a0c 	A@9
00a13a34 	A@9
00a13a64 	A@9
00a13c05 ki8JE@9_
00a13c95 ki8JE@9_
00a1423d 80.	
00a143db T,	@
00a1447f T,	@
00a14787 Tm	@
00a14807 TV	@
00a14a99 ki8JE@9_
00a14b29 ki8JE@9_
00a14ba3 Ra"@
00a14e10 hB@9h
00a14f74 kC@9l
00a150c4 	A@9
00a150ec 	A@9
00a1511c 	A@9
00a152c4 +ki8JE@9_
00a15354 +ki8JE@9_
00a15741 ki8JE@9_
00a157d1 ki8JE@9_
00a15a8b 4hB@9h
00a15bf0 kC@9l
00a15d40 	A@9
00a15d68 	A@9
00a15d98 	A@9
00a15f1d ji8JE@9_
00a15fc5 ji8JE@9_
00a16d50 )(A)
00a16e93 R*$A)
00a16f13 Tk*@
00a16f1f Tj.@
00a1785c +ih8J	
00a17f90 +ih8J	
00a18517 T*,@
00a1858f Tl)@
00a1859f Tl-@
00a1865b TL)@
00a18667 TL-@
00a18767 TL)@
00a18773 TL-@
00a18925 ji8JE@9_
00a189cd ji8JE@9_
00a18b89 ki8JE@9_
00a18c19 ki8JE@9_
00a18c7f Ra"@
00a18ecf 4hB@9h
00a19034 kC@9l
00a19184 	A@9
00a191ac 	A@9
00a191dc 	A@9
00a19411 CA9JA
00a19a4f =a"@
00a19cd1 80.	
00a1a33d A@9H
00a1a775 ji8JE@9_
00a1a81d ji8JE@9_
00a1a9a3 T,	@
00a1aa63 T,	@
00a1ad3f T,	@
00a1adff T,	@
00a1b0f5 ji8JE@9_
00a1b19d ji8JE@9_
00a1b4c5 80.i
00a1b94d ki8JE@9_
00a1b9dd ki8JE@9_
00a1bf43 TtV@
00a1c58d i`8_
00a1c5cd i)8k
00a1c7ac 	i+8	i*8
00a1c8d0 *i78*i+8
00a1c8e8 )iw8?
00a1c998 +il8*i,8*i(8h
00a1c9e8 yi78yi)8
00a1ce01 ji8JE@9_
00a1cea9 ji8JE@9_
00a1d065 ki8JE@9_
00a1d0f5 ki8JE@9_
00a1d15b Ra"@
00a1d3ab 4hB@9h
00a1d510 kC@9l
00a1d660 	A@9
00a1d688 	A@9
00a1d6b8 	A@9
00a1d954 +ki8JE@9_
00a1d9e4 +ki8JE@9_
00a1decc +ki8JE@9_
00a1df5c +ki8JE@9_
00a1e43d ki8JE@9_
00a1e4cd ki8JE@9_
00a1e51f =		@
00a1ee2f *!T@
00a1f3d9 cB9h
00a1f593 43}@
00a1f61b 4(}@
00a1f800 *k48
00a1f8ec Ik88
00a1f940 	i+8	i*8
00a1fe19 CD9h
00a1ffcc *it8
00a2012f ohE@
00a203cc hB@9t
00a203f4 hB@9t
00a2042c *is8
00a20484 *is8
00a204a9 #C9h
00a205f7 *!T@
00a20659 #C9H+
00a20691 #C9h
00a20a74 *is8
00a2116b *>9	
00a21177 R!0#
00a211ab R!H5
00a21305 #@9h
00a214e5 #@9h
00a215cc 	a@9i
00a215dc hky8(
00a21671 #@9(
00a21739 #@9h
00a21901 j58h
00a21b61 j58h
00a21d97 Th6@
00a21f09 CB9h
00a2237b Th"@
00a22475 CB9h
00a2294d B@9h
00a22acb *!T@
00a22b8b *!T@
00a22f5d CB9H
00a2378d ji8JE@9_
00a23835 ji8JE@9_
00a239d5 ji8JE@9_
00a23a7d ji8JE@9_
00a23d97 Rln@
00a23f61 i`8_
00a23fa1 i)8k
00a240d0 *i88*i+8
00a240e8 )ix8?
00a24198 +iv8*i68*i(8h
00a241d8 |i88|i)8
00a24261 #@9?
00a243db Tt"@
00a2461b Tt"@
00a24c09 i`8_
00a24c49 i)8k
00a24dcc *i78*i+8
00a24de4 )iw8?
00a24e80 +il8*i,8*i(8h
00a24ec8 zi78zi)8
00a24eeb =J	@
00a25372 A9JA
00a256c3 *!T@
00a25a43 *!T@
00a25d07 r)!A
00a25df2 @9kq}
00a25df8 (hh8*hi8)}@
00a260d7 r)!A
00a261c2 @9kq}
00a261c8 (hh8*hi8)}@
00a2633f 4H/@
00a267d8 	a@9i
00a267e8 Hkx8(
00a268d4 	a@9i
00a268e4 hky8(
00a2699b Rln@
00a26b65 i`8_
00a26ba5 i)8k
00a26c99 j58h
00a26dce @9?}
00a26ed0 *i78*i+8
00a26ee8 )iw8?
00a26f98 ,ik8*i+8*i(8h
00a26fbb =*	@
00a26ffc zi78zi)8
00a27324 	a@9i
00a27334 Hkx8(
00a275b5 ki8JE@9_
00a27645 ki8JE@9_
00a27697 =		@
00a27d48 hB@9t
00a27d7c hB@9
00a27da0 hB@9t
00a280bd ki8JE@9_
00a2814d ki8JE@9_
00a28407 4hB@9h
00a2856c kC@9l
00a286bc 	A@9
00a286e4 	A@9
00a28714 	A@9
00a288fa @9	 @
00a28a90 ,ij8k	
00a293ef *!T@
00a29473 *!T@
00a294f9 #A9H
00a298d3 *	k@
00a29bb8 ?i(8
00a29c84 ?i(8
00a29d40 ?i(8
00a29e70 ?i(8
00a29ea8 ?i(8
00a2a50c ?i(8
00a2a5c8 ?i(8
00a2a67c ?i(8
00a2a78d yixJ	
00a2af94 ?i(8
00a2b050 ?i(8
00a2b118 ?i(8
00a2b16c ?i(8
00a2b224 ?i(8
00a2b2dc ?i(8
00a2b364 ?i(8
00a2b42f T`E@
00a2b67c ?i(8
00a2b734 ?i(8
00a2b7ec ?i(8
00a2b8b4 ?i(8
00a2b97c ?i(8
00a2b9ec ?i(8
00a2ba74 ?i(8
00a2bb2c ?i(8
00a2bbf4 ?i(8
00a2bd2c ?i(8
00a2bde4 ?i(8
00a2beac ?i(8
00a2bf94 ?i(8
00a2c050 ?i(8
00a2c11c ?i(8
00a2c180 ?i(8
00a2c23c ?i(8
00a2c308 ?i(8
00a2c563 T)	@y
00a2c5fa @y?%
00a2c70e @y?-
00a2c86e @y?-
00a2c8aa @y?=
00a2c912 @y_5
00a2cdd1 C@9h
00a2ce7d C@9h
00a2cf19 C@9(
00a2cf59 C@9(
00a2d225 CA9H
00a2d3bd CA9(
00a2d45d CA9(
00a2d50a @y?%
00a2d6d1 CA9H
00a2d98f T)	@y
00a2da26 @y?%
00a2da64 Lyixk	
00a2da7e @y_-
00a2daf2 @y_M
00a2dafb T)%@y
00a2dbb6 @y_5
00a2dbda @y?=
00a2dc26 @y_E
00a2dc2f T)!@yI1
00a2dcb6 @y?U
00a2ddce @y?]
00a2ddd9 -@yZ,
00a2deee @y?e
00a2def9 1@yw'
00a2e0a6 @y?m
00a2e7e9 C@9(
00a2eb0c ?i(8
00a2ebdb ThBA9
00a2ec1a 	K6	@
00a2ec68 ?i(8
00a2ec77 Ti"C
00a2edbb o)i@
00a2edca @9)A
00a2ee32 A9JA
00a2efbb Th.@
00a2f03f Th:@
00a2f313 6h"@
00a2f3f0 hB@9t
00a2f4c3 *!T@
00a2f4ed #@9(
00a2f54d #@9(
00a2fa13 *!T@
00a2fc73 *!T@
00a308ab *!T@
00a30a1b *!T@
00a30f67 T*-@
00a3102c ;[E)
00a311b3 T*)@
00a313ff T*)@
00a317c9 c@9h
00a31947 *!T@
00a3239b T*-@
00a325c7 *!T@
00a32b81 #@9h
00a33053 TiR@
00a330f3 R	y9
00a331b3 *!T@
00a335ef T*-@
00a33790 j"@9l
00a337f4 +hi8J%@9_
00a3381f 5j"B
00a33853 ThbA9j&F
00a33b48 h"@9
00a33bbd cA9h
00a33ecb TjFA
00a33f73 T	-@
00a346d7 Tt*@
00a348a1 ki8JE@9_
00a34931 ki8JE@9_
00a35d0b *!T@
00a35f13 *!T@
00a35f9f *!T@
00a3601f *!T@
00a366a7 Tk)@
00a369a9 j88h
00a36a8f Tvf@
00a36abf oI}I
00a375cb R`N@
00a37a4b Th:@
00a37c47 Tjr@
00a37ef0 hB@9t
00a380bc 	@@9
00a38170 *iu8
00a38224 *iu8
00a3833f 4(`(6
00a3846b T	#A
00a38617 T(#@
00a386f7 R!p9
00a38b17 Tjr@
00a38be9 CB9h
00a38df0 hB@9t
00a38e18 hB@9t
00a38e40 hB@9t
00a3930c 	@@9
00a39330 	@@9
00a39354 	@@9
00a39378 	@@9
00a39390 	@@9
00a393b4 	@@9	
00a393d0 *A@9
00a39574 	@@9	
00a396f0 h"@9h
00a39934 h"@9h
00a39958 h"@9h
00a399b1 #@9h
00a399e9 #@9h
00a39a01 #@9h
00a39b11 "@9h
00a39b35 "@9h
00a39b79 "@9h
00a39c78 h"@9h
00a39d4d "@9h
00a39d71 "@9h
00a39db4 h"@9h
00a39f05 "@9h
00a39f29 "@9h
00a39f6d "@9h
00a3a070 h"@9h
00a3a16d "@9h
00a3a191 "@9h
00a3a1d4 h"@9h
00a3a290 h"@9h
00a3a2f5 "@9h
00a3a319 "@9h
00a3a35d "@9h
00a3a3f5 "@9h
00a3a419 "@9h
00a3a45d "@9h
00a3a498 h"@9h
00a3a4fb *	%@
00a3a5c0 h"@9h
00a3a6d7 R-~	
00a3aa75 B@9)
00a3aa90 JA@9A
00a3abd4 ?i(8
00a3adb4 hB@9jF
00a3b0a8 ?i(8
00a3b164 ?i(8
00a3b224 ?i(8
00a3b2e4 ?i(8
00a3b3cc ?i(8
00a3b48c ?i(8
00a3b548 ?i(8
00a3b604 ?i(8
00a3b81a @y?]
00a3b825 -@y4
00a3b8a8 		@y?
00a3b8fc 		@y?
00a3b9da @y_%
00a3ba2e @y_-
00a3ba82 @y_5
00a3bad6 @y_E
00a3badf T)!@y	
00a3bb2a @y_U
00a3bb33 T))@y	
00a3bb5e @y?U
00a3bb9e @y?U
00a3bbe2 @y?=
00a3bc23 T)	@y
00a3bed0 hB@9t
00a3bef6 @y?M
00a3c089 CA9h
00a3c301 `@9h
00a3c36b 4h&@
00a3c3d8 ?i(8
00a3c3e7 Th"@
00a3c3f7 Rj*@
00a3c417 4h&@
00a3c48c ?i(8
00a3c49b Th"@
00a3c4ab Rj*@
00a3c580 ?i(8
00a3c604 ?i(8
00a3c613 Th&C
00a3c637 Kj"@
00a3c700 ?i(8
00a3c784 ?i(8
00a3c793 Th&C
00a3c7b7 Kj"@
00a3ccc9 i`8_
00a3cd09 i)8k
00a3cee8 	i+8	i*8
00a3d00c *i78*i+8
00a3d024 )iw8?
00a3d0d4 +il8*i,8*i(8h
00a3d124 yi78yi)8
00a3d4ec 	i+8	i*8
00a3d931 i`8_
00a3d971 i)8k
00a3da8c *i78*i+8
00a3daa4 )iw8?
00a3db54 +il8*i,8*i(8h
00a3dba4 yi78yi)8
00a3dffd ki8JE@9_
00a3e08d ki8JE@9_
00a3e0f3 Ra"@
00a3e5e1 ki8JE@9_
00a3e671 ki8JE@9_
00a3e6ef <a"@
00a3ea97 T{"E)
00a3ed0f T{"C)
00a3f057 *!T@
00a3f2e0 +ki8JE@9_
00a3f370 +ki8JE@9_
00a3f3f3 Ra"@
00a3f7cf TI/@
00a3f807 6H'E
00a3f961 C@9(
00a3fb41 C@9(
00a3fc07 6@/@
00a3fcc3 6@/@
00a3fdad j48T
00a3fe07 oZk@
00a3fe2d #@9h
00a40345 ji8J
00a404bf =ib@
00a404d7 =i6@
00a40537 Ti6@
00a4062c hB@9h
00a408ff R)!B
00a40e2c ?i(8
00a40fa4 ?i(8
00a411a0 ?i(8
00a41314 ?i(8
00a4155c ?i(8
00a41878 ?i(8
00a418fc ?i(8
00a41e0f TJ	@yJ
00a4200b =I	@
00a42099 CC9h
00a4233d CC9h
00a42418 jij8_
00a42438 jij8_
00a42467 T(!@y
00a42505 CC9H
00a42710 hB@9
00a42d07 4h&@
00a42d7c ?i(8
00a42d8b Th"@
00a42d9b Rj*@
00a42dbb 7hBA9
00a42df3 8i*B
00a42e36 @ykBA9iB@
00a42e6b 7h&@
00a42e8f 8i*B
00a42fab 4h&@
00a43018 ?i(8
00a43027 Th"@
00a43037 Rj*@
00a43057 4h&@
00a430cc ?i(8
00a430db Th"@
00a430eb Rj*@
00a4310b 4h&@
00a43180 ?i(8
00a4318f Th"@
00a4319f Rj*@
00a431fb Rd[	
00a432ff 4h&@
00a4336c ?i(8
00a4337b Th"@
00a4338b Rj*@
00a433ab 4h&@
00a43420 ?i(8
00a4342f Th"@
00a4343f Rj*@
00a437b8 J	@yk	@y
00a43860 )	@y
00a438dc )	@y
00a43904 )	@y
00a43954 )	@y
00a439f4 J	@yk	@y
00a43acc )	@y
00a43b3c )	@y
00a43bb0 )	@y
00a43bd8 )	@y
00a43c2c )	@y
00a43ca8 +ih8J	
00a43cec J	@yk	@y)
00a43e38 )	@yJ	@y
00a43e88 )	@y
00a43f18 J	@yk	@y
00a43f9c J	@y	
00a43fa4 )	@y
00a44094 J	@yk	@y
00a4410c J	@yk	@y
00a44184 J	@yk	@y
00a44280 J	@yk	@y
00a44300 J	@yk	@y
00a44378 J	@yk	@y
00a443f0 J	@yk	@y
00a44530 )	@yJ	@y)
00a445a4 )	@y
00a445b4 J	@y
00a44670 +ih8J	
00a446a8 J	@yk	@y)
00a44788 )	@yJ	@yI
00a447fc )	@y
00a4480c J	@y
00a4499c ?i(8
00a44a20 ?i(8
00a44a2f Th&C
00a44a53 Kj"@
00a44bb9 ji8JE@9_
00a44c61 ji8JE@9_
00a44e1d ki8JE@9_
00a44ead ki8JE@9_
00a44f13 Ra"@
00a45170 hB@9h
00a452d4 kC@9l
00a45424 	A@9
00a4544c 	A@9
00a4547c 	A@9
00a457a7 Tt.@
00a45985 ji8JE@9_
00a45a2d ji8JE@9_
00a45dd8 +ki8JE@9_
00a45e68 +ki8JE@9_
00a45eeb <a"@
00a4663a 	km!
00a46783 R!H"
00a46793 R!\!
00a468b3 o9k@
00a46eb5 c@9h
00a46f24 h"@9h
00a47221 j48b
00a4727c h"@9h
00a472a0 h"@9h
00a472f9 #@9h
00a47331 #@9h
00a47349 #@9h
00a47457 T	!@
00a47825 #@9h
00a479d9 #@9h
00a47f93 T*E@
00a48077 TKE@
00a48183 TLE@
00a483d3 Ti"A
00a48467 Ti"A
00a485d5 ji8JE@9_
00a4867d ji8JE@9_
00a48839 ki8JE@9_
00a488c9 ki8JE@9_
00a4892f Ra"@
00a48b7f 4hB@9h
00a48ce4 kC@9l
00a48e34 	A@9
00a48e5c 	A@9
00a48e8c 	A@9
00a49129 ji8JE@9_
00a491d1 ji8JE@9_
00a492db T,C	
00a499e3 TuZ@
00a49b9b TuZ@
00a49e71 ki8JE@9_
00a49f01 ki8JE@9_
00a4a80b 6Hy0
00a4a917 *!T@
00a4aacb *!T@
00a4b157 Tjkh8
00a4b367 Tpin8
00a4b60d iq8)i`8
00a4b630 )iq8
00a4b72b *!T@
00a4c4db *!T@
00a4cf3b T|z/
00a4cfb7 *!T@
00a4dd53 *!T@
00a4e7b3 T|z/
00a4e82f *!T@
00a4f663 T)|@
00a4f7cb T)|@
00a5047f Th2@
00a504eb TDyo
00a505fe @MKA
00a506ef Ti>@
00a5071b Tmyn
00a507df Tpyn
00a508a7 Tnyn
00a5099b Tlyn
00a509b7 Tiyn
00a509e3 Ti*@
00a50b0f Tk:@
00a50cbf NTAA
00a50d23 Tj8@
00a50e03 Tj8@
00a50e43 NQIA
00a50e67 NPEA
00a50e9f Tj8@
00a50f2b Tj8@
00a50f9f Tj8@
00a50ffb Tj8@
00a510ab TtT@
00a51aa3 N4M@
00a5224b Tj	@
00a5260b o"6@
00a52a63 Tj8@
00a52bf7 Ti(@
00a52d57 Ti(@
00a52e77 Ti(@
00a52f4f Ti,@
00a52f87 Nk}	
00a5303f T{D@
00a5408b 6I!@
00a540ab Rk}L
00a54963 R	v	
00a5786b Nu|	
00a579f3 <I4@
00a57c4f N	}	
00a57e9f Th	@
00a57faf ^B(c
00a57fba cnB(e
00a57fc3 ^B(c
00a582bb ^B(c
00a582c6 cnB(e
00a582cf ^B(c
00a583e3 Tbxn
00a58437 ^B(c
00a58442 cnB(e
00a5844b ^B(c
00a584eb oe<@
00a585a7 Tq|	
00a5888f R>f	
00a588b7 R4f	
00a58f1b ^!(b
00a58f26 bn!(d
00a58f2f ^!(b
00a5904f ^!(b
00a5905a bn!(d
00a59063 ^!(b
00a591af ^!(b
00a591ba bn!(d
00a591c3 ^!(b
00a59487 ^!(b
00a59492 bn!(d
00a5949b ^!(b
00a598cb R/b	
00a598f3 R%b	
00a59a07 oZk@
00a59d43 Th	@
00a59e07 T"ze
00a59ea7 ^B(c
00a59eb6 cnB(e
00a59ebf ^B(c
00a59fc2 @M"B
00a5a23f Tbxo
00a5a2a3 ^B(c
00a5a2b2 cnB(e
00a5a2bb ^B(c
00a5a34a bN"h
00a5a36b o%*@
00a5a4a3 ^B(c
00a5a4b2 enB(d
00a5a4bb ^B(c
00a5a803 Tl}	
00a5a87f RB^	
00a5a8a7 R8^	
00a5afd7 T@D@
00a5b0f7 T@D@
00a5b20b T*,B
00a5b2f3 ^!(b
00a5b302 bn!(d
00a5b30b ^!(b
00a5b8db R+Z	
00a5bc53 Tl}	
00a5bccf R.Y	
00a5bcf7 R$Y	
00a5c7cf Th2@
00a5c83b T@yo
00a5c982 @MKA
00a5ca5f T`ym
00a5cb67 Tj.@
00a5cc9f Tl>@
00a5d017 R\T	
00a5d357 1D)@
00a5d3a7 1$)@
00a5d448 jkh8
00a5d457 1$!H
00a5d6c7 *JA9
00a5da4b *!T@
00a5dafb *!T@
00a5dbb7 *!T@
00a5dbcb RoQ	
00a5dc5f *!T@
00a5dc73 REQ	
00a5dd07 *!T@
00a5dd97 *!T@
00a5de8f *!T@
00a5dedd cD9(
00a5df15 CC9(
00a5df39 #E9H
00a5e04d cD9h
00a5e209 CC9h
00a5e493 R=O	
00a5e72f 7hB@9H
00a5e754 hB@9
00a5ea59 #@9H
00a5f14f Tt.@
00a5f26b Tu^@
00a5f37f Tu^@
00a6005a <-'B?-
00a60157 Th  
00a6017b 4h  
00a61a50 9`@9	?
00a61a7c (d@9[
00a61bd3 RmA	
00a61c1b *!lA
00a61e4b *!lA
00a6271b *!lA
00a62aff *!lA
00a63270 c (.`
00a632f3 K!hi8
00a632f9 ji8!
00a633fd hm8chm8
00a63450 !hm8B
00a635d8 B ).c (.`
00a6365f K!hi8
00a63665 ji8!
00a63748 Ehv8D
00a63769 hm8chm8
00a637bc !hm8B
00a63cb0 B ).c (
00a63e20 Ehv8D
00a65553 Rnb@
00a655f3 4k&@
00a657ab T)	@
00a659f4 $hb8B
00a65a01 h#8c
00a65aee @9h}
00a6603d `A9(
00a6607f 6HcA9w
00a6615c HcA9w
00a66173 /JcA9
00a6618b qJW@
00a661c0 ICA9
00a6626c ICA9
00a66347 TJCA9K3D
00a66415 `A9(
00a66453 6hbA9
00a6645b /iV@
00a66484 hBA9
00a664f8 iBA9
00a66697 TI(@
00a66b8f R~-	
00a66ca1 d"N!d#N!
00a66cf9 d!Na
00a66f09 d"n!d#n!
00a66f61 d!na
00a66ff9 d!.a
00a67069 ix8kix8
00a670a4 Jix8
00a676df /Bxq
00a67a66 :Nz7
00a67abd kaNw
00a67ecb ^1*2
00a67ed7 ^1*4
00a67edf ^1*5
00a67eeb ^1*3
00a67ef7 ^1*4
00a6985f R	)A
00a699d8 6^@)1
00a69b69 BA)a
00a69b89 BA)ai*
00a69e60 ni-8
00a69e95 hc8_
00a69ea5 hj8_
00a69eb5 hk8_
00a69ec5 hl8_
00a69ed5 hm8_
00a69f99 j"8`
00a6a191 i18t
00a6a1b1 i&8]
00a6a8f7 T	|	
00a6bb3c  	@z	
00a6c237 NcD@
00a6c370 @	Bz
00a6c54f T	`@
00a6c7f3 6h&@
00a6c86b Tib@
00a6cba4 +ih8J	
00a6e46a 2NsV7O
00a6e607 r!("
00a6eb72 4NcT7O
00a6ec8a 4NcT7O
00a6ed3a 4NBT7O
00a6eda7 N!8=
00a6edba 4NBT7O
00a6ee07 <>.	
00a6ef76 4NBT7O
00a6efef T!	@
00a6f073 N!8=
00a6f086 4NBT7O
00a6f3e9 HaNfHaN
00a6f3f6 bNcH!
00a6f41f N1JA
00a6f46a !NcHa
00a6f476 bNcH!
00a6f4ca !NcHa
00a6f4d6 bNcH!
00a6f50a !NcHa
00a6f516 bNcH!
00a6f625 HaNfHaN
00a6f632 bNc(!.
00a6f65b N1JA
00a6f6a6 !NcHa
00a6f6b2 bNc(!.
00a6f706 !NcHa
00a6f712 bNc(!.
00a6f746 !NcHa
00a6f752 bNc(!.
00a6f7bb *` %
00a6f7ef ReL$
00a6f8b7 ReL$
00a6fb26 !OGV
00a6fb50 fJaN
00a6fb59 JaN2JaN
00a6fb79 H!N0J!N
00a6fbf2 !O'V
00a6fbfa !OfV
00a6fc0b N1Ja
00a6fd43 NV"%
00a6fe1b N1Ja
00a6fe2b NRJa
00a6fe34 qJaN
00a6fe41 JaN'
00a6fe5c 'J!NPJ!N
00a6fef6 !OrV
00a6ff07 NRJa
00a6ff15 HaN0JaNG
00a70462 !O&V
00a7055c #HaN`
00a70612 !OrV
00a7061b NRJa
00a70621 HaNG
00a7068b NbHa
00a70690 "HaN@
00a709a3 *` %
00a709d7 ReL$
00a70a9b ReL$
00a70c65  %.6
00a70d06 !OGV
00a70d30 fJaN
00a70d39 JaN2JaN
00a70d59 (!n0*!n
00a70d89  %.S
00a70dd2 !O'V
00a70dda !OfV
00a70deb N1Ja
00a70f01  &.4"%.1B
00a70f18 1"%.
00a70f23 NV"%.RB
00a70f40 R"%.
00a70ffb N1Ja
00a7100b NRJa
00a71014 qJaN
00a71021 JaN'
00a71039 *!.'*!nP*!n
00a71071 "%.1"&.
00a7107c R"%.
00a710d6 !OrV
00a710e7 NRJa
00a710f5 HaN0JaNG
00a71642 !O&V
00a71659 (!.&
00a7173c #HaN`
00a717bc 2"%.
00a717c1 "&.T
00a717f2 !OrV
00a717fb NRJa
00a71801 HaNG
00a7182d "&.%"%.
00a7186b NbHa
00a71870 "HaN@
00a71ba9  !.K
00a72015 (!nI
00a72721 H!NI
00a7424c iil8
00a747c2 #.ckh
00a74a08 iil8
00a74a6e #.ckh
00a74eea  nki
00a74ef6  ndi
00a74f1e &N.j
00a74f4e 5Nuj
00a74f9a 6N6k
00a74fce =N}k
00a74fe2  nDk
00a7500e *NJi
00a75190 eHaN
00a75197 =$HaN
00a751a7 N!(!.a(!n
00a753fe %N"j
00a75422 4Ntj
00a7545e 5N1k
00a75482 <N|k
00a7549a ;NXk
00a754b2 )NIi
00a7560e !NcHa
00a75618 #HaNEHaN
00a7562a bN!H!
00a75630 AH!N
00a75bbd K!N!K!N
00a75bc8 BK!NcK!N
00a763ad K!N!K!N
00a763b8 BK!NcK!NC
00a76b09 *!.!*!.B*!.c*!.
00a76b19 +!n!+!n
00a76b24 B+!nc+!n#
00a76e00 Ph`N
00a76e0c qh`N
00a76e14 Ri`N
00a76e20 si`N
00a76e84 Xh`N
00a76e90 yh`N
00a76e9c Zi`N
00a76ea8 {i`N
00a76ecd i`N)$@
00a76ee1 i`NB
00a76f1c Ph`N
00a76f28 qh`N
00a76f30 Ri`N
00a76f38 si`N%
00a76f79 i`N%
00a76f9c Xh`N
00a76fa4 yh`N
00a76fac Zi`N
00a76fb4 {i`N
00a7706c  HaNBHa
00a77074 bHaN
00a77088 @H!N
00a770e0 Ph`N
00a770ec qh`N
00a770f4 Ri`N
00a77100 si`N
00a77128 Xh`N
00a77130 yh`N
00a77138 Zi`N
00a77140 {i`N!
00a77155 i`N)
00a772a8 Ph`N
00a772b4 qh`N
00a772bc Ri`N
00a772c8 si`N
00a7732c Xh`N
00a77338 yh`N
00a77344 Zi`N
00a77350 {i`N
00a77375 i`N)$@
00a773d8 Ph`N
00a773e4 qh`N
00a773ec Ri`N
00a773f4 si`N%
00a77435 i`N%
00a77458 Xh`N
00a77460 yh`N
00a77468 Zi`N
00a77470 {i`N
00a7752c  HaNBHa
00a77534 bHaN
00a77545 (!.@(!n
00a775a8 Ph`N
00a775b4 qh`N
00a775bc Ri`N
00a775c8 si`N
00a775f0 Xh`N
00a775f8 yh`N
00a77600 Zi`N
00a77608 {i`N!
00a7761d i`N)
00a77716 $NDi
00a77786 $NDi
00a77796 &Nfi
00a777c6 lN!p
00a777f2 &Nfi
00a778a3 N p@L
00a77926 $NDi
00a77932 &N p@Lfi
00a77acc 8KaNzKaN
00a77af0 0JaNrJaN
00a77b2c XK!N
00a77b3c PJ!N
00a77b9b Nfie
00a77c52 lN!p
00a77cdb N p@
00a77ce3 NDie
00a77ceb Nfie
00a77e14 8KaN
00a77e24 0JaN
00a77f4a (nDi
00a77fca (nDi
00a77fda &Nfi
00a77fe2 (n p
00a78012 lN!p
00a7803e &Nfi
00a78107 N p@L
00a78196 (nDi
00a781a2 &N p@Lfi
00a78354 8KaNzKaN
00a78378 0JaNrJaN
00a783b1 +!.X+!n
00a783c1 *!.P*!n
00a7842b Nfie
00a7847e (.fie
00a784de (. p
00a78502 lN!p
00a785a3 N p@
00a785ab NDie
00a785b3 Nfie
00a7860a (.fie
00a786fc 8KaN
00a7870c 0JaN
00a7885a %n.p
00a788aa %n*p
00a788ce 7N+p
00a788fa {N6k
00a78912 }N.p
00a7892e %n/p
00a7895a 7NTk
00a789c2 zNuj
00a78a98 0JaNrJaN
00a78aa1 HaN(IaN
00a78ab9 *!.P*!n
00a78ac5 )!nph
00a78c3e 3N*p
00a78c62 7N+p
00a78c8e {N6k
00a78ca6 }N.p
00a78cb2 ~N/p
00a78cde 7NTk
00a78d36 zNuj
00a78e04 0JaNrJaN
00a78e0d HaN(IaN
00a78e28 PJ!N
00a78e31 I!Nph
00a79b8b 6Dx@L
00a79bcf 6Dx@
00a79ebb 6Dx@L
00a79edf 6Dx@
00a7a09f 6Dx@L
00a7a0b3 6Dx@
00a7a19a  N$ 
00a7a1a2  N%$
00a7a1aa  N&(
00a7a1b2  N',
00a7a1ba  N$0
00a7a1c2  N%4
00a7a1ca  N&8
00a7a1d2  N'<
00a7a202  NRL
00a7a20a  NTT
00a7a212  NV\
00a7a376 (6PD
00a7a38a  6Xd
00a7a579 ip81i08
00a7a7cd e@93
00a7a844 ki@9`
00a7ae37 <!( n h`nJ
00a7ae96 1n%8
00a7aeb1 ( nd( n'
00a7aebd h`n%8
00a7aecd ( n"( n%
00a7aedd h`n@h`nH
00a7af6f =!( n h`n
00a7b0b3 /$D@
00a7b0c6 (.!(!
00a7b0df nB(!
00a7b157 <!( n h`nJ
00a7b1c1 ( nd( n'
00a7b1cd h`n%8
00a7b1dd ( n"( n%
00a7b1ed h`n@h`n
00a7b26f =!( n h`n(
00a7b438 !( . h`.
00a7b49c !( . h`.
00a7b50c !( . h`.
00a7b54a 1n"( n!
00a7b553 <@h`n(
00a7b62a (.!(!
00a7b6a0 !( . h`.
00a7b6dc "( n!
00a7b6e3 <@h`nH
00a7b743 =!( n h`n
00a7bd07 qJA@9
00a7c231 a@9*
00a7c26b <!( n h`nJ
00a7c2ca 1n%8
00a7c2e5 ( nd( n'
00a7c2f1 h`n%8
00a7c301 ( n"( n%
00a7c311 h`n@h`nH
00a7c3a3 =!( n h`n
00a7c4e7 /$D@
00a7c4fa (.!(!
00a7c513 nB(!
00a7c58b <!( n h`nJ
00a7c5f5 ( nd( n'
00a7c601 h`n%8
00a7c611 ( n"( n%
00a7c621 h`n@h`n
00a7c6a3 =!( n h`n(
00a7c878 !( . h`.
00a7c8dc !( . h`.
00a7c94c !( . h`.
00a7c98e 1n"( n!
00a7c997 <@h`n(
00a7ca6e (.!(!
00a7cae4 !( . h`.
00a7cb20 "( n!
00a7cb27 <@h`nH
00a7cb87 =!( n h`n
00a7d6d3 TN|	
00a7d703 TM|	
00a7d711 j)8)
00a7d7c7 TM0	
00a7d7ff TJ0	
00a7d811 j)8)
00a7d8a3 TL,	
00a7d8db TJ,	
00a7da35 j)8)
00a7da4b R+hj8
00a7da6f R+hj8
00a7da93 R+hj8
00a7dac0 !( N
00a7dac8 B( N
00a7dad0 !(`Nc( NB(`N
00a7dadd ( Nc(`N!
00a7dae9 (`Nb
00a7dc05 ib8l!
00a7dd1c fhg8
00a7dd25 h38s
00a7df1d a@9,a
00a7e3b8 #j`N
00a7e457 TqD@
00a7e4b2 @8qC
00a7e689 ( N#j`N
00a7e734 #j`N
00a7e73d h`NH
00a7e7d3 TqD@
00a7e82e @8qC
00a7e9eb =d( NE( N
00a7ea52 2nd( NE( N
00a7ea65 h`Nh
00a7eacc B( Nc( N@h`Nah`N
00a7eb1c "( N
00a7eb23 <@h`NH
00a7eb83 =!( N h`Nr
00a7ec82 2nD( Ne( N
00a7ecda 2n"( N
00a7ece3 <@h`N(
00a7ed46 2n"( N
00a7ed4f =@h`N
00a7fabc #j`N
00a7fb5b TqD@
00a7fd8d ( N#j`N
00a7fe38 #j`N
00a7fe41 h`NH
00a7fed7 TqD@
00a800ef =d( NE( N
00a80156 2nd( NE( N
00a80169 h`Nh
00a801d0 B( Nc( N@h`Nah`N
00a80220 "( N
00a80227 <@h`NH
00a80287 =!( N h`Nr
00a80386 2nD( Ne( N
00a803de 2n"( N
00a803e7 <@h`N(
00a8044a 2n"( N
00a80453 =@h`N
00a80ac5 (Bo!
00a80ad9 (Co p
00a80ae0 0 R/1 Ro2(R/3(Ro
00a80af3 /4 S/5 So6(S/7(So!p
00a80b1d (bo!
00a80b35 (co p
00a80b3c 0 r/1 ro2(r/3(ro
00a80b54 4 s/5 so6(s/7(so
00a80b6d  boJ
00a80b79 (bo!
00a80b8d (coK	
00a80b94 0 r/1 ro2(r/3(ro4 s/5 sol	
00a80bb0 6(s/7(so
00a80c77 6@x@LAy@Lby@L
00a80cbb 6@x@
00a80da9 (Bo!
00a80db4 0 R/1 Ro2(R/3(Ro
00a80de1 (bo!
00a80df0 0 r/1 ro2(r/3(ro
00a80e0d  boJ
00a80e19 (bo!
00a80e1f /0 r/1 ro2(r/3(ro
00a80ea7 6@x@LAy@L
00a80ecb 6@x@
00a80f61  Bo!
00a80f6c 0 R/1 Ro
00a80f89  bo!
00a80f98 0 r/1 ro
00a80fad  bo!
00a80fb3 /0 r/1 ro
00a8100f 6@x@L
00a81023 6@x@
00a8109b O%$}m
00a810a7 O&(~m
00a8110d i`Nc
00a8117d i`N,
00a8119c %$}mn
00a811a4 &(~mo
00a811d9 x@LL
00a811fd i`N,
00a812e4 @x@LAy@Lby@L
00a81373 6@x@
00a81465 k`N<
00a814d5 k`N<
00a8156c @x@LAy@L
00a815cb 6@x@
00a8167d j`N'l
00a816f4 @x@L
00a8173b 6@x@
00a817b3 O%$}m
00a817bf O&(~m
00a8182d i`Nc
00a8189d i`N,
00a818bc %$}mn
00a818c4 &(~mo
00a818d1 i`N!
00a81919 i`N,
00a81a85 k`N<
00a81ab9 k`N!
00a81af1 k`N<
00a81c01 j`N'l
00a81db3 N$* n
00a81dc0 g* n
00a81dc9 h`nD* n
00a81de1 * n%* n
00a81df3 Nf( nAj`n
00a81e11 h`nh
00a81ed0 c( n
00a81ed5 ( nah`n
00a8208b <cip
00a82140 c( n
00a8214c ah`n
00a82205 h`nE8
00a8220f N`h`n
00a82215 ( n"( n
00a82224 `h`n@h`n
00a82294 !( . h`.
00a82313 =!( n h`n(
00a82382 @8	!
00a8238a @8	1
00a823a4 "( n
00a823ab <@h`n
00a825a8 "( .
00a825b0 @h`.
00a825f0 "( n
00a825f7 <@h`nH
00a82663 <"( n
00a8266b =@h`n
00a82972  ne8
00a82985 ( nf( n
00a82af4 )e@9
00a82b60 ki@9
00a82d15 e@9c
00a82dc5 e@9*
00a82e75 ( n%
00a82ef1 ( n%
00a82f9a @8 "
00a82fa2 @8 B
00a82faa @8 b
00a82fd6  ne8
00a82fe9 ( nf( n$
00a83fa7 6@x@LAy@Lby@L
00a83fb9 x@Lex@L
00a8402b 6@x@
00a8435b 6@x@LAy@Lby@L
00a8439f 6@x@
00a8455b 6@x@LAy@L
00a8457f 6@x@
00a846ab 6@x@L
00a846bf 6@x@
00a84807 N$* N
00a84814 g* N
00a8481d h`ND* N
00a84835 * N%* N
00a84847 Nf( NAj`N
00a84865 h`Nh
00a84924 c( N
00a84929 ( Nah`N
00a84adf <cip
00a84b94 c( N
00a84ba0 ah`N
00a84c59 h`NE8
00a84c63 N`h`N
00a84c69 ( N"( N
00a84c78 `h`N@h`N
00a84d67 =!( N h`N(
00a84dd6 @8	!
00a84dde @8	1
00a84df8 "( N
00a84dff <@h`N
00a85044 "( N
00a8504b <@h`NH
00a850b7 <"( N
00a850bf =@h`N
00a85251 ( Nf( N
00a85261 h`NH
00a852cd ( Nf( N
00a852dd h`N	
00a853b5 ( Nf( N
00a85588 qj@9Ja
00a85863 Nd8BNbxBN
00a8586d ( NE( N$	
00a85878 ah`N
00a8587d h`NH
00a858d7 Nd8BNbxBN
00a858e1 ( NE( N$	
00a858ec ah`N
00a85982 @8 "
00a8598a @8 B
00a85992 @8 b
00a859c5 xBNd( NE( N#	
00a85df0 ij@9
00a865c7 NA8@N@x@N
00a865e8 !( N
00a865f5 ( N1h`ND8
00a8660d xBNd( NE( N
00a86625 h`Nh
00a8666f T"ia
00a8669f NA8CNBxCN
00a866d7 o!( NB( N
00a866e3 n1h`NPh`Nd8
00a866f9 x@Nd( N
00a86817 Nb8ANaxAN
00a86834 B( N
00a8683f n!( NRh`Ne8
00a8684f N'h`N
00a8685d ( Nf( N
00a86871 h`Nd
00a86e9b 6@x@LAy@Lby@L
00a86ead x@Lex@L
00a86f1f 6@x@
00a8724f 6@x@LAy@Lby@L
00a87293 6@x@
00a8744f 6@x@LAy@L
00a87473 6@x@
00a8759f 6@x@L
00a875b3 6@x@
00a8819b qIy(
00a885ef 6`f@
00a88673 6`*@
00a88c15 "@9h
00a88cf6 @9v"
00a89018 	i|8?
00a89191 CB9H
00a891cd #@9h
00a89275 cA9H
00a8932d #@9u
00a89585 #@9h
00a896b9 cA9H
00a89823 *!T@
00a898c0 	`@9
00a89a89 `@9h
00a89dcf Tt"@
00a89f0b R	L@
00a8a139 @@9H
00a8a22b *!T@
00a8a35b *!T@
00a8a485 c1)uB
00a8a545 B@9h
00a8a7c5 C@9h
00a8a887 7hB@9
00a8a89c hB@9h
00a8a9ac hB@9
00a8a9f5 B@9h
00a8aa4c 	@@9
00a8abf9 c@9h
00a8af0b R!,?
00a8b1ec hB@9
00a8b235 B@9h
00a8b3a5 ki8JE@9_
00a8b435 ki8JE@9_
00a8b4ab Ra"@
00a8bbc1 "@9h
00a8bc67 *!T@
00a8bd3c h"@9h
00a8bde5 j68u
00a8be29 j68u
00a8be39 "@9h
00a8bee3 *!T@
00a8c11d #@9h	
00a8c1b1 #@9h
00a8c22c 	!@9
00a8c693 o{k@
00a8c6f7 R!D$
00a8c7fd c@9h
00a8c94f *!T@
00a8ca3d c@9(
00a8ccb7 R!X?
00a8cf47 *!T@
00a8d0f3 o)i@
00a8d21e B9Ha
00a8d637 *!T@
00a8d7e3 *!T@
00a8d8d3 q(C@
00a8df65 `A9(
00a8df8b 4`&@
00a8e0ce @9(	
00a8e6eb *!T@
00a8e80b *!T@
00a8e8ef 4a"@
00a8ea44 H(@m
00a8ec6f T  c
00a8ec77 Ta@`
00a8ecfb *!T@
00a8f7d1  @9H
00a8fb5d  @9(
00a8fc5f rt2@
00a8fc7f Th.@
00a8fca3 Ti2@
00a8fe75  @9(
00a8ffdd  @9(
00a90370 h"@9h
00a903fc h"@9h
00a9047f 5h"@9h
00a90723 *!T@
00a90892 @9H!
00a9091d  @9(
00a90a8c h"@9h
00a90b18 h"@9h
00a90ba4 h"@9h
00a90e6b *!T@
00a90f95  @9(
00a910d5 "@9(
00a91a55  @9H
00a921cd  @9H
00a9222b 4i>@
00a92477 Th.@
00a9249b Ti2@
00a926c9 "@9H
00a927cb 6h:@
00a92843 )J}@
00a92857 6h:@
00a92936 C9?	
00a92c25 "@9H
00a92de5 "@9h
00a93353 3zB@
00a93ca9  @9(
00a940d9  @9(
00a948e4 (ih8
00a94a51 c@9h
00a94a9d c@9h
00a94c4d j(8d
00a94f77 *!T@
00a959f9 C@9(
00a95a39 C@9(
00a95bd1 j48a
00a95be9 C@9h
00a96025 #@9H
00a96139 #@9h
00a96434 ?k78
00a96451 c@9h
00a96639 CA9H
00a9674d CA9(
00a9676d CA9(
00a96ad5 #@9h
00a96b55 #@9h
00a96b8d #@9h
00a96d29 #@9h
00a96d61 #@9h
00a96d79 #@9h
00a96e91 #@9(
00a96ef1 #@9(
00a96f29 #@9h
00a96f61 #@9h
00a970f5 #@9h
00a97159 #@9H
00a9719d #@9h
00a97e9d cA9h
00a97f1d CB9(
00a97f9d CB9(
00a97fd5 cA9H
00a9815f R!X;
00a98745 #@9h
00a98a69 cA9h
00a98b11 cA9h
00a98f78 ?i(8
00a99030 ?i(8
00a990e8 ?i(8
00a991d8 H@@9
00a99204 (A@9
00a99418 (C@9
00a994a7 *(+@
00a996cc ?i(8
00a997ac ?i(8
00a9991c ?i(8
00a99a83 T)	@y
00a99b1a @y?%
00a99c69 CA9H
00a99d79 CA9(
00a99d99 CA9(
00a99e18 J	@y
00a99e85 jj8_
00a9a03e \8H	
00a9a3b6 Z8(0
00a9a405 	@yh
00a9a526 Z8H'
00a9a575 	@yh
00a9a5ae @yi%
00a9a72b T+	@y
00a9a811 C@9(
00a9a871 C@9(
00a9a944 _k98
00a9aa81 CA9h
00a9aab1 CA9h
00a9ae74 		@y?
00a9af10 ?k88
00a9af60 		@y?
00a9afd4 		@y?
00a9b463 4h&@
00a9b4d0 ?i(8
00a9b4df Th"@
00a9b4ef Rj*@
00a9b577 RJ]B
00a9b5d3 4h&@
00a9b658 ?i(8
00a9b667 Th"@
00a9b677 Rj*@
00a9b6ef 4h&@
00a9b75c ?i(8
00a9b76b Th"@
00a9b77b Rj*@
00a9b79b 4h&@
00a9b810 ?i(8
00a9b81f Th"@
00a9b82f Rj*@
00a9b8b7 4h&@
00a9b92c ?i(8
00a9b93b Th"@
00a9b94b Rj*@
00a9b968 hBA9
00a9b977 4h&@
00a9b997 8i*B
00a9badc ?i(8
00a9bb60 ?i(8
00a9bb6f Th&C
00a9bb93 Kj"@
00a9bc03 4h&@
00a9bc70 ?i(8
00a9bc7f Th"@
00a9bc8f Rj*@
00a9bd8f o{k@
00a9c4f7 RI 	
00a9c50b RI 	
00a9c5cb Ri 	
00a9c5df Ri 	
00a9c6d3 RI 	
00a9c6e7 RI 	
00a9cc96 (*"	(
00a9d1bd `E9	
00a9d1d4 Lii8k	
00a9d5c3 T	@ 
00a9d5ef T !)
00a9d73c h!@9`
00a9d744 j%@9
00a9d78d [@)u
00a9d977 T !(
00a9dacb Th&C)
00a9dc40 hbE9yb
00a9dce0 i*D)(
00a9dcf8 m"C)
00a9dd17 Qi1	
00a9dd36 	Kk&
00a9dd3f )	C)
00a9dd73 ThB@
00a9de02 B9j&@
00a9de2c ka@9
00a9de4b TcZ@
00a9defb *d*@
00a9e32d Y`x 
00a9e65c jEJ*I}	
00a9e679 AHJvnB
00a9e68d 5HJw
00a9e90a 	J)M
00a9e970 jEJ*H}
00a9ea7f Th&A
00a9eb2b Th&A
00a9eb6b Th:@
00a9eeb7 T(  
00a9eed3 T  !
00a9eeeb TH  
00a9ef07 T@ "
00a9efd0 Ie@9
00a9eff0 Ie@9
00a9f4c4 *C@9,
00a9f518 !C@9
00a9f56c )G@91
00a9f5b7 6*c@9
00a9f61c #c@9
00a9f660 !c@9
00a9f6d6 Axj!
00a9fc05 #h)?
00a9fce3 T(  
00a9fcff T  !
00a9fd17 TH  
00a9fd33 T@ "
00a9fdec Ie@9
00a9fe0c Ie@9
00aa019b T(  
00aa01b7 T  !
00aa01d5 #C9J
00aa0290 Ie@9
00aa02b0 Ie@9
00aa02c4 Ie@9
00aa02cf TH	@
00aa05df T(@ 
00aa05eb T	@ 
00aa0695 W6))g@9
00aa06ac )g@9
00aa06c0 )g@9
00aa06d4 )g@9
00aa06df T A 
00aa0a38 hbE9
00aa0ab8 h&D)m:C)
00aa0af0 l>E)z
00aa0b60 +yhxJ	
00aa0b6c j"C)i.@
00aa0b83 Tx&@
00aa0bd4 h&C)k2@
00aa0e3b RkB@
00aa110f R)Q9
00aa1123 R)17
00aa1297 Rk!;
00aa141b Rk1>
00aa19d3 T(  
00aa19ef T  !
00aa1a07 TH  
00aa1a23 T@ "
00aa221b T(  
00aa2237 T  !
00aa224f TH  
00aa226b T@ "
00aa2291 #C9h
00aa24b3 T  !
00aa24e8 hih8
00aa250f T"@!
00aa2ca8 	(C)
00aa2daa R9jVD
00aa2fa3 RJ!;
00aa3013 RJ1>
00aa30fd XD)	
00aa3191 cB9j.C
00aa31b1 cB9j.C
00aa31c7 RfB@
00aa31cd cB9j.C
00aa3a63 R	)	
00aa3ac7 T  !
00aa3aef T"@!
00aa3d77 =jB@
00aa3d87 *l.C
00aa3ef3 RJQ9
00aa42d9 CB9[
00aa42e1 #B9h
00aa442f T  !
00aa4680 hbE9
00aa4686 A9y^
00aa46e0 h&C)
00aa4703 Ti&@
00aa4758 k2D)
00aa4784 h&C)@
00aa478c m*E)
00aa4a91 E@9G
00aa4da7 RfN@
00aa4e86 Y9J}	
00aa5487 *J1.
00aa57bf T(  
00aa57e3 T  !
00aa5c33 R)A3
00aa5d9d ]IKj}
00aa5de3 9)]HK
00aa5f07 9)]HK
00aa5f3f R)]HK
00aa5f77 9)]HK
00aa5faf R)]HK
00aa5ff7 yh}@
00aa620b 9Dh#
00aa6253 qc@'
00aa6293 9Dh#
00aa62db qc@'
00aa6319 ]IK+Y
00aa6369 ]IK+Y
00aa657a LQ)M
00aa659f *K-	
00aa67df RJIA9
00aa6903 y)Q	
00aa69aa LQ)M
00aa69cf *K-	
00aa70cf rJQ?
00aa70de Zx	Y
00aa7393 *)aB
00aa75bd CWx	q
00aa7bad {Cy	]
00aa7c05 kCyk
00aa7c3e 1yl	
00aa7c86 LQ)M
00aa7ca1 yixk	
00aa7de1 ii8J	
00aa7e52 XQ)	
00aa7f2f *K-	
00aa8442 Byl	
00aa847a 09i	
00aa89b7 yk1%
00aa8a29 KAyK)
00aa8a75 +Ayl
00aa8b15 [@yj
00aa8b96 99	?
00aa8bae :9	C
00aa8bbd c<9	
00aa8bd9 C=9	K
00aa9345 (D)o|
00aa93cf T)~`
00aa94af T	~`
00aa954b T	~`
00aa9b2e D)my
00aa9f16 C)	8@
00aaa4ea !.)m
00aabbb1 j>8)
00aac0d8 ^k|8
00aac733 T]}	
00aac807 8Ak.8
00aac882 @9n}	
00aacb0d k08!
00aad2da @9k}	
00aad755 %@8Oxo
00aad7b2 	*k!
00aad7be 	Kk}`
00aad7e6 @8Mxm
00aadb5b Ti,@
00aadf92 }n}h
00aae12b Ti,@
00aae47f Tm9@
00aae85e $Ndj
00aae99a 2NkA
00aaee7f Tl4A
00aaf023 TN=A
00aaf816 !Ncd
00aaf826 "NPf
00aaf87a $Ncd
00ab020e 0nsn
00ab02d2 $Ncd
00ab04b6 @m*9@9+=@9%
00ab04e3 NI,@
00ab0581 ^Em?=
00ab0589 F@mv
00ab05b9 FGmR
00ab05c9 R@mQ
00ab05f1 b@ms
00ab0615 b@m6
00ab0645 f@mv
00ab0659 ^@m8
00ab0661 fLmR
00ab068e uNRN
00ab06bf NRJa
00ab06c8 rJaN0JaNQ
00ab06d6 eN1J!
00ab06dd J!N0f&N
00ab07ce tNT3@
00ab0830 0JaN
00ab08f8 !	@m
00ab0900 *9@9+=@9#
00ab0b24 #@Dm
00ab0b38 1HFm
00ab0b50 4XHm
00ab0bba Emj-@m
00ab0bc4  xGm
00ab0bcc i	@m
00ab0bfc {}@mK
00ab0c48  TOm
00ab0c55 ;Rm@
00ab0c5c hy@mk
00ab0c64 4<Nm
00ab0c84 !4Pmg
00ab0c8c c	@m
00ab0c98 ;PSm
00ab0cac d)@m
00ab0cb4 +8Rm
00ab0cc0 ,lUm
00ab0cd8 t1@m'
00ab0ce4 - Wm
00ab0cec !$Tm
00ab0d00 am@mk
00ab0d08 *,VmC
00ab0d10 >0Ym
00ab0d18 b}@m!
00ab0d24 >$Xm
00ab0dd6 tN0L[md
00ab0de0 qI@m
00ab0e26 pN!@
00ab0e7f NcHa
00ab0e91 HaN"HaN`
00ab0ea4  H!N
00ab103e eNEI@
00ab1076 bNBY@
00ab109a dNDQ@
00ab10d6 bNBy@
00ab11d8  HaN
00ab1694 dHaN
00ab169a bNBH!
00ab185c dHaN
00ab1862 bNBH!
00ab18b6 @M*=
00ab18e9 P@m)!
00ab190c P"HOs
00ab1928 p"XOR
00ab193d TCmQ"h
00ab1944 P"hO
00ab1951 PDms
00ab1964 p"xO
00ab1975 TEmQ*H
00ab197c P*HO
00ab1989 PFms
00ab199c p*XO
00ab19ad TGmQ*h
00ab19b4 P*hOg*h
00ab19c0 f*hO
00ab19d0 P*xOg*x
00ab19d8 f*xOh
00ab1a17 N1Ja
00ab1a25 HaN&
00ab1a5d P@m?
00ab1a7c P"HOg"H
00ab1a84 f"HOa
00ab1a95 LAm?
00ab1aa8 P"XOg"X
00ab1ab0 f"XO
00ab1ab9 LBm?
00ab1acc P"hOg"h
00ab1ad4 f"hO
00ab1aed LCm?
00ab1b00 P"xOg"x
00ab1b08 f"xO
00ab1b11 LDm?
00ab1b24 P*HOg*H
00ab1b2c f*HO
00ab1b45 LEm?
00ab1b58 P*XOg*X
00ab1b60 f*XOC
00ab1b7c P*hOg*h
00ab1b84 f*hO
00ab1bf6 @Ml=
00ab1c60 P"HOs
00ab1c7c p"XOR
00ab1c91 TCmQ"h
00ab1c98 P"hO
00ab1ca5 PDms
00ab1cb8 p"xO
00ab1cc9 TEmQ*H
00ab1cd0 P*HO
00ab1cdd PFms
00ab1cf0 p*XO
00ab1d01 TGmQ*h
00ab1d08 P*hOg*h
00ab1d14 f*hO
00ab1d24 P*xOg*x
00ab1d2c f*xOh
00ab1d60 P"HOg"H
00ab1d68 f"HOa
00ab1d8c P"XOg"X
00ab1d94 f"XO
00ab1db0 P"hOg"h
00ab1db8 f"hO
00ab1de4 P"xOg"x
00ab1dec f"xO
00ab1e08 P*HOg*H
00ab1e10 f*HO
00ab1e3c P*XOg*X
00ab1e44 f*XOC
00ab1e60 P*hOg*h
00ab1e68 f*hO
00ab1eab N1Ja
00ab1eb9 HaN&
00ab1f7b N2L@m
00ab1f84 TT@m
00ab1f90 6`Am
00ab1fa0 WdAm
00ab206c TJaN
00ab2071 JaNuJaN
00ab208a eNRJ!
00ab2099 J!NRf0Nsf0NRn1Nsn1NrL
00ab20ff N1Ja
00ab2105 JaN0
00ab21b3 N1H@m
00ab21c0 4XAm
00ab224f N1Ja
00ab2268 qJaNVJaN
00ab2275 KaN1
00ab2286 cN1J!
00ab2290 qJ!N
00ab2295 J!N1f'NRf'N1n0NRn0NqH
00ab2378 C0#NF0$
00ab2380 D0$N
00ab23bc eH!N
00ab23c1 H!NE
00ab23ee aNcH!
00ab2484 d0$Ng0%
00ab248c e0%N
00ab24ed H!NF
00ab2542 `NcT
00ab2630 UJaNtJaN
00ab263e eNRJ!
00ab2644 rJ!NRf0NRn1Nr
00ab2682 qNQN
00ab269b N1Ja
00ab26a1 HaN&
00ab27a4 TJaNuJaN
00ab27b2 eNRJ!
00ab27b8 rJ!NRf0NRn1Nr
00ab27ee cN1N
00ab2807 N1Ja
00ab280d HaN&
00ab287e @mB!A
00ab2956 &.'hl
00ab295e 0.0jl
00ab2a92 0.0hv
00ab2a9a '.ghv
00ab2aa2 0.pjv
00ab2bee &.ghn
00ab2bf6 0.0hn
00ab2bfe '.'jn
00ab2d36 @m !A
00ab2e76 '.'jt
00ab2e7e 0.pjt
00ab3042 @m*I
00ab3073 NI(@
00ab320c rMBm?
00ab3236 0.qUCm
00ab324e snSid
00ab3262 qnwIDm
00ab328e wns]Em
00ab329e rnrkd
00ab32ba snuMFm
00ab32ca wn7kd
00ab32d2 5.Vkd
00ab32e6 unrUGm
00ab3312 rnwIHm
00ab333e wns]Im
00ab334e rnrjd
00ab336a snuMJm
00ab3382 5.6jd
00ab3396 unrUKm
00ab33c2 rnwILm
00ab33ee wns]Mm
00ab3416 snsq@
00ab343e bnPF
00ab345c 0JaN
00ab3524 qMBm0
00ab3530 5" .v
00ab354b /s" .
00ab355c wUCmQ
00ab3575 " .R
00ab3588 u]Dmq
00ab35a1 " .s
00ab35b8 wUEm
00ab35e4 v]FmQ
00ab35fd " .R
00ab3610 wYGmq
00ab3629 " .s
00ab363c v]Hm
00ab3668 wYImQ
00ab3681 " .R
00ab3694 v]Jmq
00ab36ad " .s
00ab36c0 wYKm
00ab36ec v]LmQ
00ab3705 " .R
00ab3718 wYMmq
00ab3731 " .s
00ab373e wNrq@
00ab3748 R" .
00ab3756 rN1V
00ab376f N1Ja
00ab3775 JaN0
00ab37f6 @m*I@9+M@9!
00ab382f NI,@
00ab38cd VDm?=
00ab38d5 N@mv
00ab38e1 ^@mT
00ab3931 fFmR
00ab395d bGmR
00ab3989 bHmR
00ab39b5 bImR
00ab39e1 bJmR
00ab3a0d bKmR
00ab3a9b NRJa
00ab3aa4 rJaN
00ab3aa9 JaNR
00ab3ab2 gNR*!.r*!nRf0nRn1n
00ab3b4d "!.6
00ab3b7f /9#!.4
00ab3b9d "!.6
00ab3bb9 "!.8
00ab3bd3 /9#!.4
00ab3bf1 "!.6
00ab3c09 "!.8
00ab3c32 tNsV
00ab3c4b NsJa
00ab3c50 SJaNr
00ab3c56 gNR*!.Rf$.Rn%.
00ab3fde &.gin
00ab3fe6 0.Pin
00ab3fee '.'in
00ab40d0 dHaN
00ab40d6 bNB(!.@d .
00ab41ae '.Pin
00ab41b6 1.qin
00ab4298 dHaN
00ab429e bNB(!.@d .
00ab42f2 @M*M
00ab42ff N&	@
00ab432d T@m)!
00ab4349 XAmr"H
00ab4350 q"HO
00ab4365 "!.s"!.
00ab4381 XCmr"h
00ab4388 q"hO
00ab439d "!.s"!.
00ab43b9 XEmr*H
00ab43c0 q*HO
00ab43d5 "!.s"!.
00ab43ed *XOr*h
00ab43f4 q*hO
00ab4409 "!.s"!.
00ab4415 *xOp*x
00ab441c g*xOh
00ab445b NRJa
00ab4464 2JaN
00ab4469 HaNG
00ab44a1 T@m?
00ab44b9 "!.r"H
00ab44c0 q"HO
00ab44c9 "HOa
00ab44d9 PAm?
00ab44e0 s"!.
00ab44e5 "!.r"X
00ab44ec q"XO
00ab44fd PBm?
00ab4504 s"!.
00ab4509 "!.r"h
00ab4510 q"hO
00ab4531 PCm?
00ab4538 s"!.
00ab453d "!.r"x
00ab4544 q"xO
00ab4555 PDm?
00ab455c s"!.
00ab4561 "!.r*H
00ab4568 q*HO
00ab4589 PEm?
00ab4590 s"!.
00ab4595 "!.r*X
00ab459c q*XO
00ab45a5 *XOC
00ab45b4 s"!.
00ab45b9 "!.r*h
00ab45c0 q*hO
00ab463a @MlM
00ab4647 Nf	@
00ab46a5 XAmr"H
00ab46ac q"HO
00ab46c1 "!.s"!.
00ab46dd XCmr"h
00ab46e4 q"hO
00ab46f9 "!.s"!.
00ab4715 XEmr*H
00ab471c q*HO
00ab4731 "!.s"!.
00ab4749 *XOr*h
00ab4750 q*hO
00ab4765 "!.s"!.
00ab4771 *xOp*x
00ab4778 g*xOh
00ab47a5 "!.r"H
00ab47ac q"HO
00ab47b5 "HOa
00ab47cc s"!.
00ab47d1 "!.r"X
00ab47d8 q"XO
00ab47f0 s"!.
00ab47f5 "!.r"h
00ab47fc q"hO
00ab4824 s"!.
00ab4829 "!.r"x
00ab4830 q"xO
00ab4848 s"!.
00ab484d "!.r*H
00ab4854 q*HO
00ab487c s"!.
00ab4881 "!.r*X
00ab4888 q*XO
00ab4891 *XOC
00ab48a0 s"!.
00ab48a5 "!.r*h
00ab48ac q*hO
00ab48f7 NRJa
00ab4900 2JaN
00ab4905 HaNG
00ab49c7 N2L@m
00ab49d0 TT@m
00ab49d8 R" .6`Am
00ab49e1 "!.!
00ab49e8 s" .WdAm
00ab49f1 " .Z
00ab4a09 # .{
00ab4a2c 9#!.S
00ab4ab8 TJaN
00ab4abd JaNuJaN
00ab4ad6 eNR*!.s*!.
00ab4ae5 *!nRf0nsf0nRn1nsn1nrL
00ab4b1d " .1"!.
00ab4b4b N1Ja
00ab4b51 JaN0
00ab4bff N1H@m
00ab4c0c 4XAm
00ab4c18 1" .
00ab4c20 R" .
00ab4c29 " .8
00ab4c9b N1Ja
00ab4cb4 qJaNVJaN
00ab4cc1 KaN1
00ab4cd2 cN1*!.R*!.q*!n
00ab4ce1 *!n1f'nRf'n1n0nRn0nqH
00ab4dc0 E0#.C0#nF0$.D0$n
00ab4e05 (!.e(!n
00ab4e0d (!nE
00ab4e2c C0#.cT
00ab4e3a aNc(!.C
00ab4e54 B0#.BT
00ab4ecc f0$.d0$ng0%.e0%n
00ab4f39 (!nF
00ab4f58 d0$.
00ab4f71 (!.D
00ab4f88 c0$.d
00ab4f8e `NcT
00ab5024 R"!.s"!.
00ab5031 "".V
00ab507c UJaNtJaN
00ab508a eNR*!.r*!nRf0nRn1nr
00ab50c1  !.1"".
00ab50ce qNQN
00ab50e7 N1Ja
00ab50ed HaN&
00ab51a0 R"!.s"!.T
00ab51f0 TJaNuJaN
00ab51fe eNR*!.r*!nRf0nRn1nr
00ab523a cN1N
00ab5253 N1Ja
00ab5259 HaN&
00ab52ba @}I(@
00ab52fb lB $
00ab5349 V+O1V+O
00ab5357 OD A
00ab5364 R AO
00ab536d  AOt A
00ab5374 p AO
00ab5381 T+OCV+OdV+O&V+O
00ab539f NBXCN
00ab53a5 XFNB
00ab5409 T+OB
00ab5418 f AO
00ab542f NbXDNB
00ab549b Oe A
00ab54a0 f AO
00ab54bb N XCN
00ab552b Tl4A
00ab55db <Bd#N
00ab55ed f1NBd#N
00ab55f5 d%NBd&Nbd"NBd!NBl N
00ab565f =Bd#N
00ab5673 =Bd&Nf
00ab567d d%Ncd'N
00ab5689 d#NBd%Nbd"NBd!NBl N
00ab56cf TN=A
00ab576f <Bd#N
00ab5781 f1NBd#N
00ab5789 d%NBd&Nbd"NBd!NBl N
00ab57ef =Bd#Ne
00ab5803 =Bd&N
00ab580d d%Ncd'N
00ab5819 d#NBd%Nbd"NBd!NBl N
00ab58c9 d#N&
00ab58d1 d#N!
00ab58e9 l"ND
00ab58f1 l"NF
00ab5976 @}I(@
00ab59b7 lB $.QI
00ab59c3 /p $.
00ab59cd  %.1
00ab5a05 V+O1V+O
00ab5a13 OD A
00ab5a20 R AO
00ab5a29  AOt A
00ab5a30 p AO
00ab5a3d T+OCV+OdV+O&V+O
00ab5a5b NBXCN
00ab5a61 XFNB
00ab5a98 c ".
00ab5ac5 T+OB
00ab5ad4 f AO
00ab5aeb NbXDNB
00ab5b2c c ".
00ab5b57 Oe A
00ab5b5c f AO
00ab5b77 N XCN
00ab5be7 Tl4A
00ab5c97 <Bd#n
00ab5ca9 f1nBd#n
00ab5cb1 d%nBd&nbd"nBl nBd!n
00ab5d1b =Bd#n
00ab5d2f =Bd&nf
00ab5d39 d%ncd'n
00ab5d45 d#nBd%nbd"nBl nBd!n
00ab5d8b TN=A
00ab5e2b <Bd#n
00ab5e3d f1nBd#n
00ab5e45 d%nBd&nbd"nBl nBd!n
00ab5eab =Bd#ne
00ab5ebf =Bd&n
00ab5ec9 d%ncd'n
00ab5ed5 d#nBd%nbd"nBl nBd!n
00ab5f8d d!nh
00ab5ffd d#n&
00ab6005 d#n!
00ab601d l"nD
00ab6025 l"nF
00ab6050 Bl .Bd!.B
00ab606c @l .
00ab611b 6#@`
00ab61bf 6#@`
00ab623b 6#@`
00ab6ecb 7 @`
00ab72f8 1xEN
00ab7300 sxGNRxFN
00ab7309 xPN!8EN5zSNc8GNVzTN
00ab731f nB8FN
00ab732b n%:SNF:TN0xCNW
00ab7344 QxDN
00ab7358 48CNU8DN
00ab7425 xDNe
00ab742b =f8@Ncx@N18GN!xGNG8ENBxEN%:FN&zFN18CN2xCN
00ab7461 xBNa8ENbxEN
00ab7479 zQNg:RNpzRN
00ab78d1 x!N#x!
00ab78d8 !x!NB
00ab7905 x!NA
00ab791b = x!
00ab7937 < x!
00ab7974 @h!N!h!
00ab797c ah!N@
00ab79e7 NI(@
00ab7b4b NI(@
00ab7cef NI(@
00ab7eca "N"j
00ab7f12 "Nbi
00ab7f1e "NBi
00ab82d6  N"DC
00ab82fb =,5@
00ab8323 =/9@
00ab833f =>}@
00ab8357 =6\J
00ab836b =<u@
00ab8392 *N4LL
00ab839a (N;i@
00ab83b6 -N9a@
00ab83ca /N0,O
00ab83ee <N  Q
00ab8406 9N6]@
00ab8412 8N!pS
00ab842e 6N$`U
00ab843a 3N0y@
00ab8446 &N:E@
00ab8456 0N$LW
00ab8596 &n!!
00ab85a2 $N )
00ab85ba 'N 9
00ab85c2 $Ndk
00ab85ce !N I
00ab85da &N%k
00ab85e6 $N Y
00ab85fe %N i
00ab8616 !N y
00ab8622 %Nej
00ab8682 !NAi
00ab89ba rNr"
00ab8e5e +N{#
00ab8ee6 +N{#
00ab906f Lbhl
00ab90a3 ndhx
00ab90ab nehy
00ab90b3 nphz
00ab90bb nqh{
00ab9157 Lbhk
00ab921f 6	!@
00ab945a rNr"
00ab94a2 %Nk!
00ab9626 6N<j
00ab9866 +N{#
00ab98ee +N{#
00ab9b23 O1H@
00ab9b3b N3PA
00ab9c4a @MhV1O]
00ab9c7a @M	yM
00ab9cce rNsT
00ab9cde 2NrD
00ab9d23 NRV1Oi
00ab9d5a @M	yK
00ab9eca 4N@ 
00ab9ed2 3N@@
00ab9fd7 qRLA
00aba246 Amb@A
00aba267 Na@@
00aba2a3 O5XA
00aba347 N*jh
00aba384 kW3O
00aba39d W3O?
00aba3ad W3OH
00aba77f N1HA
00aba7f7 N	yd
00aba804 zW1O
00aba876 @M	yI
00aba9a2 znG@
00aba9fc 1V1O
00abaa1a @M	yK
00abaabb ndyj
00abaada @MhyI
00abab67 O2LB
00abab7a !N0DA
00abab92 !N4TC
00ababa2 !NRJa
00ababc2 !NrJaN
00ababcc 0JaN
00ababed J!N'J!N
00abac01 l%NF
00abac80 $HaN
00abacf7 O2LB
00abad0a !N0DA
00abad22 !N4TC
00abad32 !NRJa
00abad52 !NrJaN
00abad5c 0JaN
00abad7d *!n'*!n
00abad91 l%nF
00abaddd l".D
00abae10 $HaN
00abb02f NI,@
00abb28b NI,@
00abb329 REm?=
00abb349 NDmR
00abb3bd V@m6
00abb3ed Z@mv
00abb582 fNF3@
00abb59a rNRC@
00abb8a8 x]@m
00abb8bc |m@mk
00abb8f4 &@Fm
00abb91c 1XHm
00abb95c o9@m
00abb98c  LKm
00abb9b4 !hMm
00abb9c0 }y@mK
00abb9e0 h}@mk
00abb9f4  HOm3
00abba00 x]@m
00abba08 10Nm
00abba20 {q@m
00abba30 *,Pmk
00abba3c =DSm
00abba50 b=@m
00abba64 +tUm
00abba6c ~1@m
00abba7c w-@m$
00abba88 - Wm
00abba90 )(Tm
00abbaa4 {}@mk
00abbaac )4Vm
00abbab4 !,Ym
00abbabc |y@ma
00abbac8 ;$Xm
00abbb72 wN0L[m
00abbb7c qI@mc
00abbc12  n!@
00abbc26 !ncHa
00abbc35 HaNBHa
00abbc3e qN"HaN
00abbc4a qN H!N
00abbc55 l3N@h
00abbdf6 eNEI@
00abbe4a cNCQ@
00abbe6e bNEa@
00abbe8e dNDy@
00abbf88  HaN
00abc087 T0E@mJ!
00abc094 2MAm
00abc0b5 "GO%"G
00abc0bc #"GO0EBmF"W
00abc0c8 D"WOe"W
00abc0d0 c"WO2MCm
00abc0e9 "gOs
00abc0f4 #"gO0EDmF"w
00abc100 D"wOe"w
00abc108 c"wO2MEm
00abc121 *GOs
00abc12c #*GO0EFmF*W
00abc138 D*WOe*W
00abc140 c*WO2MGm
00abc159 *gOP
00abc164 #*gOq
00abc171 *wO%*w
00abc178 #*wOh
00abc196 !N?<
00abc1a2 $n'AA
00abc1cc eHaN
00abc1d6 `NcH!
00abc1dd H!Ncd!Ncl"N
00abc208 0E@m_
00abc229 "GO%"G
00abc230 #"GOa
00abc240 0EAm_
00abc255 "WO%"W
00abc25c #"WO
00abc263 T0EBm_
00abc279 "gO%"g
00abc280 #"gO
00abc298 0ECm_
00abc2ad "wO%"w
00abc2b4 #"wO
00abc2bb T0EDm_
00abc2d1 *GO%*G
00abc2d8 #*GO
00abc2f0 0EEm_
00abc305 *WO%*W
00abc30c #*WOC
00abc313 T0EFm)
00abc329 *gO%*g
00abc330 #*gO
00abc3cb TpE@m
00abc3d8 rMAm
00abc3f9 "GO%"G
00abc400 $"GOpEBmF"W
00abc40c C"WOe"W
00abc414 d"WOrMCm
00abc42d "gOs
00abc438 $"gOpEDmF"w
00abc444 C"wOe"w
00abc44c d"wOrMEm
00abc465 *GOs
00abc470 $*GOpEFmF*W
00abc47c C*WOe*W
00abc484 d*WOrMGm
00abc49d *gOP
00abc4a8 $*gOq
00abc4b5 *wO%*w
00abc4bc $*wOh
00abc4d4 pE@m
00abc4f1 "GO%"G
00abc4f8 $"GOa
00abc508 pEAm
00abc51d "WO%"W
00abc524 $"WO
00abc52b TpEBm
00abc541 "gO%"g
00abc548 $"gO
00abc560 pECm
00abc575 "wO%"w
00abc57c $"wO
00abc583 TpEDm
00abc599 *GO%*G
00abc5a0 $*GO
00abc5b8 pEEm
00abc5cd *WO%*W
00abc5d4 $*WOC
00abc5db TpEFmk
00abc5f1 *gO%*g
00abc5f8 $*gO
00abc61a !N?<
00abc626 #ngAA
00abc646 !NfHaN
00abc655 HaNcH!
00abc661 H!Ncd!Ncl"N	
00abc847 OyV@
00abc86b O;R@
00abca9b nRk+
00abcf33 msP@
00abd032 9Nxa
00abd03a ;NWa
00abd082 7NWi
00abd09e 8Nxi
00abd0b2 (Nh#
00abd1a6 >N{c
00abd1b2 <NZ#
00abd1ba 6N6#
00abd3ea @LJa
00abd3f6 )Nka
00abd63f Nf0@
00abd86a ;N{a
00abd946 9N1j
00abd99e $NB!
00abda22 $NBA
00abda46 $NDB
00abda5e "NbB
00abdc22 =NFa	nw
00abdc3e &NEb
00abdc52 !Ndb
00abdca3 =BA	n
00abdce2 0NsB
00abdd62  N%!
00abdd6a !N&#
00abddbe $NE"
00abddfe 'N"A
00abde46  NBB
00abdf32 0N4c
00abdf8e 4Nuc
00abdf9e 6NVc
00abdfca 7N7C
00abe006 6NuC
00abe01a 7NVC
00abe0c6 &Ns"
00abe31f Ne0@
00abe4fe %N"`
00abe696 0NPa
00abe6ee !Na"
00abe6f6  N@ 
00abe9f3 q^|A
00abeb83 qV\A
00abecb3 N1I/
00abeccb NTT@
00abecd3 qW`A
00abee07 NPD@
00abeed6 @Mm!
00abf133 NPD@
00abf13b qRLA
00abf3ab NUP@
00abf3bb NFDA
00abf71b qRLA
00abf87b NXd@
00abf883 q[pA
00abfa63 NPD@
00ac0315 !@Lh
00ac031c 4!@L
00ac0321 !@L#
00ac0333 O;p@
00ac0346 8N=xA
00ac038e :N	p
00ac06da DNk!
00ac072b Tm9@
00ac0832 Cnc4BNc4
00ac09ae Cnc4BNc4
00ac0b26 DNdj
00ac0b4a Cnc4ANc4
00ac0bde Cnc4ANc4
00ac0da0 n2@m
00ac0dc0 /&@m
00ac0f39 VKm'
00ac0f81 VMm'
00ac10e5 ZAm5
00ac1247 /bA@
00ac1672 FNeh
00ac1692 DN%j
00ac16e6 DNek
00ac172a PNDi
00ac174e BNB4@NB4
00ac1906 BNB4@NB4
00ac19ea ENB4@Nc4@NB4
00ac1a56 CNB4@NB4
00ac1aaa CNB4@NB4
00ac1b8e DNB4@Nc4@NB4
00ac1c06 CNB4@NB4
00ac1c66 CNB4@NB4
00ac1e1e DNc4@NB4@Nc4
00ac1e9a BN"j
00ac1ee2 BNbi
00ac1eee BNBi
00ac1efa BNb4@NB4
00ac1fc2 CNB4@NB4
00ac268b .3@`
00ac291d gKm`
00ac2c33 .LB`
00ac2c9f .YA`
00ac2caf .xA`
00ac2ce3 .5A`
00ac2e45 CKm!1
00ac2e67 .MC`
00ac3282 DNDi
00ac3292 DN$i
00ac32a2 Cnc4ANc4
00ac33d6 DNDi
00ac33e6 DNdi
00ac33fe Cnc4ANc4
00ac359d XFN%
00ac3612 @Mnhq
00ac36e7 6	!@
00ac384a @M($
00ac3863 Tl4A
00ac3913 <B4CN
00ac3925 6QNB4CN
00ac392d 4ENB4FNb4BNB4
00ac393b NB4@N
00ac3997 =B4CN
00ac39ab =B4FNf
00ac39b5 4ENc4GN
00ac39c1 4CNB4ENb4BNB4
00ac39cf NB4@N
00ac3a03 TN=A
00ac3aa3 <B4CN
00ac3ab5 6QNB4CN
00ac3abd 4ENB4FNb4BNB4
00ac3acb NB4@N
00ac3b23 =B4CNe
00ac3b37 =B4FN
00ac3b41 4ENc4GN
00ac3b4d 4CNB4ENb4BNB4
00ac3b5b NB4@N
00ac3de2 Cnc4@Nc4
00ac3f5e CnB4@NB4
00ac40f6 Cnc4@Nc4
00ac418a CnB4@NB4
00ac4222 `NgI
00ac424a !Ncd`N
00ac425a "NPf`Nc
00ac42a6 `NBd`N
00ac42ae $Ncd`N
00ac431e `NBd`Ncd`N
00ac43cf T1H@
00ac43ef N3TA
00ac4492 JN9W
00ac44b6 _NZW
00ac44e6 ~NsP
00ac4502 qNvH
00ac459a FN#V
00ac45bd Tp_`
00ac45f5 T`_`
00ac4631 4DN&
00ac4638 c4EN!
00ac4640 B4FN!4GN
00ac4664 A4AN
00ac46ee @y(|
00ac475f qPDA
00ac47ad 4ANc4ANB4AN
00ac4aaa ENB4@Nc4@NB4
00ac4ade CNB4@NB4
00ac4b02 CN@4@N
00ac4b62 DNc4@N
00ac4b69 4@Nc4
00ac4b92 CNc4@Nc4
00ac4bb2 CN@4@N
00ac4c0c B<CnB4@NB4
00ac4c2f =B<Cn@4@N
00ac4c8c c<Bnc4@Nc4
00ac4cab =b<Bn@4@N
00ac4d01 4BN!4CN`
00ac4d29 4AN`
00ac4d90 !4@NB4@Na
00ac4db4 !4@Na
00ac4dcb = 4@N
00ac4f3e EnB4@Nc4@NB4
00ac4f72 CnB4@NB4
00ac4f96 Cn@4@N
00ac4ff6 Dnc4@N
00ac4ffd 4@Nc4
00ac5026 Cnc4@Nc4
00ac5046 Cn@4@N
00ac50a0 C<Cnc4@Nc4
00ac50bf =B<Cn@4@N
00ac5123 Nc4@N
00ac5129 4@Nc4
00ac5153 Nc4@Nc4
00ac5173 N@4@N
00ac530b NB4@Nc4@NB4
00ac533f NB4@NB4
00ac5363 N@4@N
00ac53c3 Nc4@N
00ac53c9 4@Nc4
00ac53f3 Nc4@Nc4
00ac5413 N@4@N
00ac5468 B4@Nc4@NB4
00ac5494 B4@NB4
00ac54af =@4@N
00ac54f2 @mi8
00ac5503 Nd`@
00ac554f Os6GN
00ac55ca tnQH
00ac55ef OR6GN
00ac575f OBddN@l`N 
00ac57c6 `NBdaN
00ac57ce $NcdaN
00ac5806 `NBdaN
00ac5832 `N!dcN@
00ac58cd 4@NB4@Nc4
00ac5931 4@NB4@Nc4
00ac5bf7 N0D@
00ac5c17 N2PA
00ac5cae CNZW
00ac5d5e Kn7.
00ac5e4a Sn1,
00ac5ec6 EN",
00ac60d3 TPE@
00ac60eb ORAA
00ac60f3 OQIB
00ac60ff OPMC
00ac612e !N?<
00ac613a $nGAA
00ac6164 eHaN
00ac616e `NcH!
00ac6175 H!Ncd!Ncl"N)
00ac62e6 !N?<
00ac6312 !NfHaN
00ac6321 HaNcH!
00ac632d H!Ncd!Ncl"N	
00ac6485 l!N	
00ac661b N1Ja
00ac6629 HaN&
00ac66a6 @mII
00ac6798 0JaN
00ac67d7 /jD@
00ac6993 NRJa
00ac699c 2JaN
00ac69a1 HaNG
00ac6abe UN!@
00ac6ac5 6DN16DN
00ac6aef 6`D@
00ac6b1b 6`$@|
00ac6c99 7DN!@
00ac6ca0 97DNZ7DN{7DN
00ac6d0b 6`D@
00ac6d17 <aE@
00ac6d6f 6`$@|
00ac6d7b <a%@|
00ac6ecb T`D@
00ac6ed7 <!E@
00ac6f6b O`D@
00ac6f73 O!E@
00ac6f7b OBE@
00ac6f83 OcE@
00ac7025 7DN97DNZ7DN{7DN
00ac7041 7DN!@
00ac70b4 `$@|
00ac70c3 O!%@|
00ac70cb OB%@|
00ac70d3 Oc%@|
00ac726f T`D@
00ac729f TcD@
00ac72ab O(E@
00ac72cf ODE@
00ac72db OhE@
00ac7357 O`D@
00ac735f O(E@
00ac7383 OAE@
00ac738f OhE@
00ac7413 TcD@
00ac741f O(E@
00ac7443 ODE@
00ac744f OhE@
00ac7555 7DN97DNZ7DN{7DN
00ac7571 7DN!@
00ac75ef 6`D@
00ac7677 6`$@|
00ac7680 A%@|
00ac7685 %@| A
00ac7a51 7DN97DNZ7DN{7DN
00ac7a6d 7DN!@
00ac7ae3 6`D@
00ac7aef <!E@
00ac7b6f 6`$@|
00ac7b7b <!%@|B%@|c%@|
00ac7e41 7DN97DNZ7DN{7DN
00ac7e5d 7DN!@
00ac7ed3 6`D@
00ac7edf <!E@
00ac7f5f 6`$@|
00ac7f6b <!%@|B%@|c%@|
00ac8131 6DN16DN
00ac8339 7DN97DNZ7DN{7DN
00ac872d 7DN97DNZ7DN{7DN
00ac8749 7DN!@
00ac87c1 %@|5
00ac87d1 &@|7
00ac87e1 &@|9
00ac8c9d 7DN97DNZ7DN{7DN
00ac8cb9 7DN!@
00ac91e9 7DN97DNZ7DN{7DN
00ac9205 7DN!@
00ac9639 7DN97DNZ7DN{7DN
00ac9655 7DN!@
00ac9886 `MH$@
00ac9f52 $N! 
00ac9fef <`D@
00aca13a 2N! 
00aca376 $N! 
00aca413 <`D@
00aca56e 2N! 
00aca953 6`D@
00acac5a &N! 
00acad1b 6`D@
00acad27 MAE@
00acb0a6 &N! 
00acb167 6`D@
00acb173 MAE@
00acb61b 6`D@
00acb652 $N! 
00acba62 &N! 
00acbb23 6`D@
00acbb2f MAE@
00acbfeb 6`D@
00acc022 $N! 
00acc4ba &N! 
00acc5c3 6`D@
00acc5cf MAE@
00accaaa &N! 
00accbb3 6`D@
00accbbf MAE@
00acd132 &N! 
00acd347 6`D@
00acd61a &N! 
00acd713 6`D@
00acdc02 &N! 
00acdd0b 6`D@
00acdd17 MAE@
00ace2d2 &N! 
00ace4e3 6`D@
00ad09fe &N! 
00ad0e06 &N! 
00ad1416 &N! 
00ad1b2e &N! 
00ad26c2 &N! 
00ad2d9a &N! 
00ad3104 0j`N
00ad310c rj`N
00ad313d j`N`@
00ad3174 8j`N
00ad317c zj`N
00ad31ec 0j`Nrj`N
00ad3244 8j`Nzj`NU
00ad32a8  HaN! 
00ad3302 Cm0j`Nrj`N
00ad3328 8j`Nzj`N
00ad33d4 0j`N
00ad33dc rj`N
00ad3420 8j`N
00ad3428 zj`N
00ad3445 j`NB
00ad3474 0j`N
00ad347c rj`N
00ad34c0 8j`Nzj`NU
00ad3520  HaN! 
00ad357a Cm0j`Nrj`N
00ad35a0 8j`Nzj`N
00ad3640 0j`Nrj`N
00ad3684 8j`N
00ad368c zj`N
00ad36d0 0j`Nrj`N
00ad3714 8j`Nzj`NU
00ad3770  HaN! 
00ad37ca Cm0j`Nrj`N
00ad37f0 8j`Nzj`N
00ad38f4 Ph`Nqh`N
00ad3900 Ri`Nsi`N
00ad3990 Xh`Nt
00ad3998 yh`N
00ad39a0 Zi`N{i`N
00ad3a48 Ph`Nqh`NRi`Nsi`N
00ad3ad4 Xh`Nyh`NZi`N{i`N
00ad3b9c  HaNbHaN! 
00ad3bb4  H!Na
00ad3c1c Ph`N
00ad3c24 qh`N
00ad3c2c Ri`N
00ad3c34 si`N
00ad3c64 Xh`N
00ad3c6c yh`N
00ad3c74 Zi`N
00ad3c7c {i`N
00ad3d9c Ph`N
00ad3da4 qh`N
00ad3dac Ri`N
00ad3db4 si`N
00ad3e18 Xh`N
00ad3e20 yh`N
00ad3e28 Zi`N
00ad3e30 {i`N
00ad3e9c Ph`N
00ad3ea4 qh`N
00ad3eac Ri`N
00ad3eb4 si`N
00ad3f0c Xh`N
00ad3f14 yh`N
00ad3f1c Zi`N
00ad3f24 {i`N
00ad3fc4  HaNbHaN! 
00ad3fdc  H!Na
00ad4044 Ph`N
00ad404c qh`N
00ad4054 Ri`N
00ad405c si`N
00ad408c Xh`N
00ad4094 yh`N
00ad409c Zi`N
00ad40a4 {i`N
00ad41b4 Ph`N
00ad41bc qh`N
00ad41c4 Ri`N
00ad41cc si`N
00ad4228 Xh`N
00ad4230 yh`N
00ad4238 Zi`N
00ad4240 {i`N
00ad42ac Ph`N
00ad42b4 qh`N
00ad42bc Ri`N
00ad42c4 si`N
00ad431c Xh`N
00ad4324 yh`N
00ad432c Zi`N
00ad4334 {i`N
00ad43d4  HaNbHaN! 
00ad43ec  H!Na
00ad4454 Ph`N
00ad445c qh`N
00ad4464 Ri`N
00ad446c si`N
00ad449c Xh`N
00ad44a4 yh`N
00ad44ac Zi`N
00ad44b4 {i`N
00ad4b19 (qO@
00ad4c81 K!N!K!NBK!NcK!Nk
00ad4c95 d$N!d$NBd$Ncd$N!@
00ad4ca9 l%N!l%NBl%Ncl%N
00ad4da9  SO@
00ad4e4d  sO 
00ad542d K!N!K!NBK!NcK!Nk
00ad5441 d$N!d$NBd$Ncd$N!@
00ad5455 l%N!l%NBl%Ncl%Nc
00ad5551  SO`
00ad55f5  sO@
00ad5699 (SO 
00ad5d35 K!N!K!NBK!NcK!Nk
00ad5d49 d$N!d$NBd$Ncd$N!@
00ad5d5d l%N!l%NBl%Ncl%N
00ad61b5 K!N!K!NBK!NcK!Nk
00ad61c9 d$N!d$NBd$Ncd$N!@
00ad61dd l%N!l%NBl%Ncl%Nc
00ad6619 K!N!K!NBK!NcK!Nk
00ad662d d$N!d$NBd$Ncd$N!@
00ad6641 l%N!l%NBl%Ncl%N
00ad672b 6`D@
00ad68ac 0j`N
00ad68b4 rj`N
00ad691c 8j`N
00ad6924 zj`N
00ad6994 0j`Nrj`N
00ad69ec 8j`Nzj`NU
00ad6a05 j`N@
00ad6a54  HaN! 
00ad6ab2 Cm0j`Nrj`N
00ad6ad8 8j`Nzj`N
00ad6ae5 j`N)!
00ad6b9c 0j`N
00ad6ba4 rj`N
00ad6be8 8j`N
00ad6bf0 zj`N
00ad6c0d j`NB
00ad6c3c 0j`N
00ad6c44 rj`N
00ad6c88 8j`N
00ad6c90 zj`NU
00ad6ca1 j`N 
00ad6cf0  HaN! 
00ad6d4a Cm0j`Nrj`N
00ad6d70 8j`Nzj`N
00ad6d7d j`N)!
00ad6e38 0j`Nrj`N
00ad6e7c 8j`N
00ad6e84 zj`N
00ad6ec8 0j`Nrj`N
00ad6f0c 8j`N
00ad6f14 zj`NU
00ad6f25 j`N@
00ad6f74  HaN! 
00ad6fd2 Cm0j`Nrj`N
00ad6ff8 8j`Nzj`N
00ad7005 j`N)!
00ad7124 Ph`Nqh`N
00ad7130 Ri`Nsi`N
00ad71c0 Xh`N
00ad71c8 yh`N
00ad71d0 Zi`N{i`N
00ad7278 Ph`Nqh`NRi`Nsi`N
00ad7304 Xh`Nyh`NZi`N{i`N
00ad73d0  HaNbHaN! 
00ad73e8  H!Na
00ad73f5 d!Nk
00ad7454 Ph`N
00ad745c qh`N
00ad7464 Ri`N
00ad746c si`N
00ad749c Xh`N
00ad74a4 yh`N
00ad74ac Zi`N
00ad74b4 {i`N
00ad74c9 i`N)A
00ad75fc Ph`N
00ad7604 qh`N
00ad760c Ri`N
00ad7614 si`N
00ad7678 Xh`N
00ad7680 yh`N
00ad7688 Zi`N
00ad7690 {i`N
00ad76fc Ph`N
00ad7704 qh`N
00ad770c Ri`N
00ad7714 si`N
00ad776c Xh`N
00ad7774 yh`N
00ad777c Zi`N
00ad7784 {i`N
00ad782c  HaNbHaN! 
00ad7844  H!Na
00ad7851 d!Nk
00ad78ac Ph`N
00ad78b4 qh`N
00ad78bc Ri`N
00ad78c4 si`N
00ad78f4 Xh`N
00ad78fc yh`N
00ad7904 Zi`N
00ad790c {i`N
00ad7921 i`N)A
00ad7a44 Ph`N
00ad7a4c qh`N
00ad7a54 Ri`N
00ad7a5c si`N
00ad7ab8 Xh`N
00ad7ac0 yh`N
00ad7ac8 Zi`N
00ad7ad0 {i`N
00ad7b3c Ph`N
00ad7b44 qh`N
00ad7b4c Ri`N
00ad7b54 si`N
00ad7bac Xh`N
00ad7bb4 yh`N
00ad7bbc Zi`N
00ad7bc4 {i`N
00ad7c6c  HaNbHaN! 
00ad7c84  H!Na
00ad7c91 d!Nk
00ad7cec Ph`N
00ad7cf4 qh`N
00ad7cfc Ri`N
00ad7d04 si`N
00ad7d34 Xh`N
00ad7d3c yh`N
00ad7d44 Zi`N
00ad7d4c {i`N
00ad7d61 i`N)A
00ad83e9 (qO@
00ad855d K!N!K!NBK!NcK!Nk
00ad8571 d$N!d$NBd$Ncd$N!@
00ad8585 l%N!l%NBl%Ncl%N#
00ad8679  SO`
00ad871d  sO@
00ad87c1 (SO 
00ad8d35 K!N!K!NBK!NcK!Nk
00ad8d49 d$N!d$NBd$Ncd$N!@
00ad8d5d l%N!l%NBl%Ncl%N#
00ad8e51  SO`
00ad8ef5  sO@
00ad8f99 (SO 
00ad9665 K!N!K!NBK!NcK!N
00ad9679 d$N!d$Nk
00ad9684 Bd$Ncd$N!@
00ad9691 l%N!l%NBl%Ncl%NC	
00ad9b15 K!N!K!NBK!NcK!N
00ad9b29 d$N!d$Nk
00ad9b34 Bd$Ncd$N!@
00ad9b41 l%N!l%NBl%Ncl%NC
00ad9fa9 K!N!K!NBK!NcK!N
00ad9fbd d$N!d$Nk
00ad9fc8 Bd$Ncd$N!@
00ad9fd5 l%N!l%NBl%Ncl%N
00ada214 0j`N
00ada21c rj`N
00ada24d j`N`@
00ada284 8j`N
00ada28c zj`N
00ada2fc 0j`Nrj`N
00ada354 8j`Nzj`NU
00ada36d j`N@
00ada3bc  HaN! 
00ada41a Cm0j`Nrj`N
00ada440 8j`Nzj`N
00ada4e4 0j`N
00ada4ec rj`N
00ada530 8j`N
00ada538 zj`N
00ada555 j`NB
00ada584 0j`N
00ada58c rj`N
00ada5d0 8j`Nzj`NU
00ada5e5 j`N@
00ada634  HaN! 
00ada692 Cm0j`Nrj`N
00ada6b8 8j`Nzj`N
00ada760 0j`Nrj`N
00ada7a4 8j`N
00ada7ac zj`N
00ada7f0 0j`Nrj`N
00ada834 8j`Nzj`NU
00ada849 j`N 
00ada894  HaN! 
00ada8f2 Cm0j`Nrj`N
00ada918 8j`Nzj`N
00adaa24 Ph`Nqh`N
00adaa30 Ri`Nsi`N
00adaac0 Xh`Nt
00adaac8 yh`N
00adaad0 Zi`N{i`N
00adab78 Ph`Nqh`NRi`Nsi`N
00adac04 Xh`Nyh`NZi`N{i`N
00adacd0  HaNbHaN! 
00adace8  H!Na
00adad54 Ph`N
00adad5c qh`N
00adad64 Ri`N
00adad6c si`N
00adad9c Xh`N
00adada4 yh`N
00adadac Zi`N
00adadb4 {i`N
00adaedc Ph`N
00adaee4 qh`N
00adaeec Ri`N
00adaef4 si`N
00adaf58 Xh`N
00adaf60 yh`N
00adaf68 Zi`N
00adaf70 {i`N
00adafdc Ph`N
00adafe4 qh`N
00adafec Ri`N
00adaff4 si`N
00adb04c Xh`N
00adb054 yh`N
00adb05c Zi`N
00adb064 {i`N
00adb108  HaNbHaN! 
00adb120  H!Na
00adb131 l"Nc
00adb184 Ph`N
00adb18c qh`N
00adb194 Ri`N
00adb19c si`N
00adb1cc Xh`N
00adb1d4 yh`N
00adb1dc Zi`N
00adb1e4 {i`N
00adb2f4 Ph`N
00adb2fc qh`N
00adb304 Ri`N
00adb30c si`N
00adb368 Xh`N
00adb370 yh`N
00adb378 Zi`N
00adb380 {i`N
00adb3ec Ph`N
00adb3f4 qh`N
00adb3fc Ri`N
00adb404 si`N
00adb45c Xh`N
00adb464 yh`N
00adb46c Zi`N
00adb474 {i`N
00adb518  HaNbHaN! 
00adb530  H!Na
00adb541 l"Nc
00adb594 Ph`N
00adb59c qh`N
00adb5a4 Ri`N
00adb5ac si`N
00adb5dc Xh`N
00adb5e4 yh`N
00adb5ec Zi`N
00adb5f4 {i`N
00adbc59 (qO@
00adbdbd K!N!K!NBK!NcK!Nk=
00adbdd1 d$N!d$NBd$Ncd$N!@
00adbde5 l%N!l%NBl%Ncl%Nc
00adbf85  sO`
00adc029 (SO@
00adc569 K!N!K!NBK!NcK!Nk=
00adc57d d$N!d$NBd$Ncd$N!@
00adc591 l%N!l%NBl%Ncl%N
00adc691  SO`
00adc735  sO@
00adc7d9 (SO 
00adce71 K!N!K!NBK!NcK!Nk=
00adce85 d$N!d$NBd$Ncd$N!@
00adce99 l%N!l%NBl%Ncl%N
00add2f1 K!N!K!NBK!NcK!Nk=
00add305 d$N!d$NBd$Ncd$N!@
00add319 l%N!l%NBl%Ncl%N
00add755 K!N!K!NBK!NcK!Nk=
00add769 d$N!d$NBd$Ncd$N!@
00add77d l%N!l%NBl%Ncl%N
00add863 6`D@
00add9dc 0j`N
00add9e4 rj`N
00adda4c 8j`N
00adda54 zj`N
00addac4 0j`Nrj`N
00addb1c 8j`Nzj`NU
00addb35 j`N@
00addb88  HaN! 
00addbe2 Cm0j`Nrj`N
00addc08 8j`Nzj`N
00addc15 j`N)!
00addccc 0j`N
00addcd4 rj`N
00addd18 8j`N
00addd20 zj`N
00addd3d j`NB
00addd6c 0j`N
00addd74 rj`N
00adddb8 8j`N
00adddc0 zj`NU
00adddd1 j`N`
00adde24  HaN! 
00adde82 Cm0j`Nrj`N
00addea8 8j`Nzj`N
00addeb5 j`N)!
00addf68 0j`Nrj`N
00addfac 8j`N
00addfb4 zj`N
00addff8 0j`Nrj`N
00ade03c 8j`N
00ade044 zj`NU
00ade055 j`N@
00ade0a8  HaN! 
00ade102 Cm0j`Nrj`N
00ade128 8j`Nzj`N
00ade135 j`N)!
00ade254 Ph`Nqh`N
00ade260 Ri`Nsi`N
00ade2f0 Xh`N
00ade2f8 yh`N
00ade300 Zi`N{i`N
00ade3a8 Ph`Nqh`NRi`Nsi`N
00ade434 Xh`Nyh`NZi`N{i`N
00ade504  HaNbHaN! 
00ade51c  H!Na
00ade529 d!Nk=
00ade584 Ph`N
00ade58c qh`N
00ade594 Ri`N
00ade59c si`N
00ade5cc Xh`N
00ade5d4 yh`N
00ade5dc Zi`N
00ade5e4 {i`N
00ade5f9 i`N)A
00ade72c Ph`N
00ade734 qh`N
00ade73c Ri`N
00ade744 si`N
00ade7a8 Xh`N
00ade7b0 yh`N
00ade7b8 Zi`N
00ade7c0 {i`N
00ade82c Ph`N
00ade834 qh`N
00ade83c Ri`N
00ade844 si`N
00ade89c Xh`N
00ade8a4 yh`N
00ade8ac Zi`N
00ade8b4 {i`N
00ade960  HaNbHaN! 
00ade978  H!Na
00ade985 d!Nk=
00ade9dc Ph`N
00ade9e4 qh`N
00ade9ec Ri`N
00ade9f4 si`N
00adea24 Xh`N
00adea2c yh`N
00adea34 Zi`N
00adea3c {i`N
00adea51 i`N)A
00adeb74 Ph`N
00adeb7c qh`N
00adeb84 Ri`N
00adeb8c si`N
00adebe8 Xh`N
00adebf0 yh`N
00adebf8 Zi`N
00adec00 {i`N
00adec6c Ph`N
00adec74 qh`N
00adec7c Ri`N
00adec84 si`N
00adecdc Xh`N
00adece4 yh`N
00adecec Zi`N
00adecf4 {i`N
00adeda0  HaNbHaN! 
00adedb8  H!Na
00adedc5 d!Nk=
00adee1c Ph`N
00adee24 qh`N
00adee2c Ri`N
00adee34 si`N
00adee64 Xh`N
00adee6c yh`N
00adee74 Zi`N
00adee7c {i`N
00adee91 i`N)A
00adf519 (qO@
00adf689 K!N!K!NBK!NcK!Nk=
00adf69d d$N!d$NBd$Ncd$N!@
00adf6b1 l%N!l%NBl%Ncl%NC
00adf7a9  SO`
00adf84d  sO@
00adf8f1 (SO 
00adfe61 K!N!K!NBK!NcK!Nk=
00adfe75 d$N!d$NBd$Ncd$N!@
00adfe89 l%N!l%NBl%Ncl%NC
00adff81  SO`
00ae0025  sO@
00ae00c9 (SO 
00ae0791 K!N!K!NBK!NcK!N
00ae07a5 d$N!d$Nk=
00ae07b0 Bd$Ncd$N!@
00ae07bd l%N!l%NBl%Ncl%Nc	
00ae0c41 K!N!K!NBK!NcK!N
00ae0c55 d$N!d$Nk=
00ae0c60 Bd$Ncd$N!@
00ae0c6d l%N!l%NBl%Ncl%Nc
00ae10d5 K!N!K!NBK!NcK!N
00ae10e9 d$N!d$Nk=
00ae10f4 Bd$Ncd$N!@
00ae1101 l%N!l%NBl%Ncl%N
00ae1369  '.!
00ae15f1 (qO`
00ae161d  '.B
00ae1899 (qO@
00ae19e9 *!.!*!.B*!.c*!.e
00ae19fd +!n!+!nB+!nc+!nk=
00ae1a11 d$n!d$nBd$ncd$n!@
00ae1a25 l%n!l%nBl%ncl%nc
00ae1a81  '.!
00ae1bc5  sO`
00ae1c69 (SO@
00ae1ded  '.!
00ae1e0d  @O`@
00ae206d  '.j
00ae20dd  '.B
00ae2371 (qO@
00ae24c1 *!.!*!.B*!.c*!.e
00ae24d5 +!n!+!nB+!nc+!nk=
00ae24e9 d$n!d$nBd$ncd$n!@
00ae24fd l%n!l%nBl%ncl%nc
00ae2559  '.!
00ae269d  sO`
00ae2741 (SO@
00ae28b9  '.!
00ae28dd  @O`@
00ae2b59 (qO`
00ae2b85  '.B
00ae2e01 (qO@
00ae2f51 *!.!*!.B*!.c*!.e
00ae2f65 +!n!+!nB+!nc+!nk=
00ae2f79 d$n!d$nBd$ncd$n!@
00ae2f8d l%n!l%nBl%ncl%nc
00ae2fe9  '.!
00ae312d  sO`
00ae31d1 (SO@
00ae38f9 *!.!*!.B*!.c*!.e
00ae390d +!n!+!nB+!nc+!nk=
00ae3921 d$n!d$nBd$ncd$n!@
00ae3935 l%n!l%nBl%ncl%n#
00ae3a37 6`D@
00ae3ed1 *!.!*!.B*!.c*!.e
00ae3ee5 +!n!+!nB+!nc+!nk=
00ae3ef9 d$n!d$nBd$ncd$n!@
00ae3f0d l%n!l%nBl%ncl%nc
00ae4013 6`D@
00ae41e9  '.!
00ae449d  '.B
00ae4719 (qO@
00ae4871 *!.!*!.B*!.c*!.e
00ae4885 +!n!+!nB+!nc+!nk=
00ae4899 d$n!d$nBd$ncd$n!@
00ae48ad l%n!l%nBl%ncl%n#
00ae4901  '.!
00ae4a45  sO`
00ae4ae9 (SO@
00ae4c9d  '.!
00ae4f8d  '.B
00ae5221 (qO@
00ae5239 (sOk
00ae5381 *!.!*!.B*!.c*!.e
00ae5395 +!n!+!nB+!nc+!nkM
00ae53a9 d$n!d$nBd$ncd$n!@
00ae53bd l%n!l%nBl%ncl%n#
00ae5411  '.!
00ae5555  sO`
00ae55f9 (SO@
00ae57a9  '.!
00ae5a75  '.B
00ae5cf1 (qO@
00ae5e49 *!.!*!.B*!.c*!.e
00ae5e5d +!n!+!nB+!nc+!nk=
00ae5e71 d$n!d$nBd$ncd$n!@
00ae5e85 l%n!l%nBl%ncl%n#
00ae5ed9  '.!
00ae601d  sO`
00ae60c1 (SO@
00ae6829 *!.!*!.B*!.c*!.e
00ae683d +!n!+!nB+!nc+!n
00ae6851 d$n!d$nBd$ncd$n!@
00ae6865 l%n!l%nBl%ncl%n
00ae6e31 *!.!*!.B*!.c*!.e
00ae6e45 +!n!+!nB+!nc+!n
00ae6e59 d$n!d$nk=
00ae6e64 Bd$ncd$n!@
00ae6e71 l%n!l%nBl%ncl%n
00ae8712 @9J%
00ae923a A9*}
00ae9856 A9J%
00ae9866 A9)%
00ae9c1f RF}	
00ae9e33 RF}	
00ae9f1d `A9J%
00ae9f2d dA9)%
00aea36f RF}	
00aea583 RF}	
00aea676 A9J%
00aea686 A9)%
00aeae35 $B9J%
00aeae61 `A9*}
00aeae6d dA9+
00aeb373 RF}	
00aeb587 RF}	
00aeb672 A9J%
00aeb6d5 dA9k%
00aebcdf T1~`
00aec086 A9k%
00aec7d1 "D9I
00aeca7c 	@@9)
00aecab8 myjx
00aecb47 *!|B
00aecbdb *!|B
00aecbf0 )A@9I	
00aecc6b *!|B
00aecc80 )A@9
00aeccfb *!|B
00aecdb3 *!|B
00aece37 *!|B
00aecebb *!|B
00aecf3f *!|B
00aecfc3 *!|B
00aed047 *!|B
00aed0bf *!|B
00aed411 @@9h
00aee13f 4h*@
00aee21f 5h^@
00aee3c1 !@qAI
00aee4db *!|B
00aee613 *!|B
00aee6af *!|B
00aee74b *!|B
00aee7e7 *!|B
00aee883 *!|B
00aee91f *!|B
00aee9a3 *!|B
00aeea17 *!|B
00aeea8b *!|B
00aeeb03 *!|B
00aeeb77 *!|B
00aeebeb *!|B
00aeec5f *!|B
00aeecdb *!|B
00aeed5b *!|B
00aeeddb *!|B
00aeee77 *!|B
00aeeef7 *!|B
00aefc3f osj@
00af10cb ThB@9
00af113b *!|B
00af1233 *!|B
00af12b7 *!|B
00af132b *!|B
00af139f *!|B
00af1413 *!|B
00af1487 *!|B
00af16eb *!|B
00af1783 *!|B
00af1813 *!|B
00af20f7 *!|B
00af216b *!|B
00af21df *!|B
00af2267 *!|B
00af399b T($P6h
00af39ef Tjj@
00af3a3b Tkv@
00af3a77 Tl*@
00af3a97 TlB@
00af3ab7 TlZ@
00af3ad7 Tlr@
00af3c4f ThV@
00af3c7f Thr@
00af3d5c hB@9t
00af3e0f *!|B
00af3e93 *!|B
00af3f07 *!|B
00af3f7b *!|B
00af3fef *!|B
00af4063 *!|B
00af40d7 *!|B
00af414b *!|B
00af41bf *!|B
00af4233 *!|B
00af42a7 *!|B
00af431b *!|B
00af438f *!|B
00af4403 *!|B
00af4477 *!|B
00af44eb *!|B
00af455f *!|B
00af45d3 *!|B
00af53f7 *!|B
00af543c 	A@9I,
00af56b4 hB@9t
00af56dc hB@9t
00af5753 *!|B
00af57e7 *!|B
00af585b *!|B
00af58df *!|B
00af5943 *!|B
00af59b7 *!|B
00af5a3b *!|B
00af5a9f *!|B
00af5b13 *!|B
00af5b97 *!|B
00af5c35 #@9H
00af5e99 #@9(
00af609f 4h>@
00af6107 *h6@
00af6129 0D9(
00af6177 4h>@
00af61b7 4h>@
00af61f7 4h>@
00af62d7 *!|B
00af635b *!|B
00af63ff *!|B
00af64bf *!|B
00af657f *!|B
00af6c2f 4h>@
00af6c6f 5h6@
00af6dff o9k@
00af78a9 #@9h
00af794d #@9h
00af7985 #@9h
00af7c05 @@9h
00af80db T,	@
00af8183 T,	@
00af8613 9Jq@
00af87c1 cC9H
00af8801 c@9H
00af8895 CB9H
00af891d cC9(
00af895d c@9(
00af897d cC9(
00af89ad CB9h
00af89fd c@9(
00af8bbc 	i|8?
00af8be5 ii8_
00af8c69 i|8?
00af8ebd "@9h
00af8f4c h"@9h
00af922f R`j@
00af92ef R`n@
00af93f3 Th.@
00af9e61 kh8)	
00af9e70 	A@9I
00afa40f T(+@
00afa458 HC@9h
00afd331 C@9h
00afd391 #A9h
00afd429 C@9h
00afd441 #A9h
00afdaf9 C@9h
00afdb59 #A9h
00afdbf9 C@9h
00afdc11 #A9h
00afdfa1 #@9h
00afe099 #@9h
00afe309 #C9H
00afe349 #@9h
00afe489 cE9H
00afe4c9 cB9H
00afe53d CD9H
00afe5bd CA9H
00afe9c5 #I9H
00afea05 #F9H
00afea45 #C9H
00afea85 #@9h
00afecc5 cK9H
00afece6 I9H	
00afed05 cH9H
00afed45 cE9H
00afed85 cB9H
00afedf9 CJ9H
00afee79 CG9H
00afeef9 CD9H
00afef79 CA9H
00aff0db TtZ@
00aff24f TvR@
00aff4a8 jjh8)	
00aff4b8 	A@9I
00b00b05 kh8)	
00b00b14 	A@9I
00b0108f T(+@
00b010d8 HC@9h
00b01b11 #@9h
00b01c11 #@9h
00b02dc1 #@9h
00b02ed1 #@9h
00b03e69 #@9h
00b03f79 #@9h
00b04335 #@9h
00b0442d #@9h
00b04673 TH+@
00b051f5 #@9h
00b052fd #@9h
00b0553f Th+@
00b05c61 #@9h
00b05d69 #@9h
00b065d9 C@9h
00b06639 #A9h
00b06755 #A9h
00b06e71 A@9(
00b07b39 C@9h
00b07b99 #A9h
00b07cbd #A9h
00b0804d #@9h
00b08145 #@9h
00b082e1 c@9h
00b084d9 c@9h
00b08540 +yhxJ	
00b08829 c@9h
00b0889d c@9h
00b08a05 c@9h
00b08c69 jh8*9
00b08cb4 *iu8K9
00b08d7a @y+,
00b08e91 j48h*@
00b08efd j48h*@
00b08f49 iy8_
00b08fb9 j48h*@
00b0909d j48h*@
00b0926d ii8K9
00b092b6 @9l9
00b0936c *i`8K9
00b093fd jh8*9
00b09446 @9l9
00b095b5 j58h*@
00b09611 j58h*@
00b099d3 *!lA
00b09c0f *!lA
00b09cc9 #@9H
00b09d1d ij8l9
00b09d95 ij8l9
00b09de8 lii8
00b09e4d ii8l9
00b0a05f *!lA
00b0ab45 ji8JE@9_
00b0abed ji8JE@9_
00b0afdf 4hb@9h
00b0b563 R!l'
00b0b5a5 C@9h
00b0b605 #A9h
00b0b6a5 C@9h
00b0b6d9 #A9h
00b0b927 R!l'
00b0ba9e 	9IA
00b0bc67 R!l'
00b0bf7f R!l'
00b0c29f R!l'
00b0c6c7 R!l'
00b0c709 C@9h
00b0c821 C@9h
00b0cbc3 R!l'
00b0cc05 C@9h
00b0cd1d C@9h
00b0cfdf R!l'
00b0d303 R!l'
00b0d643 R!l'
00b0d811 #@9h
00b0d861 #@9h
00b0d8a9 #@9h
00b0d8f5 #@9h
00b0d945 #@9h
00b0d995 #@9h
00b0d9e5 #@9h
00b0da31 #@9h
00b0dad3 R)%@
00b0dd48 HC@9
00b0ddef R)e@
00b0e7a5 #@9h
00b0e7f9 #@9(
00b0e9fb R)%@
00b0f0ec ,ij8k	
00b0f0fc KA@9k
00b0f6b0 ,ij8k	
00b0f6c0 KA@9K
00b0f918 ,ij8k	
00b0f928 KA@9K
00b0fbc4 ,ij8k	
00b0fbd4 KA@9
00b0fc3b RJy"
00b1033c +ih8J	
00b10597 T 9*
00b10ae3 T 9j
00b10f38 ,ij8k	
00b10f48 KA@9K
00b110d7 9	(@
00b1115d #A96
00b1121d #@9h
00b11281 #A96
00b116c9 C@9h
00b11729 #A9h
00b117c9 C@9h
00b117fd #A9h
00b11d75 C@9h
00b11dd5 #A9h
00b11e7d C@9h
00b11ea9 #A9h
00b121ad C@9h
00b1220d #A9h
00b122b5 C@9h
00b122e1 #A9h
00b123a5 #@9h
00b123f5 #@9h
00b1243d #@9h
00b12489 #@9h
00b124d9 #@9h
00b12529 #@9h
00b12579 #@9h
00b125c5 #@9h
00b12667 R)%@
00b128dc HC@9
00b12983 R)e@
00b12fd3 R)%@
00b131bd B@9H
00b131db R)%@
00b136ab R)%@
00b13787 R)e@
00b14861 #C9H
00b148a1 #@9h
00b149c1 cB9H
00b14a75 CA9H
00b15277 RB$!
00b1548c ,ij8k	
00b1549c KA@9
00b15633 RB$!
00b16203 RB$!
00b16ced ii8J	
00b16cfc *A@9
00b16d95 ii8J	
00b16da4 *A@9
00b17001 ii8J	
00b17010 *A@9
00b170a9 ii8J	
00b170b8 *A@9
00b174e5 ii8J	
00b174f4 *A@9
00b1758d ii8J	
00b1759c *A@9
00b17987 R!L&
00b17cb1 CB9H
00b17d85 #A9H
00b17e2d cC9H
00b17ead c@9H
00b18173 R!L&
00b184b7 R!L&
00b18707 R!L&
00b18957 R!L&
00b18ba7 R!L&
00b18e0b R!L&
00b1906f R!L&
00b192d3 R!L&
00b19537 R!L&
00b1979b R!L&
00b199ff R!L&
00b19d2f R!L&
00b1a1a3 R!L&
00b1a641 ii8J	
00b1a650 *A@9
00b1a6e9 ii8J	
00b1a6f8 *A@9
00b1ab2c ,ij8k	
00b1ab3c KA@9
00b1ae5d ii8J	
00b1ae6c *A@9
00b1af05 ii8J	
00b1af14 *A@9
00b1b8d9 C@9h
00b1b9e1 C@9h
00b1bfbf RB$!
00b1c27b RB$!
00b1c449 C@9h
00b1c4a9 #A9h
00b1c551 C@9h
00b1c57d #A9h
00b1c6b3 RB$!
00b1c95f RB$!
00b1cc0b RB$!
00b1ceb7 RB$!
00b1d163 RB$!
00b1d7d7 R!H"
00b1e191 c@9h
00b1e23d c@9h
00b1e36b RB$!
00b1e6bf RB$!
00b1f187 RB$!
00b1f4a7 RB$!
00b1f79f RB$!
00b1fd67 RB$!
00b210c1 C@9h
00b21121 #A9h
00b211fd C@9h
00b21229 #A9h
00b21e63 RB$!
00b2218f RB\$
00b22455 yixJ	
00b22464 *A@9
00b22496 @9h:
00b22501 yixJ	
00b22510 *A@9
00b2320f RB$!
00b2324b RB|!
00b232b3 RBD(
00b23531 cA9h
00b23625 cA9h
00b2498d C@9h
00b249ed #A9h
00b24a95 C@9h
00b24ac1 #A9h
00b25b51 C@9h
00b25bb1 #A9h
00b25c59 C@9h
00b25c85 #A9h
00b25f91 C@9h
00b25ff1 #A9h
00b26099 C@9h
00b260c5 #A9h
00b262cb RBx%
00b2632f RB40
00b26c69 C@9h
00b26cc9 #A9h
00b26d81 C@9h
00b26dad #A9h
00b26f31 #@9h
00b26ff1 cB9H
00b27065 CA9H
00b27207 RB$!
00b274bb RB$!
00b27705 cA9h
00b277e1 #@9h
00b277f1 cA9h
00b27841 cA9h
00b278c9 cA9h
00b27925 cA9h
00b27969 cA9h
00b27b53 R)1'
00b27b81 cA9h
00b28091 #@9h
00b2824d #@9h
00b285f9 #@9h
00b286d5 #@9h
00b287e1 jh8)	
00b287f0 	A@9)
00b288d5 ii8_
00b28a73 R)i@
00b28f12 C9Ha
00b29341 #A9H
00b29a9d C@9h
00b29afd #A9h
00b29ba5 C@9h
00b29bd1 #A9h
00b29c63 =)	@
00b29c9d c@9h
00b29d79 c@9H
00b29e95 c@9h
00b29f41 c@9h
00b2a0cf RBX+
00b2a2f9 #@9h
00b2a349 #@9h
00b2a3e9 #@9h
00b2b74f =A	@
00b2b7f9 C@9h
00b2b909 C@9h
00b2becd C@9h
00b2bf2d #A9h
00b2c071 #A9h
00b2c1e9 ii8J	
00b2c1f8 *A@9
00b2c291 ii8J	
00b2c2a0 *A@9
00b2c923 osj@
00b2d0e5 ii8J	
00b2d0f4 *A@9
00b2d18d ii8J	
00b2d19c *A@9
00b2d585 ii8J	
00b2d594 *A@9
00b2d62d ii8J	
00b2d63c *A@9
00b2d989 cA9h
00b2db61 cA9h
00b2dcd0 	A@9
00b2dfdd cA9h
00b2e49d cA9h
00b2e955 ii8J	
00b2e964 *A@9
00b2e9fd ii8J	
00b2ea0c *A@9
00b2ea7d #@9h
00b2eadd #@9h
00b2ef74 ,ij8k	
00b2ef84 KA@9+
00b2f00d #@9h
00b2f599 ii8J	
00b2f5a8 *A@9*
00b2f641 ii8J	
00b2f650 *A@9
00b2f8be 	k!	
00b2ffac ,ij8k	
00b2ffbc KA@9K
00b30491 yixJ	
00b304a0 *A@9
00b304d2 @9h(
00b30539 yixJ	
00b30548 *A@9
00b3057a @9(#
00b30779 ii8J	
00b30788 *A@9
00b30883 R)a5
00b308cd @@9h
00b31125 @@9h
00b3114d c@9h
00b311b1 c@9h
00b31235 c@9h
00b312ef R)a5
00b31339 @@9h
00b31444 ,ij8k	
00b31454 KA@9K
00b31671 D@9(	
00b31760 ,ij8k	
00b31770 KA@9+
00b31815 D@9h
00b31821 #@9h
00b31929 #@9(
00b3208c +ih8J	
00b325cd C@9h
00b327b1 D@9H
00b327bd #@9h
00b32844 ,ij8k	
00b32854 KA@9k
00b32d79 D@9H
00b32d85 #@9h
00b32e0d ii8J	
00b32e1c *A@9j
00b32ec5 ii8J	
00b32ed4 *A@9
00b3330c ,yjxk	
00b3331c KA@9+#
00b33551 D@9h
00b33565 #@9h
00b35691 C@9h
00b35799 C@9h
00b35d85 C@9h
00b35de5 #A9h
00b35e8d C@9h
00b35eb9 #A9h
00b36d5f RB$!
00b3781b RB$!
00b378f7 =	)@
00b37c17 =	)@
00b3902d C@9h
00b3908d #A9h
00b39135 C@9h
00b39161 #A9h
00b395c5 yixJ	
00b395d4 *A@9
00b39606 @9h:
00b39671 yixJ	
00b39680 *A@9
00b3a565 C@9h
00b3a5c5 #A9h
00b3a66d C@9h
00b3a699 #A9h
00b3a9a1 C@9h
00b3aa01 #A9h
00b3aaa9 C@9h
00b3aad5 #A9h
00b3addd C@9h
00b3ae3d #A9h
00b3aee5 C@9h
00b3af11 #A9h
00b3bf52 w9i!
00b3c1c1 c@9h
00b3c68f 9(a@
00b3cc59 b@9H
00b3ce5a `yh!
00b3d0e9 c@9h
00b3d40d b@9H
00b3da6b 9(a@
00b3dc81 c@9H
00b3e1ea _yh!
00b3e411 c@9H
00b3e968 ia@9
00b3ec01 b@9H
00b3f30d c@9h
00b3f410 _k78h
00b3f4b6 }9jaB
00b3fe45 b@9H
00b40519 b@9H
00b40684 ?k78
00b409b9 c@9h
00b409cf R)1'
00b40d8f RJY	
00b412ee ]yh!
00b41ae1 c@9h
00b41ed9 c@9h
00b41fcf R?k78
00b41fe4 _k88
00b42749 c@9h
00b428b3 9hq@
00b42abd b@9H
00b42cea u9i!
00b432f1 Su9i
00b43575 c@9h
00b43726 v9i!
00b43b49 3v9i!
00b440f1 c@9h
00b444cd c@9h
00b4517d sv9i
00b45771 c@9h
00b45b79 c@9h
00b4623d b@9H
00b46341 b@9(
00b4663c hc@9h
00b466e0 Hc@9h
00b468f9 b@9h
00b469fd b@9H
00b46af9 b@9h
00b46bfd b@9H
00b46d41 b@9(
00b47081 b@9(
00b47138 hc@9h
00b47190 hc@9h
00b471f8 Hc@9h
00b4737d b@9H}
00b4759d b@9Hl
00b47741 b@9(_
00b47858 hc@9h
00b47902 @9("
00b47a9d b@9HD
00b47c39 b@9h7
00b47c80 hc@9h
00b48050 Hc@9
00b4813d b@9h
00b4816b 7(c@9h
00b48194 (c@9
00b481c7 7hc@9h
00b481f0 hc@9
00b4852c (c@9h
00b48579 b@9h
00b485a0 Hc@9h
00b485d8 Hc@9h
00b48609 #p9h
00b4865c h#A9h
00b4866b 7hc@9
00b486a4 hc@9h
00b486d9 c@9h
00b48733 7hc@9
00b48768 hc@9
00b48795 #A9H
00b4885f 6`:@
00b4888f T`&@
00b488f4 hb@9h
00b48e55 #@9h
00b48f2d #@9h
00b49709 cO9h
00b497fb =:	@
00b4986f RjcA
00b49c1f R)%-
00b49e8f RJq0
00b4a315 CN9jaM
00b4a4ed cO9h
00b4a8ad cO9h
00b4ab61 cO9h
00b4ac7b R)a5
00b4b469 cO9h
00b4b699 cO9h
00b4b6ce S9h'
00b4baa9 cW9h
00b4badd cS9h
00b4bb15 cS9h
00b4bf61 #@9h
00b4bfad #@9h
00b4c04d #@9h
00b4d7ed j48"
00b4d9ad c@9H
00b4dac5 c@9h
00b4dc37 =C	C
00b4def1 C@9h
00b545f7 RB$!
00b54a35 C@9h
00b54a95 #A9h
00b54bd9 #A9h
00b54d51 ii8J	
00b54d60 *A@9
00b54df9 ii8J	
00b54e08 *A@9
00b5517d C@9h
00b551dd #A9h
00b55321 #A9h
00b55499 ii8J	
00b554a8 *A@9
00b55541 ii8J	
00b55550 *A@9
00b559b0 ,ij8k	
00b559c0 KA@9
00b55a6d D@9H
00b55a79 #@9h
00b55afd #@9H
00b55ce9 ii8J	
00b55cf8 *A@9
00b55d91 ii8J	
00b55da0 *A@9
00b55ffd ii8J	
00b5600c *A@9
00b560a5 ii8J	
00b560b4 *A@9
00b56311 ii8J	
00b56320 *A@9
00b563b9 ii8J	
00b563c8 *A@9
00b56665 j58B
00b56711 cA9h
00b568e5 cA9h
00b56a1c 	A@9
00b56d15 ii8J	
00b56d24 *A@9
00b56dbd ii8J	
00b56dcc *A@9
00b56e3d #@9h
00b56e9d #@9h
00b5733d ii8J	
00b5734c *A@9*
00b573e5 ii8J	
00b573f4 *A@9
00b57a6d yixJ	
00b57a7c *A@9
00b57aae @9h(
00b57b15 yixJ	
00b57b24 *A@9
00b57b56 @9(#
00b57d55 ii8J	
00b57d64 *A@9
00b57e5f R)a5
00b57ea9 @@9h
00b58367 TtZ@
00b5845b R)a5
00b584a5 @@9h
00b585b0 ,ij8k	
00b585c0 KA@9K
00b58d4d C@9h
00b58dad #A9h
00b58efd #A9h
00b59075 ii8J	
00b59084 *A@9
00b5911d ii8J	
00b5912c *A@9
00b5939d ii8J	
00b593ac *A@9
00b59445 ii8J	
00b59454 *A@9
00b594f4 ,ij8k	
00b59504 KA@9K
00b59b45 ii8J	
00b59b54 *A@9
00b59bed ii8J	
00b59bfc *A@9
00b59c6d #@9h
00b59ccd #@9h
00b5a0ad ii8J	
00b5a0bc *A@9
00b5a155 ii8J	
00b5a164 *A@9
00b5a1d5 #@9h
00b5a235 #@9h
00b5a615 yixJ	
00b5a624 *A@9
00b5a656 @9H:
00b5a6bd yixJ	
00b5a6cc *A@9
00b5b0e8 ,ij8k	
00b5b0f8 KA@9+
00b5b181 #@9h
00b5b1c9 D@9h
00b5b1d5 #@9h
00b5b29d #@9(
00b5b518 ,ij8k	
00b5b528 KA@9+
00b5b5b1 #@9h
00b5bb71 j58"
00b5bbfd C@9h
00b5bc1d cA9h
00b5be29 cA9h
00b5bf60 	A@9
00b5c65d #@9h
00b5c920 ,ij8k	
00b5c930 KA@9
00b5c9dd D@9H
00b5c9e9 #@9h
00b5ca6d #@9H
00b5cbc3 *w|@
00b5cc35 yixJ	
00b5cc44 *A@9*
00b5cdd5 yixJ	
00b5cde4 *A@9*y
00b5d32b *!}@
00b5d907 4H_@
00b5e33b 9Jq@
00b5e46f 9Jq@
00b5e591 #A9H
00b5e601 c@9(
00b5e641 c@9(
00b5ea0b RBD(
00b5ec09 yixJ	
00b5ec18 *A@9JG
00b5edc9 cA95
00b5f15d C@9h
00b5f1f5 ii8J	
00b5f204 *A@9*
00b5fd7f RB$!
00b6023d yixJ	
00b6024c *A@9
00b6027e @9H$
00b602e5 yixJ	
00b602f4 *A@9
00b604d9 #@9h
00b609a5 #@9(
00b61495 c@9h
00b614dd c@9h
00b6153d c@9h
00b61995 c@9h
00b619dd c@9h
00b61b59 yixJ	
00b61b68 *A@9j
00b61c01 yixJ	
00b61c10 *A@9*
00b61c7d D@9h
00b637a8 ,ij8k	
00b637b8 KA@9
00b6425f RB$!
00b64e93 RB`;
00b65455 C@9h
00b65565 C@9h
00b658ad C@9h
00b6590d #A9h
00b659bd C@9h
00b659e9 #A9h
00b65e67 RB$!
00b6647d #A9(
00b664dd #A9(
00b66571 C@9h
00b66605 #A9H
00b6675b RB$!
00b66a5d yixJ	
00b66a6c *A@9
00b66a9e @9hU
00b66b05 yixJ	
00b66b14 *A@9
00b66b46 @9(P
00b66bad yixJ	
00b66bbc *A@9jL
00b66d9d CA9h
00b67d75 C@9h
00b67dd5 #A9h
00b67e75 C@9h
00b67ea9 #A9h
00b68093 Rk}<
00b68481 cA9h
00b68551 #B9h
00b6873d cN9h
00b688ed C@9(
00b68916 @9h	
00b68a65 cN9h
00b68a81 cA9h
00b68aa9 #B9h
00b694db RB$!
00b695b5 #@9h
00b69629 &@9)
00b697dc h"@9)
00b697fc 	 @9
00b69a8d C@9h
00b69b1f RB$!
00b6a077 RB$!
00b6a20d C@9h
00b6a54a 	ka	
00b6aa0f RB$!
00b6abe5 C@9h
00b6ae13 RB$!
00b6b083 RB$!
00b6b5a8 ,ij8k	
00b6b5b8 KA@9
00b6b683 R)92
00b6b8cd c@9h
00b6b9a9 c@9(
00b6bd90 ,ij8k	
00b6bda0 KA@9K
00b6be8c ,ij8k	
00b6be9c KA@9K
00b6bf68 ,ij8k	
00b6bf78 KA@9K
00b6c054 ,ij8k	
00b6c064 KA@9K
00b6c314 ,ij8k	
00b6c324 KA@9
00b6c3ad #@9h
00b6cb88 ,ij8k	
00b6cb98 KA@9K
00b6d20c ,ij8k	
00b6d21c KA@9
00b6d81c ,ij8k	
00b6d82c KA@9
00b6dd0b RJ}<
00b6e10d CA9H
00b6eaa1 C@9h
00b6eb01 #A9h
00b6ebb1 C@9h
00b6ebdd #A9h
00b6f99e 69Iq
00b6fed5 C>9I
00b70215 cW9h
00b7025d cV9h
00b702b5 cW9(
00b705a5 C[9h
00b70781 CF9h
00b707f9 #b9h
00b7090d #d9h
00b70955 #c9h
00b709ad #d9(
00b70a2d #e9h
00b70a65 cj9(	
00b70a6e j9h	
00b70a85 CM9(
00b70b85 cj9(
00b70bb5 #L9h
00b70bc5 CM9(
00b70e46 K9h 
00b70e7e M9("
00b70fd9 cV9h
00b71015 cX9h
00b710a5 C[9h
00b7112d CF9h
00b71145 #b9h
00b7118d #c9h
00b711a5 #d9h
00b711c5 #e9h
00b7122d cj9h
00b71255 #L9h
00b714d9 #@9h
00b71563 *w|@
00b715d5 yixJ	
00b715e4 *A@9*
00b71775 yixJ	
00b71784 *A@9*y
00b71ccb *!}@
00b722a7 4H_@
00b73d59 yixJ	
00b73d68 *A@9JG
00b73f19 cA95
00b742ad C@9h
00b74345 ii8J	
00b74354 *A@9*
00b75199 c@9h
00b751ed c@9h
00b758b5 yixJ	
00b758c4 *A@9
00b7595d yixJ	
00b7596c *A@9j
00b759d9 D@9h
00b77aff RBd(
00b77b97 RBd(
00b77bfb RB$)
00b77d15 C@9h
00b77d81 C@9H
00b77dc5 C@9h
00b77e1d C@9h
00b7803b RB$!
00b79d59 C@9h
00b79db9 #A9h
00b79e69 C@9h
00b79e95 #A9h
00b7a474 ,ij8k	
00b7a484 KA@9K
00b7a570 ,ij8k	
00b7a580 KA@9K
00b7a64c ,ij8k	
00b7a65c KA@9K
00b7a738 ,ij8k	
00b7a748 KA@9K
00b7a9f8 ,ij8k	
00b7aa08 KA@9
00b7aa91 #@9h
00b7b1ad C@9h
00b7b5bd C@9h
00b7b6b9 2@9)
00b7b7c8 h"@9)
00b7b7e8 	 @9
00b7ba59 C@9h
00b7bdd1 C@9h
00b7be3f RB$!
00b7c269 C@9h
00b7c6a1 C@9h
00b7ca20 ,ij8k	
00b7ca30 KA@9
00b7cafb R)92
00b7cd45 c@9h
00b7ce21 c@9(
00b7cf68 ,ij8k	
00b7cf78 KA@9
00b7d16c ,ij8k	
00b7d17c KA@9k
00b7d205 #@9h
00b7d540 ,ij8k	
00b7d550 KA@9k
00b7d5d9 #@9h
00b7d8bb Rs"&
00b7dc77 R!(=
00b7dd2d C@9h
00b7ddad C@9h
00b7e0c7 R!(=
00b7e2ed D@9h
00b7e309 #C9h
00b7e359 D@9h
00b7e375 #C9h
00b7eba1 #@9h
00b7ebf5 #@9h
00b7ec55 #@9h
00b7f17d D@9h
00b7f199 #C9h
00b7f1e9 D@9h
00b7f205 #C9h
00b7fa4b R!86
00b7fa8d C@9h
00b7fb05 CB9h
00b7fbc5 CB9(
00b7fc85 C@9h
00b7fcb1 #A9h
00b7fd01 CB9h
00b80042 J9H	
00b80061 #I9H
00b800a1 #F9H
00b800e1 #C9H
00b80121 #@9h
00b80371 cH9H	
00b803b1 cE9H
00b803f1 cB9H
00b80445 CJ9H
00b804c5 CG9H
00b80545 CD9H
00b805c5 CA9H
00b80893 R!86
00b808d5 C@9h
00b80935 #A9h
00b809cd C@9h
00b809e5 #A9h
00b81153 R!86
00b81195 C@9h
00b8120d CB9h
00b812cd CB9(
00b813bd #A9h
00b813e5 CB9h
00b814c5 #@9h
00b8273d A@9(
00b8301d C@9h
00b8307d #A9h
00b8312d C@9h
00b83159 #A9h
00b8361d C@9h
00b83695 CB9h
00b83755 CB9(
00b83855 #A9h
00b83891 CB9h
00b83dbd A@9h
00b84222 @9l9
00b843db Tk	@9
00b8460e @9?p
00b847f1 #@9H
00b84851 #@9(
00b849e9 #@9H
00b84a49 #@9(
00b84b2f 6K	@
00b84b71 "@9h
00b84c7e @9l9
00b84d2d "@9h
00b84db5 C@9h
00b84e11 C@9h
00b84e7e @9l9
00b84f0e @9Hy
00b85055 "@9h
00b8521a @9l9
00b852a5 "@9h
00b8535a @9l9
00b8544d "@9h
00b85501 C@9H
00b85539 "@9h
00b855c5 C@9h
00b855f6 @9l9
00b856d5 C@9h
00b85735 C@9h
00b857ad "@9h
00b85921 "@9h
00b85994 +ih8J	
00b85e52 @9?u
00b85eb5 "@9h
00b86035 "@9h
00b860d9 "@9h
00b865b1 #@9H
00b86611 #@9(
00b86955 #@9H
00b869b5 #@9(
00b86b4d #@9H
00b86bad #@9(
00b86c99 "@9h
00b86ce1 "@9h
00b86de0 h"@9h
00b86e05 C@9h
00b86ed1 "@9h
00b86f0a @9l9
00b87021 "@9h
00b8705a @9l9
00b8711d "@9h
00b871f2 @9l9
00b872a2 @9l9
00b87379 "@9h
00b873fa @9l9
00b8752d "@9h
00b8756e @9l9
00b87639 "@9h
00b8772f 2<!@
00b87754 	A@9
00b878a1 "@9h
00b878f2 @9l9
00b879c1 zhx)	
00b879f5 #@9h
00b87a79 #@9h
00b87ae9 #@9h
00b87b55 #@9h
00b87bc9 #@9h
00b87c3d #@9h
00b87d5e @9l9
00b87f32 @9l9
00b87fe2 @9l9
00b880b9 "@9h
00b880f2 @9l9
00b88222 @9l9
00b8832d "@9h
00b8837d "@9h
00b88505 "@9h
00b88559 "@9h
00b88592 @9l9
00b887dd #@9H
00b8883d #@9(
00b889d5 #@9H
00b88a35 #@9(
00b88bcd #@9H
00b88c2d #@9(
00b88cd5 "@9h
00b88e4d "@9h
00b88ead C@9h
00b88efd C@9h
00b88f75 "@9h
00b88fd5 C@9h
00b89025 C@9h
00b8909d "@9h
00b890f9 C@9h
00b89149 C@9h
00b89281 #@9(
00b892c1 #@9(
00b89321 #@9(
00b893ad "@9h
00b89419 "@9h
00b89605 "@9h
00b89666 @9l9
00b89729 "@9h
00b897ad "@9h
00b89991 "@9h
00b89bc9 #@9H
00b89c29 #@9(
00b89ce5 "@9h
00b89d42 @9l9
00b89dfd "@9h
00b89e5d "@9h
00b89e96 @9l9
00b89f55 "@9h
00b89fb0 H#@9h
00b8a15a @9l9
00b8a219 "@9h
00b8a2a5 c@9h
00b8a331 c@9h
00b8a54a @9l9
00b8a65d "@9h
00b8a696 @9l9
00b8a74d "@9h
00b8a7f9 "@9h
00b8a83d "@9h
00b8a87d "@9h
00b8a8d2 @9l9
00b8aa4d "@9h
00b8aa91 "@9h
00b8aad1 "@9h
00b8ab4d c@9h
00b8ac89 "@9h
00b8acc2 @9l9
00b8ae55 "@9h
00b8ae99 "@9h
00b8aedd "@9h
00b8af1d "@9h
00b8af61 "@9h
00b8b025 "@9h
00b8b19d #@9(
00b8b1dd #@9(
00b8b23d #@9(
00b8b4aa @9K9
00b8b4d2 @9_)
00b8ba5d #@9H
00b8babd #@9(
00b8bbbb osj@
00b8bf1d #@9H
00b8bf7d #@9(
00b8c07b osj@
00b8c6b3 R)M*
00b8c9a9 ki8JE@9_
00b8ca39 ki8JE@9_
00b8ca8b =		@
00b8cd07 4hB@9h
00b8ce6c kC@9l
00b8cfbc 	A@9
00b8cfe4 	A@9
00b8d014 	A@9
00b8d199 ji8JE@9_
00b8d241 ji8JE@9_
00b8d405 #@9H
00b8d465 #@9(
00b8d563 osj@
00b8deef osj@
00b8e1b7 osj@
00b8e47f osj@
00b8e747 osj@
00b8ea0f osj@
00b8ecd7 osj@
00b8ef9f osj@
00b8f267 osj@
00b8f52f osj@
00b8f7fb osj@
00b8fc17 R)M*
00b8fc77 RJi6
00b8ff03 RJ5 
00b902db R!|7
00b90613 R!|7
00b90947 R!|7
00b90b18 ,ij8k	
00b90b28 KA@9
00b90cdc ,ij8k	
00b90cec KA@9
00b90fb8 ,ij8k	
00b90fc8 KA@9
00b912f7 R!T8
00b91603 R!T8
00b917cc ,ij8k	
00b917dc KA@9
00b91990 ,ij8k	
00b919a0 KA@9
00b93865 C@9h
00b938c5 #A9h
00b93a09 #A9h
00b93b9c ,ij8k	
00b93bac KA@9
00b9919c h"@9)
00b991bc 	 @9
00b99335 #@9h
00b995f4 ,ij8k	
00b99604 KA@9
00b99d79 C@9h
00b99dd9 #A9h
00b99f1d #A9h
00b9a0b0 ,ij8k	
00b9a0c0 KA@9
00b9a75d C@9h
00b9a7bd #A9h
00b9a901 #A9h
00b9aa8c ,yjxk	
00b9aa9c KA@9
00b9ac3d #@9h
00b9b209 C@9h
00b9b269 #A9h
00b9b3ad #A9h
00b9b540 ,ij8k	
00b9b550 KA@9
00b9bb5d C@9h
00b9bbbd #A9h
00b9bd11 #A9H
00b9bec4 ,ij8k	
00b9bed4 KA@9
00b9cb71 #@9h
00b9cee4 ,yjxk	
00b9cef4 KA@9
00b9cf26 @9('
00b9d035 #@9h
00b9d0ad #@9h
00b9d8f7 R)5:
00b9d951 @@9h
00b9d971 #@9h
00b9db59 D@9(
00b9dbd8 ,ij8k	
00b9dbe8 KA@9K
00b9eb89 cB9h
00b9ec99 cB9h
00b9f449 C@9h
00b9fa87 R)5:
00b9fae1 @@9h
00b9fb01 #@9h
00b9fd14 ,ij8k	
00b9fd24 KA@9
00b9fdd9 D@9h
00ba07f5 cB9h
00ba0905 cB9h
00ba1037 R)5:
00ba1091 @@9h
00ba10b1 #@9h
00ba12c4 ,ij8k	
00ba12d4 KA@9
00ba1e3d CA9(
00ba1ebd CA9(
00ba1ff9 CA9H
00ba22d1 C@9(
00ba2311 C@9(
00ba23d1 C@9h
00ba2739 C@9(
00ba2779 C@9(
00ba2839 C@9h
00ba28fd C@9h
00ba2c21 C@9h
00ba2fd5 C@9h
00ba34f3 k$	@
00ba357b *!|B
00ba373b k$	@
00ba37ef *!|B
00ba3863 7hB@9
00ba3878 hB@9h
00ba38ef *!|B
00ba396f *!|B
00ba3d17 o{k@
00ba3d26 @9kC
00ba3f13 o{k@
00ba3f22 @9kC
00ba40be 	k,>
00ba40e3 6h:@
00ba4190 Oin8/
00ba4207 *!|B
00ba429c Oin8/
00ba4313 *!|B
00ba4337 Th.@
00ba4400 jkh8)	
00ba4442 @9?}
00ba4523 *!|B
00ba4604 hB@9t
00ba467b *!|B
00ba46eb *!|B
00ba4783 *!|B
00ba47fb *!|B
00ba4873 *!|B
00ba4917 *!|B
00ba499f *!|B
00ba4a4b *!|B
00ba4ad3 *!|B
00ba4b77 *!|B
00ba4c1b *!|B
00ba4c8b *!|B
00ba4cfb *!|B
00ba4d6b *!|B
00ba4ddb *!|B
00ba4e4b *!|B
00ba4ebb *!|B
00ba4f2b *!|B
00ba4f9b *!|B
00ba500b *!|B
00ba507b *!|B
00ba5275 #@9h
00ba8157 T,	@
00ba85cd j58h
00ba864d j58h
00ba879b 6`.@
00ba8837 6`.@
00ba8981 CA9(
00ba8a21 CA9(
00ba8b0f 7hb@9H
00ba8b34 hb@9
00ba8ce8 hb@9h
00ba8dc4 ?k88
00ba8fde @9*s
00ba9065 cD9h
00ba9240 ?k88
00ba94dd cD9h
00ba96b8 ?k88yC
00ba9975 cD9h
00ba9b58 ?k88QB
00ba9e6d #D9h
00baa17d cD9h
00baa323 *J}@
00baa4bb 6`*@
00baa6b6 A9_k98
00baa80f *J}@
00baa9a7 6`*@
00baab3d k:8X>
00baaba2 A9_k98
00baade1 cB9h
00baaf85 #B9h
00baafe5 cA9h
00bab1cf 6`*@
00bab29b 6`"@
00bab400 ?k78
00bab444 ?k78
00bab5e9 C@9h
00babd83 *!XC
00babda9 #@9h
00babdb1 CA9H
00babecf T(8@
00bac142 @9l9
00bac2d1 "@9h
00bac81b 6#!@
00bacab3 Tz2@
00bad1b1 #@9(
00bad1f1 #@9(
00bad46b =8	@
00badbd1 ki8JE@9_
00badc61 ki8JE@9_
00badcb3 =		@
00badf4d 80.i
00baead9 @@9h
00baeae8 hBA9
00baeb33 6`&@
00baec3f Tu.@
00baeedd ji8JE@9_
00baef85 ji8JE@9_
00baf061 80.	
00baf495 ki8JE@9_
00baf525 ki8JE@9_
00baf607 =a"@
00baf96b <_}<
00bb038d C@9h
00bb03ed #A9h
00bb0495 C@9h
00bb04c1 #A9h
00bb0881 C@9h
00bb08f9 cB9h
00bb09b5 cB9H
00bb0a4d C@9h
00bb0a79 #A9h
00bb0ab5 cB9h
00bb0f7d #C9h
00bb0fc9 CB9H
00bb1039 #C9H
00bb1115 CB9h
00bb1141 #C9h
00bb15d9 #C9h
00bb1625 CB9H
00bb1695 #C9H
00bb1771 CB9h
00bb179d #C9h
00bb1af1 C@9h
00bb1b51 #A9h
00bb1c01 C@9h
00bb1c2d #A9h
00bb1f49 C@9h
00bb1fa9 #A9h
00bb2059 C@9h
00bb2085 #A9h
00bb26f9 cA9h
00bb2b31 C@9h
00bb2ba9 CB9h
00bb2c65 CB9H
00bb2d05 C@9h
00bb2d31 #A9h
00bb2d6d CB9h
00bb3be3 6K	@
00bb3c0f Ti#@
00bb3c37 6K	@
00bb3cc7 4h.@
00bb3d27 Tvj@
00bb4cf7 T(G@
00bb4d73 T(#@
00bb4deb T(_@
00bb5365 #E9H
00bb5abf <HQ@
00bb5c4d cB9h
00bb6379 cG9H
00bb6633 *!lA
00bb669b *!lA
00bb67af *!lA
00bb69be K9(#
00bb6ab9 #V9h
00bb6cdd cB9h
00bb6d05 #E9H
00bb6e25 CL9h
00bb6ec1 #E9h
00bb6f01 CF9h
00bb6f59 cG9h
00bb6f71 #H9h
00bb7237 o{k@
00bb7246 @9kC
00bb75f7 oZk@
00bb7606 @9KC
00bb77cf oZk@
00bb77de @9KC
00bb79a7 oZk@
00bb79b6 @9KC
00bb7b83 o{k@
00bb7b92 @9kC
00bb7d7b oZk@
00bb7d8a @9KC
00bb7f53 oZk@
00bb7f62 @9KC
00bb8303 oZk@
00bb8312 @9KC
00bb84db oZk@
00bb84ea @9KC
00bb87e1 #@9h
00bb8da1 C@9h
00bb8e19 CB9h
00bb8ed9 CB9(
00bb900d #A9h
00bb9049 CB9h
00bb9868 jkh8)	
00bb9878 	A@9)
00bb98f7 2s~C
00bba07d ii8J	
00bba08c *A@9
00bba125 ii8J	
00bba134 *A@9J
00bbad8b 2)!@
00bbadfd ii8J	
00bbae0c *A@9
00bbae43 6h*@
00bbaea1 D@9h
00bbafb9 ii8J	
00bbafc8 *A@9
00bbc831 ii8J	
00bbc840 *A@9
00bbc8a9 C@9h
00bbc8fd C@9h
00bbeb64 +ih8J	
00bbf57b T-	@
00bbf583 rn	@
00bbf821 kh8)	
00bbf830 	A@9
00bbf84c 	A@9i
00bbffcd c@9(
00bc0005 c@9h
00bc0fbf 4i*@
00bc1e74 +ih8J	
00bc2333 6h*@
00bc2c70 ,ij8k	
00bc2c80 KA@9
00bc36f3 RB`;
00bc38e9 C@9h
00bc39f1 C@9h
00bc3b5b RB`;
00bc3dc1 C@9h
00bc3f0d C@9h
00bc4077 RB`;
00bc42a1 C@9h
00bc4301 #A9h
00bc43e5 C@9h
00bc4411 #A9h
00bc4771 C@9h
00bc47d1 #A9h
00bc48ad C@9h
00bc48d9 #A9h
00bc4c4d C@9h
00bc4cad #A9h
00bc4d5d C@9h
00bc4d89 #A9h
00bc4ec7 RB`;
00bc51cd C@9h
00bc522d #A9h
00bc5309 C@9h
00bc533d #A9h
00bc549b RB`;
00bc5659 C@9h
00bc56b9 #A9h
00bc5761 C@9h
00bc578d #A9h
00bc58f3 RB`;
00bc5b49 C@9h
00bc5c61 C@9h
00bc5e03 RB`;
00bc6031 C@9h
00bc6099 cA9H
00bc6171 C@9h
00bc61a5 cA9(
00bc61c5 cA9(
00bc635b RB`;
00bc65b1 C@9h
00bc670d C@9h
00bc68c3 RB`;
00bc6b35 C@9h
00bc6c79 C@9h
00bc6e07 RB`;
00bc7031 C@9h
00bc7141 C@9h
00bc72ab RB`;
00bc74ed C@9h
00bc754d #A9h
00bc7629 C@9h
00bc7655 #A9h
00bc7793 RB`;
00bc79d5 C@9h
00bc7a35 #A9h
00bc7b11 C@9h
00bc7b3d #A9h
00bc7e5d C@9h
00bc7ebd #A9h
00bc7f65 C@9h
00bc7f91 #A9h
00bc82dd C@9h
00bc8345 cA9H
00bc8431 C@9h
00bc8465 cA9(
00bc8485 cA9(
00bc85fb RBl 
00bc87e5 C@9h
00bc8845 #A9h
00bc88f5 C@9h
00bc8921 #A9h
00bc8c8d C@9h
00bc8cf5 cA9H
00bc8de1 C@9h
00bc8e15 cA9(
00bc8e35 cA9(
00bc9117 RB$!
00bc93ad C@9h
00bc941d #B9H
00bc9509 #B9(
00bc9539 #C9(
00bc9561 #B9h
00bc959d C@9h
00bc95e9 #B9(
00bc9629 #B9(
00bc981f RB$!
00bc9a51 C@9h
00bc9bd1 C@9h
00bca129 C@9h
00bca189 #A9h
00bca2d5 #A9h
00bca651 C@9h
00bca6b1 #A9h
00bca761 C@9h
00bca78d #A9h
00bca861 S	9IA
00bcad55 CD9h
00bcada5 CB9h
00bcadfd #C9(
00bcae15 #C9h
00bcae95 CD9(
00bcaf91 CB9h
00bcafbd #C9h
00bcaff9 CD9h
00bcb12f RB$!
00bcb3ff RB$!
00bcb9f5 C@9h
00bcba55 #A9H
00bcbb75 C@9h
00bcbd17 RB$!
00bcbed1 C@9h
00bcbf31 #A9h
00bcbfd9 C@9h
00bcc005 #A9h
00bcc371 C@9h
00bcc3d1 #A9h
00bcc481 C@9h
00bcc4ad #A9h
00bcc875 C@9h
00bcc975 C@9h
00bccb0b RB`;
00bccd05 C@9h
00bcce0d C@9h
00bccfb7 RB`;
00bcd23d C@9h
00bcd2a5 cA9H
00bcd375 C@9h
00bcd395 cA9H
00bcd3b9 cA9(
00bcd3d9 cA9(
00bcd731 C@9h
00bcd839 C@9h
00bcdc35 C@9h
00bcdc95 #A9h
00bcdd79 C@9h
00bcdda5 #A9h
00bcdec8 ,ij8k	
00bcded8 KA@9K
00bce194 ,ij8k	
00bce1a4 KA@9
00bce329 #@9h
00bce38d #@9h
00bce5a5 CA9h
00bce8b0 IA@9I
00bce9b4 (A@9
00bcea03 Tlyj
00bcea3d CA9h
00bcf40c ,ij8k	
00bcf41c KA@9
00bcf4cd D@9h
00bcf735 #@9h
00bcf799 #@9h
00bcf8ad #@9h
00bcfd07 R9O+
00bcfd68 *kh8)	
00bcfd78 	A@9)
00bcfe5e 	K:}@
00bcfe6a WzM 
00bd0ae0 ,yjxk	
00bd0af0 KA@9k:
00bd0c4d c@9h
00bd1f85 ii8J	
00bd1f94 *A@9
00bd2095 ii8J	
00bd20a4 *A@9
00bd2149 ii8J	
00bd2158 *A@9*
00bd224d ii8J	
00bd225c *A@9j
00bd230d ii8J	
00bd231c *A@9j
00bd3c98 ,yjxk	
00bd3ca8 KA@9
00bd3e41 cA9h
00bd43b1 #@9h
00bd52c4 ,ij8k	
00bd52d4 KA@9
00bd5440 ,ij8k	
00bd5450 KA@9
00bd55bc ,ij8k	
00bd55cc KA@9
00bd5759 ii8J	
00bd5768 *A@9
00bd5801 ii8J	
00bd5810 *A@9
00bd5929 D@9h
00bd60bc ,ij8k	
00bd60cc KA@9
00bd6258 ,yjxk	
00bd6268 KA@9
00bd6c04 ,yjxk	
00bd6c14 KA@9+;
00bd6e96 	K)}@
00bd7939 #C9h
00bd79b4 ,ij8k	
00bd79c4 KA@9
00bd79f1 #C9h
00bd8251 #C9h
00bd82cc ,ij8k	
00bd82dc KA@9
00bd8309 #C9h
00bd89b9 ii8J	
00bd89c8 *A@9
00bd8b51 ii8J	
00bd8b60 *A@9
00bd8bf9 ii8J	
00bd8c08 *A@9
00bd9710 ,ij8k	
00bd9720 KA@9
00bd9a7c ,ij8k	
00bd9a8c KA@9
00bd9b68 ,ij8k	
00bd9b78 KA@9k
00bd9c5c ,ij8k	
00bd9c6c KA@9
00bd9d51 D@9H
00bda54c ,ij8k	
00bda55c KA@9
00bda6cc ,ij8k	
00bda6dc KA@9
00bda865 ii8J	
00bda874 *A@9j
00bda90d ii8J	
00bda91c *A@9*
00bda9b5 ii8J	
00bda9c4 *A@9
00bdad7c ,ij8k	
00bdad8c KA@9+
00bdaf91 ii8J	
00bdafa0 *A@9
00bdb039 ii8J	
00bdb048 *A@9
00bdb69c 	A@9
00bdb6f7 Th*@
00bdbad1 yixJ	
00bdbae0 *A@9
00bdbb79 ii8J	
00bdbb88 *A@9j
00bdbc75 D@9h
00bdbc89 C@9h
00bdbde3 TH}@
00bdc349 yixJ	
00bdc358 *A@9
00bdc38a @9H%
00bdc43d ii8J	
00bdc44c *A@9
00bdc6df S)}@
00bdc7d3 Th*@
00bdd1e8 ,ij8k	
00bdd1f8 KA@9
00bdd49c ,yjxk	
00bdd4ac KA@9
00bdd4de @9h+
00bdd501 @@9H* 6
00bdd9ef Thjw
00bde305 c@9h
00bde345 c@9h
00bde4d5 c@9h
00bde95b RB`;
00bdeb55 C@9h
00bdebb5 #A9h
00bdec5d C@9h
00bdec89 #A9h
00bdefb5 C@9h
00bdf015 #A9h
00bdf0bd C@9h
00bdf0e9 #A9h
00bdf227 RB`;
00bdf451 C@9h
00bdf4b1 #A9h
00bdf595 C@9h
00bdf5c1 #A9h
00bdf925 C@9h
00bdf985 #A9h
00bdfa69 C@9h
00bdfa95 #A9h
00bdfdb1 C@9h
00bdfe11 #A9h
00bdfec1 C@9h
00bdfeed #A9h
00be01fd C@9h
00be025d #A9h
00be0305 C@9h
00be0331 #A9h
00be0669 C@9h
00be06c9 #A9h
00be0779 C@9h
00be07a5 #A9h
00be0afd C@9h
00be0b5d #A9h
00be0c0d C@9h
00be0c39 #A9h
00be1025 C@9h
00be1085 #A9h
00be112d C@9h
00be1161 #A9h
00be1479 C@9h
00be14d9 #A9h
00be1581 C@9h
00be15ad #A9h
00be1723 RB`;
00be1951 C@9h
00be19b9 cA9H
00be1a91 C@9h
00be1ac5 cA9(
00be1ae5 cA9(
00be1c23 RB`;
00be1e55 C@9h
00be1eb5 #A9h
00be1f5d C@9h
00be1f89 #A9h
00be22e9 C@9h
00be2349 #A9h
00be23f1 C@9h
00be241d #A9h
00be25b3 RB`;
00be2809 C@9h
00be2965 C@9h
00be2b1b RB`;
00be2d71 C@9h
00be2e81 C@9h
00be3255 C@9h
00be3365 C@9h
00be3759 C@9h
00be389d C@9h
00be3c49 C@9h
00be3d59 C@9h
00be409d C@9h
00be40fd #A9h
00be41a5 C@9h
00be41d1 #A9h
00be44e9 C@9h
00be4549 #A9h
00be45f1 C@9h
00be461d #A9h
00be4935 C@9h
00be4995 #A9h
00be4a3d C@9h
00be4a69 #A9h
00be4db1 C@9h
00be4e19 cA9H
00be4f05 C@9h
00be4f39 cA9(
00be4f59 cA9(
00be52ad C@9h
00be530d #A9h
00be53bd C@9h
00be53e9 #A9h
00be58e5 C@9h
00be5a9d C@9h
00be5ad9 #A9h
00be601d C@9h
00be61d5 C@9h
00be6211 #A9h
00be6575 C@9h
00be65d5 #A9h
00be667d C@9h
00be66a9 #A9h
00be69b1 C@9h
00be6a11 #A9h
00be6ab9 C@9h
00be6ae5 #A9h
00be70ad C@9h
00be710d #A9h
00be71b5 C@9h
00be71e1 #A9h
00be7531 C@9h
00be7639 C@9h
00be79f9 C@9h
00be7a61 cA9H
00be7b39 C@9h
00be7b6d cA9(
00be7b8d cA9(
00be7ee9 S	9)
00be8681 C@9h
00be86e1 #A9h
00be8789 C@9h
00be87b5 #A9h
00be8ca9 c@9h
00be8cfd c@9h
00be9509 #@9h
00be9559 #@9h
00be98ad C@9h
00be9915 cA9H
00be9a01 C@9h
00be9a35 cA9(
00be9a55 cA9(
00be9dbd C@9h
00be9e25 cA9H
00be9efd C@9h
00be9f31 cA9(
00be9f51 cA9(
00bea2b9 C@9h
00bea321 cA9H
00bea3f9 C@9h
00bea42d cA9(
00bea44d cA9(
00bea79d C@9h
00bea7fd #A9h
00bea8a5 C@9h
00bea8d1 #A9h
00beacbd C@9h
00bead1d #A9h
00beadc5 C@9h
00beadf9 #A9h
00beb1a1 C@9h
00beb2b1 C@9h
00beb5f5 C@9h
00beb655 #A9h
00beb6fd C@9h
00beb729 #A9h
00bebaf1 C@9h
00bebc35 C@9h
00bebf79 C@9h
00bebfd9 #A9h
00bec081 C@9h
00bec0ad #A9h
00bec3c5 C@9h
00bec425 #A9h
00bec4cd C@9h
00bec4f9 #A9h
00bec5cd S	9IA
00becab5 CD9h
00becb05 CB9h
00becb5d #C9(
00becb75 #C9h
00becbf5 CD9(
00beccf1 CB9h
00becd1d #C9h
00becd59 CD9h
00bed081 C@9h
00bed181 C@9(
00bed511 C@9h
00bed571 #A9h
00bed621 C@9h
00bed64d #A9h
00bed8fd c@9h
00bed975 c@9h
00bedcf9 C@9h
00bedd59 #A9h
00bede01 C@9h
00bede2d #A9h
00bee225 C@9h
00bee79d C@9h
00bee7fd #A9H
00bee91d C@9h
00beeaff RB`;
00beed25 C@9h
00beed8d cA9H
00beee65 C@9h
00beee99 cA9(
00beeeb9 cA9(
00beefdc ,ij8k	
00beefec KA@9K
00bef344 HC@9H
00bef498 HC@9
00befb48 HC@9H
00befc9c HC@9
00bf030c ,ij8k	
00bf031c KA@9
00bf0510 ,ij8k	
00bf0520 KA@9k
00bf0585 A@9H
00bf089c ,ij8k	
00bf08ac KA@9
00bf0cd8 *kh8)	
00bf0ce8 	A@9)
00bf0dce 	K:}@
00bf0dda WzM 
00bf140c ,yjxk	
00bf141c KA@9
00bf1f94 ,yjxk	
00bf1fa4 KA@9
00bf1fd6 @9('
00bf2055 D@9h0
00bf2acd ii8J	
00bf2adc *A@9
00bf2bd9 ii8J	
00bf2be8 *A@9
00bf2c8d ii8J	
00bf2c9c *A@9*
00bf2d91 ii8J	
00bf2da0 *A@9j
00bf2e51 ii8J	
00bf2e60 *A@9j
00bf3f00 ,ij8k	
00bf3f10 KA@9
00bf40a9 cA9h
00bf45b1 #@9h
00bf47f0 ,ij8k	
00bf4800 KA@9
00bf496c ,ij8k	
00bf497c KA@9
00bf4ae8 ,ij8k	
00bf4af8 KA@9
00bf4c64 ,ij8k	
00bf4c74 KA@9
00bf4de0 ,ij8k	
00bf4df0 KA@9
00bf4f5c ,ij8k	
00bf4f6c KA@9
00bf50f9 ii8J	
00bf5108 *A@9
00bf51a1 ii8J	
00bf51b0 *A@9
00bf52c9 D@9h
00bf57c4 ,ij8k	
00bf57d4 KA@9
00bf5960 ,yjxk	
00bf5970 KA@9
00bf59a2 @9h 
00bf5aa1 c@9h
00bf6024 ,yjxk	
00bf6034 KA@9KC
00bf6165 #A9h
00bf62c5 A@9(-
00bf63aa 	K)}@
00bf6bd9 #C9h
00bf6c54 ,ij8k	
00bf6c64 KA@9
00bf6c91 #C9h
00bf7321 #C9h
00bf739c ,ij8k	
00bf73ac KA@9
00bf73d9 #C9h
00bf7a89 ii8J	
00bf7a98 *A@9
00bf7c21 ii8J	
00bf7c30 *A@9
00bf7cc9 ii8J	
00bf7cd8 *A@9
00bf8220 ,ij8k	
00bf8230 KA@9
00bf8414 ,ij8k	
00bf8424 KA@9+
00bf8635 yixJ	
00bf8644 *A@9
00bf86dd ii8J	
00bf86ec *A@9j
00bf87d9 D@9h
00bf87ed C@9h
00bf8947 TH}@
00bf8cdc ,ij8k	
00bf8cec KA@9
00bf8f8b q9ih
00bf9288 ,ij8k	
00bf9298 KA@9K
00bf9484 *kh8)	
00bf9494 	A@9)
00bf9559 C@9h
00bf9b8c ,ij8k	
00bf9b9c KA@9k
00bfa510 ,yjxk	
00bfa520 KA@9K%
00bfa801 CA9H
00bfaecb T({z
00bfb0d5 CA9(
00bfb339 ii8J	
00bfb348 *A@9
00bfb445 ii8J	
00bfb454 *A@9
00bfb4f9 ii8J	
00bfb508 *A@9*
00bfb5fd ii8J	
00bfb60c *A@9j
00bfb6bd ii8J	
00bfb6cc *A@9j
00bfc68c ,ij8k	
00bfc69c KA@9
00bfc809 #C9h
00bfc884 ,ij8k	
00bfc894 KA@9
00bfc8c1 #C9h
00bfcf71 ii8J	
00bfcf80 *A@9
00bfd019 ii8J	
00bfd028 *A@9
00bfd141 D@9h
00bfd658 ,ij8k	
00bfd668 KA@9
00bfd7a5 c@9h
00bfd7e5 A@9h
00bfd8e7 Tizi
00bfdcb0 ,yjxk	
00bfdcc0 KA@9
00bfe3e1 c@9h
00bfe530 ,ij8k	
00bfe540 KA@9
00bfe61c ,ij8k	
00bfe62c KA@9k
00bfe710 ,ij8k	
00bfe720 KA@9
00bfe805 D@9H
00bfee84 ,yjxk	
00bfee94 KA@9
00bff9d4 ,yjxk	
00bff9e4 KA@9+#
00bffb61 #@9h
00c00109 ii8J	
00c00118 *A@9j
00c001b1 ii8J	
00c001c0 *A@9*
00c003b3 T(}@
00c0071d ii8J	
00c0072c *A@9j
00c007c5 ii8J	
00c007d4 *A@9*
00c0086d ii8J	
00c0087c *A@9
00c00bdc ,ij8k	
00c00bec KA@9
00c00e8b q9ih
00c01133 TIyw
00c01818 ,yjxk	
00c01828 KA@9
00c0185a @9(P
00c01b33 =)	@
00c01b70 HC@9h
00c03268 ,ij8k	
00c03278 KA@9
00c03b1b Th.@
00c03bff Th>@
00c03ce3 Thn@
00c04189 c@9h
00c04533 osj@
00c04c33 T*E@
00c04d17 TKE@
00c04e23 TLE@
00c04edf T*E@
00c05369 c@9h
00c05885 c@9h
00c05af7 T E@
00c05bdb T@E@
00c05ce7 T@E@
00c05da3 T E@
00c0622d c@9h
00c07109 C@9H
00c074d1 c@9h
00c07529 c@9H
00c08599 C@9h
00c08905 c@9h
00c0895d c@9h
00c08b81 #@9h
00c09ee9 #@9h
00c0a509 C@9h
00c0a965 ii8J	
00c0a974 *A@9j
00c0aba5 ii8J	
00c0abb4 *A@9j
00c0b0d4 ,ij8k	
00c0b0e4 KA@9
00c0bffd CA9h
00c0c56f R)M<
00c0c881 #@9h
00c0c974 ,ij8k	
00c0c984 KA@9
00c0cd79 #@9(
00c0d257 =)	@
00c0d449 c@9h
00c0d5a5 c@9H
00c0dac6 @9(	
00c0dfb3 =)	@
00c0e701 c@9h
00c0e941 c@9(
00c0ee4d C@9h
00c0f3c9 #@9h
00c0fd5d #>)(
00c0fd8c +ih8J	
00c1007d #@9(
00c1009d #@9(
00c10337 *)!;
00c10340 +ih8J	
00c10383 rJ1,
00c1041b 9)Q@
00c1048f 4j"@
00c104a7 6iB@9
00c1051f TTil
00c106f1 c@9h
00c1096f 4j"@
00c10987 6iB@9
00c109ff TTil
00c10bd1 c@9h
00c11289 B@9(
00c112cb 2J}C
00c1131b 25yw
00c113af 25yw
00c11435 B@9(
00c11477 2J}C
00c114c7 25yw
00c1155b 25yw
00c115f3 RZK;
00c11618 Jkh8)	
00c11868 +ih8J	
00c11ac9 #@9h
00c11b85 #@9h
00c11cc9 #@9h
00c11d85 #@9h
00c12058 hB@9
00c12381 !@9n
00c12667 R{O<
00c12898 hB@9y
00c12964 hB@9u
00c131b4 hB@9t
00c13f78 	@@9i
00c14131 #@9(
00c14210 	A@9i
00c142df o9k@
00c150d3 R	D@
00c1522b Ti"@
00c159e5 ki8JE@9_
00c15a75 ki8JE@9_
00c15adb Ra"@
00c15d2b 4hB@9h
00c15e90 kC@9l
00c15fe0 	A@9
00c16008 	A@9
00c16038 	A@9
00c161bd ji8JE@9_
00c16265 ji8JE@9_
00c16421 ki8JE@9_
00c164b1 ki8JE@9_
00c16517 Ra"@
00c16767 4hB@9h
00c168cc kC@9l
00c16a1c 	A@9
00c16a44 	A@9
00c16a74 	A@9
00c16b83 osj@
00c17995 C@9h
00c17cc9 #@9(
00c17d29 #@9(
00c17dfb 5h:@
00c17e07 Th.@
00c17eaf TH[@
00c17fdb THC@9
00c17fe2 '6i"@
00c1801c HC@9
00c18022 ?6i"@
00c18acb T`F@
00c18c71 C@9H
00c18d3f T`^@
00c190d7 T yt
00c191c5 #@9(
00c19225 #@9(
00c1929f T yt
00c1938d #@9(
00c193ed #@9(
00c196e3 T yt
00c197d1 #@9(
00c19831 #@9(
00c198ab T yt
00c19999 #@9(
00c199f9 #@9(
00c19b89 ki8JE@9_
00c19c19 ki8JE@9_
00c19c7f Ra"@
00c19ecf 4hB@9h
00c1a034 kC@9l
00c1a184 	A@9
00c1a1ac 	A@9
00c1a1dc 	A@9
00c1a361 ji8JE@9_
00c1a409 ji8JE@9_
00c1a5a9 ji8JE@9_
00c1a651 ji8JE@9_
00c1a7f1 ji8JE@9_
00c1a899 ji8JE@9_
00c1aa13 o9k@
00c1b011 ji8JE@9_
00c1b0b9 ji8JE@9_
00c1b259 ji8JE@9_
00c1b301 ji8JE@9_
00c1b4c4 +ki8JE@9_
00c1b554 +ki8JE@9_
00c1b5cb Ra"@
00c1b815 @@9h
00c1b834 hB@9h
00c1b998 kC@9l
00c1bae8 	A@9
00c1bb10 	A@9
00c1bb40 	A@9
00c1bcc5 ji8JE@9_
00c1bd6d ji8JE@9_
00c1bf29 ki8JE@9_
00c1bfb9 ki8JE@9_
00c1c033 Ra"@
00c1c2a0 hB@9h
00c1c404 kC@9l
00c1c554 	A@9
00c1c57c 	A@9
00c1c5ac 	A@9
00c1c6d7 T yt
00c1c7c5 #@9(
00c1c825 #@9(
00c1c9c1 #@9(
00c1ca21 #@9(
00c1cb4b TK	@
00c1cb8f TK	@
00c1cfa5 #@9H
00c1d05f T	(@
00c1d0e7 TK	@
00c1d12b TK	@
00c1d37d #@9(
00c1d3dd #@9(
00c1d7c7 4hb@9h
00c1db85 ki8JE@9_
00c1dc15 ki8JE@9_
00c1dc87 Ra"@
00c1dedc hB@9h
00c1e0d8 kC@9l
00c1e228 	A@9
00c1e250 	A@9
00c1e280 	A@9
00c1e819 ki8JE@9_
00c1e8a9 ki8JE@9_
00c1f1f9 ki8JE@9_
00c1f289 ki8JE@9_
00c1f8a6 	kiB
00c1f90e 	kiZ
00c1f976 	kir
00c1fe37 Ttj@
00c1fef7 Ti&@
00c1ff1f 6K	@
00c1ff47 Th2@
00c1ff6f Th>@
00c1ff97 ThJ@
00c1ffb5 B@9(
00c2008f 6h^@
00c200bb 6hb@
00c200e7 6hf@
00c20112 '6`j@
00c2011e /6`n@
00c2012a 06tr@
00c2016a 86tv@
00c20233 Ti2@
00c2025b 6K	@
00c202d7 6hf@
00c20303 6hj@
00c2032f 6`n@
00c203cf Th"@
00c203f7 Th.@
00c2041f Th:@
00c20447 ThF@
00c2046f ThR@
00c2050f 6ib@
00c2053b 6hf@
00c20768 jyhx)	
00c20841 -87(
00c20960 	U@8?
00c20990 z"E)_
00c209b4 z"E)_
00c209dc z"E)_
00c20ce6 @9x	87
00c21843 Tj&@
00c2188b Tj2@
00c218db Ti>@
00c2192b TiJ@
00c2197b TiV@
00c219f6 86`v@
00c21a2e @6hz@
00c21adf 6h^@
00c21b23 6hb@
00c21b67 6hf@
00c21baa '6`j@
00c21bda /6`n@
00c21c0a 76`r@
00c21c44 	!@9
00c21d6a 	kiB
00c21dce 	kiZ
00c21e32 	kir
00c21f26  75	(75
00c22322 	kiZ
00c22692 	ki"
00c226f6 	ki:
00c22742 	K.j
00c2275a 	kiR
00c227be 	kij
00c228d2 	K`I
00c229c0 (@@9
00c22a10 +ih8J	
00c22a79 B@9H
00c22c75 B@9h
00c235af Tb^@
00c23914 	!@9
00c23c46 	ki"
00c23cae 	ki:
00c23d16 	kiR
00c23fb3 6K	@
00c23fdb Ti"@
00c24003 6K	@
00c2402b Th.@
00c24093 6i6@
00c240bf 6i:@
00c240eb 6h>@
00c241e8 jih8)	
00c24583 Tb^@
00c24af7 Ti:@
00c24b1f Tj"@
00c24b67 Tj.@
00c24bd3 6h>@
00c24c77 6i6@
00c24cbb 6i:@
00c24d08 	!@9
00c24dae 	ki"
00c24e12 	ki:
00c24e5e 	K @
00c24e76 	kiR
00c2511f RJ%-
00c252c3 6`&@
00c252cf 6`*@
00c25390 jkh8)	
00c255df Tb^@
00c25a17 6`&@
00c25a47 6`*@
00c25a98 	!@9
00c25b3e 	ki"
00c25ba2 	ki:
00c25e22 	ki"
00c25e8a 	ki:
00c25ef2 	kiR
00c25f5a 	kij
00c261f3 TtN@
00c26337 Th.@
00c2635f Th:@
00c2639a  6`N@
00c2640b 6hB@
00c26437 6hF@
00c26463 6hJ@
00c26565 kh8)	
00c271cf Ti:@
00c27246 06hV@
00c272c7 6hB@
00c2730b 6hF@
00c2734f 6hJ@
00c27392 '6`N@
00c273c2 /6hR@
00c273ec 	!@9
00c27492 	ki"
00c274f6 	ki:
00c2755a 	kiR
00c275be 	kij
00c27927 <)T@
00c2795f RJa-
00c27bed 	Jz@
00c27d07 Tb^@
00c27ff4 *!@9)	@
00c2821c hB@9
00c28443 Tb^@
00c28730 	A@9
00c28794 *!@9)	@
00c2882a 	ki"
00c28839 B@9h
00c28a2e 	ki"
00c28a9a 	ki:
00c28b02 	kiR
00c28b6a 	kij
00c29020 jyhx)	
00c294fb Tb^@
00c29983 Ti.@
00c299d3 Ti:@
00c29a23 TiF@
00c29a73 TiR@
00c29ac3 Ti^@
00c29b23 6ib@
00c29b67 6hf@
00c29bcc 	!@9
00c29f6d 	Hz 
00c2a34c *!@9)	@
00c2a3f3 =)	@
00c2a5e2 	kiZ
00c2aa47 Tsn@
00c2abf1 {hx)	
00c2ac20 w"C)
00c2ac48 w"C)
00c2ac74 w"C)
00c2bef7 4Ju~
00c2bf5f Ti2@
00c2c203 6if@
00c2c247 6ij@
00c2c28b 6in@
00c2c34c 	!@9
00c2c378 l!@9k	@
00c2c43f <+(@
00c2c49f =+T@
00c2c8bd "C)_
00c2c901 "C)_
00c2c921 "C)_
00c2c9f7 Tb^@
00c2cd28 	!@9
00c2d0bd @@9h
00c2d0c3 7h*@
00c2d0ff yh*@
00c2d383 Tb^@
00c2d529 B@9h
00c2d644 	@@9
00c2d720 *!@9)	@
00c2d758 (@@9
00c2d79f Th*@
00c2dd7b Tb^@
00c2df44 	!@9
00c2e15b RJE.
00c2e724 	!@9
00c2e744 	!@9
00c2ed6b Tb^@
00c2eecd @@9h
00c2ef20 	!@9
00c2ef58 (@@9
00c2f710 	!@9
00c2fc23 Tb^@
00c2fd85 @@9h
00c2fdd8 	!@9
00c2fe10 (@@9
00c3048c 	!@9
00c304ac 	!@9
00c30895 	Jz@
00c309af Tb^@
00c30c9c *!@9)	@
00c30de0 +ih8J	
00c310ac +ih8J	
00c3113d B@9H
00c312b1 B@9H
00c314d0 jkh8)	
00c3184f Tb^@
00c31975 B@9h
00c31bb0 +ih8J	
00c31ccc 	!@9
00c31e10 *!@9)	@
00c31e30 K!@9J	@
00c324f8 *!@9)	@
00c327e3 6K	@
00c3280b Ti"@
00c32833 6K	@
00c3285b Ti.@
00c32883 6K	@
00c328ab Th:@
00c328d3 ThF@
00c329a3 6iN@
00c329cf 6hR@
00c32adc jyhx)	
00c32f8f Tb^@
00c33527 Ti:@
00c3354f Tj"@
00c33597 TiR@
00c335a7 Tj.@
00c335ef Tj:@
00c3363f ThF@
00c33757 6hR@
00c337f7 6iN@
00c33844 	!@9
00c338e6 	ki"
00c3394a 	ki:
00c339ae 	kiR
00c33a12 	kij
00c34a61  @9H
00c34c19 B@9(
00c34d09 "@9h
00c35fc5 j58h
00c36f10 	0@9
00c37408 	0@9
00c37978 	@@9
00c379f0 	@@9
00c37db7 7hF@9
00c37e04 hF@9
00c37e0b 5h2@
00c37ee8 	D@9
00c37ef7 4hB@9
00c3808f ThF@9
00c38183 7i"E)
00c3819c hF@9h	
00c381a3 5b.@
00c38218 i"E)
00c383c7 K(	@
00c383e4 hF@9h
00c38655 #@9h
00c386d1 #@9(
00c38bf9 C@9h
00c38c4b 9)1@
00c38ca9 C@9h
00c38db7 rH!@
00c38e29 C@9h
00c38f29 C@9h
00c39330 Jkh8)	
00c39a42 	K,}
00c3a0ff TIp	
00c3a1f3 TIp	
00c3a2d4 +ih8J	
00c3a66c 	 @9
00c3a75c {"@)
00c3a870 x"@)
00c3a954 z"@)
00c3aab8 {"@)
00c3abcc x"@)
00c3acb0 z"@)
00c3ae14 {"@)
00c3af28 x"@)
00c3b00c z"@)
00c3b9c8 hZ@)
00c3ba28 hZ@)
00c3bc34 hZ@)
00c3bc94 hZ@)
00c3bea0 hZ@)
00c3bf00 hZ@)
00c3c10c hZ@)
00c3c16c hZ@)
00c3c378 hZ@)
00c3c3d8 hZ@)
00c3c8bf RJ}@
00c3cabd `@9H
00c3cb38 	`@9
00c3cb78 	`@9
00c3cba8 	`@9
00c3ce0e A9JA
00c3cfc9 yix*$
00c3cfed yix*$
00c3d011 yix*$
00c3d031 yix*$
00c3d041 Y`x($
00c3d2c2 _8+}
00c3d316 _8*}
00c3d647 6h:@
00c3d700 hz@9
00c3d7d1 #@9h
00c3d855 j48(
00c3d85f 6`.@
00c3d8e0 hz@9h
00c3da59 j48(
00c3dbc3 6`.@
00c3dc4f R!|/
00c3dc73 RkB@9
00c3dc7f qiF@9H
00c3dc8f 2jJ@9
00c3dc9f 2kN@9
00c3dca8 iR@9_
00c3dcb8 jV@9
00c3dcce 	*iZ@9_
00c3dce0 j^@9
00c3de0f R!$,
00c3df43 6`2@
00c3e2e3 7h"A9H
00c3e308 h"A9
00c3e30f 6`.@
00c3e38d z@9H	
00c3e5fd v@9`
00c3e6a3 TH/@
00c3e95b R!P9
00c3ea41 z@9H
00c3ea7b R!P9
00c3eb21 z@9(
00c3eb5b R!P9
00c3ec83 R!06
00c3edfb R!P9
00c3f035 z@9h
00c3f0cd C@9h
00c3f92a @9?Y
00c3faeb N	q}
00c3fd77 9B3N
00c4009f T(	@
00c403e2 _x_	
00c4089f R!$,
00c408ed cA9!
00c40911 cA9)
00c4093e C9JA
00c40a08 jih8)	
00c40d9b *?C:
00c40e77 *?C:
00c40f76 @9?	
00c40f92 @9	1
00c40faf 7?C:
00c41122 _x_	
00c412ba @9?Q
00c4138e @y?(
00c41398 $	Dz
00c41457 R!$,
00c41549 CD9(
00c41856 @9?U
00c41892 @9?U
00c41c9a @9_q
00c41d11 ADq+
00c41d9b T7#@
00c41f4f R $@
00c42181 	@)y
00c421df T*iwx?
00c4231b T*ix
00c423f2 @9?q
00c42772 @9?q
00c427b2 @8?u
00c428a6 @9?q
00c42b4a @9?u
00c42f56 @9?A
00c430c3 T	|@
00c430f8 jih8)	
00c4330c ?@Dq
00c435e8 lkj8k	
00c4364f TK	@9k
00c4371a H6?	
00c43822 H7?	
00c4443a @y?(
00c444b9 M@)?(
00c44c67 TuZ@
00c44e1f TuZ@
00c45197 TuZ@
00c458e7 5t&M)
00c4593e 	*)y
00c45b1f 4*|}
00c45b77 *-i,
00c45c27 */i.
00c45c87 */i.
00c45d77 3Mi+
00c45eef *-i,
00c46087 *-i,
00c46156 	*)}`
00c4617f 3Mi+
00c465ea 	*J}
00c46717 7h.@
00c4674f 9h.@
00c467bb 9h.@
00c467cb 5iBJ
00c4695f *BH(
00c469e1 80.,
00c469ee @yImo
00c46c6b 3+i(
00c46cf0 +M@8LM@8
00c46d31 @A9)
00c46d88 Nik8
00c46d93 TKik
00c46e2c KM@8
00c46e63 3)}`
00c46e74 KM@8
00c46f30 h"A9h
00c46f6b 4hN@
00c46fa7 7h.@
00c470b4 ?@@q
00c470bd B@qk
00c471dc h"A9
00c471ef 4hN@
00c47234 hBA9
00c4733f T!kv8Bkv8
00c4738f *h"A9
00c4739f 4hN@
00c473bb 7h.@
00c47405 @A9H
00c4743c h"A9
00c4744f 4hN@
00c474a4 h"A9
00c474b7 4hN@
00c474e3 7h.@
00c4750f 7h.@
00c47580 h"A9(
00c47593 4hN@
00c475bf 7h.@
00c47648 h"A9
00c4766b 4hN@
00c476dc h"A9(
00c476ef 4hN@
00c4771b 7h.@
00c47774 h"A9
00c47787 4hN@
00c477c3 7h.@
00c47853 R!P5
00c47924 	 A9i
00c479df 7h.@
00c47a87 7h.@
00c47ba9  A9h
00c47bfc +yhxJ	
00c47c54 hBA9
00c47c68 hBA9
00c47f48 hBA9	
00c47fc4 hBA9
00c481a9 CA9(
00c4847a _x_	
00c4858a @yH	
00c4864a _x_	
00c4871d  A9h
00c487d7 6`"@
00c487e9 C@9h
00c48803 T`"@
00c492eb TuZ@
00c494a3 TuZ@
00c4981b TuZ@
00c49ca0 hb@9
00c49e37 Tiz.
00c49ecb Tiz+
00c49f4d "Qzi
00c49f6b Tlz1
00c49f97 T!~@
00c49fb3 Tlz!
00c49ff8 CL@8
00c4a099 N@8q
00c4a123 R@)JzJ
00c4a12b Rd!IzI
00c4a182 @9+y
00c4a1fe @9*y
00c4a213 R`)Jz$!Jz	
00c4a3f7 T4A@)
00c4a56c *-@)_
00c4a830 *-@)_
00c4aa38 vN@8u
00c4aa9f 7	;@
00c4b02a @9()
00c4b15f Tj&A)
00c4b35f 7 }}
00c4b3f3 Ti.@
00c4b41d 1@i+y-xk	
00c4b42c .y,x!
00c4b440 *y+xJ
00c4b74b Tm}@
00c4b7b3 Tl}@
00c4b95f T,yl
00c4b96f TKy(
00c4b9a0 mjk8
00c4bb57 T?}?
00c4c083 Tk;@
00c4c46b *k}@
00c4c4f9 ii8J	
00c4cab8 wO@8v
00c4ceff RMii8)
00c4d062 @9Lykx
00c4d079 i-x@
00c4d095 im8"
00c4d0ac @y`x"x
00c4d116 _8h.
00c4d145 #@9?
00c4d178 pim8
00c4d25b Roimx
00c4d289 ypx 
00c4d294 "$@x1
00c4d29c _  k
00c4d311 #@9t
00c4d3a2 @9Kyk
00c4d3ae @9`%
00c4d3b6 @9Kyn
00c4d3c6 @9Iyi
00c4d3d2 @9Mym
00c4d3de @9Kyk
00c4d521 TE)(
00c4daa0 +ih8J	
00c4e060 +ih8J	
00c4e7d7 5`.@
00c4e83c ; E)
00c4e900 $jd8
00c4e943 TqZq
00c4e9a7 q$	@z`
00c4e9db TkZj
00c4ed2f QH[{
00c4ed77 Tjyj
00c4edb7 9J}@
00c4ee37 T)	@
00c4f180 *kh8
00c4f27b R!8=
00c4f2ef Tc2@9
00c4f3c7 R!4	
00c4f61c ( @9H
00c4f749 `@9h
00c4f871 7@9W
00c4f8e7 QLYl
00c4fa01 6@9H
00c4fa67 Q+Yk
00c4fa8b Tm}@
00c4fe4b R!$"
00c4fe8b T(7@9
00c4ff1b Q+Yk
00c4ff3f Tm}@
00c5017f QLYl
00c5029d 7@9(
00c50303 Q+Yk
00c50327 Tm}@
00c50707 R!$"
00c5074b T(7@9
00c50757 6(&@
00c507cf Q+Yk
00c507f3 Tm}@
00c509b4 H7@9
00c50cef QLYl
00c50dff QLYl
00c50fdb R!$"
00c510ab Q+Yk
00c510cf Tm}@
00c5125d 6@9)
00c51577 QLYl
00c5168b QLYl
00c51867 R!$"
00c51937 Q+Yk
00c5195b Tm}@
00c51af5 6@9T
00c51b6f QLYl
00c51c3d `@9"
00c51d4b Q+Yk
00c51d6f Tm}@
00c5213f R!$"
00c52187 TH7@9
00c52203 Q+Yk
00c52227 Tm}@
00c5246f QLYl
00c5253d `@9"
00c525e5 7@9H
00c5264b Q+Yk
00c5266f Tm}@
00c52a4b R!$"
00c52a8f T(7@9
00c52a9b 6(&@
00c52b13 Q+Yk
00c52b37 Tm}@
00c52cfc i6@9W
00c5305f Q+Yk
00c53083 Tm}@
00c53167 Q+Yk
00c5318b Tm}@
00c53313 R!$"
00c53407 Q+Yk
00c5342b Tm}@
00c535a0 h6@9
00c53907 Q+Yk
00c5392b Tm}@
00c53a17 Q+Yk
00c53a3b Tm}@
00c53bc7 R!$"
00c53c9b Q+Yk
00c53cbf Tm}@
00c54027 R!47
00c540cf R((@
00c54263 T	#@
00c542a5 		*I
00c54abf Tl	@
00c54da1 80.	
00c55576 /6uz(
00c557fe /65y(
00c55a98 (Q@)	
00c55b2f TLyl
00c55c63 2,M@8*
00c55ceb TLyl
00c55cf7 T,}@
00c55e03 TLyl
00c55e0f T,}@
00c55e7f T,yl
00c55eab Tn}@
00c562da @MkC
00c564f2 @MiB
00c565f8 	)H)
00c566af *	 @
00c56b18 Okm8
00c56b34 -M@8,
00c56b6a @y?	
00c56fb7 R!t0
00c573c7 9;k?
00c575db R!P1
00c57795 `@9h
00c57b57 TuZ@
00c57d0f TuZ@
00c58087 TuZ@
00c586a7 Th2@
00c586c3 7IM@
00c58710 +kj8
00c5875b Th:@
00c58763 4h*@
00c5878f Ti:@
00c5879b Ti*@
00c587bf Rj*@
00c588d3 7iZ@
00c588df Ti*@
00c58954 )yhx)%
00c58987 TJ}F
00c5899f KJ9@
00c58c3f 4h*@
00c58c8c 	`@9
00c597d9 80.	
00c5a10e _x?	
00c5a467 R)I)
00c5a470 +ih8J	
00c5a4aa 	ka	
00c5a552 @9DT
00c5a769 #@9h
00c5a801 j48(
00c5aa4c mi(8
00c5ab76 _x?	
00c5aba7 Tmyy
00c5abe3 4WYy
00c5adbe @9?-
00c5adce _x?	
00c5aefe )*(!
00c5af42 )*(!
00c5b73b 5J#@
00c5b95d CDqj
00c5ba68 J'@)
00c5bb4d X .(
00c5be37 *i*@)
00c5c414 +ih8J	
00c5c426 _x?	
00c5c48b T+yj
00c5c516 _x?	
00c5c807 R`zw
00c5c90f R`zw
00c5ca4e @9?	
00c5cad3 T`zx
00c5cb66 _x?	
00c5cb7a @9)!
00c5cbae _x_	
00c5cd18 +ih8J	
00c5cd7c mij8
00c5cdce @9%J
00c5d0ac +ih8J	
00c5d1d6 @9#I
00c5d256 _x_	
00c5d6fd #@9h
00c5d80d ADq 
00c5e1f3 TuZ@
00c5e3ab TuZ@
00c5e723 TuZ@
00c5ecc8 +ih8J	
00c5ed97 R!p;
00c5ee9c +ih8J	
00c5ef4e @y`"@
00c5f043 T`"@
00c5f086 @y`"@
00c5f179 c@)_
00c5f183 Ty"@
00c5f55c +ih8J	
00c5f737 SI1	*)
00c5f743 S?A@q
00c5fb57 T	0@
00c5fc86 @9kq}
00c5fc91 ji8)}@
00c5fe1d hk8)
00c6047b *)EE
00c60b9b T) @
00c61923 T`6@
00c619d7 T`6@
00c61f77 4h+A
00c61fa7 4h+A
00c6200f 4hSA
00c62187 RiZ@
00c621f3 R!L6
00c62203 R!|>
00c622a3 RiZ@
00c62307 RiZ@
00c62547 ThZ@
00c62555 C@9H
00c62563 R!|>
00c62573 R!L6
00c62583 R!L6
00c62593 R!|>
00c625b9 C@9h
00c6260f R!L6
00c6293f k)Q 
00c62c59 f@9h
00c62ccf R	M	
00c62d33 R	M	
00c62d77 Thjx
00c63366 	*+=
00c636b3 o C_
00c63a23 *kA!
00c63a8b S_1Hk
00c63c6a 	kl	
00c63ddc +ih8J	
00c63e18 mij8
00c63ee4 +ih8J	
00c64148 myjx
00c64199 	DzB
00c64a0f R_U,q
00c64b49 ii8J	
00c64b5a LQ)M
00c64b99 ii8J	
00c64d6c I@B)M
00c64da0 ehn8
00c65157 RJ4@
00c6552b RJ4@
00c6563f RJ4@
00c656d7 4I4@
00c657d3 *dYn
00c65a1f 6@A_
00c65b1b 6MA_
00c65bfb T+U@9
00c65cea @9J#
00c65de4 	-@8*y
00c65e25 	@9k
00c65eba @9)y
00c66079 *@9)
00c66089 .@9J
00c66099 2@9+
00c660e5 -@9)Yj
00c66133 Tj	@9J
00c662f7 R)a9
00c66327 R)a9
00c66357 R)a9
00c66460 	=@8?
00c66484 	=@8?
00c665d5 !@9K
00c66605 %@9K
00c66635 )@9K
00c66665 -@9	
00c666c0 	-@8*y
00c66701 	@9k
00c6686d !@9K
00c6689d %@9K
00c668cd )@9K
00c66905 -@9	
00c66946 @yIj
00c66a2e @9Iy
00c66a45 0@x)
00c66b3b T	 @9*
00c66b5f T	$@9*
00c66b83 T	(@9*
00c66ba7 T	,@9*
00c66bcb T	0@9*
00c66bf1 4@9	
00c66c36 @xil
00c66d69 *@9)
00c66d79 .@9J
00c66d89 2@9k
00c66df0 	-@8*y
00c66e2d 	@9k
00c670d3 R+)@9
00c670e7 9(-@9JYk
00c67566 _8?1
00c67669 "@9J
00c67679 &@9k
00c676b4 	-@8*y
00c676f9 	@9k
00c677fa @yIj
00c67951 -@9i*
00c67b95 -@9)Yj
00c67c92 	kA	
00c67cc9 "@9J
00c67cd9 &@9!
00c67d3d *@9)
00c67d4d .@9J
00c67d5d 2@9k
00c67dd4 	-@8*y
00c67e11 	@9k
00c67f28 +ih8J	
00c68491 nE9)
00c684a1 rE9J
00c684b1 vE9k
00c68bc8 +ih8J	
00c68eab ThY3
00c69240 Lii8k	
00c693ac Iii8?
00c693bb R	)	
00c6960b *m,@)
00c69657 *J5@
00c6a26b TI,B)
00c6ad24 +ih8J	
00c6ad8e @8+-@8_
00c6b170 Lii8k	
00c6b23a @8+-@8_
00c6b70c +ih8J	
00c6b73c h&@)
00c6b818 i"@)
00c6b902 	*j2
00c6bb38 Lii8k	
00c6bba0 	 @)*
00c6bc6d $@)?
00c6c0bc +ih8J	
00c6c4e8 Lii8k	
00c6ca6c +ih8J	
00c6ce98 Lii8k	
00c6d2b4 ( @9
00c6d318 ( @9
00c6e384 	%@9I	 6
00c6e491 -D)?
00c6e563 5 E@
00c6e5a8 	)D))
00c6e5b2 	j	!
00c6e76d )D)i
00c6e931 )D)i
00c6ea27 **%@
00c6eac4 L-D)
00c6eb9b **%@
00c6ec20 +)D)h
00c6ed8f 5 E@
00c6edd4 	)D))
00c6edde 	j	!
00c6efec 	)D))
00c6eff6 	j	!
00c6f07b * E@
00c6f150 	-D))
00c6f15a 	j	!
00c6f2a3 * E@
00c6f398 	-D))
00c6f3a2 	j	!
00c6f4bb * E@
00c6f590 	-D))
00c6f59a 	j	!
00c6f6b3 * E@
00c6f7a8 	-D))
00c6f7b2 	j	!
00c6f8cb * E@
00c6f9a0 	-D))
00c6f9aa 	j	!
00c6fb98 	-D))
00c6fba2 	j	!
00c6fd90 	-D))
00c6fd9a 	j	!
00c6ff88 	-D))
00c6ff92 	j	!
00c70180 	-D))
00c7018a 	j	!
00c70378 	-D))
00c70382 	j	!
00c70493 * E@
00c704fc 	)D))
00c70506 	j	!
00c7068c 	)D))
00c70696 	j	!
00c70814 	)D))
00c7081e 	j	!
00c71446 _8F&
00c714eb 4`^@
00c71576 ^8`^
00c715f3 Th*@
00c71603 T`"@
00c717c6 _8f%
00c7186b 4`^@
00c71973 Th*@
00c71983 T`"@
00c71aa7 *c"@
00c71de7 *c"@
00c72414 h @9
00c7299a @9_	
00c72eed cA9h
00c72f91 cA9h
00c73391 cA9h
00c73435 cA9h
00c73835 cA9h
00c738d9 cA9h
00c73cd9 cA9h
00c73d7d cA9h
00c7417d cA9h
00c74221 cA9h
00c74621 cA9h
00c746c5 cA9h
00c74a99 cA9h
00c74f21 cA9h
00c753a9 cA9h
00c75843 R!\$
00c75958 *a@9_
00c75984 *e@9_
00c759c0 M-@8
00c759d0 M=@8
00c759e0 MM@8
00c759f0 M]@8
00c75a00 Mm@8
00c75a10 M}@8
00c75ac0 M-A8
00c75ad0 M=A8
00c75ae0 MMA8
00c75af0 M]A8
00c75b00 MmA8
00c75b10 M}A8
00c75b67 T?A!
00c75b90 Iii8
00c75be8 iii8	
00c75d10 h @9
00c762aa @9_	
00c768fd cA9h
00c76dd5 cA9h
00c772ad cA9h
00c77785 cA9h
00c77c5d cA9h
00c78135 cA9h
00c781cd cA9z
00c78569 cA9h
00c7868d cA9z
00c78a29 cA9h
00c78b4d cA9z
00c78ee9 cA9h
00c79393 R!\$
00c79429 #A9h
00c7971f T?A!
00c79740 Iii8
00c79798 iii8	
00c79c64 kil8
00c7a704 H @9
00c7aaf3 R!\$
00c7aed4 )ih8?
00c7b27f R!\$
00c7b4ef R!\$
00c7b75b R!\$
00c7babf R!\$
00c7bafb R!\$
00c7bb33 R!\$
00c7bb6b R!\$
00c7bf57 R!\$
00c7bfcf R!\$
00c7c0b4 )ih8?
00c7c637 R!\$
00c7c673 R!\$
00c7c6ab R!\$
00c7c6e3 R!\$
00c7c98f R!\$
00c7ca10 H @9
00c7cb2b r+!A
00c7ce1b R!\$
00c7d0f4 )ih8?
00c7d67b R!\$
00c7d8fb R!\$
00c7db77 R!\$
00c7dedb R!\$
00c7df17 R!\$
00c7df4f R!\$
00c7df87 R!\$
00c7e2f7 R!\$
00c7e3cc )ih8?
00c7e95f R!\$
00c7e99b R!\$
00c7e9d3 R!\$
00c7ea0b R!\$
00c7ecb7 R!\$
00c7ee8b *)%@
00c7eec7 *)%@
00c7f810 +yhxJ	
00c805f3 *(5@
00c8062f *(5@
00c80fbc +yhxJ	
00c825c5 s@9i
00c82620 Chc8
00c827c5 s@9)
00c82a50 jih8)	
00c82fe1 cB9K
00c83021 il8/kl8
00c831b1 #C9*
00c8341c @%87
00c83531 #C9*
00c83641 #C9*
00c838dd cB9h
00c83925 #C9h
00c83a55 #C9H
00c83c29 #A9(
00c8420c Chc8
00c84668 jih8)	
00c84a44 kIj8
00c84a95 CC9s
00c84cf9 CC9s
00c8560d #B9h
00c8573d #B9h
00c85755 CC9(
00c85795 CC9(
00c860bf R!\$
00c86121 CB9h
00c865a0 Jkh8)	
00c86c61 cB9h
00c86d09 cB9h
00c86d2d cB9H
00c870d9 cB9h
00c8710f R!\$
00c8716d cB9h
00c87545 ih8)	
00c87723 NKu}
00c87c15 CB9h
00c87cbd CB9h
00c87ce1 CB9H
00c882ff R!\$
00c88337 R!\$
00c8836f R!\$
00c8a55f T yv
00c8aa9f T yv
00c8b8cf 7h"A9
00c8b908 h"A9h
00c8b90f 6`.@
00c8b91f 6`"@
00c8badb 7h"A9
00c8bb14 h"A9h
00c8bb1b 6`.@
00c8bb2b 6`"@
00c8bce7 7h"A9
00c8bd20 h"A9h
00c8bd27 6`.@
00c8bd37 6`"@
00c8bef3 7h"A9
00c8bf2c h"A9h
00c8bf33 6`.@
00c8bf43 6`"@
00c8d0f9 j58i
00c8d85f T	yi
00c8d89b T	yi
00c8d92f R!\$
00c8dabb R!\$
00c8dd0b nB(a
00c8dd13 nc(a
00c8dd27 .B(!
00c8dd47 T	D@
00c8dd94 hb@9H
00c8dde0 hb@9H
00c8de77 R!\$
00c8dffb R!\$
00c8e43c hb@9H
00c8f097 R!\$
00c8f371 C_8(
00c8fd2b T+}F
00c8fda7 T+}K
00c8fdb3 T+}J
00c8fdcb TK-@xl
00c8fe7c ?9@q#
00c8fe93 T+}L
00c90301 	@9`
00c907df T		@9?
00c909a3 SK	n
00c90be3 SJ	n
00c90de0 	`@9
00c90e28 	`@9
00c90e78 	`@9
00c90ec0 	`@9
00c911f0 	`@9
00c914e8 	`@9
00c9162b 6`zE
00c92acc jih8)	
00c93558 jih8)	
00c9359f T_5 q
00c93c74 h"O9u"
00c93d1c hBP9tB
00c93eb0 	E@8?
00c94014 	E@8?
00c941e1 aE9*
00c9422c 	E@8?
00c9433d aE9*
00c94394 	E@8?
00c94527 RhbN9vb
00c9456c hbN9
00c94770 h"O9t"
00c94818 hBP9tB
00c94998 hb@9H
00c94a85 c@9H
00c94b08 hBP9
00c94b1f 7h"O9
00c94b2f 7hbN9h
00c94b77 7hBD9(
00c94b8f 7h"C9
00c94b9f 7hbB9h
00c94bb7 7hBA9(	
00c94bc2 @9h	
00c94bcf 7h"@9h
00c94c14 h"O9
00c94c34 hbN9
00c94c58 hBD9(
00c94c7f 6`z@
00c94c88 h"C9h
00c94c8f 6`n@
00c94c9f 6`b@
00c94ca8 hbB9
00c94caf 6`V@
00c94cbf 6`J@
00c94ccf 6`>@
00c94cd8 hBA9(
00c94cdf 6`2@
00c94cef 6`&@
00c94d08 h"@9h
00c94ea4 hBP9
00c94ebb 7h"O9
00c94ecb 7hbN9h
00c94f13 7hBD9(
00c94f2b 7h"C9
00c94f3b 7hbB9h
00c94f53 7hBA9(	
00c94f5e @9h	
00c94f6b 7h"@9h
00c94fb0 h"O9
00c94fd0 hbN9
00c94ff4 hBD9(
00c9501b 6`z@
00c95024 h"C9h
00c9502b 6`n@
00c9503b 6`b@
00c95044 hbB9
00c9504b 6`V@
00c9505b 6`J@
00c9506b 6`>@
00c95074 hBA9(
00c9507b 6`2@
00c9508b 6`&@
00c950a4 h"@9h
00c95125 Ik8ke
00c95603 R!\$
00c9584d #@9H
00c9597c +ih8J	
00c95b30 +ih8J	
00c95f79 #@9H
00c961c9 ZA9h
00c9623b Th*@
00c96260 h"A9
00c962fb Th6@
00c963c5 ^A9H
00c964a9 C@9h
00c967ac +ih8J	
00c96970 +ih8J	
00c96da1 rA9h
00c96e13 Th*@
00c96e38 h"A9
00c96ed3 Th6@
00c96f9d vA9H
00c97081 C@9h
00c9732f R!\$
00c978eb 7h"A9
00c978fb 7hb@9h
00c97928 h"A9H
00c9792f 6`.@
00c9793f 6`"@
00c97948 hb@9
00c979ab 7h"A9
00c979bb 7hb@9h
00c979e8 h"A9H
00c979ef 6`.@
00c979ff 6`"@
00c97a08 hb@9
00c97a6b 7h"A9
00c97a7b 7hb@9h
00c97aa8 h"A9H
00c97aaf 6`.@
00c97abf 6`"@
00c97ac8 hb@9
00c97b2b 7h"A9
00c97b3b 7hb@9h
00c97b68 h"A9H
00c97b6f 6`.@
00c97b7f 6`"@
00c97b88 hb@9
00c98680 hb@9H
00c98827 R!\$
00c98973 R!\$
00c98af3 R!\$
00c98c6f R!\$
00c98ddf R!\$
00c98f4f R!\$
00c9903f R @ 
00c9908b R!\$
00c9917f R @`
00c991cb R!\$
00c9931b R!\$
00c997eb T*E@
00c9988d @P9h
00c998a3 7h"O9(
00c998b3 7hbN9h
00c998fb 7hBD9
00c99913 7h"C9H
00c99923 7hbB9
00c99936 A9H	
00c9993b 7hBA9
00c99953 7h"@9h
00c999a4 h"O9(
00c999c4 hbN9
00c999e8 hBD9
00c99a0f 6`z@
00c99a18 h"C9
00c99a1f 6`n@
00c99a2f 6`b@
00c99a38 hbB9
00c99a3f 6`V@
00c99a4f 6`J@
00c99a5f 6`>@
00c99a68 hBA9
00c99a6f 6`2@
00c99a7f 6`&@
00c99a98 h"@9
00c99abd @P9h
00c99ad3 7h"O9(
00c99ae3 7hbN9h
00c99b2b 7hBD9
00c99b43 7h"C9H
00c99b53 7hbB9
00c99b66 A9H	
00c99b6b 7hBA9
00c99b83 7h"@9h
00c99bd4 h"O9(
00c99bf4 hbN9
00c99c18 hBD9
00c99c3f 6`z@
00c99c48 h"C9
00c99c4f 6`n@
00c99c5f 6`b@
00c99c68 hbB9
00c99c6f 6`V@
00c99c7f 6`J@
00c99c8f 6`>@
00c99c98 hBA9
00c99c9f 6`2@
00c99caf 6`&@
00c99cc8 h"@9
00c9ac11 j48h
00c9ac67 Th&@
00c9b124 	i`8
00c9b1dd i!8a
00c9b4c1 j48h
00c9c249 #@9h
00c9c2f1 #@9h
00c9c309 #@9h
00c9cc0b SJYi
00c9cd47 SJYi
00c9d100 ?i(8
00c9d2ed C@9h
00c9d359 YjxJ
00c9d3b5 Ymx)=@
00c9d3bd ykxL
00c9d3c5 yixM	
00c9d47b TIyix
00c9d4c7 Rk=@
00c9d4e4 	YaxH
00c9d4f9 YixJ
00c9d508 KYhx
00c9d50f RIyix
00c9d57d Ykx)=@
00c9d585 yixK
00c9d5f3 Ri~@
00c9d63b S)=@
00c9d649 YlxJ=@
00c9d6cd ykxk
00c9d6dd ykxK
00c9d6f1 Ylxk=@
00c9d791 YoxJ=@
00c9d79d Yqx A
00c9d7a9 ylx/
00c9d7b1 ymx0
00c9d7b9 Ynx1	
00c9d7c1 yjx+
00c9da8b =A	@
00c9dd95 #@9h
00c9de01 #@9h
00c9de19 #@9h
00c9e262 @9?i
00c9e40a @9?}
00c9e416 @9?i
00c9e44e @9?}
00c9e463 TI	@9?
00c9e496 @9?}
00c9e4ab TI!@9?
00c9e4b7 TI%@9?
00c9e4c3 TI)@9?
00c9e4cf TI-@9?
00c9e4db TI1@9?
00c9e699 h(8t
00c9e7fe @9_Q
00c9e84c myjx
00c9e887 Th&@
00c9e896 @9?}
00c9e91f TkNA
00c9e9f7 T*	@9_
00c9ea3f T*!@9_
00c9ea4b T*%@9_}
00c9ea57 T*)@9_
00c9ea63 T*-@9_
00c9ea6f T*1@9_%
00c9eae2 @9?I
00c9f464 h"L9
00c9f46b 4h&@
00c9f6ec Lyixk	
00c9fe16 @9?}
00c9fe5a @9?}
00c9fea8 h"L9
00c9feaf 4h&@
00ca00f2 @9?1
00ca023f TH	@9
00ca03a2 @9_I
00ca0599 kh8)	
00ca08f6 @98 
00ca0afe @9?}
00ca0bfa @9?i
00ca18eb r	h(
00ca1992 @9?M
00ca1a04 ,ih8k	
00ca1d2e @9?%
00ca1d4f 6hNA
00ca1dc3 6hNA
00ca1ddf TiRA
00ca2028 J%@9_
00ca223a @9?Q
00ca225a @9?1
00ca2310 j&L9h
00ca237b 9hnA
00ca238b TwjA
00ca246f TJyi
00ca2487 TTyu
00ca26e4 k.@9I
00ca271a @9_	
00ca284e @9_U
00ca2b40 	h(xh
00ca2cf3 R)A"
00ca2d55 $@9i
00ca2dcd (@9i
00ca2e45 ,@9i
00ca3090 Lyixk	
00ca30d4 Lyixk	
00ca313c Lyixk	
00ca3180 Lyixk	
00ca31d2 @9?=
00ca32d8 Lyixk	
00ca331c Lyixk	
00ca335c Lyixk	
00ca33a0 myjx
00ca3430 myjx
00ca3474 myjx
00ca3518 Lyixk	
00ca355b T		@9?}
00ca356a @9?}
00ca35a3 T	!@9?
00ca35af T	%@9?
00ca35bb T	)@9?
00ca389e @9?}
00ca39e2 @9?}
00ca3c36 @9?}
00ca3c6f T	!@9?
00ca3c7b T	%@9?
00ca3c87 T	)@9?
00ca4042 @9_1
00ca41a7 T		@9?
00ca4243 T		@9?i
00ca42ab T		@9?
00ca430d 	@9K
00ca43cd !@9K
00ca43ed %@9K
00ca4551 	@9l
00ca4615 !@9K
00ca4635 %@9K
00ca4655 )@9K
00ca4675 -@9K
00ca4695 1@9K
00ca46b5 5@9K
00ca46d5 9@9K
00ca46f5 =@9K
00ca4715 A@9K
00ca4735 E@9K
00ca4881 jj8l
00ca49c6 @9?Y
00ca49e2 @9?-
00ca4a2a @9_1
00ca4b0a @9?Y
00ca4b26 @9?-
00ca4cdc Lii8k	
00ca4d18 Lii8k	
00ca4d5a @9?Y
00ca4d8a @9?=
00ca4e08 Lii8k	
00ca4e58 Lii8k	
00ca4e96 @9?I
00ca4ec6 @9?1
00ca4f3c Lii8k	
00ca542e @9_}
00ca5686 @9,'
00ca57e1 	@9_9
00ca5edf q$	A
00ca5f06 @9?a
00ca6387 Tk*A
00ca6667 r)A(
00ca6bff R)A"
00ca703f R)A"
00ca70c6 @9?U
00ca7532 @9?}
00ca77c7 R	h(8h
00ca787b R	h(8h
00ca78f7 R	h(8
00ca7dc7 o 	@
00ca7e8d #@9@
00ca801d i+8k
00ca8076 fne4
00ca80ca !NaT
00ca8103 9hi)8
00ca8143 =cX3
00ca8254 	h(xh
00ca82d7 R	h(xh
00ca8342 @9?Q
00ca8370 Lii8k	
00ca889f R)A"
00ca89f4 	h(8h
00ca8ee7 R	h(8h
00ca93f4 	h(8
00ca948c 	h(8
00ca94e3 R	h(8h
00ca9538 	h(8
00ca958f R	h(8h
00ca960b R	h(x
00ca9618 	 @9
00ca9714 	h(8h
00ca9797 R	h(8h
00ca9887 R	h(xh
00ca9b69 h(8h
00ca9baf r	h(
00ca9d73 r	h(
00caa028 7`C)
00caa28b R	h(8h
00caa2e0 	h(8h
00caa363 R	h(xh
00caa41c 	h(xh
00caa49f R	h(8
00caa52f R	h(8h
00caa628 	h(8h
00caa6b0 	h(8h
00caa7a4 	h(8h
00caa808 	h(xh
00caa86c 	h(8h
00caa92c 	h(8
00caa988 	h(8h
00caaae4 	h(8h
00caab6c 	h(x
00caabc8 	h(8h
00caac0c 	`@9(
00caac57 R	h(xh
00caacc1 f@9(
00cab1ba @9_}
00cab1c8 K	@9
00cab1d6 @9_1
00cab1f2 @9_	
00cab20e @9_1
00cab21c K!@9
00cab227 TJ%@9_}
00cab3fc 	h(xh
00cab4dc myjx
00cab514 Lyixk	
00cab634 Lyixk	
00cab680 Lyixk	
00cab7c8 Lyixk	
00cab814 Lii8k	
00cab842 @9?=
00cab920 Lyixk	
00cab96c Lyixk	
00cab99a @9?I
00caba80 Lii8k	
00cabc20 v&L9
00cabc2c w"L9
00cabc4a 	*i&
00cabed0 	h(8h
00cabf6f R)A"
00cac00b R)A"
00cac137 R)A"
00cac263 R)A"
00cac2ff R)A"
00cac39b R)A"
00cac507 R)A5
00cac5e8 	h(xh
00cac7e4 	h(8h
00cac86c 	h(xh
00cac8f4 	h(8h
00cacf44 	h(8h
00cacfc7 R	h(8h
00cad18f R	h(xh
00cad238 	h(8
00cad28f R	h(8h
00cad324 	h(8
00cad37b R	h(8h
00cad548 	h(8h
00cad700 	h(8h
00cad827 R	h(8h
00cada4f R	h(8h
00cadaa8 +ih8J	
00cadba7 R+a@
00cadddb R	h(8h
00cadfb4 	h(8h
00cae298 	h(xh
00cae338 +ih8J	
00cae437 R+a@
00cae58b R+Q@
00cae874 	h(8
00cae8db R	h(8h
00cae92b R	h(8h
00caecc3 R	h(8h
00caed88 	h(8
00caeddf R	h(8h
00caf0fb R	h(xh
00caf1b4 	h(8h
00caf252 @9_Y
00caf272 @9_-
00caf2aa @9_=
00caf38e @9?e
00caf3fe @9?=
00caf782 @9?Y
00caf80d .@9l
00caf8fd "@9_
00cafae7 R)A"
00cafc56 @9?}
00cafd46 @9_}
00cafe0e @9?Q
00caff90 ,%@9
00cb0043 9*%@9
00cb029f R	h(8h
00cb0433 R	h(8h
00cb04b4 	h(8
00cb0510 	h(8h
00cb0873 R	h(8h
00cb092c 	h(8h
00cb09e7 R	h(8h
00cb0f43 R	h(8h
00cb109c 	h(8h
00cb11ba _8?u
00cb1203 R	h(8h
00cb1253 R	h(8h
00cb12e8 	h(8h
00cb1390 *%@9
00cb141d (@9H
00cb14ef R	h(8
00cb15c5 (@9H
00cb164f R	h(8h
00cb1824 (!@9
00cb182f T(%A
00cb1907 R	h(8h
00cb191d (@9H
00cb19a7 R	h(8h
00cb19fb R	h(8
00cb1b40 (!@9
00cb1b4b T(%A
00cb1b9d (@9H
00cb1c27 R	h(8h
00cb1d21 *@9(
00cb1dbd *@9h
00cb1de5 .@9(
00cb1f49 p@9h	
00cb1f9d *@9h
00cb1fc5 .@9(
00cb2407 Th:@
00cb2ceb Th&~
00cb356c Mih8
00cb35cc H%@x,
00cb3b83 Ki*(
00cb3c5e @yN	
00cb3f6b T(<@
00cb3feb T(<@
00cb409f Th>@
00cb413c h:A9
00cb466c  	Az
00cb47a7 ThF@
00cb4857 7i>@
00cb4897 Th:A9h
00cb48c3 Th6@
00cb4924 h:A9
00cb492b 5h6A9H
00cb4933 4h2A9(
00cb493b 4h2@
00cb4949 B@98
00cb495d B@9h
00cb49b7 Th:A9h
00cb49bf 5h>@
00cb49cb Th2@
00cb4a1b Th:A9H
00cb4a23 5h>@
00cb4a93 Th2@
00cb4b4b ThF@
00cb4b84 h6A9
00cb4b8b 4h2A9i
00cb4bff Th6@
00cb4c47 Th2@
00cb4d1a G)t:
00cb4d33 Th2@
00cb4d5f Th6@
00cb4e1b Th>@
00cb4e3b Ty2A9|6A9
00cb4e8c h2A9
00cb4e93 qi6A9
00cb4ee0 h2A9
00cb4ee8 i6A9
00cb4ef7 Tj:A9J
00cb4f03 4h2@
00cb4f93 ThJ@
00cb5047 Th>@
00cb50b7 ThJ@
00cb5187 Th>@
00cb51af ThJ@
00cb5e36 **K 
00cb5e93 T/}`
00cb5f57 T/}`
00cb636b *@|_
00cb63eb *@|_
00cb64eb * |_
00cb6dad f@9z
00cb6ed2 @9	{
00cb6fc7 R9_2
00cb6fe2 @9		
00cb6ff4 *ki8
00cb7178 +ih8J	
00cb7294 +ih8J	
00cb79a3 Q(O(
00cb7a11 #\8_
00cb7a51 #\8_
00cb7d75 zjxk	
00cb7daa @9)	
00cb7e3f 9	|	
00cb81c6 	*H}
00cb822f *i}	
00cb8297 9	|	
00cb8467 5i"A
00cb87f0 Lii8k	
00cb88fc Lii8k	
00cb8948 Lii8k	
00cb8af4 +ih8J	
00cb8b31 %@x(
00cb8bf0 Lii8k	
00cb901e @9)	
00cb9060 M{kx
00cb912f QhN(
00cb9143 ThN+
00cb95e0 Lyixk	
00cb9640 Lyixk	
00cb9683 ThN 
00cb96bb TiN 
00cba022 @9Y@#
00cba1e0 +ih8J	
00d10001 __cxa_finalize
00d10010 __cxa_atexit
00d1001d strcmp
00d10024 OrtSessionOptionsAppendExecutionProvider_Nnapi
00d10053 OrtGetApiBase
00d10061 OrtSessionOptionsAppendExecutionProvider_CPU
00d1008e __stack_chk_fail
00d1009f strlen
00d100a6 memcpy
00d100ad memset
00d100b4 strncpy
00d100bc __sF
00d100c1 fwrite
00d100c8 fprintf
00d100d0 memchr
00d100d7 memcmp
00d100de strncmp
00d100e6 localtime_r
00d100f2 strftime
00d100fb fclose
00d10102 fseeko
00d10109 ftello
00d10110 fflush
00d10117 memmove
00d1011f fread
00d10125 fopen
00d1012b fseek
00d10131 localeconv
00d1013c __errno
00d10144 strtoull
00d1014d strtoll
00d10155 strtod
00d1015c __vsnprintf_chk
00d1016c __strlen_chk
00d10179 munmap
00d10180 close
00d10186 mmap
00d1018b __system_property_get
00d101a1 dlopen
00d101a8 dlsym
00d101ae dlerror
00d101b6 __memcpy_chk
00d101c3 expf
00d101cc log1pf
00d101d3 tanh
00d101d8 logf
00d101e1 free
00d101e6 malloc
00d101ed fmodf
00d101f3 sinf
00d101fc cosf
00d10201 tanf
00d10206 asinf
00d1020c acosf
00d10212 atanf
00d10218 sinhf
00d1021e coshf
00d10224 asinhf
00d1022b acoshf
00d10232 atanhf
00d1023d powf
00d10242 fmod
00d10247 log2
00d1024c wmemcmp
00d10254 wmemset
00d1025c wmemcpy
00d10264 remainderf
00d1026f tanhf
00d10275 sincosf
00d1027d sincos
00d10288 log10
00d1028e __memmove_chk
00d1029c posix_memalign
00d102ab strnlen
00d102b3 atoi
00d102b8 strtol
00d102bf ldexpf
00d102c6 _ZTH15ThreadedBufSize
00d102dc syscall
00d102e4 vsnprintf
00d102ee gmtime_r
00d102f7 mktime
00d102fe difftime
00d10307 pthread_self
00d10314 sched_getcpu
00d10321 llroundl
00d1032a __android_log_print
00d1033e dirname
00d10346 pthread_attr_init
00d10358 pthread_attr_setstacksize
00d10372 pthread_create
00d10381 nanosleep
00d1038b __open_2
00d10394 fstat
00d1039a lseek
00d103a0 read
00d103a5 sysconf
00d103ad stat
00d103b2 mkdir
00d103b8 nftw
00d103bd open
00d103c2 realpath
00d103cb getpid
00d103d2 dlclose
00d103da getenv
00d103e1 strerror_r
00d103ec pthread_join
00d103f9 remove
00d10400 clock_gettime
00d1040e gettimeofday
00d1041b pthread_mutex_init
00d1042e pthread_mutex_lock
00d10441 pthread_mutex_unlock
00d10456 pthread_mutex_destroy
00d1046c pthread_once
00d10479 realloc
00d10481 memalign
00d1048a _ctype_
00d10492 pthread_getspecific
00d104a6 pthread_setspecific
00d104ba pthread_key_create
00d104cd fcntl
00d104d3 strerror
00d104dc __read_chk
00d104e7 write
00d104ed __android_log_write
00d10501 fputs
00d10507 strtof
00d1050e pthread_rwlock_init
00d10522 abort
00d10528 pthread_rwlock_destroy
00d1053f pthread_rwlock_wrlock
00d10555 pthread_rwlock_unlock
00d1056b pthread_rwlock_rdlock
00d10581 __strchr_chk
00d1058e calloc
00d10595 sched_yield
00d105a1 dl_iterate_phdr
00d105b1 __android_log_vprint
00d105c6 qsort
00d105cc getauxval
00d105d6 pthread_cond_broadcast
00d105ed pthread_cond_wait
00d105ff pthread_cond_timedwait
00d10616 ungetc
00d1061d getc
00d10622 newlocale
00d1062c uselocale
00d10636 vsscanf
00d1063e vasprintf
00d10648 isxdigit_l
00d10653 isdigit_l
00d1065d strftime_l
00d10668 mbsrtowcs
00d10672 sscanf
00d10679 freelocale
00d10684 strcoll_l
00d1068e strxfrm_l
00d10698 wcscoll_l
00d106a2 wcsxfrm_l
00d106ac iswlower_l
00d106b7 islower_l
00d106c1 isupper_l
00d106cb toupper_l
00d106d5 tolower_l
00d106df iswspace_l
00d106ea iswprint_l
00d106f5 iswblank_l
00d10700 iswcntrl_l
00d1070b iswupper_l
00d10716 iswalpha_l
00d10721 iswdigit_l
00d1072c iswpunct_l
00d10737 iswxdigit_l
00d10743 towupper_l
00d1074e towlower_l
00d10759 btowc
00d1075f wctob
00d10765 wcsnrtombs
00d10770 wcrtomb
00d10778 mbsnrtowcs
00d10783 mbrtowc
00d1078b mbtowc
00d10792 __ctype_get_mb_cur_max
00d107a9 mbrlen
00d107b0 wcslen
00d107b7 strtoll_l
00d107c1 strtoull_l
00d107cc strtold_l
00d107d6 wmemmove
00d107df snprintf
00d107e8 vfprintf
00d107f1 fputc
00d107f7 android_set_abort_message
00d10811 openlog
00d10819 syslog
00d10820 closelog
00d10829 __cxa_thread_atexit_impl
00d10842 pthread_key_delete
00d10855 libonnxruntime.so
00d10867 VERS_1.14.1
00d10873 libdl.so
00d1087c LIBC
00d10881 libm.so
00d10889 libc.so
00d10891 $ORIGIN
00d10899 liblog.so
00d108a3 libovertoneruntime.so
00d108cc Android
00d10918 8775105
00d10980 Android (8490178, based on r450784d) clang version 14.0.6 (https://android.googlesource.com/toolchain/llvm-project 4c603efb0cca074e9238af8b4106c30add4418f6)
00d10a1d Linker: LLD 14.0.6
00d10a32 .init_array
00d10a3e .fini_array
00d10a4a .text
00d10a50 .got
00d10a55 .comment
00d10a5e .note.android.ident
00d10a72 .got.plt
00d10a7b .rela.plt
00d10a85 .bss
00d10a8a .dynstr
00d10a92 .eh_frame_hdr
00d10aa0 .gnu.version_r
00d10aaf .data.rel.ro
00d10abc .rela.dyn
00d10ac6 .gnu.version
00d10ad3 .dynsym
00d10adb .gnu.hash
00d10ae5 .eh_frame
00d10aef .gcc_except_table
00d10b01 .note.gnu.build-id
00d10b14 .gnu.version_d
00d10b23 .dynamic
00d10b2c .shstrtab
00d10b36 .rodata
00d10b3e .data
