00000244 Android
00000250 r26b
00000290 10909125
00003539 DR|P
00003625 }IV93
0000364c Z:hkF
0000365d !HUyD
000036ad __cxa_finalize
000036bc __cxa_atexit
000036c9 __register_atfork
000036db strlen
000036e2 memmove
000036ea __stack_chk_fail
000036fb _ZNSt6__ndk16__treeINS_4pairIiiEENS_4lessIS2_EENS_9allocatorIS2_EEE30__emplace_hint_unique_key_argsIS2_JRKS2_EEENS1_INS_15__tree_iteratorIS2_PNS_11__tree_nodeIS2_PvEElEEbEENS_21__tree_const_iteratorIS2_SF_lEERKT_DpOT0_
000037d6 _ZN3c1018ThrowEnforceNotMetEPKciS1_S1_PKv
00003800 _ZN6caffe212OperatorBaseC2ERKNS_11OperatorDefEPNS_9WorkspaceE
0000383e _ZN6caffe231_DeviceOption_default_instance_E
0000386b _ZN6caffe212OperatorBaseD2Ev
00003888 FLAGS_caffe2_operator_throw_if_fp_exceptions
000038b5 FLAGS_caffe2_operator_throw_if_fp_overflow_exceptions
000038eb feclearexcept
000038f9 fetestexcept
00003906 _ZN6caffe216ProtoDebugStringERKN6google8protobuf11MessageLiteE
00003945 _ZN3c105Error11add_contextENSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEE
000039a4 _ZTVN6caffe210CPUContextE
000039be _ZN3c1018ThrowEnforceNotMetEPKciS1_RKNSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEPKv
00003a2a memset
00003a31 _ZNSt6__ndk113basic_ostreamIcNS_11char_traitsIcEEElsEi
00003a68 _ZNSt6__ndk124__put_character_sequenceIcNS_11char_traitsIcEEEERNS_13basic_ostreamIT_T0_EES7_PKS4_m
00003acb _ZTTNSt6__ndk119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
00003b18 _ZTVNSt6__ndk115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
00003b61 _ZNSt6__ndk115basic_streambufIcNS_11char_traitsIcEEED2Ev
00003b9a _ZNSt6__ndk113basic_ostreamIcNS_11char_traitsIcEEED2Ev
00003bd1 _ZNSt6__ndk19basic_iosIcNS_11char_traitsIcEEED2Ev
00003c03 _ZTVNSt6__ndk119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
00003c50 _ZNSt6__ndk18ios_base4initEPv
00003c6e _ZNSt6__ndk115basic_streambufIcNS_11char_traitsIcEEEC2Ev
00003ca7 _ZN6caffe214ArgumentHelperC1ERKNS_11OperatorDefE
00003cd8 _ZNK6caffe214ArgumentHelper17GetSingleArgumentIiEET_NSt6__ndk117basic_string_viewIcNS3_11char_traitsIcEEEERKS2_
00003d48 _ZN6caffe28ArgumentD1Ev
00003d60 _ZN6caffe25Event13event_waiter_E
00003d81 _ZN3c106detail14torchCheckFailEPKcS2_jS2_
00003dab _ZN6caffe25Event15event_finisher_E
00003dce _ZNSt6__ndk112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6insertEmPKcm
00003e1e _ZN6google10LogMessageC1EPKcii
00003e3d _ZN6google10LogMessage6streamEv
00003e5d _ZN6google10LogMessageD1Ev
00003e78 _ZNSt6__ndk16chrono12steady_clock3nowEv
00003ea0 _ZN6caffe25Event22event_finished_setter_E
00003eca _ZN6caffe25Event15event_recorder_E
00003eed logf
00003ef2 powf
00003ef7 _ZN3c106detail19maybe_wrap_dim_slowIlEET_S2_S2_b
00003f28 _ZN6caffe26detail27Caffe2Tensor_metadata_indexE
00003f58 _ZN3c1019UndefinedTensorImpl10_singletonE
00003f82 memcmp
00003f89 _ZN3c1010TensorImpl12HandleResizeEv
00003fad _ZN6caffe25emptyEN3c108ArrayRefIlEENS0_13TensorOptionsE
00003fe5 _ZN3c1017get_default_dtypeEv
00004002 _ZN6caffe28TypeMeta13typeMetaDatasEv
00004027 _ZN3c104impl15SizesAndStrides14resizeSlowPathEmm
00004058 _ZN3c1010TensorImpl28empty_tensor_restride_symintENS_12MemoryFormatE
0000409d _ZNK3c1010TensorImpl18compute_contiguousEv
000040c8 _ZNK3c1010TensorImpl35compute_channels_last_contiguous_2dEv
00004104 _ZNK3c1010TensorImpl37compute_strides_like_channels_last_2dEv
00004142 _ZNK3c1010TensorImpl35compute_channels_last_contiguous_3dEv
0000417e _ZNK3c1010TensorImpl37compute_strides_like_channels_last_3dEv
000041bc _ZNK3c1010TensorImpl33compute_non_overlapping_and_denseEv
000041f6 _ZN3c1012GetAllocatorERKNS_10DeviceTypeE
0000421f _ZN3c1022PlacementDeleteContext11makeDataPtrEONS_7DataPtrEPFvPvmEmNS_6DeviceE
0000426d _ZNK3c1011StorageImpl27throw_data_ptr_access_errorEv
000042a2 _ZN3c1021warnDeprecatedDataPtrEv
000042c3 _ZN3c104impl3cow15is_cow_data_ptrERKNS_7DataPtrE
000042f4 _ZN3c104impl3cow23materialize_cow_storageERNS_11StorageImplE
00004331 _ZN3c1021throwNullDataPtrErrorEv
00004352 _ZNSt6__ndk113basic_ostreamIcNS_11char_traitsIcEEElsEl
00004389 _ZNK3c1010TensorImpl27throw_data_ptr_access_errorEv
000043c5 _ZTIN3c105ErrorE
000043d6 _ZTVN3c105ErrorE
000043e7 _ZNSt6__ndk119__shared_weak_count14__release_weakEv
0000441b _ZTVNSt6__ndk110__function6__funcIPFNS_10unique_ptrIN6caffe212OperatorBaseENS_14default_deleteIS4_EEEERKNS3_11OperatorDefEPNS3_9WorkspaceEENS_9allocatorISE_EESD_EE
000044bf strcmp
000044c6 _ZNSt6__ndk119piecewise_constructE
000044e9 _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES7_EENS_22__unordered_map_hasherIS7_S8_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_S8_SD_SB_Lb1EEENS5_IS8_EEE25__emplace_unique_key_argsIS7_JRKNS_21piecewise_construct_tENS_5tupleIJRKS7_EEENSN_IJEEEEEENS_4pairINS_15__hash_iteratorIPNS_11__hash_nodeIS8_PvEEEEbEERKT_DpOT0_
0000467d _ZNSt6__ndk112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEaSERKS5_
000046c8 _ZNSt6__ndk15mutex4lockEv
000046e2 _ZNKSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN6caffe212OperatorBaseENS_14default_deleteISB_EEEERKNSA_11OperatorDefEPNSA_9WorkspaceEEEEEENS_22__unordered_map_hasherIS7_SM_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SM_SR_SP_Lb1EEENS5_ISM_EEE4findIS7_EENS_21__hash_const_iteratorIPNS_11__hash_nodeISM_PvEEEERKT_
0000488e _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN3c1016RegistryPriorityEEENS_22__unordered_map_hasherIS7_SA_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SA_SF_SD_Lb1EEENS5_ISA_EEE25__emplace_unique_key_argsIS7_JRKNS_21piecewise_construct_tENS_5tupleIJRKS7_EEENSP_IJEEEEEENS_4pairINS_15__hash_iteratorIPNS_11__hash_nodeISA_PvEEEEbEERKT_DpOT0_
00004a37 _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN6caffe212OperatorBaseENS_14default_deleteISB_EEEERKNSA_11OperatorDefEPNSA_9WorkspaceEEEEEENS_22__unordered_map_hasherIS7_SM_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SM_SR_SP_Lb1EEENS5_ISM_EEE25__emplace_unique_key_argsIS7_JRKNS_21piecewise_construct_tENS_5tupleIJRKS7_EEENS11_IJEEEEEENS_4pairINS_15__hash_iteratorIPNS_11__hash_nodeISM_PvEEEEbEERKT_DpOT0_
00004c40 _ZNSt6__ndk15mutex6unlockEv
00004c5c stderr
00004c63 fprintf
00004c6b exit
00004c70 _ZNSt13runtime_errorC1ERKNSt6__ndk112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEE
00004ccd _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN3c1016RegistryPriorityEEENS_22__unordered_map_hasherIS7_SA_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SA_SF_SD_Lb1EEENS5_ISA_EEE21__construct_node_hashIRKNS_21piecewise_construct_tEJNS_5tupleIJRKS7_EEENSP_IJEEEEEENS_10unique_ptrINS_11__hash_nodeISA_PvEENS_22__hash_node_destructorINS5_ISX_EEEEEEmOT_DpOT0_
00004e85 _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN3c1016RegistryPriorityEEENS_22__unordered_map_hasherIS7_SA_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SA_SF_SD_Lb1EEENS5_ISA_EEE8__rehashILb1EEEvm
00004f9e _ZNSt6__ndk112__next_primeEm
00004fbb _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN3c1016RegistryPriorityEEENS_22__unordered_map_hasherIS7_SA_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SA_SF_SD_Lb1EEENS5_ISA_EEE11__do_rehashILb1EEEvm
000050d8 _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN6caffe212OperatorBaseENS_14default_deleteISB_EEEERKNSA_11OperatorDefEPNSA_9WorkspaceEEEEEENS_22__unordered_map_hasherIS7_SM_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SM_SR_SP_Lb1EEENS5_ISM_EEE21__construct_node_hashIRKNS_21piecewise_construct_tEJNS_5tupleIJRKS7_EEENS11_IJEEEEEENS9_INS_11__hash_nodeISM_PvEENS_22__hash_node_destructorINS5_IS18_EEEEEEmOT_DpOT0_
000052e6 _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN6caffe212OperatorBaseENS_14default_deleteISB_EEEERKNSA_11OperatorDefEPNSA_9WorkspaceEEEEEENS_22__unordered_map_hasherIS7_SM_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SM_SR_SP_Lb1EEENS5_ISM_EEE8__rehashILb1EEEvm
0000545e _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN6caffe212OperatorBaseENS_14default_deleteISB_EEEERKNSA_11OperatorDefEPNSA_9WorkspaceEEEEEENS_22__unordered_map_hasherIS7_SM_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SM_SR_SP_Lb1EEENS5_ISM_EEE11__do_rehashILb1EEEvm
000055da _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES7_EENS_22__unordered_map_hasherIS7_S8_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_S8_SD_SB_Lb1EEENS5_IS8_EEE21__construct_node_hashIRKNS_21piecewise_construct_tEJNS_5tupleIJRKS7_EEENSN_IJEEEEEENS_10unique_ptrINS_11__hash_nodeIS8_PvEENS_22__hash_node_destructorINS5_ISV_EEEEEEmOT_DpOT0_
0000577d _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES7_EENS_22__unordered_map_hasherIS7_S8_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_S8_SD_SB_Lb1EEENS5_IS8_EEE8__rehashILb1EEEvm
00005881 _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEES7_EENS_22__unordered_map_hasherIS7_S8_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_S8_SD_SB_Lb1EEENS5_IS8_EEE11__do_rehashILb1EEEvm
00005989 _ZNSt6__ndk16__treeINS_4pairIiiEENS_4lessIS2_EENS_9allocatorIS2_EEE12__find_equalIS2_EERPNS_16__tree_node_baseIPvEENS_21__tree_const_iteratorIS2_PNS_11__tree_nodeIS2_SA_EElEERPNS_15__tree_end_nodeISC_EESD_RKT_
00005a5b _ZNSt6__ndk16__treeINS_4pairIiiEENS_4lessIS2_EENS_9allocatorIS2_EEE12__find_equalIS2_EERPNS_16__tree_node_baseIPvEERPNS_15__tree_end_nodeISC_EERKT_
00005aef _ZN6caffe216OpSchemaRegistry3mapEv
00005b12 _ZNSt6__ndk16__treeINS_12__value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN6caffe28OpSchemaEEENS_19__map_value_compareIS7_SA_NS_4lessIS7_EELb1EEENS5_ISA_EEE4findIS7_EENS_15__tree_iteratorISA_PNS_11__tree_nodeISA_PvEElEERKT_
00005c08 _ZNK6caffe28OpSchema6VerifyERKNS_11OperatorDefE
00005c38 _ZN6caffe211OperatorDefC1ERKS0_
00005c58 _ZN6caffe211OperatorDefD1Ev
00005c74 _ZTVNSt6__ndk110__function6__funcIPFNS_10unique_ptrIN6caffe217GradientMakerBaseENS_14default_deleteIS4_EEEERKNS3_11OperatorDefERKNS_6vectorINS3_15GradientWrapperENS_9allocatorISC_EEEEENSD_ISJ_EESI_EE
00005d3c _ZNKSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN6caffe217GradientMakerBaseENS_14default_deleteISB_EEEERKNSA_11OperatorDefERKNS_6vectorINSA_15GradientWrapperENS5_ISJ_EEEEEEEEENS_22__unordered_map_hasherIS7_SQ_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SQ_SV_ST_Lb1EEENS5_ISQ_EEE4findIS7_EENS_21__hash_const_iteratorIPNS_11__hash_nodeISQ_PvEEEERKT_
00005f0c _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN6caffe217GradientMakerBaseENS_14default_deleteISB_EEEERKNSA_11OperatorDefERKNS_6vectorINSA_15GradientWrapperENS5_ISJ_EEEEEEEEENS_22__unordered_map_hasherIS7_SQ_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SQ_SV_ST_Lb1EEENS5_ISQ_EEE25__emplace_unique_key_argsIS7_JRKNS_21piecewise_construct_tENS_5tupleIJRKS7_EEENS15_IJEEEEEENS_4pairINS_15__hash_iteratorIPNS_11__hash_nodeISQ_PvEEEEbEERKT_DpOT0_
00006139 _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN6caffe217GradientMakerBaseENS_14default_deleteISB_EEEERKNSA_11OperatorDefERKNS_6vectorINSA_15GradientWrapperENS5_ISJ_EEEEEEEEENS_22__unordered_map_hasherIS7_SQ_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SQ_SV_ST_Lb1EEENS5_ISQ_EEE21__construct_node_hashIRKNS_21piecewise_construct_tEJNS_5tupleIJRKS7_EEENS15_IJEEEEEENS9_INS_11__hash_nodeISQ_PvEENS_22__hash_node_destructorINS5_IS1C_EEEEEEmOT_DpOT0_
0000636b _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN6caffe217GradientMakerBaseENS_14default_deleteISB_EEEERKNSA_11OperatorDefERKNS_6vectorINSA_15GradientWrapperENS5_ISJ_EEEEEEEEENS_22__unordered_map_hasherIS7_SQ_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SQ_SV_ST_Lb1EEENS5_ISQ_EEE8__rehashILb1EEEvm
00006507 _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN6caffe217GradientMakerBaseENS_14default_deleteISB_EEEERKNSA_11OperatorDefERKNS_6vectorINSA_15GradientWrapperENS5_ISJ_EEEEEEEEENS_22__unordered_map_hasherIS7_SQ_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SQ_SV_ST_Lb1EEENS5_ISQ_EEE11__do_rehashILb1EEEvm
000066a7 _ZN6caffe219CPUOperatorRegistryEv
000066c9 _ZN6caffe216OpSchemaRegistry9NewSchemaERKNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEES9_i
0000673a _ZN6caffe28OpSchema9NumInputsEi
0000675a _ZN6caffe28OpSchema10NumOutputsEi
0000677c _ZN6caffe28OpSchema28IdenticalTypeAndShapeOfInputEi
000067b0 _ZN6caffe28OpSchema12AllowInplaceENSt6__ndk13setINS1_4pairIiiEENS1_4lessIS4_EENS1_9allocatorIS4_EEEE
00006815 _ZN6caffe28OpSchema6SetDocERKNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEE
00006876 _ZN6caffe28OpSchema5InputEiPKcS2_
00006898 _ZN6caffe28OpSchema6OutputEiPKcS2_
000068bb _ZN6caffe216GradientRegistryEv
000068da _ZN3c108demangleEPKc
000068ef _ZTIN6caffe212OperatorBaseE
0000690b _ZN6caffe212OperatorBase18AddRelatedBlobInfoEPN3c105ErrorE
00006946 _ZTINSt6__ndk110__function6__funcIPFNS_10unique_ptrIN6caffe212OperatorBaseENS_14default_deleteIS4_EEEERKNS3_11OperatorDefEPNS3_9WorkspaceEENS_9allocatorISE_EESD_EE
000069ea _ZTINSt6__ndk110__function6__baseIFNS_10unique_ptrIN6caffe212OperatorBaseENS_14default_deleteIS4_EEEERKNS3_11OperatorDefEPNS3_9WorkspaceEEEE
00006a77 _ZTINSt6__ndk110__function6__funcIPFNS_10unique_ptrIN6caffe217GradientMakerBaseENS_14default_deleteIS4_EEEERKNS3_11OperatorDefERKNS_6vectorINS3_15GradientWrapperENS_9allocatorISC_EEEEENSD_ISJ_EESI_EE
00006b3f _ZTINSt6__ndk110__function6__baseIFNS_10unique_ptrIN6caffe217GradientMakerBaseENS_14default_deleteIS4_EEEERKNS3_11OperatorDefERKNS_6vectorINS3_15GradientWrapperENS_9allocatorISC_EEEEEEE
00006bf9 free
00006bfe _ZNK6caffe214ArgumentHelper19GetRepeatedArgumentIfEENSt6__ndk16vectorIT_NS2_9allocatorIS4_EEEENS2_17basic_string_viewIcNS2_11char_traitsIcEEEERKS7_
00006c92 _ZNK6caffe214ArgumentHelper17GetSingleArgumentIbEET_NSt6__ndk117basic_string_viewIcNS3_11char_traitsIcEEEERKS2_
00006d02 _ZNK6caffe214ArgumentHelper17GetSingleArgumentIfEET_NSt6__ndk117basic_string_viewIcNS3_11char_traitsIcEEEERKS2_
00006d72 _ZNSt6__ndk19to_stringEm
00006d8b _ZNSt6__ndk112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6appendEPKcm
00006dda _ZNSt6__ndk113basic_ostreamIcNS_11char_traitsIcEEElsEm
00006e11 malloc
00006e18 expf
00006e1d memcpy
00006e24 _ZN6caffe28OpSchema10NumOutputsEii
00006e47 _ZN6caffe28OpSchema3ArgEPKcS2_b
00006e67 _ZNK6caffe214ArgumentHelper17GetSingleArgumentINSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEET_NS2_17basic_string_viewIcS5_EERKS9_
00006f01 _ZNSt6__ndk113__stable_sortINS_17_ClassicAlgPolicyERZN6caffe217BoxWithNMSLimitOpINS2_10CPUContextEE13DoRunWithTypeIfEEbvEUliiE_PiEEvT1_SA_T0_NS_15iterator_traitsISA_E15difference_typeEPNSD_10value_typeEl
00006fcd _ZN3c1010TensorImpl6ExtendElf
00006feb _ZNSt6__ndk113__stable_sortINS_17_ClassicAlgPolicyERZN6caffe217BoxWithNMSLimitOpINS2_10CPUContextEE13DoRunWithTypeIiEEbvEUliiE_PiEEvT1_SA_T0_NS_15iterator_traitsISA_E15difference_typeEPNSD_10value_typeEl
000070b7 _ZN3c1031get_default_dtype_as_scalartypeEv
000070e2 _ZN3c105ErrorC1ENS_14SourceLocationENSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEE
0000714a _ZN3c1010TensorImplC2EONS_7StorageENS_14DispatchKeySetEN6caffe28TypeMetaE
00007194 _ZN3c104impl12PyObjectSlotC1Ev
000071b3 _ZN3c104impl12PyObjectSlotD1Ev
000071d6 _ZNSt6__ndk19to_stringEi
000071ef _ZNSt6__ndk19to_stringEf
00007208 sincos
0000720f _ZNSt6__ndk115__inplace_mergeINS_17_ClassicAlgPolicyERZN6caffe217BoxWithNMSLimitOpINS2_10CPUContextEE13DoRunWithTypeIiEEbvEUliiE_PiEEvT1_SA_SA_OT0_NS_15iterator_traitsISA_E15difference_typeESF_PNSE_10value_typeEl
000072e4 _ZNSt6__ndk118__stable_sort_moveINS_17_ClassicAlgPolicyERZN6caffe217BoxWithNMSLimitOpINS2_10CPUContextEE13DoRunWithTypeIiEEbvEUliiE_PiEEvT1_SA_T0_NS_15iterator_traitsISA_E15difference_typeEPNSD_10value_typeE
000073b4 _ZNSt6__ndk113basic_ostreamIcNS_11char_traitsIcEEElsEf
000073eb _ZNSt6__ndk115__inplace_mergeINS_17_ClassicAlgPolicyERZN6caffe217BoxWithNMSLimitOpINS2_10CPUContextEE13DoRunWithTypeIfEEbvEUliiE_PiEEvT1_SA_SA_OT0_NS_15iterator_traitsISA_E15difference_typeESF_PNSE_10value_typeEl
000074c0 _ZNSt6__ndk118__stable_sort_moveINS_17_ClassicAlgPolicyERZN6caffe217BoxWithNMSLimitOpINS2_10CPUContextEE13DoRunWithTypeIfEEbvEUliiE_PiEEvT1_SA_T0_NS_15iterator_traitsISA_E15difference_typeEPNSD_10value_typeE
00007590 _ZN6caffe28OpSchema9NumInputsEii
000075b1 _ZNK6caffe214ArgumentHelper19GetRepeatedArgumentIlEENSt6__ndk16vectorIT_NS2_9allocatorIS4_EEEENS2_17basic_string_viewIcNS2_11char_traitsIcEEEERKS7_
00007645 _ZN6caffe26detail25std_string_metadata_indexE
00007673 _ZN6caffe24math10CopyMatrixIfNS_10CPUContextEEEviiPKT_iPS3_iPT0_
000076b4 _ZN6caffe24math9TransposeIlfNS_10CPUContextEEEviPKT_PKiPKT0_PS8_PT1_
000076f9 _ZN6caffe212DeviceOptionC2EPN6google8protobuf5ArenaEb
0000772f _ZN6caffe212DeviceOptionD1Ev
0000774c _ZN6caffe211OperatorDefC2EPN6google8protobuf5ArenaEb
00007781 _ZN6google8protobuf8internal14ArenaStringPtr3SetERKNSt6__ndk112basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEEPNS0_5ArenaE
00007804 _ZN6caffe28Argument8CopyFromERKS0_
00007827 _ZN6google8protobuf5Arena18CreateMaybeMessageIN6caffe212DeviceOptionEJEEEPT_PS1_DpOT0_
0000787e _ZN6caffe212DeviceOption8CopyFromERKS0_
000078a6 _ZN6google8protobuf5Arena26AllocateAlignedWithCleanupEmPKSt9type_info
000078ec _ZN6google8protobuf8internal20RepeatedPtrFieldBase18AddOutOfLineHelperEPv
00007936 _ZN6google8protobuf5Arena18CreateMaybeMessageIN6caffe28ArgumentEJEEEPT_PS1_DpOT0_
00007988 _ZN6caffe28OpSchema21IdenticalTypeAndShapeEv
000079b5 _ZN6caffe28OpSchema17InheritOnnxSchemaERKNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEE
00007a22 _ZNK6caffe214ArgumentHelper11HasArgumentENSt6__ndk117basic_string_viewIcNS1_11char_traitsIcEEEE
00007a82 _ZNK6caffe214ArgumentHelper19GetRepeatedArgumentIiEENSt6__ndk16vectorIT_NS2_9allocatorIS4_EEEENS2_17basic_string_viewIcNS2_11char_traitsIcEEEERKS7_
00007b16 _ZN6caffe211TensorShapeC2EPN6google8protobuf5ArenaEb
00007b4b _ZN6google8protobuf13RepeatedFieldIlE7ReserveEi
00007b7b _ZN6caffe211TensorShapeD1Ev
00007b97 _ZN6caffe218DataTypeToTypeMetaERKNS_20TensorProto_DataTypeE
00007bd3 _ZN6caffe212DeviceOptionC1ERKS0_
00007bf4 _ZN6caffe212DeviceOption12InternalSwapEPS0_
00007c20 _ZN6caffe211TensorShape8CopyFromERKS0_
00007c47 _ZN6caffe211TensorShape12InternalSwapEPS0_
00007c72 _ZN6caffe211TensorShapeC1ERKS0_
00007c92 _ZN6caffe24math10CopyMatrixINS_10CPUContextEEEvmiiPKviPviPT_PFvS4_S5_mE
00007cda _ZN6caffe26Tensor8CopyFromERKS0_b
00007cfc _ZTVNSt6__ndk110__function6__funcIPFNS_6vectorIN6caffe211TensorShapeENS_9allocatorIS4_EEEERKNS3_11OperatorDefERKS7_ENS5_ISE_EESD_EE
00007d80 _ZTVNSt6__ndk110__function6__funcIPFN6caffe28OpSchema4CostERKNS2_11OperatorDefERKNS_6vectorINS2_11TensorShapeENS_9allocatorIS9_EEEEENSA_ISG_EESF_EE
00007e14 _ZTVNSt6__ndk110__function6__funcIPFNS_4pairINS_6vectorIN6caffe212DeviceOptionENS_9allocatorIS5_EEEES8_EERKNS4_11OperatorDefEENS6_ISE_EESD_EE
00007ea2 _ZN6caffe28OpSchema23TensorInferenceFunctionENSt6__ndk18functionIFNS1_6vectorINS_11TensorShapeENS1_9allocatorIS4_EEEERKNS_11OperatorDefERKS7_EEE
00007f33 _ZN6caffe28OpSchema21CostInferenceFunctionENSt6__ndk18functionIFNS0_4CostERKNS_11OperatorDefERKNS1_6vectorINS_11TensorShapeENS1_9allocatorIS8_EEEEEEE
00007fc9 _ZN6caffe28OpSchema23DeviceInferenceFunctionENSt6__ndk18functionIFNS1_4pairINS1_6vectorINS_12DeviceOptionENS1_9allocatorIS5_EEEES8_EERKNS_11OperatorDefEEEE
00008065 _ZN6caffe28OpSchema19NeedsAllInputShapesENSt6__ndk18functionIFNS1_6vectorINS_11TensorShapeENS1_9allocatorIS4_EEEERKNS_11OperatorDefERKS7_EEE
000080f2 _ZTINSt6__ndk110__function6__funcIPFNS_6vectorIN6caffe211TensorShapeENS_9allocatorIS4_EEEERKNS3_11OperatorDefERKS7_ENS5_ISE_EESD_EE
00008176 _ZTINSt6__ndk110__function6__baseIFNS_6vectorIN6caffe211TensorShapeENS_9allocatorIS4_EEEERKNS3_11OperatorDefERKS7_EEE
000081ec _ZTINSt6__ndk110__function6__funcIPFN6caffe28OpSchema4CostERKNS2_11OperatorDefERKNS_6vectorINS2_11TensorShapeENS_9allocatorIS9_EEEEENSA_ISG_EESF_EE
00008280 _ZTINSt6__ndk110__function6__baseIFN6caffe28OpSchema4CostERKNS2_11OperatorDefERKNS_6vectorINS2_11TensorShapeENS_9allocatorIS9_EEEEEEE
00008306 _ZTINSt6__ndk110__function6__funcIPFNS_4pairINS_6vectorIN6caffe212DeviceOptionENS_9allocatorIS5_EEEES8_EERKNS4_11OperatorDefEENS6_ISE_EESD_EE
00008394 _ZTINSt6__ndk110__function6__baseIFNS_4pairINS_6vectorIN6caffe212DeviceOptionENS_9allocatorIS5_EEEES8_EERKNS4_11OperatorDefEEEE
00008414 _ZN3c1010ReplaceAllERNSt6__ndk112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEENS0_17basic_string_viewIcS3_EES9_
0000848e FLAGS_caffe2_force_shared_col_buffer
000084b3 _ZN6caffe218createSharedBufferINS_10CPUContextEEEvPNS_9WorkspaceE
000084f5 memchr
000084fc _ZTVNSt6__ndk110__function6__funcIZN6caffe26ConvOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNHWCEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
0000858c _ZN6caffe219runWithSharedBufferINS_10CPUContextEEEvPNS_9WorkspaceENSt6__ndk18functionIFvPNS_6TensorEEEE
000085f4 _ZTVNSt6__ndk110__function6__funcIZN6caffe26ConvOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNCHWEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
00008684 _ZN6caffe24math3SetIfNS_10CPUContextEEEvlT_PS3_PT0_
000086b8 _ZN6caffe24math6GemmExIfNS_10CPUContextENS_13DefaultEngineEEEv15CBLAS_TRANSPOSES4_iiiT_PKS5_iS7_iS5_PS5_iPT0_
00008726 _ZN6caffe24math4GemmIfNS_10CPUContextENS_13DefaultEngineEEEv15CBLAS_TRANSPOSES4_iiifPKT_S7_fPS5_PT0_NS_20TensorProto_DataTypeE
000087a5 _ZN6caffe24math8Im2ColNdIfNS_10CPUContextELNS_12StorageOrderE1EEEviiiPKiS5_S5_S5_S5_S5_PKT_PS6_PT0_i
0000880a _ZN6caffe24math6Im2ColIfNS_10CPUContextELNS_12StorageOrderE1EEEviiiiiiiiiiiiiPKT_PS4_PT0_i
00008865 _ZN6caffe24math18GemmStridedBatchedIfNS_10CPUContextENS_13DefaultEngineEEEv15CBLAS_TRANSPOSES4_iiiifPKT_iS7_ifPS5_iPT0_NS_20TensorProto_DataTypeE
000088f7 _ZN6caffe24math11GemmBatchedIfNS_10CPUContextENS_13DefaultEngineEEEv15CBLAS_TRANSPOSES4_iiiifPPKT_S8_fPPS5_PT0_NS_20TensorProto_DataTypeE
00008981 _ZN6caffe24math6Im2ColIfNS_10CPUContextELNS_12StorageOrderE2EEEviiiiiiiiiiiiiPKT_PS4_PT0_i
000089dc _ZN6caffe24math8Im2ColNdIfNS_10CPUContextELNS_12StorageOrderE2EEEviiiPKiS5_S5_S5_S5_S5_PKT_PS6_PT0_i
00008a41 _ZNSt6__ndk113basic_ostreamIcNS_11char_traitsIcEEElsEj
00008a78 _ZN6caffe28OpSchema9FillUsingENSt6__ndk18functionIFvRS0_EEE
00008ab4 _ZTINSt6__ndk110__function6__baseIFvRN6caffe28OpSchemaEEEE
00008aef _ZTINSt6__ndk110__function6__funcIZN6caffe26ConvOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNHWCEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
00008b7f _ZTINSt6__ndk110__function6__baseIFvPN6caffe26TensorEEEE
00008bb8 _ZTINSt6__ndk110__function6__funcIZN6caffe26ConvOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNCHWEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
00008c48 _ZN6google15LogMessageFatalC1EPKci
00008c6b _ZN6google15LogMessageFatalD1Ev
00008c8b _ZTVNSt6__ndk110__function6__funcIZN6caffe215ConvTransposeOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNCHWEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
00008d25 _ZTVNSt6__ndk110__function6__funcIZN6caffe215ConvTransposeOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNHWCEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
00008dbf _ZN6caffe218ReinitializeTensorEPNS_6TensorEN3c108ArrayRefIlEENS2_13TensorOptionsE
00008e11 _ZN6caffe24math6Col2ImIfNS_10CPUContextELNS_12StorageOrderE2EEEviiiiiiiiiiiiiPKT_PS4_PT0_i
00008e6c _ZN6caffe24math7BiasCHWIfNS_10CPUContextEEEvPKT_S5_iiPS3_PT0_
00008eaa _ZN6caffe24math6Col2ImIfNS_10CPUContextELNS_12StorageOrderE1EEEviiiiiiiiiiiiiPKT_PS4_PT0_i
00008f05 _ZN6caffe24math3AddIfNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
00008f45 _ZTINSt6__ndk110__function6__funcIZN6caffe215ConvTransposeOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNCHWEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
00008fdf _ZTINSt6__ndk110__function6__funcIZN6caffe215ConvTransposeOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNHWCEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
00009079 _ZN6caffe29Workspace13GetThreadPoolEv
0000909f _ZTVNSt6__ndk110__function6__funcIZN6caffe221ConvTransposeMobileOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNCHWEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
0000913f _ZTVNSt6__ndk110__function6__funcIZN6caffe225reinterleaveMultithreadedILi1EfNS2_10CPUContextEEEvPKT0_S7_PS5_iiiiiiiPNS2_10ThreadPoolEEUlimE_NS_9allocatorISB_EEFvimEEE
000091e6 _ZTVNSt6__ndk110__function6__funcIZN6caffe225reinterleaveMultithreadedILi2EfNS2_10CPUContextEEEvPKT0_S7_PS5_iiiiiiiPNS2_10ThreadPoolEEUlimE_NS_9allocatorISB_EEFvimEEE
0000928d _ZTVNSt6__ndk110__function6__funcIZN6caffe225reinterleaveMultithreadedILi3EfNS2_10CPUContextEEEvPKT0_S7_PS5_iiiiiiiPNS2_10ThreadPoolEEUlimE_NS_9allocatorISB_EEFvimEEE
00009334 _ZTVNSt6__ndk110__function6__funcIZN6caffe225reinterleaveMultithreadedILi4EfNS2_10CPUContextEEEvPKT0_S7_PS5_iiiiiiiPNS2_10ThreadPoolEEUlimE_NS_9allocatorISB_EEFvimEEE
000093db _ZTINSt6__ndk110__function6__funcIZN6caffe221ConvTransposeMobileOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNCHWEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
0000947b _ZTINSt6__ndk110__function6__baseIFvimEEE
000094a5 _ZTINSt6__ndk110__function6__funcIZN6caffe225reinterleaveMultithreadedILi1EfNS2_10CPUContextEEEvPKT0_S7_PS5_iiiiiiiPNS2_10ThreadPoolEEUlimE_NS_9allocatorISB_EEFvimEEE
0000954c _ZTINSt6__ndk110__function6__funcIZN6caffe225reinterleaveMultithreadedILi2EfNS2_10CPUContextEEEvPKT0_S7_PS5_iiiiiiiPNS2_10ThreadPoolEEUlimE_NS_9allocatorISB_EEFvimEEE
000095f3 _ZTINSt6__ndk110__function6__funcIZN6caffe225reinterleaveMultithreadedILi3EfNS2_10CPUContextEEEvPKT0_S7_PS5_iiiiiiiPNS2_10ThreadPoolEEUlimE_NS_9allocatorISB_EEFvimEEE
0000969a _ZTINSt6__ndk110__function6__funcIZN6caffe225reinterleaveMultithreadedILi4EfNS2_10CPUContextEEEvPKT0_S7_PS5_iiiiiiiPNS2_10ThreadPoolEEUlimE_NS_9allocatorISB_EEFvimEEE
00009741 _ZN6caffe216RandomNumberSeedEv
00009760 _ZN6caffe28OpSchema10Arg_IsTestE
00009781 _ZN6caffe28OpSchema9ArgIsTestEPKc
000097a3 _ZNSt6__ndk112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE4nposE
000097ec _ZN6caffe221elementwise_ops_utils33ComputeBinaryBroadcastForwardDimsERKN3c108ArrayRefIiEES5_
00009849 _ZN6caffe221elementwise_ops_utils27ComputeLegacyBroadcastSizesERKNS_6TensorES3_i
0000989a _ZN6caffe24math3AddIiNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
000098da _ZN6caffe24math3AddIlNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
0000991a _ZN6caffe24math3AddIdNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
0000995a _ZN6caffe24math3DivIiNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
0000999a _ZN6caffe24math3DivIlNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
000099da _ZN6caffe24math3DivIfNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
00009a1a _ZN6caffe24math3DivIdNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
00009a5a _ZN6caffe24math3MulIiNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
00009a9a _ZN6caffe24math3MulIlNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
00009ada _ZN6caffe24math3MulIfNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
00009b1a _ZN6caffe24math3MulIdNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
00009b5a _ZN6caffe24math3SubIiNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
00009b9a _ZN6caffe24math3SubIlNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
00009bda _ZN6caffe24math3SubIfNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
00009c1a _ZN6caffe24math3SubIdNS_10CPUContextEEEviPKiiS4_PKT_S7_PS5_PT0_
00009c5a _ZN6caffe24math3AddIfNS_10CPUContextEEEviPKT_S5_PS3_PT0_
00009c93 _ZN6caffe24math3AddIdNS_10CPUContextEEEviPKT_S5_PS3_PT0_
00009ccc _ZN6caffe24math3AddIiNS_10CPUContextEEEviPKT_S5_PS3_PT0_
00009d05 _ZN6caffe24math3AddIlNS_10CPUContextEEEviPKT_S5_PS3_PT0_
00009d3e _ZN6caffe28OpSchema21InputsCanCrossDevicesEv
00009d6b _ZNSt6__ndk16__treeIiNS_4lessIiEENS_9allocatorIiEEE30__emplace_hint_unique_key_argsIiJRKiEEENS_4pairINS_15__tree_iteratorIiPNS_11__tree_nodeIiPvEElEEbEENS_21__tree_const_iteratorIiSE_lEERKT_DpOT0_
00009e30 _ZN6caffe24math11RandUniformIfNS_10CPUContextEEEvmT_S3_PS3_PT0_
00009e70 _ZNK6caffe214ArgumentHelper23HasSingleArgumentOfTypeIiEEbNSt6__ndk117basic_string_viewIcNS2_11char_traitsIcEEEE
00009ee0 _ZNK6caffe214ArgumentHelper23HasSingleArgumentOfTypeIfEEbNSt6__ndk117basic_string_viewIcNS2_11char_traitsIcEEEE
00009f50 _ZN6caffe24math11RandUniformIiNS_10CPUContextEEEvmT_S3_PS3_PT0_
00009f90 _ZN6caffe24math17RandUniformUniqueIiNS_10CPUContextEEEvmT_S3_PS3_mPKS3_PT0_
00009fdc _ZN6caffe24math17RandUniformUniqueIlNS_10CPUContextEEEvmT_S3_PS3_mPKS3_PT0_
0000a028 _ZNK6caffe214ArgumentHelper23HasSingleArgumentOfTypeIlEEbNSt6__ndk117basic_string_viewIcNS2_11char_traitsIcEEEE
0000a098 _ZNK6caffe214ArgumentHelper17GetSingleArgumentIlEET_NSt6__ndk117basic_string_viewIcNS3_11char_traitsIcEEEERKS2_
0000a108 _ZN6caffe24math3SetIdNS_10CPUContextEEEvlT_PS3_PT0_
0000a13c _ZN6caffe24math3SetIbNS_10CPUContextEEEvlT_PS3_PT0_
0000a170 _ZN6caffe24math3SetIaNS_10CPUContextEEEvlT_PS3_PT0_
0000a1a4 _ZN6caffe24math3SetIsNS_10CPUContextEEEvlT_PS3_PT0_
0000a1d8 _ZN6caffe24math3SetIiNS_10CPUContextEEEvlT_PS3_PT0_
0000a20c _ZN6caffe24math3SetIlNS_10CPUContextEEEvlT_PS3_PT0_
0000a240 _ZN6caffe24math3SetIhNS_10CPUContextEEEvlT_PS3_PT0_
0000a274 _ZN6caffe24math3SetItNS_10CPUContextEEEvlT_PS3_PT0_
0000a2a8 _ZNK6caffe214ArgumentHelper17GetSingleArgumentIdEET_NSt6__ndk117basic_string_viewIcNS3_11char_traitsIcEEEERKS2_
0000a318 _ZNK6caffe214ArgumentHelper17GetSingleArgumentIaEET_NSt6__ndk117basic_string_viewIcNS3_11char_traitsIcEEEERKS2_
0000a388 _ZNK6caffe214ArgumentHelper17GetSingleArgumentIsEET_NSt6__ndk117basic_string_viewIcNS3_11char_traitsIcEEEERKS2_
0000a3f8 _ZNK6caffe214ArgumentHelper17GetSingleArgumentIhEET_NSt6__ndk117basic_string_viewIcNS3_11char_traitsIcEEEERKS2_
0000a468 _ZNK6caffe214ArgumentHelper17GetSingleArgumentItEET_NSt6__ndk117basic_string_viewIcNS3_11char_traitsIcEEEERKS2_
0000a4d8 _ZN6caffe24math12RandGaussianIfNS_10CPUContextEEEvmT_S3_PS3_PT0_
0000a519 _ZNSt6__ndk16__treeIiNS_4lessIiEENS_9allocatorIiEEE12__find_equalIiEERPNS_16__tree_node_baseIPvEENS_21__tree_const_iteratorIiPNS_11__tree_nodeIiS8_EElEERPNS_15__tree_end_nodeISA_EESB_RKT_
0000a5d5 _ZN6caffe28OpSchema9NumInputsENSt6__ndk13setIiNS1_4lessIiEENS1_9allocatorIiEEEE
0000a625 _ZN6caffe24math4GemvIfNS_10CPUContextENS_13DefaultEngineEEEv15CBLAS_TRANSPOSEiifPKT_S7_fPS5_PT0_NS_20TensorProto_DataTypeE
0000a6a0 _ZTVNSt6__ndk110__function6__funcINS_6__bindIRFNS_6vectorIN6caffe211TensorShapeENS_9allocatorIS5_EEEERKNS4_11OperatorDefERKS8_bEJRKNS_12placeholders4__phILi1EEERKNSH_ILi2EEEbEEENS6_ISO_EEFS8_SB_SD_EEE
0000a769 _ZTINSt6__ndk16__bindIRFNS_6vectorIN6caffe211TensorShapeENS_9allocatorIS3_EEEERKNS2_11OperatorDefERKS6_bEJRKNS_12placeholders4__phILi1EEERKNSF_ILi2EEEbEEE
0000a804 _ZTVNSt6__ndk110__function6__funcINS_6__bindIRFN6caffe28OpSchema4CostERKNS3_11OperatorDefERKNS_6vectorINS3_11TensorShapeENS_9allocatorISA_EEEEbEJRKNS_12placeholders4__phILi1EEERKNSJ_ILi2EEEbEEENSB_ISQ_EEFS5_S8_SF_EEE
0000a8dd _ZTINSt6__ndk16__bindIRFN6caffe28OpSchema4CostERKNS1_11OperatorDefERKNS_6vectorINS1_11TensorShapeENS_9allocatorIS8_EEEEbEJRKNS_12placeholders4__phILi1EEERKNSH_ILi2EEEbEEE
0000a988 _ZN6caffe216FCShapeInferenceERKNS_11OperatorDefERKNSt6__ndk16vectorINS_11TensorShapeENS3_9allocatorIS5_EEEEb
0000a9f5 _ZN6caffe218CostInferenceForFCERKNS_11OperatorDefERKNSt6__ndk16vectorINS_11TensorShapeENS3_9allocatorIS5_EEEEb
0000aa64 _ZN6caffe224FCGradientShapeInferenceERKNS_11OperatorDefERKNSt6__ndk16vectorINS_11TensorShapeENS3_9allocatorIS5_EEEEb
0000aad9 _ZN6caffe226CostInferenceForFCGradientERKNS_11OperatorDefERKNSt6__ndk16vectorINS_11TensorShapeENS3_9allocatorIS5_EEEEb
0000ab50 _ZTINSt6__ndk110__function6__funcINS_6__bindIRFNS_6vectorIN6caffe211TensorShapeENS_9allocatorIS5_EEEERKNS4_11OperatorDefERKS8_bEJRKNS_12placeholders4__phILi1EEERKNSH_ILi2EEEbEEENS6_ISO_EEFS8_SB_SD_EEE
0000ac19 _ZTINSt6__ndk118__weak_result_typeIPFNS_6vectorIN6caffe211TensorShapeENS_9allocatorIS3_EEEERKNS2_11OperatorDefERKS6_bEEE
0000ac92 _ZTINSt6__ndk110__function6__funcINS_6__bindIRFN6caffe28OpSchema4CostERKNS3_11OperatorDefERKNS_6vectorINS3_11TensorShapeENS_9allocatorISA_EEEEbEJRKNS_12placeholders4__phILi1EEERKNSJ_ILi2EEEbEEENSB_ISQ_EEFS5_S8_SF_EEE
0000ad6b _ZTINSt6__ndk118__weak_result_typeIPFN6caffe28OpSchema4CostERKNS1_11OperatorDefERKNS_6vectorINS1_11TensorShapeENS_9allocatorIS8_EEEEbEEE
0000adf4 _ZN6caffe212MakeArgumentIiEENS_8ArgumentERKNSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEERKT_
0000ae67 _ZN6caffe28ArgumentC1ERKS0_
0000ae83 _ZNK6caffe214ArgumentHelper23HasSingleArgumentOfTypeINSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEEbNS2_17basic_string_viewIcS5_EE
0000af1d _ZNK6caffe214ArgumentHelper19GetRepeatedArgumentIdEENSt6__ndk16vectorIT_NS2_9allocatorIS4_EEEENS2_17basic_string_viewIcNS2_11char_traitsIcEEEERKS7_
0000afb1 _ZNK6caffe214ArgumentHelper19GetRepeatedArgumentIbEENSt6__ndk16vectorIT_NS2_9allocatorIS4_EEEENS2_17basic_string_viewIcNS2_11char_traitsIcEEEERKS7_
0000b045 _ZNK6caffe214ArgumentHelper19GetRepeatedArgumentIsEENSt6__ndk16vectorIT_NS2_9allocatorIS4_EEEENS2_17basic_string_viewIcNS2_11char_traitsIcEEEERKS7_
0000b0d9 _ZNK6caffe214ArgumentHelper19GetRepeatedArgumentINSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEEENS2_6vectorIT_NS6_ISA_EEEENS2_17basic_string_viewIcS5_EERKSC_
0000b18d _ZN6caffe26NetDefC2EPN6google8protobuf5ArenaEb
0000b1bc _ZN6caffe26NetDefD1Ev
0000b1d2 _ZN6caffe29CreateNetERKNS_6NetDefEPNS_9WorkspaceE
0000b204 _ZNK6caffe214ArgumentHelper23HasSingleArgumentOfTypeINS_6NetDefEEEbNSt6__ndk117basic_string_viewIcNS3_11char_traitsIcEEEE
0000b27e _ZNK6caffe214ArgumentHelper17GetSingleArgumentINS_6NetDefEEET_NSt6__ndk117basic_string_viewIcNS4_11char_traitsIcEEEERKS3_
0000b2f8 _ZN6caffe28OpSchema12AllowInplaceENSt6__ndk18functionIFbiiEEE
0000b336 _ZTINSt6__ndk110__function6__baseIFbiiEEE
0000b360 _ZN6caffe28OpSchema10ScalarTypeENS_20TensorProto_DataTypeE
0000b39b _ZN6caffe24math3LogIfNS_10CPUContextEEEviPKT_PS3_PT0_
0000b3d1 _ZNK3c107SymBool10guard_boolEPKcl
0000b3f3 _ZNK3c1017SymbolicShapeMeta32init_is_channels_last_contiguousEv
0000b433 _ZNK3c1017SymbolicShapeMeta35init_is_channels_last_3d_contiguousEv
0000b476 _ZNK3c1017SymbolicShapeMeta18init_is_contiguousEv
0000b4a8 _ZN6caffe211GetArgumentERKNS_11OperatorDefENSt6__ndk117basic_string_viewIcNS3_11char_traitsIcEEEE
0000b50a _ZN6caffe24math3MinIfNS_10CPUContextEEEviPKT_S5_PS3_PT0_
0000b543 _ZN6caffe24math3MaxIfNS_10CPUContextEEEviPKT_S5_PS3_PT0_
0000b57c _ZN6caffe24math9NHWC2NCHWIfNS_10CPUContextEEEviiiPKT_PS3_PT0_
0000b5ba _ZN6caffe24math9NCHW2NHWCIfNS_10CPUContextEEEviiiPKT_PS3_PT0_
0000b5f8 _ZNSt6__ndk1plIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_12basic_stringIT_T0_T1_EEPKS6_RKS9_
0000b656 _ZN6caffe24math10ReduceMeanIfNS_10CPUContextEEEviPKiS4_T_PKS5_PS5_PT0_b
0000b69e _ZN6caffe24math5ScaleIffNS_10CPUContextEEEvlT_PKT0_PS4_PT1_
0000b6da _ZN6caffe24math9ReduceMaxIfNS_10CPUContextEEEviPKiS4_T_PKS5_PS5_PT0_b
0000b720 _ZN6caffe28OpSchema37IdenticalTypeAndShapeOfMultipleInputsERKNSt6__ndk16vectorIiNS1_9allocatorIiEEEE
0000b785 _ZNSt6__ndk16__treeINS_12__value_typeINS_4pairIN6caffe214TypeIdentifierES4_EENS_8functionIFvRKNS3_6TensorES9_PS8_PS7_bEEEEENS_19__map_value_compareIS5_SE_NS_4lessIS5_EELb1EEENS_9allocatorISE_EEE30__emplace_hint_unique_key_argsIS5_JRKNS2_IKS5_SD_EEEEENS2_INS_15__tree_iteratorISE_PNS_11__tree_nodeISE_PvEElEEbEENS_21__tree_const_iteratorISE_SV_lEERKT_DpOT0_
0000b8ea _ZNSt6__ndk16__treeINS_12__value_typeINS_4pairIN6caffe214TypeIdentifierES4_EENS_8functionIFvRKNS3_6TensorES9_PS8_PS7_bEEEEENS_19__map_value_compareIS5_SE_NS_4lessIS5_EELb1EEENS_9allocatorISE_EEE12__find_equalIS5_EERPNS_16__tree_node_baseIPvEERPNS_15__tree_end_nodeISQ_EERKT_
0000b9fd _ZNSt6__ndk16__treeINS_12__value_typeINS_4pairIN6caffe214TypeIdentifierES4_EENS_8functionIFvRKNS3_6TensorES9_PS8_PS7_bEEEEENS_19__map_value_compareIS5_SE_NS_4lessIS5_EELb1EEENS_9allocatorISE_EEE12__find_equalIS5_EERPNS_16__tree_node_baseIPvEENS_21__tree_const_iteratorISE_PNS_11__tree_nodeISE_SO_EElEERPNS_15__tree_end_nodeISQ_EESR_RKT_
0000bb4e _ZNSt6__ndk16__treeINS_12__value_typeINS_4pairIN6caffe214TypeIdentifierES4_EENS_8functionIFvRKNS3_6TensorES9_PS8_PS7_bEEEEENS_19__map_value_compareIS5_SE_NS_4lessIS5_EELb1EEENS_9allocatorISE_EEE16__construct_nodeIJRKNS2_IKS5_SD_EEEEENS_10unique_ptrINS_11__tree_nodeISE_PvEENS_22__tree_node_destructorINSJ_ISU_EEEEEEDpOT_
0000bc8f _ZTVNSt6__ndk117bad_function_callE
0000bcb2 _ZTINSt6__ndk117bad_function_callE
0000bcd5 _ZNSt6__ndk117bad_function_callD1Ev
0000bcf9 _ZN6caffe28OpSchema16NumInputsOutputsENSt6__ndk18functionIFbiiEEE
0000bd3b _ZN6caffe28OpSchema9NumInputsENSt6__ndk18functionIFbiEEE
0000bd74 _ZTINSt6__ndk110__function6__baseIFvRKN6caffe26TensorES5_PS4_PS3_bEEE
0000bdba _ZTINSt6__ndk110__function6__baseIFbiEEE
0000bde3 _ZN6caffe24math5ScaleIfdNS_10CPUContextEEEvlT_PKT0_PS4_PT1_
0000be1f _ZN6caffe210CPUContext19CopyBytesSameDeviceEmPKvPv
0000be52 _ZN6caffe223ReinitializeAndCopyFromEPNS_6TensorEN3c1013TensorOptionsERKS0_b
0000be9e _ZN6caffe24math3SetIcNS_10CPUContextEEEvlT_PS3_PT0_
0000bed2 _ZN6caffe28OpSchema20DisallowInputFillersEv
0000befe _ZN6caffe24math3DotIfNS_10CPUContextEEEviPKT_S5_PS3_PT0_
0000bf37 _ZN6caffe24math3MulIfNS_10CPUContextEEEviPKT_S5_PS3_PT0_
0000bf70 _ZN6caffe24math3ExpIfNS_10CPUContextEEEviPKT_PS3_PT0_
0000bfa6 _ZNSt6__ndk113basic_ostreamIcNS_11char_traitsIcEEElsEd
0000bfdd _ZN6caffe24math7MomentsIfNS_10CPUContextEEEviPKiS4_PKT_PS5_S8_PT0_b
0000c021 _ZN6caffe24math13AffineChannelIfNS_10CPUContextELNS_12StorageOrderE2EEEviiiPKT_S6_S6_PS4_PT0_
0000c07f _ZN6caffe24math13AffineChannelIfNS_10CPUContextELNS_12StorageOrderE1EEEviiiPKT_S6_S6_PS4_PT0_
0000c0dd _ZN6caffe24math5AxpbyIffNS_10CPUContextEEEvlT_PKT0_S3_PS4_PT1_
0000c11c _ZN6caffe24math6InvStdIfNS_10CPUContextEEEviT_PKS3_PS3_PT0_
0000c158 _ZN6caffe28OpSchema10NumOutputsENSt6__ndk13setIiNS1_4lessIiEENS1_9allocatorIiEEEE
0000c1aa _ZN6caffe28OpSchema14EnforceInplaceENSt6__ndk13setINS1_4pairIiiEENS1_4lessIS4_EENS1_9allocatorIS4_EEEE
0000c211 _ZN6caffe29Workspace10CreateBlobERKNSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEE
0000c278 _ZN6caffe24math4TanhIfNS_10CPUContextEEEviPKT_PS3_PT0_
0000c2af _ZNSt6__ndk16__sortIRNS_6__lessIiiEEPiEEvT0_S5_T_
0000c2e1 _ZN6caffe24math9TransposeIldNS_10CPUContextEEEviPKT_PKiPKT0_PS8_PT1_
0000c326 _ZN6caffe24math9TransposeIliNS_10CPUContextEEEviPKT_PKiPKT0_PS8_PT1_
0000c36b _ZN6caffe24math9TransposeIllNS_10CPUContextEEEviPKT_PKiPKT0_PS8_PT1_
0000c3b0 _ZN6caffe218GetMutableArgumentERKNSt6__ndk112basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEEbPNS_11OperatorDefE
0000c428 _ZN6caffe28Argument5ClearEv
0000c444 _ZN6google8protobuf8internal20RepeatedPtrFieldBase14InternalExtendEi
0000c489 _ZN6caffe28Argument9MergeFromERKS0_
0000c4ad _ZN6caffe212TensorProtosC2EPN6google8protobuf5ArenaEb
0000c4e3 _ZN6google8protobuf11MessageLite14ParseFromArrayEPKvi
0000c519 ZSTD_decompress
0000c529 ZSTD_isError
0000c536 _ZN6caffe212TensorProtosD1Ev
0000c553 ZSTD_getErrorName
0000c565 _ZNSt6__ndk16__treeINS_12__value_typeIiNS_8functionIFPhPN6caffe26TensorEEEEEENS_19__map_value_compareIiS9_NS_4lessIiEELb1EEENS_9allocatorIS9_EEE30__emplace_hint_unique_key_argsIiJRKNS_4pairIKiS8_EEEEENSI_INS_15__tree_iteratorIS9_PNS_11__tree_nodeIS9_PvEElEEbEENS_21__tree_const_iteratorIS9_SR_lEERKT_DpOT0_
0000c698 _ZNSt6__ndk16__treeINS_12__value_typeIiNS_8functionIFPhPN6caffe26TensorEEEEEENS_19__map_value_compareIiS9_NS_4lessIiEELb1EEENS_9allocatorIS9_EEE12__find_equalIiEERPNS_16__tree_node_baseIPvEENS_21__tree_const_iteratorIS9_PNS_11__tree_nodeIS9_SJ_EElEERPNS_15__tree_end_nodeISL_EESM_RKT_
0000c7b5 _ZNSt6__ndk16__treeINS_12__value_typeIiNS_8functionIFPhPN6caffe26TensorEEEEEENS_19__map_value_compareIiS9_NS_4lessIiEELb1EEENS_9allocatorIS9_EEE16__construct_nodeIJRKNS_4pairIKiS8_EEEEENS_10unique_ptrINS_11__tree_nodeIS9_PvEENS_22__tree_node_destructorINSE_ISQ_EEEEEEDpOT_
0000c8c6 _ZTINSt6__ndk110__function6__baseIFPhPN6caffe26TensorEEEE
0000c900 _ZN6caffe24math10CopyVectorIfNS_10CPUContextEEEviPKT_PS3_PT0_
0000c93e _ZNSt6__ndk111__call_onceERVmPvPFvS2_E
0000c965 _ZN6caffe28TypeMeta13_typeMetaDataINS_4int813Int8TensorCPUEEEtv
0000c9a5 _ZN6google15LogMessageFatalC1EPKciRKNS_13CheckOpStringE
0000c9dd _ZN6google4base21CheckOpMessageBuilderC1EPKc
0000ca0a _ZN6google4base21CheckOpMessageBuilder7ForVar2Ev
0000ca3b _ZN6google4base21CheckOpMessageBuilder9NewStringEv
0000ca6e _ZN6google4base21CheckOpMessageBuilderD1Ev
0000ca99 _ZN6google22MakeCheckOpValueStringIhEEvPNSt6__ndk113basic_ostreamIcNS1_11char_traitsIcEEEERKT_
0000caf8 frexp
0000cafe _ZN6caffe24math9TransposeIlhNS_10CPUContextEEEviPKT_PKiPKT0_PS8_PT1_
0000cb43 _ZN3c1013C10FlagParser5ParseIbEEbRKNSt6__ndk112basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEEPT_
0000cbad _ZTVNSt6__ndk110__function6__funcIPFNS_10unique_ptrIN3c1013C10FlagParserENS_14default_deleteIS4_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEENSB_ISH_EESG_EE
0000cc5e _ZNKSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN3c1013C10FlagParserENS_14default_deleteISB_EEEERKS7_EEEEENS_22__unordered_map_hasherIS7_SJ_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SJ_SO_SM_Lb1EEENS5_ISJ_EEE4findIS7_EENS_21__hash_const_iteratorIPNS_11__hash_nodeISJ_PvEEEERKT_
0000cde9 _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN3c1013C10FlagParserENS_14default_deleteISB_EEEERKS7_EEEEENS_22__unordered_map_hasherIS7_SJ_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SJ_SO_SM_Lb1EEENS5_ISJ_EEE25__emplace_unique_key_argsIS7_JRKNS_21piecewise_construct_tENS_5tupleIJSG_EEENSY_IJEEEEEENS_4pairINS_15__hash_iteratorIPNS_11__hash_nodeISJ_PvEEEEbEERKT_DpOT0_
0000cfce _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN3c1013C10FlagParserENS_14default_deleteISB_EEEERKS7_EEEEENS_22__unordered_map_hasherIS7_SJ_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SJ_SO_SM_Lb1EEENS5_ISJ_EEE21__construct_node_hashIRKNS_21piecewise_construct_tEJNS_5tupleIJSG_EEENSY_IJEEEEEENS9_INS_11__hash_nodeISJ_PvEENS_22__hash_node_destructorINS5_IS13_EEEEEEmOT_DpOT0_
0000d1b8 _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN3c1013C10FlagParserENS_14default_deleteISB_EEEERKS7_EEEEENS_22__unordered_map_hasherIS7_SJ_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SJ_SO_SM_Lb1EEENS5_ISJ_EEE8__rehashILb1EEEvm
0000d30f _ZNSt6__ndk112__hash_tableINS_17__hash_value_typeINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_8functionIFNS_10unique_ptrIN3c1013C10FlagParserENS_14default_deleteISB_EEEERKS7_EEEEENS_22__unordered_map_hasherIS7_SJ_NS_4hashIS7_EENS_8equal_toIS7_EELb1EEENS_21__unordered_map_equalIS7_SJ_SO_SM_Lb1EEENS5_ISJ_EEE11__do_rehashILb1EEEvm
0000d46a nnp_initialize
0000d479 _ZNSt6__ndk19to_stringEj
0000d492 _ZNSt6__ndk14coutE
0000d4a5 _ZNKSt6__ndk18ios_base6getlocEv
0000d4c5 _ZNSt6__ndk15ctypeIcE2idE
0000d4df _ZNKSt6__ndk16locale9use_facetERNS0_2idE
0000d508 _ZNSt6__ndk16localeD1Ev
0000d520 _ZNSt6__ndk113basic_ostreamIcNS_11char_traitsIcEEE3putEc
0000d559 _ZNSt6__ndk113basic_ostreamIcNS_11char_traitsIcEEE5flushEv
0000d594 vsnprintf
0000d59e _ZN3c1016C10FlagsRegistryEv
0000d5ba _ZTINSt6__ndk110__function6__funcIPFNS_10unique_ptrIN3c1013C10FlagParserENS_14default_deleteIS4_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEENSB_ISH_EESG_EE
0000d66b _ZTINSt6__ndk110__function6__baseIFNS_10unique_ptrIN3c1013C10FlagParserENS_14default_deleteIS4_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
0000d70e cpuinfo_initialize
0000d721 pthread_once
0000d72e calloc
0000d735 realloc
0000d73d legacy_pthreadpool_compute_4d_tiled
0000d761 legacy_pthreadpool_compute_3d_tiled
0000d785 legacy_pthreadpool_compute_1d_tiled
0000d7a9 legacy_pthreadpool_compute_1d
0000d7c7 legacy_pthreadpool_compute_2d
0000d7e5 __wrap__ZTISt12length_error
0000d801 __wrap__ZNSt9bad_allocC1Ev
0000d81c __wrap___cxa_begin_catch
0000d835 __wrap__ZTVN10__cxxabiv120__si_class_type_infoE
0000d865 __wrap__ZTVN10__cxxabiv117__class_type_infoE
0000d892 __wrap___cxa_allocate_exception
0000d8b2 __wrap___cxa_guard_release
0000d8cd __wrap__ZdlPv
0000d8db __wrap__ZNSt13runtime_errorD1Ev
0000d8fb __wrap__ZNSt20bad_array_new_lengthD1Ev
0000d922 __wrap___cxa_end_catch
0000d939 __wrap___cxa_pure_virtual
0000d953 __wrap__ZTVSt12length_error
0000d96f __wrap___gxx_personality_v0
0000d98b __wrap__Unwind_Resume
0000d9a1 __wrap___cxa_throw
0000d9b4 __wrap___cxa_free_exception
0000d9d0 __wrap__ZNSt9bad_allocD1Ev
0000d9eb __wrap__ZTISt9bad_alloc
0000da03 __wrap__Znwm
0000da10 __wrap__ZSt9terminatev
0000da27 __wrap__ZTISt9exception
0000da3f __wrap__ZNSt11logic_errorC2EPKc
0000da5f __wrap__ZNSt12length_errorD1Ev
0000da7e __wrap__ZNSt20bad_array_new_lengthC1Ev
0000daa5 __wrap___cxa_guard_acquire
0000dac0 __wrap__ZTISt20bad_array_new_length
0000dae4 __wrap__ZTISt13runtime_error
0000db01 __wrap___cxa_guard_abort
0000db1a __wrap__ZTISt12out_of_range
0000db36 __wrap__ZTVN10__cxxabiv120__function_type_infoE
0000db66 __wrap__ZTVN10__cxxabiv119__pointer_type_infoE
0000db95 __wrap__ZNSt12out_of_rangeD1Ev
0000dbb4 __wrap__ZNSt9exceptionD2Ev
0000dbcf __wrap__ZTVSt12out_of_range
0000dbeb __wrap__ZdaPv
0000dbf9 __wrap__Znam
0000dc06 __wrap___cxa_rethrow
0000dc1b __android_log_vprint
0000dc30 __wrap__ZnwmRKSt9nothrow_t
0000dc4b __wrap__ZSt7nothrow
0000dc5f legacy_pthreadpool_compute_2d_tiled
0000dc83 nnp_hwinfo
0000dc8e clock_gettime
0000dc9c mmap
0000dca1 munmap
0000dca8 getauxval
0000dcb2 __system_property_get
0000dcc8 strncmp
0000dcd0 libm.so
0000dcd8 LIBC
0000dcdd libc.so
0000dce5 libxplat_third-party_zstd__zstd.so
0000dd08 libxplat_folly_executor.so
0000dd23 libdl.so
0000dd2c libdouble-conversion.so
0000dd44 libxplat_caffe2_caffe2.so
0000dd5e libxplat_caffe2_c10_c10.so
0000dd79 libthird-party_zlib_1_3_1_z.so
0000dd98 libc++_shared.so
0000dda9 libxplat_caffe2_pthreadpool.so
0000ddc8 liblog.so
0000ddd2 libxplat_caffe2_common_core.so
0000ddf1 libxplat_caffe2_caffe2_proto_types.so
0000de17 libxplat_third-party_NNPACK_NNPACK.so
0000de3d libcaffe2_core_ops.so
0000de58 APS2
0001b09e o@{dim}
0001b0a7 The convolution operator consumes an input vector, a {dim}filter blob
0001b0ed and a bias blob and computes the output. {conv_doc}
0001b121 MaxPool{dim} {pool_doc}
0001b139 AveragePool{dim} {pool_doc}
0001b155 is_empty
0001b15e IsEmpty
0001b166 identity
0001b16f bool (default true), transform the boxes to the scaled image space after applying the bbox deltas.Set to false to match the detectron code, set to true for keypoint models and for backward compatibility
0001b23a convolution_transform_strategy
0001b259 Failed to query workspace size to precompute kernels, falling back to re-compute strategy
0001b2b3 computeDispatchKey
0001b2c6 BatchBoxCox
0001b2d2 A tensor that is coerced into a 2D blob of size (KxN) containing fully connected weight matrix
0001b331 input float or double N * D matrix
0001b354 StumpFuncIndex
0001b363 start_idx
0001b36d end_idx
0001b375 should_output_softmax
0001b38b Int8Softmax
0001b397 failed to create Clamp operator with [%u, %u] output range: range min must be below range max
0001b3f5 failed to create Sigmoid operator with [%u, %u] output range: range min must be below range max
0001b455 failed to create add operator with [%u, %u] output range: range min must be below range max
0001b4b1 failed to create Leaky ReLU operator with [%u, %u] output range: range min must be below range max
0001b518 Input data blob from previous layer; has size (N x H x W x C), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that NHWC is supported now
0001b5d5 Index_Low
0001b5df axis_w
0001b5e6 dilation_w
0001b5f1 kernel_w
0001b5fa adj_w
0001b600 tiled_batch_w
0001b60e stride_w
0001b617 pooled_w
0001b620 pad_w
0001b626 Int8Conv
0001b633 saved_inv_stdev
0001b643 Int8LeakyRelu
0001b651 Int8ConvRelu
0001b65e Int8SumRelu
0001b66a Int8MaxPoolRelu
0001b67a Int8AveragePoolRelu
0001b68e Int8AddRelu
0001b69a PRelu
0001b6a0 Int8Relu
0001b6ad (*int*): set to 1 to use the first input as shape; `shape` input must be in CPU context
0001b705 (*Tuple(int)*): length of each output
0001b72b (Default to 1) Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output
0001b7a5 Transposed output
0001b7b7 1D output tensor with same shape as input
0001b7e1 Output data blob with same shape as input
0001b80b Cannot set extra_shape when there is no input
0001b839 Dropout
0001b841 box_out
0001b849 rois_out
0001b852 is_test
0001b85a Int8ResizeNearest
0001b86c broadcast
0001b876 end >= start
0001b883 options.device_opt() != std::nullopt
0001b8a8 history_labels.dim32(0) == historical_count
0001b8d4 candidate_prod_preds.dim32(0) == candidate_count
0001b905 number of output channels must be divisible by groups count
0001b941 number of input channels must be divisible by groups count
0001b97c front
0001b982 HeatmapMaxKeypoint
0001b995 HeatmapPCAKeypoint
0001b9a8 Y_zero_point
0001b9b5 Y_zero_point == X.zero_point
0001b9d2 Y_offset == X.zero_point
0001b9eb Y_offset == X0.zero_point
0001ba05 (*Tensor`<int>`*): 1-D tensor of the shape of the output, must be used with `input_as_shape` argument
0001ba6b Output tensorargument and its type is specified by the 'dtype' argument
0001bab3 ConstantFill op cannot have undefined 'dtype' argument
0001baea UniqueUniformFill op cannot have undefined 'dtype' argument
0001bb26 Cannot have undefined 'dtype' argument
0001bb4d subpixel_refinement
0001bb61 value vector must have 1 element
0001bb82 sum.size() == dims_.server + dims_.client
0001bbac Gather with axis > 0 must use dense_gradient
0001bbd9 SoftmaxGradient
0001bbe9 LeakyReluGradient
0001bbfb PReluGradient
0001bc09 EluGradient
0001bc15 ResizeNearestGradient
0001bc2b BatchGatherGradient
0001bc3f ClipGradient
0001bc4c SoftsignGradient
0001bc5d TanhGradient
0001bc6a NormalizeGradient
0001bc7c ChannelShuffleGradient
0001bc93 PadImageGradient
0001bca4 QuantDecodeGradient
0001bcb8 SliceGradient
0001bcc6 SigmoidGradient
0001bcd6 FCTransposedGradient
0001bceb FCGradient
0001bcf6 ByteWeightDequant
0001bd08 constant
0001bd11 concat_result
0001bd1f device_default
0001bd2e BoxWithNMSLimit
0001bd3e The tensor to split
0001bd52 (*Tensor*): tensor to split
0001bd6e ConvSequencePredictionSplit
0001bd8a DepthSplit
0001bd95 inefficiency in convolution with %ux%u kernel and %u+%u height padding: input top padding is greater or equal to kernel height
0001be14 inefficiency in convolution with %ux%u kernel and %u+%u height padding: input bottom padding is greater or equal to kernel height
0001be96 filter height must be equal to kernel height
0001bec3 (int) warped feature block height
0001bee5 Output tensor quantization offset
0001bf07 Failed to initialize then subnet
0001bf28 Failed to initialize else subnet
0001bf49 then_net
0001bf52 else_net
0001bf5f reflect
0001bf67 failed to setup QNNPACK convolution object
0001bf92 failed to create QNNPACK convolution object
0001bfbe tensor of float
0001bfce DepthConcat
0001bfda Int8Concat
0001bfe5 pad_t
0001bfeb When input_as_shape is true, the input must be a 1D tensor of data type int64_t
0001c03b nnp_status_success == status
0001c058 Conv requires at least 2 inputs
0001c078 starts
0001c07f roi_batch_splits
0001c090 BBoxConcatBatchSplits
0001c0a6 failed to allocate %zu bytes for packed weights
0001c0d6 failed to create max pooling with 1 pooling element: 1x1 pooling is meaningless
0001c126 failed to create average pooling with 1 pooling element: 1x1 pooling is meaningless
0001c17a PackedInt8BGRANHWCToNCHWCStylizerPreprocess
0001c1a6 BRGNCHWCToPackedInt8BGRAStylizerDeprocess
0001c1d0 setupStatus == qnnp_status_success
0001c1f3 runStatus == qnnp_status_success
0001c214 qnnpackStatus == qnnp_status_success
0001c239 createStatus == qnnp_status_success
0001c25d nnpack_status == nnp_status_success
0001c281 Pass 1 to add the axis specified in arg 'axis' to all input tensors
0001c2c5 anchors
0001c2cd keeps
0001c2d3 semantic_axis_ != string::npos
0001c2f2 dilations
0001c2fc sums
0001c301 output example features with transforms
0001c32d C_dims_int == B_dims
0001c342 C_dims_int == A_dims
0001c357 axis < numDims
0001c366 kernels
0001c36e sum_lengths == input_channels
0001c38c add_axis_ ? OutputSize() : std::accumulate(axis_data, axis_data + OutputSize(), 0) == input_channels
0001c3f1 1D input slope tensor. If `Slope` is of size 1, the value is shared across different channels
0001c44f mean.numel() == kOutputChannels
0001c46f C == kInputChannels
0001c483 mean.numel() == kInputChannels
0001c4a2 history_labels
0001c4b1 input labels
0001c4be input_boxes_include_bg_cls
0001c4d9 output_classes_include_bg_cls
0001c4f7 GenerateProposals
0001c509 adjs
0001c50e add_axis
0001c517 rois
0001c51c legnths
0001c524 use_scaling_lengths
0001c538 SplitByLengths
0001c547 prev_bboxes
0001c553 next_bboxes
0001c55f Next frame bounding boxes
0001c579 Previous frame bounding boxes
0001c597 merged bounding boxes
0001c5ad (float) Lower bound on updated scores to discard boxes
0001c5e4 IOU threshold for associating new boxes with old boxes
0001c61b valid_axes
0001c626 Axes argument passed in had invalid values
0001c651 nbytes
0001c658 merged concept probabilites
0001c674 classes
0001c67c history_features
0001c68d new_features
0001c69a num_client_features
0001c6ae num_server_features
0001c6c2 num_additional_features
0001c6da mobile_ranking_features
0001c6f2 candidate_features
0001c705 converted_features
0001c718 input features
0001c727 output converted features
0001c741 scores
0001c748 soft_nms_min_score_thres
0001c761 Output tensor of unique uniform samples
0001c789 scales
0001c790 num_max_stories
0001c7a0 num_prev_stories
0001c7b1 Labels for already shown stories
0001c7d2 Features values for already shown stories
0001c7fc Production predictions for candidate stories
0001c829 Features for candidate stories
0001c848 num_batches
0001c854 set_sizes_and_strides
0001c86a wrap_indices
0001c877 (*Tuple(int)*): list of starting indices
0001c8a0 List of starting indices
0001c8b9 (*Tuple(int)*): list of ending indices
0001c8e0 List of ending indices
0001c8f7 (Optional) The dimension to slice over. If specified start_idx and end_idx should also be given and it takes precedence over starts and ends
0001c984 prev_ids
0001c98d next_ids
0001c996 prod_preds
0001c9a1 pads
0001c9a6 rois_probs
0001c9b1 bbox_deltas
0001c9bd vector<float> weights [wx, wy, ww, wh] for the deltas
0001c9f3 no_bias
0001c9fb RoIs
0001ca00 Next frame IDs
0001ca0f Previous frame IDs
0001ca22 MedianBlur
0001ca2d axis_str
0001ca36 this->qnnpackObject_ != nullptr
0001ca56 this->qnnpackGlobalOperator_ != nullptr
0001ca7e this->qnnpackOperator_ != nullptr
0001caa4 1D blob containing bias vector
0001cac3 failed to setup QNNPACK SoftArgMax operator
0001caef failed to run QNNPACK SoftArgMax operator
0001cb19 failed to create QNNPACK SoftArgMax operator
0001cb46 failed to setup QNNPACK Clamp operator
0001cb6d failed to run QNNPACK Clamp operator
0001cb92 failed to create QNNPACK Clamp operator
0001cbba failed to setup QNNPACK Max Pooling operator
0001cbe7 failed to run QNNPACK Max Pooling operator
0001cc12 failed to create QNNPACK Max Pooling operator
0001cc40 failed to setup QNNPACK Global Average Pooling operator
0001cc78 failed to run QNNPACK Global Average Pooling operator
0001ccae failed to create QNNPACK Global Average Pooling operator
0001cce7 failed to setup QNNPACK Average Pooling operator
0001cd18 failed to run QNNPACK Average Pooling operator
0001cd47 failed to create QNNPACK Average Pooling operator
0001cd79 then_net must be specified in If operator
0001cda3 failed to setup QNNPACK channel shuffle operator
0001cdd4 failed to run QNNPACK channel shuffle operator
0001ce03 failed to create QNNPACK channel shuffle operator
0001ce35 failed to setup QNNPACK Sigmoid operator
0001ce5e failed to run QNNPACK Sigmoid operator
0001ce85 failed to create QNNPACK Sigmoid operator
0001ceaf failed to setup QNNPACK fully connected operator
0001cee0 failed to create QNNPACK fully connected operator
0001cf12 failed to setup QNNPACK add operator
0001cf37 failed to run QNNPACK add operator
0001cf5a failed to create QNNPACK add operator
0001cf80 failed to setup QNNPACK Leaky ReLU operator
0001cfac failed to run QNNPACK Leaky ReLU operator
0001cfd6 failed to create QNNPACK Leaky ReLU operator
0001d003 failed to run QNNPACK operator
0001d022 (*Tensor`<int>`*): filled output tensor
0001d04a (*Tensor`<float>`*): filled output tensor
0001d074 (*Tensor*): sliced output tensor
0001d095 2D output tensor
0001d0a6 (*Tensor*): output tensor
0001d0c0 Output tensor
0001d0ce 1D input tensor
0001d0de 1-D input tensor
0001d0ef Input tensor
0001d0fc (N, 5) float tensor
0001d110 (N, 4) float tensor
0001d124 Conv2D should have 4D filter tensor
0001d148 Conv1D should have 3D filter tensor
0001d16c Concatenate a list of tensors into a single tensor
0001d19f Concatenated tensor
0001d1b3 Input must be 4D tensor
0001d1cb filter must be 4D tensor
0001d1e4 bias must be 1D tensor
0001d1fb Output Int8 tensor
0001d20e Input Int8 tensor
0001d220 Tensor
0001d227 NNPACK convolution filter pre-transformation return error
0001d261 NNPACK convolution computation returned error
0001d28f StyleButNotColor
0001d2a0 match_outer
0001d2ac filter
0001d2b3 Gather
0001d2ba shared_buffer
0001d2c8 failed to allocate %zu bytes for indirection buffer
0001d2fc Int8Conv only supports NHWC order
0001d31e Int8ConvTransposeOp only supports NHWC order
0001d34b Int8ChannelShuffleOp only supports NHWC order
0001d379 4-d tensor in NHWC order
0001d392 bias dimension must be equal to output channel number
0001d3c8 filter number must be equal to input channel number
0001d3fc saved_var
0001d406 max blob must be scalar
0001d41e min blob must be scalar
0001d436 Output data tensor from max pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes. Output will go through rectified linear
0001d4e0 pad_r
0001d4e6 sumsq
0001d4ec group
0001d4f2 RoIWarp
0001d4fa noiseCycle >= kOutputChannels * kLoadPixelsPerLoop
0001d52d Clip
0001d532 feature_map
0001d542 [Deprecated] Running mean is not initialized in SpatialBatchNorm Op
0001d586 [Deprecated] Running variance is not initialized in SpatialBatchNorm Op
0001d5ce TypeToProto
0001d5da failed to setup deconvolution with %zux%zu input: input dimensions must be non-zero
0001d62e failed to setup convolution with %zux%zu input: input dimensions must be non-zero
0001d680 failed to setup max pooling with %zux%zu input: input dimensions must be non-zero
0001d6d2 failed to setup average pooling with %zux%zu input: input dimensions must be non-zero
0001d728 failed to create deconvolution with %ux%u dilation: dilation dimensions must be non-zero
0001d781 failed to create convolution with %ux%u dilation: dilation dimensions must be non-zero
0001d7d8 failed to create max pooling with %ux%u dilation: dilation dimensions must be non-zero
0001d82f failed to create deconvolution with %ux%u kernel: kernel dimensions must be non-zero
0001d884 failed to create convolution with %ux%u kernel: kernel dimensions must be non-zero
0001d8d7 failed to create convolution with %ux%u subsampling: subsampling dimensions must be non-zero
0001d934 failed to create max pooling with %ux%u pooling size: pooling size dimensions must be non-zero
0001d993 failed to create average pooling with %ux%u pooling size: pooling size dimensions must be non-zero
0001d9f6 failed to create deconvolution with %ux%u stride: stride dimensions must be non-zero
0001da4b failed to create max pooling with %ux%u stride: stride dimensions must be non-zero
0001da9e failed to create average pooling with %ux%u stride: stride dimensions must be non-zero
0001daf5 failed to create channel shuffle operator with %zu group channels: number of group channels must be non-zero
0001db62 failed to create Soft ArgMax operator with %zu channels: number of channels must be non-zero
0001dbbf failed to create Clamp operator with %zu channels: number of channels must be non-zero
0001dc16 failed to create global average pooling operator with %zu channels: number of channels must be non-zero
0001dc7e failed to create Sigmoid operator with %zu channels: number of channels must be non-zero
0001dcd7 failed to create add operator with %zu channels: number of channels must be non-zero
0001dd2c failed to create Leaky ReLU operator with %zu channels: number of channels must be non-zero
0001dd88 failed to create max pooling with %zu channels: number of channels must be non-zero
0001dddc failed to create average pooling with %zu channels: number of channels must be non-zero
0001de34 failed to setup global average pooling operator with width %zu: width must be non-zero
0001de8b angle_bound_lo
0001de9a sampling_ratio
0001dea9 (int) sampling ratio
0001debe algo
0001dec3 split_info
0001dece im_info
0001ded6 An Int8TensorCPU with scale and zero point info
0001df06 Exception from observer: unknown
0001df27 Error happened during an operator run
0001df4d outputn
0001df55 epsilon
0001df5d inefficiency in convolution with %ux%u kernel and %ux%u subsampling: height subsampling is greater than kernel height; subsampling should be performed before the convolution
0001e00b inefficiency in convolution with %ux%u kernel and %ux%u subsampling: width subsampling is greater than kernel width; subsampling should be performed before the convolution
0001e0b7 failed to run QNNPACK convolution
0001e0d9 Scalar boolean condition
0001e0f2 input production prediction
0001e10e # of feature maps to put in height direction
0001e13b # of pixels to pad between feature maps in height direction
0001e177 # of feature maps to put in width direction
0001e1a3 # of pixels to pad between feature maps in width direction
0001e1de BatchNormalization
0001e1f1 activation
0001e1fc Input tensor to provide shape information
0001e226 1 == dilation
0001e234 BatchSequenceConversion
0001e24c Scale along height dimension
0001e269 Scale along width dimension
0001e285 angle_bound_on
0001e294 Which axis to split on
0001e2ab (*int*): axis to split on
0001e2c5 Which axis to concat on
0001e2e1 rois_in
0001e2ed Softsign
0001e2f6 Int8RoIAlign
0001e303 Int8Flatten
0001e30f gaussian
0001e318 saved_mean
0001e323 codes_n
0001e32b decoded_n
0001e335 momentum
0001e33e Int8Sum
0001e346 output matrix that applied box-cox transform
0001e373 BBoxTransform
0001e381 InstanceNorm
0001e38e (*Tensor*): tensor to extract slices from
0001e3b8 We don't allow change of src data type in OutputTensorCopyFrom
0001e3f7 Gemm
0001e3fc 0 <= idx && idx < indexing_axis_dim
0001e420 detections_per_im
0001e432 in_Qparam
0001e43c MatMul
0001e443 data_ptr_impl_impl
0001e456 data_dtype_initialized_impl
0001e472 data_impl
0001e47c StorageImpl
0001e488 Int8MaxPool
0001e494 Int8AveragePool
0001e4a4 ConstantFill
0001e4b1 GivenTensorIntFill
0001e4c4 UniformIntFill
0001e4d3 Int8GivenIntTensorFill
0001e4ea Int8GivenTensorFill
0001e4fe XavierFill
0001e509 GaussianFill
0001e516 UniqueUniformFill
0001e528 GivenTensorBoolFill
0001e53c DiagonalFill
0001e549 GivenTensorStringFill
0001e55f GivenTensorDoubleFill
0001e575 LengthsRangeFill
0001e586 MSRAFill
0001e58f GivenTensorByteStringToUInt8Fill
0001e5b0 GivenTensorInt16Fill
0001e5c5 GivenTensorInt64Fill
0001e5da in_size + *pad_head + *pad_tail >= dkernel
0001e605 total
0001e60b Input for NHWC2NCHW must be >= 3 dimensional
0001e638 Input for NCHW2NHWC must be >= 3 dimensional
0001e665 pad_l
0001e66b mask
0001e670 codebook
0001e679 caffe2_profile_nnpack
0001e693 dim == dim_j
0001e6a0 angle_bound_hi
0001e6af All dimensions of input must be of equal length
0001e6df inefficiency in convolution with %ux%u kernel and %u+%u width padding: input right padding is greater or equal to kernel width
0001e75e inefficiency in convolution with %ux%u kernel and %u+%u width padding: input left padding is greater or equal to kernel width
0001e7dc filter width must be equal to kernel width
0001e807 (int) warped feature block width
0001e828 nms_thresh
0001e833 score_thresh
0001e840 clip_angle_thresh
0001e852 Tanh
0001e857 Index_High
0001e862 Tensor of shape (batch_size) with each element denoting the number of RoIs belonging to the corresponding image in batch
0001e8db ExplodeBatch
0001e8e8 Opposite to ImplodeBatch
0001e901 ro.arch
0001e909 dilation_h
0001e914 kernel_h
0001e91d adj_h
0001e923 tiled_batch_h
0001e931 stride_h
0001e93a pooled_h
0001e943 pad_h
0001e949 xplat/caffe2/caffe2/core/context.h
0001e96c xplat/caffe2/caffe2/utils/cast.h
0001e98d xplat/caffe2/caffe2/core/event.h
0001e9ae xplat/caffe2/caffe2/core/operator_gradient.h
0001e9db xplat/caffe2/c10/core/MemoryFormat.h
0001ea00 xplat/caffe2/caffe2/operators/utility_ops.h
0001ea2c xplat/caffe2/caffe2/operators/minmax_ops.h
0001ea57 xplat/caffe2/caffe2/operators/order_switch_ops.h
0001ea88 xplat/caffe2/caffe2/operators/elementwise_ops.h
0001eab8 xplat/caffe2/caffe2/share/fb/mobileranking/conv_sequence_ops.h
0001eaf7 xplat/caffe2/c10/core/TensorOptions.h
0001eb1d xplat/caffe2/caffe2/operators/generate_proposals_op_util_nms.h
0001eb5c xplat/caffe2/caffe2/utils/eigen_utils.h
0001eb84 xplat/caffe2/caffe2/operators/quantized/int8_utils.h
0001ebb9 xplat/caffe2/caffe2/operators/generate_proposals_op_util_boxes.h
0001ebfa xplat/caffe2/caffe2/core/types.h
0001ec1b xplat/caffe2/caffe2/core/operator.h
0001ec3f xplat/caffe2/caffe2/core/tensor.h
0001ec61 xplat/caffe2/caffe2/core/observer.h
0001ec85 xplat/caffe2/caffe2/operators/quantized/int8_softmax_op.h
0001ecbf xplat/caffe2/caffe2/operators/quantized/int8_conv_op.h
0001ecf6 xplat/caffe2/caffe2/operators/quantized/int8_leaky_relu_op.h
0001ed33 xplat/caffe2/caffe2/operators/quantized/int8_relu_op.h
0001ed6a xplat/caffe2/caffe2/operators/dropout_op.h
0001ed95 xplat/caffe2/caffe2/operators/quantized/int8_resize_nearest_op.h
0001edd6 xplat/caffe2/caffe2/share/fb/mask_rcnn/heatmap_pca_keypoint_op.h
0001ee17 xplat/caffe2/caffe2/operators/byte_weight_dequant_op.h
0001ee4e xplat/caffe2/caffe2/operators/box_with_nms_limit_op.h
0001ee84 xplat/caffe2/caffe2/operators/concat_split_op.h
0001eeb4 xplat/caffe2/caffe2/operators/quantized/int8_concat_op.h
0001eeed xplat/caffe2/caffe2/share/fb/mask_rcnn/bbox_concat_batch_splits_op.h
0001ef32 xplat/caffe2/caffe2/operators/filler_op.h
0001ef5c xplat/caffe2/caffe2/operators/gather_op.h
0001ef86 xplat/caffe2/caffe2/operators/quantized/int8_roi_align_op.h
0001efc2 xplat/caffe2/caffe2/operators/roi_align_op.h
0001efef xplat/caffe2/caffe2/operators/quantized/int8_flatten_op.h
0001f029 xplat/caffe2/caffe2/operators/flatten_op.h
0001f054 xplat/caffe2/caffe2/operators/spatial_batch_norm_op.h
0001f08a xplat/caffe2/caffe2/operators/instance_norm_op.h
0001f0bb xplat/caffe2/caffe2/operators/bbox_transform_op.h
0001f0ed xplat/caffe2/caffe2/operators/matmul_op.h
0001f117 xplat/caffe2/caffe2/operators/quantized/int8_max_pool_op.h
0001f152 xplat/caffe2/caffe2/operators/quantized/int8_average_pool_op.h
0001f191 xplat/caffe2/caffe2/operators/pool_op.h
0001f1b9 xplat/caffe2/caffe2/operators/given_tensor_fill_op.h
0001f1ee xplat/caffe2/caffe2/operators/given_tensor_byte_string_to_uint8_fill_op.h
0001f238 xplat/caffe2/caffe2/operators/if_op.h
0001f25e xplat/caffe2/caffe2/operators/resize_op.h
0001f288 xplat/caffe2/caffe2/operators/quantized/int8_conv_transpose_op.h
0001f2c9 xplat/caffe2/caffe2/operators/quantized/int8_transpose_op.h
0001f305 xplat/caffe2/caffe2/operators/transpose_op.h
0001f332 xplat/caffe2/caffe2/operators/quantized/int8_reshape_op.h
0001f36c xplat/caffe2/caffe2/operators/reshape_op.h
0001f397 xplat/caffe2/caffe2/operators/shape_op.h
0001f3c0 xplat/caffe2/caffe2/operators/quantized/int8_channel_shuffle_op.h
0001f402 xplat/caffe2/caffe2/operators/channel_shuffle_op.h
0001f435 xplat/caffe2/caffe2/operators/quant_decode_op.h
0001f465 xplat/caffe2/caffe2/operators/quantized/int8_slice_op.h
0001f49d xplat/caffe2/caffe2/operators/slice_op.h
0001f4c6 xplat/caffe2/caffe2/operators/quantized/int8_sigmoid_op.h
0001f500 xplat/caffe2/caffe2/share/fb/mask_rcnn/bbox_id_op.h
0001f534 xplat/caffe2/caffe2/operators/fully_connected_op.h
0001f567 xplat/caffe2/caffe2/operators/quantized/int8_add_op.h
0001f59d xplat/caffe2/caffe2/operators/pad_op.h
0001f5c4 xplat/caffe2/caffe2/operators/quantized/int8_fc_op.h
0001f5f9 xplat/caffe2/caffe2/operators/conv_op_impl.h
0001f626 xplat/caffe2/caffe2/operators/conv_transpose_op_impl.h
0001f65d xplat/caffe2/caffe2/operators/conv_transpose_op_mobile_impl.h
0001f69b xplat/caffe2/c10/core/TensorImpl.h
0001f6be xplat/caffe2/c10/core/StorageImpl.h
0001f6e2 xplat/caffe2/c10/util/ArrayRef.h
0001f703 xplat/caffe2/caffe2/core/context_base.h
0001f72b xplat/caffe2/caffe2/operators/conv_transpose_unpool_op_base.h
0001f769 xplat/caffe2/caffe2/operators/conv_pool_op_base.h
0001f79b xplat/caffe2/caffe2/proto/caffe2_pb.h
0001f7c1 xplat/caffe2/aten/src/ATen/core/blob.h
0001f7e8 xplat/caffe2/caffe2/core/operator_schema.h
0001f817 In-place is allowed only with the first tensor when legacy-broadcasting
0001f85f basic_string
0001f86c Unsupported axis string
0001f884 concept mapping
0001f894 MergeProbAndBboxWithConceptMapping
0001f8b7 positive_mean_pooling
0001f8cd negative_mean_pooling
0001f8e3 global_pooling
0001f8f2 ConvSequencePredictionRebatching
0001f913 Features in format that is compatible with ConvSequenceRebatching
0001f955 failed to allocate %zu bytes for zero padding
0001f983 operator does not handle row width padding
0001f9ae cls_agnostic_bbox_reg
0001f9c4 Error from operator: no op def
0001f9e6 H: %3zu, W: %3zu, iC: %3zu, oC: %3zu, K: %1zu, S: %1zu, P: %1zu, GMACs: %4.2f, totalT: %6.3f, inputT: %6.3f, kernelT: %6.3f, blockT: %6.3f, outputT: %6.3f, GFLOPS: %6.3f
0001fa90 Y_scale == 1.0f / 256.0f
0001faa9 roi_w >= 0.0f && roi_h >= 0.0f
0001fac8 Int8Dequantize
0001fad7 Int8Quantize
0001fae4 output_size
0001faf0 *out_size >= standard_out_size
0001fb0f keeps_size
0001fb1a axes.size() == tensor_size
0001fb35 min_size
0001fb3e min_block_size
0001fb4d canonical_axis < adj_size
0001fb67 (int) default to 1; describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size
0001fbfa roi_batch_id < batch_size
0001fc14 noise_size
0001fc1f decomp_size == dc_size
0001fc36 Int8ResizeNearest expects 2 dim output size
0001fc62 Axes argument passed in had the incorrect size
0001fc91 NNPACK only supports pad < kernel size
0001fcb8 total_size == size
0001fccb totalSize == size
0001fcdd axis to normalize
0001fcef Normalize
0001fcf9 noise.numel() >= defaultNoiseSize
0001fd1b input tensor that's coerced into a 2D matrix of size (MxK) as described above
0001fd69 last_positive
0001fd77 failed to create Leaky ReLU operator with %.7g negative slope: slope must be finite and positive
0001fdd8 failed to create Soft ArgMax operator with %.7g output scale: scale must be finite and positive
0001fe38 failed to create global average pooling operator with %.7g output scale: scale must be finite and positive
0001fea3 failed to create Sigmoid operator with %.7g output scale: scale must be finite and positive
0001feff failed to create fully connected operator with %.7g output scale: scale must be finite and positive
0001ff63 failed to create add operator with %.7g output scale: scale must be finite and positive
0001ffbb failed to create Leaky ReLU operator with %.7g output scale: scale must be finite and positive
0002001a failed to create deconvolution with %.7g output scale: scale must be finite and positive
00020073 failed to create convolution with %.7g output scale: scale must be finite and positive
000200ca failed to create average pooling with %.7g output scale: scale must be finite and positive
00020125 failed to create Soft ArgMax operator with %.7g input scale: scale must be finite and positive
00020184 failed to create global average pooling operator with %.7g input scale: scale must be finite and positive
000201ee failed to create Sigmoid operator with %.7g input scale: scale must be finite and positive
00020249 failed to create fully connected operator with %.7g input scale: scale must be finite and positive
000202ac failed to create Leaky ReLU operator with %.7g input scale: scale must be finite and positive
0002030a failed to create deconvolution with %.7g input scale: scale must be finite and positive
00020362 failed to create convolution with %.7g input scale: scale must be finite and positive
000203b8 failed to create average pooling with %.7g input scale: scale must be finite and positive
00020412 failed to create fully connected operator with %.7g kernel scale: scale must be finite and positive
00020476 failed to create deconvolution with %.7g kernel scale: scale must be finite and positive
000204cf failed to create convolution with %.7g kernel scale: scale must be finite and positive
00020526 failed to create add operator with %.7g B scale: scale must be finite and positive
00020579 failed to create add operator with %.7g A scale: scale must be finite and positive
000205cc Each axis should be non-negative
000205ed Axis should be non-negative
00020609 (*Tensor`<int>`*): scalar tensor containing maximum value, inclusive
0002064e (*Tensor`<float>`*): scalar tensor containing maximum value, inclusive
00020695 (*int*): maximum value, inclusive
000206b7 (*float*): maximum value, inclusive
000206db Maximum value, inclusive
000206f4 (*Tensor`<int>`*): scalar tensor containing minimum value, inclusive
00020739 (*Tensor`<float>`*): scalar tensor containing minimum value, inclusive
00020780 (*int*): minimum value, inclusive
000207a2 (*float*): minimum value, inclusive
000207c6 Minimum value, inclusive
000207df Net executed when condition is true
00020803 An input must be given if input_as_shape is true
00020834 dense_gradient == true
0002084b low_value
00020855 high_value
00020860 transformStrategy_ == nnp_convolution_transform_strategy_reuse || transformStrategy_ == nnp_convolution_transform_strategy_compute
000208e3 float16_compute
000208f3 SetDimsTemplate
00020903 Int8ConvTranspose
00020915 Int8Transpose
00020923 SparseToDense
00020931 The softsign gradient (sgn(x)/(1+|x|)^2) values of the input tensor computed element-wise
0002098b The hyperbolic tangent values of the input tensor, computed element-wise
000209d4 failed to allocate %zu bytes for qnnp_operator structure
00020a0d prod_feature
00020a1a dtype
00020a20 device_type
00020a2c Only 1-3d convolution is supported for NHWC storage type
00020a65 Argument 'value' is of unexpected type
00020a8c Slope
00020a92 Int8Reshape
00020a9e new_shape
00020aa8 input_as_shape
00020ab7 old_shape
00020ac1 exploded_shape
00020ad0 extra_shape
00020adc New shape
00020ae6 1D tensor containing the desired output shape
00020b14 Input tensor shape
00020b27 Shape
00020b2d legacy_plus_one
00020b3d Cannot set the shape argument and pass in an input at the same time
00020b81 Upsample
00020b8a features_sample
00020b9a Int8ChannelShuffle
00020bad failed to allocate 256 bytes for Soft ArgMax lookup table
00020be7 failed to allocate 256 bytes for Sigmoid lookup table
00020c1d failed to allocate 256 bytes for Leaky ReLU lookup table
00020c56 apply_scale
00020c62 height_scale
00020c6f spatial_scale
00020c7d width_scale
00020c89 Y_scale
00020c91 Y_scale == X.scale
00020ca4 Y_scale == X0.scale
00020cb8 Output tensor quantization scale
00020cd9 (float) spatial scale
00020cef Scale
00020cf5 ResizeLike
00020d00 Axis out of range
00020d12 failed to create global average pooling operator with %.7g input-to-output scale ratio: scale ratio must be in [2**-8, 2**8) range
00020d95 failed to create Leaky ReLU operator with %.7g input-to-output scale ratio: scale ratio must be in [2**-8, 2**8) range
00020e0c failed to create average pooling with %.7g input scale and %.7g output scale: input-to-output scale ratio (%.7f) must be in [2**-8, 2**8) range
00020e9c failed to create add operator with %.7g A-to-output scale ratio: scale ratio must be in [2**-14, 2**8) range
00020f09 edge
00020f0e PadImage
00020f17 Coefficient of leakage
00020f2e mode
00020f33 QuantDecode
00020f3f empty_tensor_restride
00020f55 range_sequence
00020f64 Int8Slice
00020f6e noise_std
00020f78 QuantDecompZstd
00020f88 Unexpected soft_nms_method
00020fa3 map::at:  key not found
00020fbb iou_threshold
00020fc9 tensor of int64 indices for elements below/equal threshold
00021004 tensor of int64 indices for elements above threshold
00021039 avoid
0002103f Int8Sigmoid
0002104b storage_initialized
0002105f qnnp_setup_channel_shuffle_nc_x8 failed because QNNPACK is not properly initialized
000210b3 qnnp_create_channel_shuffle_nc_x8 failed because QNNPACK is not properly initialized
00021108 qnnp_setup_max_pooling2d_nhwc_u8 failed because QNNPACK is not properly initialized
0002115c qnnp_create_max_pooling2d_nhwc_u8 failed because QNNPACK is not properly initialized
000211b1 qnnp_setup_clamp_nc_u8 failed because QNNPACK is not properly initialized
000211fb qnnp_create_clamp_nc_u8 failed because QNNPACK is not properly initialized
00021246 qnnp_setup_global_average_pooling_nwc_q8 failed because QNNPACK is not properly initialized
000212a2 qnnp_create_global_average_pooling_nwc_q8 failed because QNNPACK is not properly initialized
000212ff qnnp_setup_deconvolution2d_nhwc_q8 failed because QNNPACK is not properly initialized
00021355 qnnp_create_deconvolution2d_nhwc_q8 failed because QNNPACK is not properly initialized
000213ac qnnp_setup_convolution2d_nhwc_q8 failed because QNNPACK is not properly initialized
00021400 qnnp_create_convolution2d_nhwc_q8 failed because QNNPACK is not properly initialized
00021455 qnnp_setup_average_pooling2d_nhwc_q8 failed because QNNPACK is not properly initialized
000214ad qnnp_create_average_pooling2d_nhwc_q8 failed because QNNPACK is not properly initialized
00021506 qnnp_setup_softargmax_nc_q8 failed because QNNPACK is not properly initialized
00021555 qnnp_create_softargmax_nc_q8 failed because QNNPACK is not properly initialized
000215a5 qnnp_setup_leaky_relu_nc_q8 failed because QNNPACK is not properly initialized
000215f4 qnnp_create_leaky_relu_nc_q8 failed because QNNPACK is not properly initialized
00021644 qnnp_setup_sigmoid_nc_q8 failed because QNNPACK is not properly initialized
00021690 qnnp_create_sigmoid_nc_q8 failed because QNNPACK is not properly initialized
000216dd qnnp_setup_fully_connected_nc_q8 failed because QNNPACK is not properly initialized
00021731 qnnp_create_fully_connected_nc_q8 failed because QNNPACK is not properly initialized
00021786 qnnp_setup_add_nc_q8 failed because QNNPACK is not properly initialized
000217ce qnnp_create_add_nc_q8 failed because QNNPACK is not properly initialized
00021817 Decompressed data n if existed
00021836 Decompressed data 2 if existed
00021855 Decompressed data 1 if existed
00021874 constant fill string from tensor is not supported
000218a6 failed to create Soft ArgMax operator with %.7g output scale: only output scale of 1/256 is supported
0002190c failed to create Sigmoid operator with %.7g output scale: only output scale of 1/256 is supported
0002196e failed to create Soft ArgMax operator with %u output zero point: only output zero point of 0 is supported
000219d8 failed to create Sigmoid operator with %u output zero point: only output zero point of 0 is supported
00021a3e Not implemented
00021a4e Fill 'shape' argument was a scalar, list expected
00021a80 Invalid condition in If operator: tensor expected
00021ab2 Invalid condition tensor in If operator: single value expected
00021af1 rotated
00021af9 compressed
00021b04 FCTransposed
00021b11 prod_neg_pred
00021b1f candidate_prod_pred
00021b33 failed to create channel shuffle operator with %zu groups: at least two groups required
00021b8b reshaped
00021b94 aligned
00021b9c soft_nms_enabled
00021bad Invalid maximum index specified
00021bcd Optional Qparam blob that contains quant param computed on activation histogram dataWill overwrite Y_scale and Y_zero_point argument if specified
00021c5f Optional Qparam blob that contains quant param computed on activation histogram dataWill overwrite X_scale and X_zero_point argument if specified
00021cf1 Int8Add
00021cf9 DropoutGrad
00021d05 legacy_pad
00021d10 count_include_pad
00021d22 get_channels_last_strides_3d
00021d3f get_channels_last_strides_2d
00021d5c StumpFunc
00021d66 xplat/caffe2/caffe2/operators/minmax_ops.cc
00021d92 xplat/caffe2/caffe2/share/fb/stylizer/yuv_ops.cc
00021dc3 xplat/caffe2/caffe2/share/fb/stylizer/median_blur_ops.cc
00021dfc xplat/caffe2/caffe2/operators/stylizer_ops.cc
00021e2a xplat/caffe2/caffe2/operators/order_switch_ops.cc
00021e5c xplat/caffe2/caffe2/share/fb/mask_rcnn/batch_tile_ops.cc
00021e95 xplat/caffe2/caffe2/share/fb/mobileranking/conv_sequence_ops.cc
00021ed5 xplat/caffe2/caffe2/operators/is_empty_op.cc
00021f02 xplat/caffe2/caffe2/operators/batch_box_cox_op.cc
00021f34 xplat/caffe2/caffe2/operators/quantized/int8_softmax_op.cc
00021f6f xplat/caffe2/caffe2/operators/softmax_op.cc
00021f9b xplat/caffe2/caffe2/operators/norm_planar_yuv_op.cc
00021fcf xplat/caffe2/caffe2/operators/quantized/int8_conv_op.cc
00022007 xplat/caffe2/caffe2/operators/conv_op.cc
00022030 xplat/caffe2/caffe2/share/contrib/nnpack/conv_op.cc
00022064 xplat/caffe2/caffe2/operators/prelu_op.cc
0002208e xplat/caffe2/caffe2/operators/quantized/int8_leaky_relu_op.cc
000220cc xplat/caffe2/caffe2/operators/leaky_relu_op.cc
000220fb xplat/caffe2/caffe2/operators/quantized/int8_relu_op.cc
00022133 xplat/caffe2/caffe2/operators/relu_op.cc
0002215c xplat/caffe2/caffe2/operators/elu_op.cc
00022184 xplat/caffe2/caffe2/operators/dropout_op.cc
000221b0 xplat/caffe2/caffe2/operators/quantized/int8_resize_nearest_op.cc
000221f2 xplat/caffe2/caffe2/operators/heatmap_max_keypoint_op.cc
0002222b xplat/caffe2/caffe2/share/fb/mask_rcnn/heatmap_pca_keypoint_op.cc
0002226d xplat/caffe2/caffe2/operators/byte_weight_dequant_op.cc
000222a5 xplat/caffe2/caffe2/operators/box_with_nms_limit_op.cc
000222dc xplat/caffe2/caffe2/operators/concat_split_op.cc
0002230d xplat/caffe2/caffe2/operators/quantized/int8_concat_op.cc
00022347 xplat/caffe2/caffe2/share/fb/mask_rcnn/bbox_concat_batch_splits_op.cc
0002238d xplat/caffe2/caffe2/operators/generate_proposals_op.cc
000223c4 xplat/caffe2/caffe2/operators/filler_op.cc
000223ef xplat/caffe2/caffe2/operators/gather_op.cc
0002241a xplat/caffe2/caffe2/share/fb/mask_rcnn/roi_warp_op.cc
00022450 xplat/caffe2/caffe2/operators/clip_op.cc
00022479 xplat/caffe2/caffe2/operators/softsign_op.cc
000224a6 xplat/caffe2/caffe2/operators/quantized/int8_roi_align_op.cc
000224e3 xplat/caffe2/caffe2/operators/roi_align_op.cc
00022511 xplat/caffe2/caffe2/operators/quantized/int8_flatten_op.cc
0002254c xplat/caffe2/caffe2/operators/flatten_op.cc
00022578 xplat/caffe2/caffe2/operators/replace_nan_op.cc
000225a8 xplat/caffe2/caffe2/operators/elementwise_sum_op.cc
000225dc xplat/caffe2/caffe2/operators/spatial_batch_norm_op.cc
00022613 xplat/caffe2/caffe2/operators/instance_norm_op.cc
00022645 xplat/caffe2/caffe2/operators/bbox_transform_op.cc
00022678 xplat/caffe2/caffe2/operators/matmul_op.cc
000226a3 xplat/caffe2/caffe2/operators/quantized/int8_max_pool_op.cc
000226df xplat/caffe2/caffe2/operators/quantized/int8_average_pool_op.cc
0002271f xplat/caffe2/caffe2/operators/pool_op.cc
00022748 xplat/caffe2/caffe2/operators/quantized/int8_given_tensor_fill_op.cc
0002278d xplat/caffe2/caffe2/operators/given_tensor_fill_op.cc
000227c3 xplat/caffe2/caffe2/operators/given_tensor_byte_string_to_uint8_fill_op.cc
0002280e xplat/caffe2/caffe2/operators/tanh_op.cc
00022837 xplat/caffe2/caffe2/operators/log_op.cc
0002285f xplat/caffe2/caffe2/share/fb/mask_rcnn/merge_prob_and_bbox_with_concept_mapping_op.cc
000228b5 xplat/caffe2/caffe2/operators/if_op.cc
000228dc xplat/caffe2/caffe2/operators/quantized/int8_dequantize_op.cc
0002291a xplat/caffe2/caffe2/operators/quantized/int8_quantize_op.cc
00022956 xplat/caffe2/caffe2/operators/resize_op.cc
00022981 xplat/caffe2/caffe2/operators/normalize_op.cc
000229af xplat/caffe2/caffe2/operators/quantized/int8_conv_transpose_op.cc
000229f1 xplat/caffe2/caffe2/operators/conv_transpose_op.cc
00022a24 xplat/caffe2/caffe2/operators/quantized/int8_transpose_op.cc
00022a61 xplat/caffe2/caffe2/operators/transpose_op.cc
00022a8f xplat/caffe2/caffe2/operators/quantized/int8_reshape_op.cc
00022aca xplat/caffe2/caffe2/operators/reshape_op.cc
00022af6 xplat/caffe2/caffe2/operators/shape_op.cc
00022b20 xplat/caffe2/caffe2/operators/quantized/int8_channel_shuffle_op.cc
00022b63 xplat/caffe2/caffe2/operators/channel_shuffle_op.cc
00022b97 xplat/caffe2/caffe2/operators/scale_op.cc
00022bc1 xplat/caffe2/caffe2/operators/quant_decode_op.cc
00022bf2 xplat/caffe2/caffe2/operators/quantized/int8_slice_op.cc
00022c2b xplat/caffe2/caffe2/operators/slice_op.cc
00022c55 xplat/caffe2/caffe2/share/contrib/zstd/quant_decomp_zstd_op.cc
00022c94 xplat/caffe2/caffe2/operators/quantized/int8_sigmoid_op.cc
00022ccf xplat/caffe2/caffe2/operators/sigmoid_op.cc
00022cfb xplat/caffe2/caffe2/share/fb/mask_rcnn/bbox_id_op.cc
00022d30 xplat/caffe2/caffe2/operators/fully_connected_op.cc
00022d64 xplat/caffe2/caffe2/operators/quantized/int8_add_op.cc
00022d9b xplat/caffe2/caffe2/operators/pad_op.cc
00022dc3 xplat/caffe2/caffe2/operators/stump_func_op.cc
00022df2 xplat/caffe2/caffe2/operators/quantized/int8_fc_op.cc
00022e28 xplat/caffe2/caffe2/operators/quantized/init_qnnpack.cc
00022e64 Cannot set both max arg and max input blob
00022e8f Cannot set both min arg and min input blob
00022eba trans_b
00022ec2 axis_b
00022ec9 pad_b
00022ecf symbolic_shape_meta
00022ee3 raw_mutable_data
00022ef4 tensor of size D with the same type as data
00022f20 failed to allocate %zu bytes for row sum data
00022f4e soft_nms_sigma
00022f5d alpha
00022f63 trans_a
00022f6b axis_a
00022f72 canonical_axis_index_
00022f88 min_ < max_
00022f94 N <= tiled_batch_h_ * tiled_batch_w_
00022fb9 then_net_
00022fc3 else_net_
00022fcd input.dim() >= axis_
00022fe2 X.t.sizes().size() >= axis_
00022ffe D == (numServerFeatures_ + numClientFeatures_) * (numMaxStories_ + 1) + numAdditionalFeatures_
0002305d filter.dim32(1) == C / this->group_
00023081 transformedFilters_.size() == group_
000230a6 size_to_dim_
000230b3 size_between_dim_
000230c5 __transformed_kernel_
000230db operator_def_
000230e9 recorder_index == type_
00023101 1 >= iou_threshold_
00023115 0 <= iou_threshold_
00023129 1.0 > threshold_
0002313a 0.0 < threshold_
0002314b __CAFFE2_STYLIZER_NOISE__
00023165 event_recorder_[recorder_index]
00023185 kernel_[dim]
00023192 adj_[dim] <= stride_[dim]
000231ac Xi.t.size(j) == Y_dims[j]
000231c6 filter.dim32(i + 2) == kernel_[i]
000231e8 filter.dim32(i + 1) == kernel_[i]
0002320a pads_[i] < kernel_[i] && pads_[i + kernel_size] < kernel_[i]
00023247 1D, 2-element, Scales tensor, [height_scale, width_scale]
00023281 Image dimensions, size (batch_size, 3), format [img_height, img_width, img_scale]
000232d3 event_finished_setter_[type_]
000232f1 event_finisher_[type_]
00023308 event_waiter_[waiter_index][type_]
0002332b threshold must be in [0, 1]
00023347 [output_0, output_1, ...]
00023363 &X != Y
0002336e &Y != &X
00023377 NHWC2NCHW
00023381 Either NHWC or NCWH, will split on C axis, defaults to NCHW
000233bd NormalizePlanarYUV
000233d0 option.device_type() == PROTO_CPU
000233f2 Cannot backpropagate through an in-place PReLU
00023421 axis_str_.size() == 1U
00023438 in.size() > 0U
00023447 axis_str_.size() == 0U
0002345e OUTPUT
00023465 legacy_pad_ == LegacyPadding::NOTSET
0002348a DIRECT
00023491 (float) TEST.NMS
000234a2 Output batch splits for scores/boxes after applying NMS
000234da INDICES
000234e2 GenerateProposalsCPP
000234f7 AUTO
000234fc post_nms_topN
0002350a pre_nms_topN
00023517 ReplaceNaN
00023522 (int) RPN_POST_NMS_TOP_N
0002353b (int) RPN_PRE_NMS_TOP_N
00023553 order != StorageOrder::UNKNOWN
00023572 order_ != StorageOrder::UNKNOWN
00023592 SpatialBN
0002359c cur == N
000235a5 std::accumulate(batch_splits.begin(), batch_splits.end(), 0.0) == N
000235e9 prod_preds.dim32(0) == N
00023602 heatmaps_in.dim32(0) == N
0002361c bboxes_in.dim32(0) == N
00023634 delta_in.dim32(0) == N
0002364b batch_splits.sum() == N
00023663 n < N
00023669 K == W.numel() / N
0002367c IMPLICIT_GEMM
0002368a (int) TEST.DETECTIONS_PER_IM
000236a7 Y->t.dim32(3) == M
000236ba bias.dim32(0) == M
000236cd filter.dim32(0) == M
000236e2 BOOL
000236e7 EnforceMetaCopyOK
000236f9 Conv_ENGINE_NNPACK
0002370c failed to initialize QNNPACK
00023729 M == X.numel() / K
0002373c (float) RPN_NMS_THRESH
00023753 (float) TEST.SCORE_THRESH
0002376d STRING
00023774 C == filter.dim32(1) * G
0002378d C == filter.dim32(filter.dim() - 1) * G
000237b5 (float) RPN_MIN_SIZE
000237ca BYTE
000237cf COMPUTE
000237d7 legacy_pad_ != LegacyPadding::VALID && legacy_pad_ != LegacyPadding::SAME
00023821 ConvTranspose_ENGINE_MOBILE
0002383d DOUBLE
00023844 (string) TEST.SOFT_NMS.METHOD
00023862 BBoxID
00023869 (bool) TEST.SOFT_NMS.ENABLED
00023886 WINOGRAD
0002388f Conv3D
00023896 MaxPool3D
000238a0 AveragePool3D
000238ae Conv2D
000238b5 MaxPool2D
000238bf AveragePool2D
000238cd Input shape must be >= 2D
000238e7 Conv1D
000238ee MaxPool1D
000238f8 AveragePool1D
00023906 DATA should be at least [axis+1]-D
00023929 lambda2.numel() == D
0002393e lambda1.numel() == D
00023953 order_ == StorageOrder::NCHW || order_ == StorageOrder::NHWC
00023990 NCHW2NHWC
0002399a (string) NCHW or NHWC
000239b0 Int8FC
000239b7 bias.dim32(0) == C
000239ca bias.numel() == C
000239dc var.numel() == C
000239ed mean.numel() == C
000239ff batch_var_sum.numel() == C
00023a1a batch_mean_sum.numel() == C
00023a36 scale.numel() == C
00023a49 beta.numel() == C
00023a5b gamma.numel() == C
00023a70 DATA
00023a75 (float) TEST.SOFT_NMS.SIGMA
00023a91 Result, has same dimensions and type as A
00023abb  axis_dim=
00023ac6 INDICES element is out of DATA bounds, id=
00023af1 > vs <
00023af8 If you did not specify split explicitly, the number of input channels:
00023b3f Description: Input #1, input dimension:
00023b67  should be divisible by the output size:
00023b90 UINT8
00023b9a SoftmaxFp16
00023ba6 UINT16
00023bad FT16
00023bb2 FLOAT16
00023bba WINOGRAD_FP16
00023bc8 roi_cols == 4 || roi_cols == 5
00023be7 box_dim == 4 || box_dim == 5
00023c04 kernel == 3 || kernel == 5
00023c1f R.dim32(1) == 4 || R.dim32(1) == 5
00023c42 proposals.cols() == 4 || proposals.cols() == 5
00023c71 boxes.cols() == 4 || boxes.cols() == 5
00023c98 deltas.cols() == 5
00023cab box.size() == 5
00023cbb INT64
00023cc1 failed to create average pooling with %u (%ux%u) pooling elements: the number of elements in the pooling area must be below 2**24
00023d43 num <= 24
00023d4d Input dim should be 4
00023d63 bboxes_in.dim32(1) >= 4
00023d7b C == 4
00023d82 Input0.dim32(1) == 4
00023d97 proposals.cols() == 4
00023dad boxes.cols() == 4
00023dbf deltas.cols() == 4
00023dd2 filter.ndim() == 4
00023de5 heatmaps_in.ndim() == 4
00023dfd X.ndim() == 4
00023e0b X.t.dim() == 4
00023e1a scores.dim() == 4
00023e2c filter.dim() == 4
00023e3e heatmaps_in.dim() == 4
00023e55 X.dim() == 4
00023e62 W.dims_size() == 4
00023e75 Y_dims.size() == 4
00023e88 weights_.size() == 4
00023e9d X.sizes().size() == 4
00023eb3 stride width must be <= 4
00023ecd axis_ < 4
00023ed7 ndim >= 3
00023ee1 in[0].dims_size() >= 3
00023ef8 iminfo_in.dim32(1) == 3
00023f10 scores_tensor.ndim() == 3
00023f2a bbox_deltas_tensor.ndim() == 3
00023f49 def_.input_size() == 2 || def_.input_size() == 3
00023f7a W.dims_size() == 3
00023f8d Inputs().size() == 3
00023fa2 kernel_.size() <= 3
00023fb6 output2
00023fbe lambda2
00023fc6 Input array of type int32
00023fe0 The data type for the elements of the output tensor.Strictly must be one of the types from DataType enum in TensorProto.This only supports INT32 and INT64 now. If not set, assume INT32
00024099 ndim >= 2
000240a3 heatmap_size >= 2
000240b5 output->dim() >= 2
000240c8 inputs.size() >= 2
000240db pred_bbox.ndim() == 2
000240f1 bboxes_in.ndim() == 2
00024107 concept_mapping.ndim() == 2
00024123 cls_prob.ndim() == 2
00024138 R.ndim() == 2
00024146 tboxes.dim() == 2
00024158 tscores.dim() == 2
0002416b bboxes_in.dim() == 2
00024180 iminfo_in.dim() == 2
00024195 roi_in.dim() == 2
000241a7 delta_in.dim() == 2
000241bb R.dim() == 2
000241c8 Input0.dim() == 2
000241da scales.numel() == 2
000241ee in.size() == 2
000241fd Inputs().size() == 2
00024212 InputSize() < 2
00024222 output1
0002422a lambda1
00024232 codes_1
0002423a decoded_1
00024244 (*Tuple(int)*): shape of the output, do not set when `input_as_shape`=1
0002428c tensor with tiled feature map in NHWC order where N=1
000242c2 Coefficient of leakage, default value is 0.01
000242f0 (Optional) The dimension to end the slice. Default is -1
00024329 actualNewShape[i] >= -1
00024341 unknown_idx == -1
00024353 unknownIdx == -1
00024364 dim == -1
0002436e Axis should be at least 1
00024388 out_dev.size() > 1
0002439b in_dev.size() > 1
000243ad InputSize() > 1
000243bd axis >= 1
000243c7 tiled_batch_w_ >= 1
000243db tiled_batch_h_ >= 1
000243ef SHAPE.dim32(0) >= 1
00024403 data.dim() >= 1
00024413 batch_size == 1
00024423 pads_[2 * dim] == 0 && pads_[2 * dim + 1] == 0 && dilation_[dim] == 1 && stride_[dim] == 1
0002447e dilation_[i] == 1
00024490 InputSize() >= 3 && InputSize() % 2 == 1
000244b9 gTypeMapper.count(type_index) == 1
000244dc tboxes.size(3) == 1
000244f0 tscores.size(3) == 1
00024505 tboxes.size(2) == 1
00024519 tscores.size(2) == 1
0002452e X.dim32(0) == 1
0002453e SHAPE.dim32(0) == 4 || SHAPE.dim32(0) == 1
00024569 dilation_h() == 1 && dilation_w() == 1
00024590 stride_h() == 1 && stride_w() == 1
000245b3 array.cols() == 1
000245c5 scores.cols() == 1
000245d8 bias.ndim() == 1
000245e9 pca_in.ndim() == 1
000245fc SHAPE.ndim() == 1
0002460e input.dim() == 1
0002461f starts.dim() == 1
00024631 tbatch_splits.dim() == 1
0002464a scales.dim() == 1
0002465c ends.dim() == 1
0002466c bias.dim() == 1
0002467c shape.dim() == 1
0002468d op_compressed.dim() == 1
000246a6 b.dim() == 1
000246b3 Input1.dim() == 1
000246c5 condition.numel() == 1
000246dc op_compressed.numel() == 1
000246f7 def_.input_size() == 1
0002470e in.size() == 1
0002471d value_vec.size() == 1
00024733 OutputSize() == 1
00024745 momentum_ <= 1
00024754 data.dim() >= axis + 1
0002476b roi_in.dim32(1) == box_dim || roi_in.dim32(1) == box_dim + 1
000247a8 Def().input_size() == Def().output_size() + 1
000247d6 InputSize() == OutputSize() + 1
000247f6 output0
000247fe a_dim1 == b_dim0
0002480f codes_0
00024817 decoded_0
00024821 exynos9810
0002482c failed to create deconvolution with %.7g input scale, %.7g kernel scale, and %.7g output scale: deconvolution scale %.7g is greater or equal to 1.0
000248c0 failed to create convolution with %.7g input scale, %.7g kernel scale, and %.7g output scale: convolution scale %.7g is greater or equal to 1.0
00024950 failed to create fully connected operator with %.7g input scale, %.7g kernel scale, and %.7g output scale: requantization scale %.7g is greater or equal to 1.0
000249f0 failed to create Leaky ReLU operator with %.7g negative slope: slope must not exceed 1.0
00024a49 alpha < 1.0
00024a55 alpha > 0.0
00024a61 the value to replace NaN, the default is 0
00024a8c (Optional) The dimension to start slice from. Default is 0
00024ac7 Decompressed data 0
00024adb ret > 0
00024ae3 dims_.addition > 0
00024af6 inner_size > 0
00024b05 epsilon_ > 0
00024b12 height_scale_ > 0
00024b24 width_scale_ > 0
00024b35 kernel_[dim] > 0
00024b46 stride_[dim] > 0
00024b57 input.size_from_dim(1) > 0
00024b72 input.numel() > 0
00024b84 shape.numel() > 0
00024b96 in[0].dims_size() > 0
00024bac in.size() > 0
00024bba start >= 0
00024bc5 roi_width >= 0 && roi_height >= 0
00024be7 *right_shift >= 0
00024bf9 axis >= 0
00024c03 dim >= 0
00024c0c *pad_tail >= 0
00024c1b end >= 0
00024c24 *pad_head >= 0
00024c33 pad_w_ >= 0
00024c3f axis_ >= 0
00024c4a ratio_ >= 0
00024c56 epsilon_ >= 0
00024c64 momentum_ >= 0
00024c73 pad_h_ >= 0
00024c7f pads_[dim] >= 0
00024c8f dilation_[dim] >= 0
00024ca3 kernel_[dim] >= 0
00024cb5 adj_[dim] >= 0
00024cc4 stride_[dim] >= 0
00024cd6 pads_[kernel_.size() + dim] >= 0
00024cf7 Y.numel() >= 0
00024d06 Y_zero_point == 0
00024d18 delta_in.dim32(1) % box_dim == 0
00024d39 bbox_deltas_tensor.dim(0) % box_dim == 0
00024d62 total_size % size == 0
00024d79 totalSize % size == 0
00024d8f (X_W + pad_w_) % tiled_batch_w_ == 0
00024db4 M % this->group_ == 0
00024dca C % this->group_ == 0
00024de0 (X_H + pad_h_) % tiled_batch_h_ == 0
00024e05 M % G == 0
00024e10 C % G == 0
00024e1b period > 0 && period % 180 == 0
00024e3b input_channels % (sum_lengths ? sum_lengths : 1) == 0
00024e71 (total_dims - 1) % (numMaxStories_ + 1) == 0
00024e9e 2 == prev_bboxes_in.ndim() || prev_bboxes_in.size() == 0
00024ed7 split_.size() == 0
00024eea input_channels % OutputSize() == 0
00024f0d lengths_length % OutputSize() == 0
00024f30 size != 0
00024f3a C != 0
00024f41 Input data tensor to check if empty.
00024f66 Args axis and axis_str cannot be used simultaneously.
00024f9c (float, default 1.0) the scale to apply.
00024fc5 *(type: int; default: 1)* Axis of the inputs when coerced to 2D matrix.
0002500d Pooling op does not support dilation right now.
0002503d Pooling op does not support stride right now.
0002506b Only NCHW order is supported right now.
00025093 NNPack only supports NCHW order. Please consider add             TransposeOp with axes=[0, 3, 1, 2] before NNPack Conv.
0002510b *(type: int | Tuple(int))* 1D tensor containing the desired output shape. First input must be in CPU context.
00025179 *(type: bool; default: False)* set to *True* to use the *input* as shape. First, input must be in CPU context.
000251e8 The bias as a 1-dimensional tensor of size $C$ to be applied to the output.
00025234 The scale as a 1-dimensional tensor of size $C$ to be applied to the output.
00025281 *(type: int; default: 1)* Indicates up to which input dimensions (exclusive) should be flattened to the outer dimension of the output.
00025308 *(type: Tensor)* A 2D tensor with the contents of the input tensor, with input dimensions up to `axis` flattened to the outer dimension of the output and the remaining input dimensions flattened into the inner dimension of the output.
000253f3 A 2D Int8 tensor with the contents of the input tensor, with input dimensions up to axis flattened to the outer dimension of the output and remaining input dimensions flattened into the inner dimension of the output.
000254cc *(type: Tensor)* Transposed output.
000254f0 The output 4-dimensional tensor of the same shape as input.
0002552c The tensor `l_i` indicates the logic block of input.
00025561 *(type: Tuple(int))* New shape. Do not set if using `new_shape` input.
000255a8 If you set split with an input blob, do not pass in split in the argument.
000255f3 *(type: Tuple(int))* Order to permute axes of input tensor. Reverses the dimensions by default.
00025653 Backward compatible operator name for Split.
00025680 You are hitting a case where Caffe's legacy padding calculation is hit. This leads to inefficient and sometimes incorrect results. We are keeping this behavior for backward compatibility, but you are strongly recommended to move away from it.
00025773 (int) default 1; Pooled output Y's height.
0002579e  should have a gradient but is not implemented yet.
000257d2 If global_pooling is set pad, dilation and stride shouldn't be set.
00025816 Backward compatible operator name for Concat.
00025844 The number of splits specified should be equal to the number of outputs.
0002588d *(type: Tensor`<int>`)* The dimensions of the inputs.
000258c3 *(type: int)* Pass non-zero integer to remove the axis specified in `axis` to all input tensors.
00025924 *(type: int)* Pass non-zero integer to add the axis specified in `axis` to all input tensors.
00025982 *(type: Tensor`<float>`)* List of input tensors.
000259b3 Input indices tensor of rank $q$. This tensor must contain integers.
000259f8 The bias blob, of length $C_{out}$, containing the biases for the operation, one bias per output channel. If not passed, biases assumed to be zeros.
00025a8d device must be provided in options.
00025ab1 2D input of shape (R, 4 or 5) specifying R RoIs representing: batch index in [0, N - 1], x1, y1, x2, y2. The RoI coordinates are in the coordinate system of the input image. For inputs corresponding to a single image, batch index can be excluded to have just 4 columns.
00025bbf A Int8 tensor of rank >= axis.
00025bde *(type: Tensor)* Input Tensor of rank >= axis.
00025c0d The rank of the tensor must be >= axis.
00025c35 1D tensor of int32 or int64 segment lengths.
00025c62 Output data blob that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths.
00025cf6 Output data blob that contains the result of the transposed convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths.
00025d95 Output data tensor from padding the H and W dimensions on the tensor. Dimensions will vary based on various pad and stride sizes.
00025e17 Output data tensor from average pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes.
00025e9d Tensor of shape (batch_size) with each element denoting the number of RoIs/boxes belonging to the corresponding image in batch. Sum should add up to total count of scores/boxes.
00025f4f *(type: int[])* Array of interested axes.If given, this operator only returns the dimensions of the given axes.Otherwise, the operator returns the dimensions of all axes.
00025ffa *(type: Tensor)* Output tensor of constant values.
0002602d If you use legacy padding VALID or SAME, you should not specify any specific padding values.
0002608a Output dimensions (HxW). If specified this takes precedence over scale values.
000260d9 Padding layer only supports explicit pad values.
0002610a You shouldn't specify both the dim to split, and the order in the case of 4-D images.
00026160 You shouldn't specify both the dim to concat, and the order in the case of 4-D images.
000261b7 Input 4 and Output 2 should be alias.
000261dd Input 3 and Output 1 should be alias.
00026203 Input must be a vector.
0002621b The value for the elements of the output tensor.
0002624c *(type: Tensor)* Reshaped output tensor.
00026275 *(type: Tensor`<float>`)* Output tensor.
0002629e The softmax normalized output values with the same shape as input tensor.
000262e8 The sigmoid normalized output values with the same shape as input tensor.
00026332 *(type: Tensor`<float>`)* The softmax normalized output tensor with the same shape as input tensor.
00026396 An input tensor.
000263a7 *(type: Tensor)* Output tensor containing shape of input tensor.
000263e8 *(type: Tensor)* Input tensor.
00026407 *(type: Tensor`<float>`)* Input tensor.
0002642f *(type: Tensor`<float>`)* Concatenated tensor.
0002645e *(type: Tensor`<float>`)* Output data tensor.
0002648c *(type: Tensor`<float>`)* Input data tensor.
000264b9 Sliced Int8 data tensor.
000264d2 *(type depends on dtype, Required=True)* The value of the elements to go in the *output* tensor.
00026533 *(type: [int])* Desired shape of the *output* tensor.
00026569 Output tensor of random values drawn from an automatically scaled uniform distribution, based on the size of the output tensor. If the shape argument is set, this is the shape specified by the shape argument, and if the *input* exists and *input_as_shape=True*, it is the shape specified by the *input* tensor.
000266a0 Output tensor of random values drawn from a normal distribution. If the shape argument is set, this is the shape specified, and if the *input* exists and *input_as_shape=True*, it is the shape specified by the *input* tensor.
00026782 Output tensor with desired dimension filled with specified data. If the shape argument is set, this is the shape specified, and if the *input* exists and *input_as_shape=True*, it is the shape specified by the *input* tensor.
00026864 Right now ResizeLike is only supported for contiguous Tensor.
000268a2 Input blob containing vector of length $N$ which describes one bias for each node in the layer.
00026902 Input blob to be coerced into a 2D matrix of shape $(N,K)$ describing a fully connected weight matrix. Here, $K$ is the number of features in a single observation and $N$ is the number of nodes in the FC layer.
000269d5 The bias blob, of length $M$, containing the biases for the convolution, one bias per filter.
00026a33 The input 4-dimensional tensor of shape $NCHW$ or $NHWC$ depending on the order parameter.
00026a8e The output tensor (Tensor) in the NCHW order.
00026abc The input data (Tensor) in the NCHW order.
00026ae7 Int8 only supports NHWC order.
00026b06 The output tensor (Tensor) in the NHWC order.
00026b34 The input data (Tensor) in the NHWC order.
00026b5f The dimensions in argument `shape` must not be a negative number.
00026ba1 The number of output channels is not divisible by group.
00026bda The number of input channels is not divisible by group.
00026c12 The data type for the elements of the output tensor.Strictly must be one of the types from DataType enum in TensorProto.
00026c8b The data type for the elements of the output tensor. Strictly must be one of the types from DataType enum in TensorProto.
00026d05 *(type: int)* The data type for the elements of the output tensor. Strictly must be one of the types from *DataType* enum in TensorProto.
00026d8f *(type: float; default: 1e-5)* The epsilon value to use to avoid division by zero.
00026de2  can not be inferred since new size is zero.
00026e0f Must pass a nonnegative epsilon.
00026e30 Output data blob, of shape $(N, C_{out}, H_{out}, W_{out})$, that contains the result of the convolution.
00026e9a The filter blob, of shape $(M, C_{out}, K_H, K_W)$, containing the filters to be used in the transposed convolution.
00026f0f Int8 Tensor qX representing X with linear quantization.
00026f47 Input blob to be coerced into a 2D matrix of shape $(M,K)$, where $M$ is the batch size and $K$ is the number of features in a single observation.
00026fda *(type: [int]; default: [])* Controls the amount of padding applied to the input feature map before computation.
0002704b Output data blob, of shape $(N, C_{out}, H_{out}, W_{out})$, that contains the result of the operation.
000270b3 *(type: Tensor)* [OPTIONAL] Input tensor to provide shape information.
000270fa Input tensor (optional) to provide shape information.
00027130 *(type: float; default: 1.0)* Defines alpha parameter used in calculation.
0002717b Cannot compute softsign gradient if you choose to do an in-place calculation.
000271c9 *(type: Tensor`<Ord>`)* Output tensor with same dimensions as input(s).Contains the maximum valued element at each location.
00027246 *(type: Tensor`<Ord>`)* Output tensor with same dimensions as input(s).Contains the minimum valued element at each location.
000272c3 Argument `shape` has more than one missing dimension.
000272f9 *(type: string; default='NCHW')* Order of blob dimensions. Concats on the C dimension.
00027350 Currently only possible to slice in 1 dimension.
00027381 *(type: int; default: -1)* Axis to concatenate on.
000273b4 The input 4-dimensional NCHW tensor to be operated on.
000273eb Input data blob to be operated on.
0002740e 1D input tensor of data to be operated on.
00027439 Input tensor of data to be operated on.
00027461 Input data blob, of shape $(N, C_{in}, H_{in}, W_{in})$, to be operated on.
000274ad *(type: float; default: 1.)* Standard deviation of the distribution to draw from.
000274ff *(type: float; default: 0.)* Mean of the distribution to draw from.
00027543 Int8 Tensor of data to extract slices from.
0002756f Axes should be a permutation of 0 to ndim.
0002759a Pad should be smaller than kernel.
000275bd *(type: bool; default: False)* Whether to use float-16 compute kernel.
00027604 The filter blob that will be used in the convolutions; has size (M x C x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel.
000276b0 The filter blob that will be used in the transposed convolution; has size (M x kH x kW x C), where C is the number of channels, and kH and kW are the height and width of the kernel.
00027766 *(type: primitive; default: 0.0f) value to populate output tensor with.
000277ae (int) default 1; Pooled output Y's width.
000277d8 *(optional)* Per-channel sum of elements squared per channel to be used to determine the variance for this batch.
0002784a *(optional)* Per-channel sums of elements to be used to determine the mean and variance for this batch.
000278b2 (Optional) Saved inverse stdev used during training to speed up gradient computation. Should not be used for testing.
00027928 (Optional) Saved mean used during training to speed up gradient computation. Should not be used for testing.
00027995 Saved variance used during training to speed up gradient computation. Should not be used for testing.
000279fb The running variance after the spatial BN operator. Must be in-place with the input *var*. Should not be used for testing.
00027a76 The running mean after the spatial BN operator. Must be in-place with the input *mean*. Should not be used for testing.
00027aee Argument `shape` is missing.
00027b0b float (default 1.0 degrees). For RRPN, clip almost horizontal boxes within this threshold of tolerance for backward compatibility. Set to negative value for no clipping.
00027bb5 Dilation not supported for legacy padding.
00027be0 *(type: int; default: 1)* Describes the axis of the input weight matrix $W$. Defaults to one because the first axis most likely describes the batch_size.
00027c7a ) tensor to zero size.
00027c91 Argument `shape` has a dimension set to zero that exceeds the original dimension size.
00027ce8 If you are doing convolution or pooling, you will need to set explicitly the kernel size.
00027d42 *(type: int; default: 1)* Describes the axis of the input data $X$. Defaults to one because in the common case when the input $X$ has shape $(M,K)$, the first axis encodes the batch size.
00027dfe Output tensor, calculated as described above.
00027e2c 1D input tensor, calculated as described above.
00027e5c The input tensor that's coerced into a 2D matrix of size (NxD) as described above.
00027eaf *(type: Tensor`<float>`)* Input tensor that's coerced into a 2D matrix of size (NxD) as described above.
00027f18 This should never happen. If this happens, double check the logic above.
00027f61 (optional) Avoid elements in this tensor. Elements must be unique.
00027fa4 Max value should be bigger than min value.
00027fcf  already set to sparse.
00027fe7  already set to dense.
00027ffe *(type: Tensor`<float>`)* First tensor to be added element-wise.
0002803f *(type: Tensor`<float>`)* Second tensor to be added element-wise.
00028081 *(type: Tensor`<float>`)* Output tensor computed as the natural log of the input tensor computed, element-wise.
000280f1 Input data tensor from the previous operator; dimensions depend on whether the NCHW or NHWC operators are being used. For example, in the former, the input has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. The corresponding permutation of dimensions is used in the latter case.
0002825d You are trying to record with a wrong device type.
00028290 *(type: Tensor`<int>`)* [OPTIONAL] Tensor containing new shape.
000282d0 New shape.
000282db Original shape.
000282eb *(type: Tensor`<Ord>`)* List of input tensors with the same shape.
0002832e The shape of the output tensor.Cannot set the shape argument and pass in an input at the same time.
00028392 *(type: int | Tuple(int))* Shape of the output tensor. Cannot pass an input blob and this arg at the same time.
00028402 New shape must not be specified by the input blob and the argument `shape` at the same time.
0002845f Axis not in input ndim range.
0002847d (float) default 1.0; Spatial scale of the input feature map X relative to the input image. E.g., 0.0625 if X has a stride of 16 w.r.t. the input image.
00028515 *(type: float; default: 0.01)* Coefficient of leakage.
0002854c *(type: int; default: 0)* If set to nonzero, run spatial batch normalization in test mode.
000285a7 First operand, should share the type with the second operand.
000285e5 CAFFE_LEGACY_POOLING is no longer supported.
00028612 Overflow floating point exception (FE_OVERFLOW) reported.
0002864c Division by zero floating point exception (FE_DIVBYZERO) reported.
0002868f Invalid floating point exception (FE_INVALID) reported.
000286c7 Not implemented.
000286d8 Not Implemented.
000286e9 *(type: int; optional)* Should the legacy padding be VALID or SAME. When used, pads should not be used.
00028751 *(type: float; default: 0.5)* Probability of an element to be zeroed.
00028797 *(type: int; default: 1)* Specifies the number of batches to apply normalization on. Requires specifying the optional sums and sumsq inputs that provide statistics across multiple batches from which mean and variance can be determined.
00028883 *(type: Tensor`<bool>`)* The output mask containing boolean values foreach element, signifying which elements are dropped out. If `is_test` isnonzero, this output is not filled.
00028935 *(type: int | Tuple(int))* Additional dimensions appended at the end of the shape indicated by the input blob. Cannot set thisargument when there is no input blob.
000289d9 The additional dimensions appended at the end of the shape indicatedby the input blob.Cannot set the extra_shape argument when there is no input blob.
00028a70 The additional dimensions appended at the end of the shape indicatedby the input blob. Cannot set the extra_shape argument when there is no input blob.
00028b08 *(type: [int])* The additional dimensions appended at the end of the *shape* indicated by the input blob. Cannot set the *extra_shape* argument when there is no input blob.
00028bb5 *(type: [int]; default: [])* Controls the stride of the kernel as it traverses the input blob.
00028c14 Input data blob, of shape $(N, C_{in}, H_{in}, W_{in})$, to be convolved with the kernels in the filter blob.
00028c82 *(type: [int]; default: [])* Desired kernel size. If left at default the kernel size will be inferred from the input $filter$ blob.
00028d06 Argument `shape` does not agree with the input data.
00028d3b 1D tensor: start-indices for each dimension of data.
00028d70 1D tensor: end-indices for each dimension of data.
00028da3 The filter blob, of shape $(M, C_{in}, K_H, K_W)$, containing the filters to be convolved with the data.
00028e0c Reshaped data.
00028e1b New shape must be specified by either the input blob or the argument `shape`.
00028e69 New shape is specified by the input blob, do not pass in the argument `shape`.
00028eb8 *(type: int; default: 0)* Pass 1 to transpose `B` before multiplication and after the dimension adjustment using `axis_b`.
00028f33 *(type: Tensor`<int>`)* Tensor containing old shape of `data`.
00028f72 *(type: int; default: 0)* Pass 1 to transpose `A` before multiplication and after the dimension adjustment using `axis_a`.
00028fed *(type: int; default: 1)* Exclusive axis that divides the first and second dimension of matrix `B`.
00029051 *(type: int; default: 1)* Exclusive axis that divides the first and second dimension of matrix `A`.
000290b5 int (default -90 degrees). If set, for rotated boxes, angle is normalized to be within [angle_bound_lo, angle_bound_hi].
0002912e int (default 90 degrees). If set, for rotated boxes, angle is normalized to be within [angle_bound_lo, angle_bound_hi].
000291a6 bool (default true). If set, for rotated boxes, angle is normalized to be within [angle_bound_lo, angle_bound_hi].
00029219 Pixel coordinates of the transformed bounding boxes,Size (M, 4*K), format [x1, y1, x2, y2]. For rotated boxes, size (M, 5*K), format [ctr_x, ctr_y, w, h, angle].
000292bb Filtered boxes, size (n, 4). For rotated boxes, size (n, 5), format [ctr_x, ctr_y, w, h, angle].
0002931c Bounding box proposals in pixel coordinates, Size (M, 4), format [x1, y1, x2, y2], orSize (M, 5), format [batch_index, x1, y1, x2, y2]. If proposals from multiple images in a batch are present, they should be grouped sequentially and in incremental order.For rotated boxes, this would have an additional angle (in degrees) in the format [<optional_batch_id>, ctr_x, ctr_y, w, h, angle].
0002949f bounding box translations and scales,size (M, 4*K), format [dx, dy, dw, dh], K = # classes. For rotated boxes, size (M, 5*K, format [dx, dy, dw, dh, da].
00029539 *(Tensor`<float>`)* Output tensor clipped within range [`min`, `max`].
00029580 *(Tensor`<float>`)* Input tensor within range [*numeric_limits::lowest()*, *numeric_limits::max()*].
000295e5 bool (default false). If true, then boxes (rois and deltas) include angle info to handle rotation. The format will be [ctr_x, ctr_y, width, height, angle (in degrees)].
0002968e Int8 Tensor qX.
0002969e FP32 Tensor that represents mapped real value of qX.
000296d3 FP32 Tensor X.
000296e2 *(type: int; default: 0)* If zero (train mode), perform dropout. If non-zero(test mode), Y = X.
00029742 Optional, 1D float tensor containing how many boxes from each batch. The summation of all elements must be N.
000297b0 4D Int8 Tensor output of shape (R, C, pooled_h, pooled_w). The r-th batch element is a pooled feature map corresponding to the r-th RoI.
00029839 4D output of shape (R, C, pooled_h, pooled_w). The r-th batch element is a pooled feature map corresponding to the r-th RoI.
000298b6 *(type: Tensor`<float>`)* Input data tensor of shape NCHW or NHWC.
000298f9 *(type: Tensor`<float>`)* Sum of A and B.
00029923 Second operand. It should be of the same size as A.
0002995a must be 4.
00029965 The 1D bias blob that is added through the convolution;has size (C). Optional, if not passed, will treat it as all 0.
000299db Output scalar boolean tensor. True if input has size == 0.
00029a16 X, Y, ...
00029a20 X1, X2, ...
00029a2c The input 1-dimensional bias tensor of size *C*.
00029a5d The input 1-dimensional scale tensor of size *C*.
00029a8f Output data tensor from max pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes. Output will go through rectified linearfunction, where y = max(0, x).
00029b57 Output data blob that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths. Output will go through rectified linear function, where y = max(0, x).
00029c32 Output data tensor from average pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes. Output will go through rectified linear function, where y = max(0, x).
00029cff (*bool*): Enables automatic scaling of the lengths values. When enabled will automatically find a value K >= 1, such that sum(lengths) * K == len(input).
00029d99 (int) default -1; number of sampling points in the interpolation grid used to compute the output value of each pooled output bin. If > 0, then exactly sampling_ratio x sampling_ratio grid points are used. If <= 0, then an adaptive number of grid points are used (computed as ceil(roi_width / pooled_w), and likewise for height).
00029ee2  is sparse (expected dense).
00029eff 4D Int8 Tensor feature map input of shape (N, C, H, W).
00029f37 4D feature map input of shape (N, C, H, W).
00029f63 *(type: Tensor`<float>`)* 2D matrix of size (M x N).
00029f98 *(type: Tensor`<float>`)* 2D matrix of size (K x N).
00029fcd The 1D bias blob that is added through the convolution; has size (M).
0002a013 *(type: Tensor`<float>`)* 2D matrix of size (M x K).
0002a048 Bounding box for each class, size (count, num_classes * 4). For rotated boxes, this would have an additional angle (in degrees) in the format [<optional_batch_id>, ctr_x, ctr_y, w, h, angle]. Size: (count, num_classes * 5).
0002a128 *(type: float)* Maximum value, under which element is replaced by max (default=*numeric_limits::max()*).
0002a191 *(type: float)* Minimum value, under which element is replaced by min (default=*numeric_limits::lowest()*).
0002a1fd Compressed data in 1d tensor (uint8_t), or 0d tensor with one element in string type.The data is compressed using mutils.compress_data_list().
0002a28c Check failed: output->sizes() == Input(i).sizes().
0002a2bf Output blob containing a 2D output matrix of shape $(M,N)$, where $M$ is the batch size and $N$ is the number of nodes in the layer. The output is calculated as $Y=XW^T+b$.
0002a36c Output tensor, with same shape as $X$.
0002a393 The output 4-dimensional tensor of the same shape as $X$.
0002a3cd The running mean (training) or the estimated mean (testing) as a 1-dimensional tensor of size $C$.
0002a430 The running variance (training) or the estimated variance (testing) as a 1-dimensional tensor of size $C$.
0002a49b *(type: string; default: "NCHW")* Specifies the order of the input data blob, where $N$ is batch size, $C$ is number of channels, $H$ is spatial height, and $W$ is spatial width. The only other valid option is "NHWC".
0002a575 order should be either "NCHW" or "NHWC".
0002a59e 1D tensor whose size is the sum of *lengths*
0002a5cb (Optional) 1D tensor specifying the shape of the output. Must be used with *input_as_shape=True*
0002a62c *(type: [int]; default: [])*
0002a649 *(type: int; default: 0)*
0002a663 anchors_tensor.sizes() == (vector<int64_t>{A, box_dim})
0002a69b bbox_deltas.sizes() == (at::ArrayRef<int64_t>{num_images, box_dim * A, height, width})
0002a6f2 scores_tensor.dims() == (vector<int>{A, H, W})
0002a721 im_info_tensor.sizes() == (vector<int64_t>{num_images, 3})
0002a75c iminfo_in.sizes() == (at::IntArrayRef{batch_size, 3})
0002a792 tensors.ParseFromArray(ptr, sz)
0002a7b2 Warped feature map, Size (M, C, pooled_h, pooled_w)
0002a7e6 Codebook in 1d tensor (float)
0002a804 Decoded tensor for codes_n (float)
0002a827 Decoded tensor for codes_1 (float)
0002a84a Decoded tensor for codes_0 (float)
0002a86d 2D matrix of size (n_bbox, n_raw_concepts)
0002a898 2D matrix of size (n_bbox, n_merged_concepts)
0002a8c6 2D matrix, size (n_raw_concepts, n_merged_concepts)
0002a8fa Optional number of filtered indices per class, size (num_classes)
0002a93c Scores, size (count, num_classes)
0002a95e Class id for each filtered score/box, size (n)
0002a98d scores of proposals, size (n)
0002a9ab Filtered scores, size (n)
0002a9c5 Optional filtered indices, size (n)
0002a9e9 *(type: float; default: 0.9)* Factor used in computing the running mean and variance. e.g., running_mean = running_mean x momentum + mean x (1 - momentum)
0002aa84 value (optional)
0002aa95 Net executed when condition is false (optional)
0002aac5 in[0].dims(j) == in[i].dims(j)
0002aae4 data.size(i) == indices.size(i)
0002ab04 !ZSTD_isError(dc_size)
0002ab1b Input array of type char(byte)
0002ab3a Image info, size (img_count, 3), format (height, width, scale)
0002ab79 (*Tensor`<int>`*): 1D tensor of start-indices for each dimension of data (dimensions following the sliced one might be omitted)
0002abf9 (*Tensor`<int>`*): 1D tensor of end-indices for each dimension of data (dimensions following the sliced one might be omitted)
0002ac77 inputs must have the same shape (broadcast semantics is not supported)
0002acbe (*Tensor`<int>`*): [OPTIONAL] list of output lengths (see also arg `split`)
0002ad0a schema->Verify(def_)
0002ad1f !std::fetestexcept(FE_OVERFLOW)
0002ad3f Input feature for warping, Size (N, C, H, W)
0002ad6c Scores from conv layer, size (img_count, A, H, W)
0002ad9e Bounding box deltas from conv layer, size (img_count, 4 * A, H, W)
0002ade1 INDICES must have the same outer dims as DATA (before dim AXIS)
0002ae21 !std::fetestexcept(FE_DIVBYZERO)
0002ae42 !std::fetestexcept(FE_INVALID)
0002ae61 shape of exploded feature map (N,H,W,C)
0002ae89 Proposed bounding boxes, Size (M, 4 or 5)
0002aeb3 (is_test_ && OutputSize() == 1) || (!is_test_ && OutputSize() == 5)
0002aef7 Bounding box anchors, size (A, 4)
0002af19 2D matrix, size (n_bbox, n_raw_concepts * 4)
0002af46 2D matrix of size (n_bbox, n_merged_concepts * 4)
0002af78 OC == Y->t.size(3)
0002af8b heatmaps_in.dim32(3) == bones_heatmaps_in.dim32(3)
0002afbe heatmaps_in.dim32(2) == heatmaps_in.dim32(3)
0002afeb Proposals, size (n x 5), format (image_index, x1, y1, x2, y2)
0002b029 Encoded codes n if existed (uint8/uint16/int32)
0002b059 Encoded codes 1 if existed (uint8/uint16/int32)
0002b089 Encoded codes 0 (uint8/uint16/int32)
0002b0ae heatmaps_in.dim32(2) == bones_heatmaps_in.dim32(2)
0002b0e1 IsInputOutputAlias(4, 2)
0002b0fa cls_prob.dim(1) * GROUP_CNT == pred_bbox.dim(1)
0002b12a K == W.t.size(1)
0002b13b num_boxes_classes * box_dim == tboxes.size(1)
0002b169 C == S.size(1)
0002b178 C == M.size(1)
0002b187 prev_bboxes_in.size() == 0 || 4 == prev_bboxes_in.dim32(1)
0002b1c2 4 == next_bboxes_in.dim32(1)
0002b1df IsInputOutputAlias(3, 1)
0002b1f8 in[0].dims_size() == in[i].dims_size() || (canonical_axis == in[0].dims_size() - 1 && in[0].dims_size() == in[i].dims_size() + 1)
0002b27a cls_prob.dim(0) == pred_bbox.dim(0)
0002b29e cls_prob.dim(1) == concept_mapping.dim(0)
0002b2c8 IC == W.t.size(0)
0002b2da N == tboxes.size(0)
0002b2ee I(0) != O(0)
0002b2fb M == filter.dim32(0)
0002b310 heatmaps_in.dim32(0) == bones_heatmaps_in.dim32(0)
0002b343 N == b.dim32(0)
0002b353 !IsInputOutputAlias(1, 0)
0002b36d this->template GetSingleArgument<T>("min", 0) < this->template GetSingleArgument<T>("max", 0)
0002b3cb (i >= 0) && (i < def_.output().size())
0002b3f2 (i >= 0) && (i < def_.input().size())
0002b418 this->InputIsTensorType(0, Context::GetDeviceType())
0002b44d !(OperatorBase::HasArgument("axis") && OperatorBase::HasArgument("order"))
0002b498 s < std::numeric_limits<int>::max()
0002b4bc Y_zero_point <= std::numeric_limits<uint8_t>::max()
0002b4f0 X.zero_point <= std::numeric_limits<uint8_t>::max()
0002b524 X0.zero_point <= std::numeric_limits<uint8_t>::max()
0002b559 filter.dim32(3) == this->kernel_w()
0002b57d filter.dim32(3) == kernel_w()
0002b59b filter.dim32(2) == kernel_w()
0002b5b9 A == anchors.rows()
0002b5cd sorted_indices.size() <= proposals.rows()
0002b5f7 proposals.rows() == scores.rows()
0002b619 boxes.rows() == deltas.rows()
0002b637 src_tensor.is_contiguous()
0002b652 Xi.sizes() == Y->sizes()
0002b66b X0.sizes() == Y->sizes()
0002b684 A.t.sizes() == B.t.sizes()
0002b69f X.sizes() == Y.sizes()
0002b6b6 Y_zero_point >= std::numeric_limits<uint8_t>::min()
0002b6ea X.zero_point >= std::numeric_limits<uint8_t>::min()
0002b71e X0.zero_point >= std::numeric_limits<uint8_t>::min()
0002b753 4 == bones_heatmaps_in.ndim()
0002b771 2 == next_bboxes_in.ndim()
0002b78c 4 == input.dim()
0002b79d canonical_axis < input.dim()
0002b7ba 4 == X.t.dim()
0002b7c9 X.dim() == filter.dim()
0002b7e1 axis < data.dim()
0002b7f3 cb_size == output->numel()
0002b80e codes.numel() == decoded_grad->numel()
0002b835 M * N == Y->numel()
0002b849 a_dim0 * b_dim1 == Y->numel()
0002b867 N == B.t.numel()
0002b878 data.dim() >= starts.numel()
0002b895 starts.numel() == ends.numel()
0002b8b4 dY.numel() == mask.numel()
0002b8cf N == b.numel()
0002b8de output->numel() == values_.numel()
0002b901 Y.numel() == dY.numel()
0002b919 dY.numel() == Y.numel()
0002b931 M * K == X.numel()
0002b944 K * N == W.numel()
0002b957 C == W.numel()
0002b966 1 == Input(2).numel()
0002b97c 1 == Input(1).numel()
0002b992 filter.dim32(2) == this->kernel_h()
0002b9b6 filter.dim32(2) == kernel_h()
0002b9d4 filter.dim32(1) == kernel_h()
0002b9f2 i < in[0].dims_size()
0002ba08 2 == output_dims.size()
0002ba20 Xi.t.dim() == Y_dims.size()
0002ba3c 4 == inputDims.size()
0002ba52 1 == in.size()
0002ba61 ndim == axes_.size()
0002ba76 starts_.size() == ends_.size()
0002ba95 dilation_.size() == kernel_.size()
0002bab8 adj_.size() == kernel_.size()
0002bad6 stride_.size() == kernel_.size()
0002baf7 pads_.size() == 2 * kernel_.size()
0002bb1a in[0].dims().size() == in[i].dims().size()
0002bb45 split_tensor.numel() == OutputSize()
0002bb6a tensors.protos_size() == OutputSize()
0002bb90 split_.size() == OutputSize()
0002bbae !g_input_.at(i).IsSparse()
0002bbc9 g_output_.at(i).IsDense()
0002bbe3 !g_input_.at(i).IsDense()
0002bbfd Input(i).dtype() == input_zero.dtype()
0002bc24 options.dtype() == src.dtype()
0002bc43 pred_bbox.template IsType<float>()
0002bc66 tboxes.template IsType<float>()
0002bc86 tscores.template IsType<float>()
0002bca7 anchors_tensor.template IsType<float>()
0002bccf im_info_tensor.template IsType<float>()
0002bcf7 codebook.template IsType<float>()
0002bd19 concept_mapping.template IsType<float>()
0002bd42 cls_prob.template IsType<float>()
0002bd64 X.template IsType<float>()
0002bd7f Input1.template IsType<float>()
0002bd9f Input0.template IsType<float>()
0002bdbf op_compressed.template IsType<uint8_t>() || op_compressed.template IsType<std::string>()
0002be18 compressed.template IsType<uint8_t>() || compressed.template IsType<std::string>()
0002be6b codebook.IsType<CodebookT>()
0002be88 codes.IsType<CodeT>()
0002be9e SHAPE.template IsType<T>()
0002beb9 !this->template HasSingleArgumentOfType<T>("max")
0002beeb this->template HasSingleArgumentOfType<NetDef>("then_net")
0002bf26 HasArgument("starts")
0002bf3c HasArgument("ends")
0002bf50 !OperatorBase::HasArgument("pads")
0002bf73 !this->template HasSingleArgumentOfType<T>("min")
0002bfa5 !OperatorBase::HasArgument("shape")
0002bfc9 ) should be divisible by number of outputs (
0002bff6 ) is not equal to total output channels (
0002c020 Input channels (
0002c031 ) should be equal to output size (
0002c054 Can not reshape a non-zero size (
0002c076 `split` size (
0002c085 ; rect2.center = (
0002c098 ; rect1.center = (
0002c0ab rect2.size = (
0002c0ba rect1.size = (
0002c0c9 Input data tensor of rank $r>=1$
0002c0ea Output tensor of rank $q+(r-1)$
0002c10a Description: Input #
0002c11f soft_nms_method_str_ == "linear" || soft_nms_method_str_ == "gaussian"
0002c166 false INTERNAL ASSERT FAILED at "xplat/caffe2/c10/core/MemoryFormat.h"
0002c1ad 0 INTERNAL ASSERT FAILED at "xplat/caffe2/c10/core/TensorOptions.h"
0002c1f1 false"TYPE" CHECK FAILED at "xplat/caffe2/c10/core/TensorOptions.h"
0002c235 false"" CHECK FAILED at "xplat/caffe2/c10/core/TensorOptions.h"
0002c275 false INTERNAL ASSERT FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c2ba extra_meta_ && extra_meta_->symbolic_shape_meta_ INTERNAL ASSERT FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c32a storage_offset_ == 0 INTERNAL ASSERT FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c37e axis_index >= -ndims"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c3ca axis_index < ndims"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c414 false"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c451 !overflowed"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c494 !has_symbolic_sizes_strides_"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c4e8 dim() == 5"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c52a dim() == 4"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c56c k >= 0 && static_cast<size_t>(k) <= dims.size()"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c5d3 (unsigned)l < dims.size() && (unsigned)k < dims.size()"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c641 new_size.size() == new_stride.size()"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c69d device_opt_.has_value()"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c6ec allow_tensor_metadata_change()"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c742 has_storage()"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c787 dtype_initialized()"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c7d2 storage_initialized()"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c81f data_type_.Match<std::remove_const_t<T>>()"" CHECK FAILED at "xplat/caffe2/c10/core/TensorImpl.h"
0002c881 allocator_ INTERNAL ASSERT FAILED at "xplat/caffe2/c10/core/StorageImpl.h"
0002c8cc !size_bytes_is_heap_allocated_"" CHECK FAILED at "xplat/caffe2/c10/core/StorageImpl.h"
0002c923 !empty()"" CHECK FAILED at "xplat/caffe2/c10/util/ArrayRef.h"
0002c961 SupportsNonFundamentalTypes() INTERNAL ASSERT FAILED at "xplat/caffe2/caffe2/core/context_base.h"
0002c9c3 false"" CHECK FAILED at "xplat/caffe2/caffe2/proto/caffe2_pb.h"
0002ca03 IsType<T>() INTERNAL ASSERT FAILED at "xplat/caffe2/aten/src/ATen/core/blob.h"
0002ca52 def_.type() == "FC" || def_.type() == "FCTransposed"
0002ca87 (*string*): order of dimensions of input and output blobs; either "NCHW" or "NHWC"
0002cada unsupported activation type "
0002caf8 operator_def was null!
0002cb0f ROIs in ROIAlign do not have non-negative size!
0002cb3f NNPack is not supported here!
0002cb5d  is not provided!
0002cb6f  should be divisible by 
0002cb88 Invalid type index 
0002cb9c Gradient of output 
0002cbb0 Input 
0002cbb7  got 
0002cbbd  vs 
0002cbc2 Convolution op: input channels does not match: # of input channels 
0002cc06 Input channels 
0002cc16 One should not call gradient for operator 
0002cc41 Operator 
0002cc4b All inputs of Concat should have same dims except canonical_axis dim that is equal to 
0002cca2 New shape at dim 
0002ccb4 Unrecognizable axis string 
0002ccd0  from order string 
0002cce4 Higher priority item already registered, skipping registration of 
0002cd27 weights size 
0002cd35 Sum of split dimensions do not match: should be 
0002cd66 All inputs of Concat should have same dims when add_axis = 1. Got different dims for inputs 0 and 
0002cdc9 All inputs of Concat should have same dims when add_axis = 1. Got different sizes for inputs 0 and 
0002ce39  != 
0002ce3e num_intersections = 
0002ce53  at axis = 
0002ce5f . The input tensors can only have different dimensions when arg 'add_axis' = 0 and along the axis = 
0002cec4 Expect dimension = 
0002ced8 rect2.angle = 
0002cee7 rect1.angle = 
0002cef6 Key already registered with the same priority: 
0002cf26  for input: 
0002cf33  but got: 
0002cf3e Unhandled type argument: 
0002cf58 , axis: 
0002cf61 Error from operator: 
0002cf77 Unsupported type of tensor: 
0002cf94 Exception from observer: 
0002cfae Unknown storage order: 
0002cfc6 Unsupported storage order: 
0002cfe2 Unknown Storage order: 
0002cffa  is not equal to kernel channels * group: 
0002d025  should match output dimension: 
0002d046 . At dim: 
0002d051 Unsupported pooling dim: 
0002d06b Dimension mismatch: 
0002d080 Unknown storage order string: 
0002d09f (GradientMaker) Operator def did not pass schema checking: 
0002d0db Unexpected 'dtype' argument value: 
0002d0ff Invalid shape type: 
0002d114 Unknown padding mode: 
0002d12b All inputs must have the same type, expected: 
0002d15a , b: 
0002d160 , dY: 
0002d16b , W: 
0002d171 , N: 
0002d177 , M: 
0002d17d , K: 
0002d183 , B: 
0002d18d , trans(B): 
0002d19a trans(A): 
0002d1a5 Unknown storage order : 
0002d1be Input data blob from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the NCHW usage. On the other hand, the NHWC Op has a different set of dimension constraints. 
0002d2cf Input data tensor from the previous operator; dimensions depend on whether the NCHW or NHWC operators are being used. For example, in the former, the input has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. The corresponding permutation of dimensions is used in the latter case. 
0002d43c Check failed: double_multiplier < 1. 
0002d462 Check failed: double_multiplier >= 0. 
0002d489 Input channels should be equal to split dimensions sum, 
0002d4c6 *(type: bool; default: False)* 
0002d4e6 len(Lengths) 
0002d4f4 (bool, default false) 
0002d50b Check failed: q_fixed <= (1ll << 31) 
0002d531 should be divisible by OutputSize() 
0002d557 Produce a 1D int64 tensor with the shape of the input tensor.
0002d595 If called with an optional argument `axes`, the result will only
0002d5d6 contain the dimensions of specified axes.
0002d601 Github Link:
0002d60e - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/shape_op.cc
0002d65b <details>
0002d666 <summary> <b>Example</b> </summary>
0002d68b **Code**
0002d69a workspace.ResetWorkspace()
0002d6b6 op = core.CreateOperator(
0002d6d0     "Shape",
0002d6dd     ["X"],
0002d6e8     ["shape"],
0002d6fa workspace.FeedBlob("X", (np.random.randint(10, size=(2,3))))
0002d737 print("X:", workspace.FetchBlob("X"))
0002d75d workspace.RunOperatorOnce(op)
0002d77b print("shape:", workspace.FetchBlob("shape"))
0002d7af **Result**
0002d7c3 [[3 2 5]
0002d7cc  [5 7 3]]
0002d7d6 shape: [2 3]
0002d7e9 </details>
0002d7f5       
0002d7fd 'If' control operator, first input is a scalar boolean blob that stores condition
0002d84f value. Accepts 'then_net' (required) and 'else_net' (optional) arguments for 'then' and
0002d8a7 'else' subnets respectively. Subnets are executed in the same workspace as 'If'.
0002d8f8     
0002d8fe Fill the output tensor with int32 samples from uniform distribution [`min`, `max`].
0002d953 - The range can be defined either by arguments or input blobs. `min` and `max` are inclusive.
0002d9b1     - If the range is given by input blobs, you also need to give the shape as input.
0002da07     - When the range is given as arguments, this operator enforces min <= max. When the range is given as inputs, the constraint is not enforced.
0002da99     - When the range is given as inputs and max < min, the first dimension of the output is set to 0. This behavior is allowed so that dynamically sampling indices into a dynamically sized tensor is possible.
0002db6a - The shape of the output can be given as argument or input.
0002dba8 Github Links:
0002dbb6 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/filler_op.h
0002dc02 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/filler_op.cc
0002dc50 <details>
0002dc5b <summary> <b>Example</b> </summary>
0002dc80 **Code**
0002dc8f workspace.ResetWorkspace()
0002dcab op_1 = core.CreateOperator(
0002dcc7     "UniformIntFill",
0002dcdd     [],
0002dce5     ["output"],
0002dcf5     min=5,
0002dd00     max=10,
0002dd0c     shape=(3,3)
0002dd1f op_2 = core.CreateOperator(
0002dd3b     "UniformIntFill",
0002dd51     ["shape", "min", "max"],
0002dd6e     ["output"],
0002dd7e     input_as_shape=1
0002dd96 // Test arg-based op
0002ddab workspace.RunOperatorOnce(op_1)
0002ddcb print("output (op_1):\n", workspace.FetchBlob("output"))
0002de05 // Test input-based op
0002de1c workspace.ResetWorkspace()
0002de37 workspace.FeedBlob("shape", np.array([5,5]))
0002de64 workspace.FeedBlob("min", np.array(13, dtype=np.int32))
0002de9c workspace.FeedBlob("max", np.array(19, dtype=np.int32))
0002ded4 workspace.RunOperatorOnce(op_2)
0002def4 print("output (op_2):\n", workspace.FetchBlob("output"))
0002df33 **Result**
0002df44 output (op_1):
0002df53  [[ 6 10  7]
0002df60  [ 5 10  6]
0002df6c  [ 7  5 10]]
0002df79 output (op_2):
0002df88  [[19 13 15 13 13]
0002df9b  [14 17 14 15 15]
0002dfad  [17 14 19 13 13]
0002dfbf  [17 18 16 13 18]
0002dfd1  [14 15 16 18 16]]
0002dfea </details>
0002dff6     
0002dffc Concatenate a list of tensors into a single tensor. Similar functionality to
0002e049 Numpy's [concatenate](https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html)
0002e0ac function. The `axis` argument specifies what axis along which the arrays will be concatenated.
0002e10b When set to non-zero (default=0), the `add_axis` argument adds the axis specified in `axis` to
0002e16a all input tensors.
0002e17e Github Links:
0002e18d - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/concat_split_op.cc
0002e1e0 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/concat_split_op.h
0002e234 <details>
0002e23f <summary> <b>Example</b> </summary>
0002e264 **Code**
0002e273 workspace.ResetWorkspace()
0002e28f op = core.CreateOperator(
0002e2a9     "Concat",
0002e2b7     ["X1",  "X2"],
0002e2ca     ["Y", "split_info"],
0002e2e3     axis=0
0002e2f1 workspace.FeedBlob("X1", np.array([[1,2],[3,4]]))
0002e323 workspace.FeedBlob("X2", np.array([[5,6]]))
0002e34f print("X1:", workspace.FetchBlob("X1"))
0002e377 print("X2:", workspace.FetchBlob("X2"))
0002e39f workspace.RunOperatorOnce(op)
0002e3bd print("Y:", workspace.FetchBlob("Y"))
0002e3e3 print("split_info:", workspace.FetchBlob("split_info"))
0002e421 **Result**
0002e432 X1: [[1 2]
0002e43d  [3 4]]
0002e445 X2: [[5 6]]
0002e451 Y: [[1 2]
0002e45b  [3 4]
0002e462  [5 6]]
0002e46a split_info: [2 1]
0002e482 </details>
0002e48e <details>
0002e499 <summary> <b>Example 2</b> </summary>
0002e4c0 **Code**
0002e4cf workspace.ResetWorkspace()
0002e4eb op = core.CreateOperator(
0002e505     "Concat",
0002e513     ["X1",  "X2"],
0002e526     ["Y", "split_info"],
0002e53f     add_axis=1,
0002e54f     axis=3
0002e55d workspace.FeedBlob("X1", np.random.randint(10, size=(1, 1, 5, 5))) // NCHW
0002e5a8 workspace.FeedBlob("X2", np.random.randint(10, size=(1, 1, 5, 5))) // NCHW
0002e5f3 print("X1:", workspace.FetchBlob("X1"))
0002e61b print("X2:", workspace.FetchBlob("X2"))
0002e643 workspace.RunOperatorOnce(op)
0002e661 print("Y:", workspace.FetchBlob("Y"))
0002e687 print("split_info:", workspace.FetchBlob("split_info"))
0002e6c5 **Result**
0002e6d6 X1: [[[[1 8 3 9 0]
0002e6e9    [6 4 6 5 6]
0002e6f8    [3 9 1 9 9]
0002e707    [5 1 0 7 7]
0002e716    [9 4 0 0 9]]]]
0002e728 X2: [[[[7 0 2 6 1]
0002e73b    [3 9 4 0 3]
0002e74a    [5 3 8 9 4]
0002e759    [3 4 2 1 0]
0002e768    [0 8 8 8 1]]]]
0002e77a Y: [[[[[1 8 3 9 0]
0002e78d     [7 0 2 6 1]]
0002e79f    [[6 4 6 5 6]
0002e7af     [3 9 4 0 3]]
0002e7c1    [[3 9 1 9 9]
0002e7d1     [5 3 8 9 4]]
0002e7e3    [[5 1 0 7 7]
0002e7f3     [3 4 2 1 0]]
0002e805    [[9 4 0 0 9]
0002e815     [0 8 8 8 1]]]]]
0002e829 split_info: [1 1]
0002e841 </details>
0002e84d     
0002e853   Convert historical features + labels and candidate features + prod_predictions
0002e8a4   to mobile ranking format
0002e8c3   Convert the batch sequence features into training examples
0002e904   Convert example based row features to sequence based
0002e93b   row features to accommodate mobile ranking
0002e96c   Conver from mobile ranking format to historical features + labels and
0002e9b4   candidate features + prod_predictions format. Operator assumes that all
0002e9fe   history features are the same
0002ea22 The transposed convolution consumes an input vector, the filter blob, and
0002ea6c the bias blob, and computes the output. Note that other parameters, such as
0002eab8 the stride and kernel size, or the pads' sizes in each direction are not
0002eb01 necessary for input because they are provided by the
0002eb36 ConvTransposeUnpoolOpBase operator. Various dimension checks are done
0002eb7c implicitly, and the sizes are specified in the Input docs for this operator.
0002ebc9 As is expected, the filter is deconvolved with a subset of the
0002ec08 image and the bias is added; this is done throughout the image data and the
0002ec54 output is computed. As a side note on the implementation layout:
0002ec95 conv_transpose_op_impl.h is the templated implementation of the
0002ecd5 conv_transpose_op.h file, which is why they are separate files.
0002ed19 PadImage pads values around the boundary of an image according to the pad
0002ed63 values and stride sizes defined by the ConvPoolOpBase operator.
0002eda7 The ConvTranspose op takes an input data tensor $X$, an input weight tensor $filter$, and optionally an input bias tensor $bias$. It then computes the transposed convolution, sometimes referred to as deconvolution, and produces a single output tensor $Y$. The hyperparameters of the op such as kernel size, stride, and padding are specified as args. At each stride, the filter is deconvolved with a subset of $X$ and the $bias$ is added. This is done throughout the input data until the output computation is complete.
0002efaf The output shapes are computed as follows. The number of channels in the output feature map is the number of kernels specified in the filter blob. The spatial height and width are computed as:
0002f071 $$H_{out} = (H_{in}-1)*strides[0] - 2*pads[0] + kernels[0]$$
0002f0b0 $$W_{out} = (W_{in}-1)*strides[1] - 2*pads[1] + kernels[1]$$
0002f0ee Note on the implementation layout: conv_transpose_op_impl.h is the templated implementation of the conv_transpose_op.h file, which is why they are separate files. Also, in the implementation this operator inherits from the *ConvTransposeUnpoolOpBase* operator.
0002f1f4 Github Links:
0002f202 - https://github.com/pytorch/pytorch/tree/main/caffe2/operators/conv_transpose_op.h
0002f256 - https://github.com/pytorch/pytorch/tree/main/caffe2/operators/conv_transpose_op.cc
0002f2ab - https://github.com/pytorch/pytorch/tree/main/caffe2/operators/conv_transpose_unpool_op_base.h
0002f30c <details>
0002f317 <summary> <b>Example</b> </summary>
0002f33c **Code**
0002f34b workspace.ResetWorkspace()
0002f367 op = core.CreateOperator(
0002f381     "ConvTranspose",
0002f396     ["X", "filter", "bias"],
0002f3b3     ["Y"],
0002f3be     kernels=[2,2],
0002f3d1     pads=[4,4,4,4],
0002f3e5     strides=[2,2]
0002f3fa // Create X: (N,C,H,W)
0002f411 data = np.random.randn(2,3,5,5).astype(np.float32)
0002f444 print("Data shape: ",data.shape)
0002f466 // Create filter: (M,C,Kh,Kw)
0002f484 filters = np.random.randn(3,1,2,2).astype(np.float32)
0002f4ba print("Filter shape: ",filters.shape)
0002f4e1 // Create b: M
0002f4f0 bias = np.array([1.]).astype(np.float32)
0002f519 print("Bias shape: ",bias.shape)
0002f53b // Put the inputs into the workspace
0002f560 workspace.FeedBlob("X", data)
0002f57e workspace.FeedBlob("filter", filters)
0002f5a4 workspace.FeedBlob("bias", bias)
0002f5c6 // Run the operator
0002f5da workspace.RunOperatorOnce(op)
0002f5f8 print("Y:\n", workspace.FetchBlob("Y"))
0002f626 **Result**
0002f637 Data shape:  (2, 3, 5, 5)
0002f651 Filter shape:  (3, 1, 2, 2)
0002f66d Bias shape:  (1,)
0002f682  [[[[0.53606427 0.5775447 ]
0002f69e    [0.40148795 1.5188271 ]]]
0002f6bd  [[[1.9903406  3.2794335 ]
0002f6d8    [0.09960175 0.31917763]]]]
0002f6fc </details>
0002f70c Given a 4-D tensor (N batches of feature maps in HWC order), this operator
0002f757 tiles N feature maps into a single big feature map. There're 4 arguments,
0002f7a1 tiled_batch_h * tiled_batch_w = N, they controls how many feature maps in height
0002f7f2 and width direction; pad_h and pad_w controls the padding between two feature
0002f840 maps.
0002f846 For example, if input is 6 feature maps whose (H, W, C) is (3, 2, 1), values for
0002f897 every feature maps are 1 to 6 respectively. (tiled_batch_h, tiled_batch_w) =
0002f8e4 (2, 3); (pad_h, pad_w) = (2, 1). The output will be:
0002f91a     11022033
0002f927     11022033
0002f934     11022033
0002f941     00000000
0002f94e     00000000
0002f95b     44055066
0002f968     44055066
0002f975     44055066
0002f987  Decompress a set of tensors that are compressed using zstd.
0002f9c4  The data can be compressed using mutils.compress_data_list(), see
0002fa07  quant_decomp_op_test.py for an example.
0002fa30  The number of outputs depended on the input.
0002fa61 Same as FC, but weight matrix is supposed to be already pretransposed.
0002faa8 FCTransposed stands for calling blass with no noTrans, noTrans
0002faed Apply the Sigmoid function element-wise to the input tensor. This is often used
0002fb3d as a non-linear activation function in a neural network. The sigmoid function is
0002fb8e defined as:
0002fb9b $$Sigmoid(x) = \frac{1}{1+\exp(-x)}$$
0002fbc2 Github Links:
0002fbd1 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/sigmoid_op.cc
0002fc21 Replace the NaN (not a number) element in the input tensor with argument `value`
0002fc74 Decode inputs using codebook. This is a general LUT operator that returns
0002fcbe tensors with values from codebook (input 0) based on given indices in
0002fd04 codes (input 1 ~ n).
0002fd1b Example:
0002fd26 Input:
0002fd2d   codebook = [1.5, 2.5, 3.5]
0002fd4a   codes_0 = [0, 1, 1, 2]
0002fd63   codes_1 = [2, 0, 0]
0002fd7b Output:
0002fd83   decoded_0 = [1.5, 2.5, 2.5, 3.5]
0002fda6   decoded_1 = [3.5, 1.5, 1.5]
0002fdc6 Produces a slice of the input Int8 tensor. Currently, only slicing in a single
0002fe15 dimension is supported.
0002fe2d Slices are passed as 2 1D vectors or as two keyword argument lists with starting
0002fe7e and end indices for each dimension of the input `data` tensor. If a negative
0002fecb value is passed for any of the start or end indices, it represents the number of
0002ff1c elements before the end of that dimension. End indices are non-inclusive unless
0002ff6c negative (end index -1 means up to and including the last element).
0002ffb2 Example:
0002ffbc   data = [
0002ffc7       [1, 2, 3, 4],
0002ffdb       [5, 6, 7, 8],
0002fff3   starts = [0, 1]
00030005   ends = [-1, 3]
00030017   result = [
00030024       [2, 3],
00030032       [6, 7],
00030046 Fill the output tensor with uniform samples between min and max (inclusive).
00030093 If the second input is given, its elements will be excluded from uniform
000300dc sampling. Using the second input will require you to provide shape via the first
0003012d input.
00030136 Merge the probabilites and bounding boxes of the raw concepts to those of
00030180 the merged concepts.
00030197 Computes the result of passing an input vector X into a fully
000301d5 connected layer with 2D weight matrix W and 1D bias vector b. That is,
0003021c the layer computes Y = X * W^T + b, where X has size (M x K),
0003025a W has size (N x K), b has size (N), and Y has size (M x N),
00030296 where M is often the batch size.
000302b9 NOTE: X does not need to explicitly be a 2D vector; rather, it will be
00030300 coerced into one. For an arbitrary n-dimensional tensor
00030338 X \in [a_0, a_1 * ... * a_{n-1}]. Only this case is supported!
00030377 Lastly, even though b is a 1D vector of size N, it is copied/resized to
000303bf be size (M x N) implicitly and added to each vector in the batch.
00030401 Each of these dimensions must be matched correctly, or else the operator
0003044a will throw errors.
0003045f The operator computes the softmax normalized values for each layer in the batch
000304af  of the given input. The input is a 2-D tensor (Tensor<float>) of size
000304f6 (batch_size x input_feature_dimensions). The output tensor has the same shape
00030544 and contains the softmax normalized values of the corresponding input.
0003058c X does not need to explicitly be a 2D vector; rather, it will be
000305cd coerced into one. For an arbitrary n-dimensional tensor
00030605 X \in [a_0, a_1, ..., a_{k-1}, a_k, ..., a_{n-1}] and k is
00030640 the axis provided, then X will be coerced into a 2-dimensional tensor with
0003068b dimensions [a_0 * ... * a_{k-1}, a_k * ... * a_{n-1}]. For the default
000306d2 case where axis=1, this means the X tensor will be coerced into a 2D tensor
0003071e of dimensions [a_0, a_1 * ... * a_{n-1}], where a_0 is often the batch size.
0003076b In this situation, we must have a_0 = N and a_1 * ... * a_{n-1} = D.
000307b0 Each of these dimensions must be matched correctly, or else the operator
000307f9 will throw errors.
0003080e Generate bounding box proposals for Faster RCNN. The proposals are generated for
0003085f a list of images based on image score 'score', bounding box regression result
000308ad 'deltas' as well as predefined bounding box shapes 'anchors'. Greedy
000308f2 non-maximum suppression is applied to generate the final bounding boxes.
0003093d Apply NMS to each class (except background) and limit the number of
00030981 returned boxes.
00030993 Transform proposal bounding boxes to target bounding box using bounding box
000309df     regression deltas.
000309f8 Reshape the input tensor similar to numpy.reshape.
00030a2c It takes a tensor as input and an optional tensor specifying the new shape.
00030a78 When the second input is absent, an extra argument `shape` must be specified.
00030ac6 It outputs the reshaped tensor as well as the original shape.
00030b05 At most one dimension of the new shape can be -1. In this case, the value is
00030b52 inferred from the size of the tensor and the remaining dimensions. A dimension
00030ba1 could also be 0, in which case the actual dimension value is going to be copied
00030bf1 from the input tensor.
00030c0a   ROI warping for Mask R-CNN, more close to RoIAlign described in the paper.
00030c59     Creates quantized tensor of type int32 with scale and zero point info.
00030ca6     Creates quantized tensor of type char(byte) with scale and zero point info.
00030cf8 ReluGradient takes both Y and dY and uses this to update dX according to the
00030d45 chain rule and derivatives of the rectified linear function.
00030d84 EluGradient takes both Y and dY and uses this to update dX according to the
00030dd0 chain rule and derivatives of the rectified linear function.
00030e0f SigmoidGradient takes both Y and dY and uses this to update dX according to the
00030e5f chain rule and derivatives of the sigmoid function.
00030e95 Given a matrix, apply L2-normalization along the specified dimension.
00030edd The operator fills the diagonal elements of the output tensor (>= 2D)
00030f23 with a constant value specified by the 'value' argument, and others 0. If
00030f6d number of dimensions of the output tensor is greater than 2, all dimensions
00030fb9 must be equal.
00030fc9 The data type is specified by the 'dtype' argument. The 'dtype' argument must
00031017 be one of the data types specified in the 'DataType' enum field in the
0003105e TensorProto message. If the 'dtype' argument is not provided, the data type of
000310ad 'value' is used.
000310bf The output tensor shape is specified by the 'shape' argument. If the number of
0003110e input is 1, the shape will be identical to that of the input at run time with
0003115c optional additional dimensions appended at the end as specified by 'extra_shape'
000311ad argument. In that case the 'shape' argument should not be set.
000311ed If input_as_shape is set to true, then the input should be a 1D tensor
00031234 containing the desired output shape (the dimensions specified in extra_shape
00031281 will also be appended)
00031299 NOTE: Currently, it supports data type of float, int32, int64, and bool.
000312e4 Concat a (N, 4) bbox to (N, 5), with first column representing index of batch.
00031333 When batch_splits is not provided, use 0 for the index of batch.
00031376     Associates previous and next bounding boxes and propagates ID for
000313bc     frame-to-frame tracking.
000313db Relu takes one input data (Tensor<T>) and produces one output data
0003141e (Tensor<T>) where the rectified linear function, y = max(0, x), is applied to
0003146c the tensor elementwise.
00031486 LeakyRelu takes input data (Tensor<T>) and an argument alpha, and produces one
000314d5 output data (Tensor<T>) where the function `f(x) = alpha * x for x < 0`,
0003151e `f(x) = x for x >= 0`, is applied to the data tensor elementwise.
00031562 Scale takes one input data (Tensor) and produces one output data
000315a3 (Tensor) whose value is the input data tensor scaled element-wise.
000315e8 Calculates the softsign gradient (sgn(x)/(1+|x|)^2) of the given input tensor
00031636 element-wise.
00031646 Split the elements and return the indices based on the given threshold.
00031690 Converts each input element into either high_ or low_value
000316cb based on the given threshold.
000316eb Region of Interest (RoI) align operation as used in Mask R-CNN.
0003172d The operator switches the order of data in a tensor from NHWC- sample index N,
0003177c height H, width H and channels C, to the NCHW order (this is for 2D images).
000317c9 In general, this operator switches the order of data in a tensor from N H_1 ...
00031819 H_k C to N C H_1 ... H_k for k-dimensional features, and currently supports
00031865 k=1, 2, and 3.
00031876 The operator switches the order of data in a tensor from NCHW- sample index N,
000318c5 channels C, height H and width W, to the NHWC order (this is for 2D images).
00031912 In general, this operator switches the order of data in a tensor from N C H_1
00031960 ... H_k to N H_1 ... H_k C for k-dimensional features, and currently supports
000319ae k=1, 2, and 3.
000319bf     Performs element-wise binary Add (with no broadcast support). "
00031a03     "Output will go through rectified linear "
00031a32     "function, where y = max(0, x).
00031a58     Performs element-wise binary Add (with no broadcast support).
00031a9c Transpose the input tensor by permuting the axes of the input according
00031ae4 to the `axes` argument. Similar to numpy's
00031b0f [transpose](https://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html)
00031b66 function.
00031b71 For example, when axes=(1, 0, 2), given an input tensor of shape
00031bb2 (1, 2, 3), the output shape will be (2, 1, 3).
00031be3 Flattens the input tensor into a 2D matrix. If input tensor has shape
00031c29 (d_0, d_1, ... d_n) then the output will have shape
00031c5d (d_0 X d_1 ... d_(axis-1), d_axis X d_(axis+1) ... X dn)
00031c98 Resizes the spatial dimensions of the input using nearest neighbor
00031cdb interpolation. The `width_scale` and `height_scale` arguments
00031d19 control the size of the output, which is given by:
00031d4c output_width = floor(input_width * width_scale)
00031d7c output_height = floor(output_height * height_scale)
00031db1 Error from operator: 
00031dc9 Applies spatial batch normalization to the input tensor as described in the original paper, [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167). Be aware, this operator has two different output sets, depending on the value of *is_test*. According to the paper, the primary operation of spatial batch normalization is:
00031f55 $$Y = \frac{X - \mu_x}{\sqrt{\sigma^2_{x} + \epsilon}}*\gamma + b$$
00031f9a In the equation, $\mu_x$ is the *mean*, $X$ is the input data, $\sigma^2_{x}$ is the *var*, $\epsilon$ is *epsilon*, $\gamma$ is the *scale*, $b$ is the *bias*, and $Y$ is the output data. The *momentum* arg also affects this calculation in the computation of the running mean and variance. The influence of *momentum* is as follows:
000320e9 $$running\_mean = running\_mean * momentum + mean * (1 - momentum)$$
0003212f $$running\_var = running\_var * momentum + var * (1 - momentum)$$
00032172 Output when is_test = 0 (train mode): *Y, mean, var, saved_mean, saved_var*
000321bf Output when is_test = 1 (test mode): *Y*
000321e9 Github Links:
000321f7 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/spatial_batch_norm_op.cc
00032250 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/spatial_batch_norm_op.h
000322ac `Dropout` takes one input data tensor (`X`) and produces two tensor outputs, `Y` and
00032301 `mask`. If the `is_test` argument is zero (default=0), the output `Y` will be the input
00032359 with random elements zeroed. The probability that a given element is zeroed is
000323a8 determined by the `ratio` argument.
000323cd If the `is_test` argument is set to non-zero, the output `Y` is exactly the same as the
00032425 input `X`. Note that outputs are scaled by a factor of $\frac{1}{1-ratio}$ during
00032477 training, so that during test time, we can simply compute an identity function. This
000324cc scaling is important because we want the output at test time to equal the expected value
00032525 at training time. Dropout has been proven to be an effective regularization technique to
0003257e prevent overfitting during training.
000325a5 Github Links:
000325b4 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/dropout_op.h
00032601 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/dropout_op.cc
00032651 <details>
0003265c <summary> <b>Example</b> </summary>
00032681 **Code**
0003268f workspace.ResetWorkspace()
000326ab op = core.CreateOperator(
000326c5     "Dropout",
000326d4     ["X"],
000326df     ["Y"] + ["mask"],
000326f5     ratio=0.5,
00032704     is_test=0
00032715 workspace.FeedBlob("X", np.random.randint(10, size=(5, 5)).astype(np.float32))
00032764 print("X:", workspace.FetchBlob("X"))
0003278a workspace.RunOperatorOnce(op)
000327a8 print("Y:", workspace.FetchBlob("Y"))
000327ce print("mask:", workspace.FetchBlob("mask"))
000327ff **Result**
0003280f X: [[5. 4. 3. 6. 9.]
00032824  [2. 1. 8. 0. 9.]
00032836  [7. 3. 0. 6. 3.]
00032848  [1. 8. 2. 6. 4.]
0003285a  [6. 2. 6. 4. 0.]]
0003286d Y: [[ 0.  0.  0. 12. 18.]
00032887  [ 0.  0. 16.  0.  0.]
0003289e  [ 0.  0.  0. 12.  6.]
000328b5  [ 0.  0.  4.  0.  0.]
000328cc  [12.  0.  0.  0.  0.]]
000328e4 mask: [[False False False  True  True]
0003290b  [False False  True  True False]
0003292c  [False False  True  True  True]
0003294d  [False False  True False False]
0003296e  [ True False False False False]]
00032995 </details>
000329a3 This operator fills the elements of the output tensor with a constant value
000329ef specified by the `value` argument.
00032a13 - The data type is specified by the `dtype` argument
00032a49 - Currently, the data types supported are *float*, *int32*, *int64*, and *bool*
00032a9a - If the `dtype` argument is not provided, the data type of `value` is used
00032ae7 - The output tensor shape is either specified by the `shape` argument or will
00032b35 match the shape of the input tensor if one is provided (if an input tensor is
00032b83 provided, a shape argument should not be set)
00032bb2 - Optional additional dimensions can be appended at the end as specified by
00032bfe `extra_shape` argument
00032c16 - If `input_as_shape` is set to True, the input should be a 1D tensor
00032c5c containing the desired output shape (the dimensions specified in `extra_shape`
00032cab will also be appended)
00032cc3 - If a second input V is passed, fill the output with the first element of V
00032d11 When specifying `dtype` argument, use the integer keys from the *DataType* enum
00032d61 in TensorProto:
00032d76 message TensorProto {
00032d8c   ...
00032d92   enum DataType {
00032da4     UNDEFINED = 0;
00032db7     FLOAT = 1;  // float
00032dd0     INT32 = 2;  // int
00032de7     BYTE = 3;  // BYTE, when deserialized, is going to be restored as uint8.
00032e34     STRING = 4;  // string
00032e4f     BOOL = 5;  // bool
00032e66     UINT8 = 6;  // uint8_t
00032e81     INT8 = 7;  // int8_t
00032e9a     UINT16 = 8;  // uint16_t
00032eb7     INT16 = 9;  // int16_t
00032ed2     INT64 = 10;  // int64_t
00032eee     FLOAT16 = 12;  // at::Half
00032f0d     DOUBLE = 13;  // double
00032f32 Github Links:
00032f41 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/filler_op.cc
00032f8f <details>
00032f9a <summary> <b>Example</b> </summary>
00032fbf **Code**
00032fcd workspace.ResetWorkspace()
00032fe9 op = core.CreateOperator(
00033003     "ConstantFill",
00033017     [],
0003301f     ["Y"],
0003302a     shape=(1,5,5)
0003303f workspace.RunOperatorOnce(op)
0003305d print("Y:", workspace.FetchBlob("Y"))
00033088 **Result**
00033098 Y: [[[0. 0. 0. 0. 0.]
000330ae   [0. 0. 0. 0. 0.]
000330c1   [0. 0. 0. 0. 0.]
000330d4   [0. 0. 0. 0. 0.]
000330e7   [0. 0. 0. 0. 0.]]]
00033100 </details>
0003310c <details>
00033116 <summary> <b>Example 2</b> </summary>
0003313d **Code**
0003314b workspace.ResetWorkspace()
00033167 op = core.CreateOperator(
00033181     "ConstantFill",
00033195     ["X"],
000331a0     ["Y"],
000331ab     value=4.0,
000331ba     dtype=1,
000331c7     extra_shape=(1,2)
000331e0 workspace.FeedBlob("X", (np.random.randint(100, size=(3,3))).astype(np.float32))
00033231 print("X:", workspace.FetchBlob("X"))
00033257 workspace.RunOperatorOnce(op)
00033275 print("Y:", workspace.FetchBlob("Y"))
000332a0 **Result**
000332b0 X: [[86. 30. 84.]
000332c2  [34. 51.  9.]
000332d1  [29. 86. 59.]]
000332e1 Y: [[[[4. 4.]]
000332f1   [[4. 4.]]
000332fe   [[4. 4.]]]
0003330d  [[[4. 4.]]
0003331a   [[4. 4.]]
00033327   [[4. 4.]]]
00033336  [[[4. 4.]]
00033343   [[4. 4.]]
00033350   [[4. 4.]]]]
00033363 </details>
00033371 Flattens the input tensor into a 2D matrix. If input tensor has shape
000333b7 $(d_0, d_1, ..., d_n)$ then the output will have shape
000333ee $\bigl((d_0 * d_1 * ... * d_{(axis-1)}), (d_{axis} * d_{(axis+1)} * ... * d_n)\bigr)$.
00033446 Github Links:
00033455 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/flatten_op.cc
000334a4 <details>
000334af <summary> <b>Example</b> </summary>
000334d4 **Code**
000334e2 workspace.ResetWorkspace()
000334fe op = core.CreateOperator(
00033518     "Flatten",
00033527     ["X"],
00033532     ["Y"],
0003353d     axis=1
0003354b workspace.FeedBlob("X", np.random.rand(1,3,2,2))
0003357c print("X:", workspace.FetchBlob("X"))
000335a2 workspace.RunOperatorOnce(op)
000335c0 print("Y:", workspace.FetchBlob("Y"))
000335eb **Result**
000335fb X: [[[[0.53432311 0.23734561]
00033619    [0.56481598 0.52152617]]
00033636   [[0.33662627 0.32472711]
00033651    [0.17939016 0.97175851]]
0003366e   [[0.87226421 0.49045439]
00033689    [0.92470531 0.30935077]]]]
000336a7 Y: [[0.53432311 0.23734561 0.56481598 0.52152617 0.33662627 0.32472711
000336ee   0.17939016 0.97175851 0.87226421 0.49045439 0.92470531 0.30935077]]
00033739 </details>
00033747 Matrix multiplication $Y = A * B$, where `A` has size (M x K), `B` has size
00033793 (K x N), and `Y` will have a size (M x N). To transpose `A` or `B` before
000337dd multiplication, pass 1 to the `trans_a` and/or `trans_b` arguments, which
00033827 separate the first and second dimensions of the respective matrices using
00033871 `axis_a` and `axis_b`.
00033889 Github Links:
00033898 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/matmul_op.cc
000338e6 <details>
000338f1 <summary> <b>Example</b> </summary>
00033916 **Code**
00033924 workspace.ResetWorkspace()
00033940 op = core.CreateOperator(
0003395a     "MatMul",
00033968     ["A", "B"],
00033978     ["Y"],
00033986 workspace.FeedBlob("A", np.random.randint(10, size=(3,3)).astype(np.float32))
000339d4 workspace.FeedBlob("B", np.random.randint(10, size=(3,3)).astype(np.float32))
00033a22 print("A:", workspace.FetchBlob("A"))
00033a48 print("B:", workspace.FetchBlob("B"))
00033a6e workspace.RunOperatorOnce(op)
00033a8c print("Y:", workspace.FetchBlob("Y"))
00033ab7 **Result**
00033ac7 A: [[1. 8. 3.]
00033ad6  [6. 4. 4.]
00033ae2  [5. 4. 7.]]
00033aef B: [[4. 0. 3.]
00033afe  [3. 1. 1.]
00033b0a  [8. 5. 8.]]
00033b17 Y: [[52. 23. 35.]
00033b29  [68. 24. 54.]
00033b38  [88. 39. 75.]]
00033b4d </details>
00033b5b This operator limits the given input within an interval. The interval is
00033ba4 specified by the `min` and `max` arguments. They default to
00033be0 *numeric_limits::lowest()* and *numeric_limits::max()* respectively. The
00033c29 clipping operation can be done in an in-place fashion by using the same output
00033c78 blob as the input blob.
00033c91 Github Links:
00033ca0 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/clip_op.cc
00033cec <details>
00033cf7 <summary> <b>Example</b> </summary>
00033d1c **Code**
00033d2a workspace.ResetWorkspace()
00033d46 op = core.CreateOperator(
00033d60     "Clip",
00033d6c     ["X"],
00033d77     ["Y"],
00033d82     min=20.0,
00033d90     max=60.0
00033da1 workspace.FeedBlob("X", (np.random.randint(100, size=(5,5))).astype(np.float32))
00033df2 print("X:", workspace.FetchBlob("X"))
00033e18 workspace.RunOperatorOnce(op)
00033e36 print("Y:", workspace.FetchBlob("Y"))
00033e62 **Result**
00033e72 X: [[45. 16. 59. 99. 48.]
00033e8c  [12. 44. 46. 82. 28.]
00033ea3  [ 1. 91. 18.  9. 71.]
00033eba  [24. 37. 61. 12. 81.]
00033ed1  [36. 38. 30. 84. 40.]]
00033ee9 Y: [[45. 20. 59. 60. 48.]
00033f03  [20. 44. 46. 60. 28.]
00033f1a  [20. 60. 20. 20. 60.]
00033f31  [24. 37. 60. 20. 60.]
00033f48  [36. 38. 30. 60. 40.]]
00033f65 </details>
00033f73 Reshape the input tensor similar to numpy's
00033f9f [reshape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html).
00033ff4 Takes a tensor as input and an optional tensor specifying the new shape. When
00034042 the second input is absent, an extra argument shape must be specified. Outputs
00034091 the reshaped tensor as well as the original shape.
000340c5 At most one dimension of the new shape can be -1. In this case, the value is
00034112 inferred from the size of the tensor and the remaining dimensions. A dimension
00034161 could also be 0, in which case the actual dimension value is going to be copied
000341b1 from the input tensor.
000341c9 For empty tensor, we will set the -1 dimension to be 0 (if one dimension is -1).
0003421a When the tensor is empty, dimension of 0 will remain to be 0.
00034258 E.g: data=np.empty(shape=[4, 0]), shape=[0, -1], the output tensor will be
000342a3 np.emtpy(shape=[0, 0])
000342bb Github Links:
000342ca - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/reshape_op.cc
00034319 <details>
00034324 <summary> <b>Example</b> </summary>
00034349 **Code**
00034357 workspace.ResetWorkspace()
00034373 op = core.CreateOperator(
0003438d     "Reshape",
0003439c     ["data"],
000343aa     ["reshaped", "old_shape"],
000343c9     shape=(3,2)
000343dc workspace.FeedBlob("data", (np.random.randint(100, size=(6))))
0003441b print("data:", workspace.FetchBlob("data"))
00034447 workspace.RunOperatorOnce(op)
00034465 print("reshaped:", workspace.FetchBlob("reshaped"))
00034499 print("old_shape:", workspace.FetchBlob("old_shape"))
000344d4 **Result**
000344e4 data: [86 60 85 96  7 37]
000344fe reshaped: [[86 60]
00034511           [85 96]
00034523           [ 7 37]]
00034536 old_shape: [6]
0003454a </details>
00034558 Transpose the input tensor by permuting the axes of the input according
000345a0 to the `axes` argument. Similar to numpy's
000345cb [transpose](https://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html)
00034622 function.
0003462d For example, when axes=(1, 0, 2), given an input tensor of shape
0003466e (1, 2, 3), the output shape will be (2, 1, 3).
0003469e Github Links:
000346ad - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/transpose_op.cc
000346fe <details>
00034709 <summary> <b>Example</b> </summary>
0003472e **Code**
0003473c workspace.ResetWorkspace()
00034758 op = core.CreateOperator(
00034772     "Transpose",
00034783     ["X"],
0003478e     ["Y"],
00034799     axes=(0,3,1,2)
000347af x = np.random.rand(1,32,32,3)
000347cd workspace.FeedBlob("X", x)
000347e8 print("X.shape (NHWC order):", workspace.FetchBlob("X").shape)
00034827 workspace.RunOperatorOnce(op)
00034845 print("Y.shape (NCHW order):", workspace.FetchBlob("Y").shape)
00034889 **Result**
00034899 X.shape (NHWC order): (1, 32, 32, 3)
000348be Y.shape (NCHW order): (1, 3, 32, 32)
000348e8 </details>
000348f6 The *IsEmpty* op accepts a single input $tensor$, and produces a single boolean output $is\_empty$. The output is *True* if and only if $tensor$ has size == 0.
00034997 Github Links:
000349a6 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/utility_ops.cc
000349f5 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/utility_ops.h
00034a45 <details>
00034a50 <summary> <b>Example</b> </summary>
00034a75 **Code**
00034a84 workspace.ResetWorkspace()
00034aa0 op = core.CreateOperator(
00034aba     "IsEmpty",
00034ac9     ["tensor"],
00034ad9     ["is_empty"],
00034aee // Use a not-empty tensor
00034b08 workspace.FeedBlob("tensor", np.random.randn(2, 2).astype(np.float32))
00034b4f print("tensor:\n", workspace.FetchBlob("tensor"))
00034b82 workspace.RunOperatorOnce(op)
00034ba0 print("is_empty: ", workspace.FetchBlob("is_empty"),"\n")
00034bdb // Use an empty tensor
00034bf2 workspace.FeedBlob("tensor", np.empty(0))
00034c1c print("tensor:\n", workspace.FetchBlob("tensor"))
00034c4f workspace.RunOperatorOnce(op)
00034c6d print("is_empty: ", workspace.FetchBlob("is_empty"))
00034ca8 **Result**
00034cb9 tensor:
00034cc1  [[ 0.26018378  0.6778789 ]
00034cdd  [-1.3097627  -0.40083608]]
00034cf9 is_empty:  False
00034d0b tensor:
00034d17 is_empty:  True
00034d2d </details>
00034d3b The *InstanceNorm* op applies Instance Normalization over a 4D input as described in [Instance Normalization: The Missing Ingredient for Fast Stylization](https://arxiv.org/abs/1607.08022).
00034dfa $$output = \frac{input-\mu_{input}}{\sqrt{\sigma_{input}^2} + \epsilon}*scale + bias$$
00034e52 Notice, two of the outputs are optional so there are three output cases for this op. Case 1: output; Case 2: output, saved_mean; Case 3: output, saved_mean, saved_inv_stdev.
00034f01 Github Links:
00034f10 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/instance_norm_op.h
00034f63 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/instance_norm_op.cc
00034fb9 <details>
00034fc4 <summary> <b>Example</b> </summary>
00034fe9 **Code**
00034ff8 workspace.ResetWorkspace()
00035014 op = core.CreateOperator(
0003502e     "InstanceNorm",
00035042     ["input", "scale", "bias"],
00035062     ["output"],
00035072     epsilon=1e-5,
00035087 workspace.FeedBlob("input", np.random.randn(2, 1, 3, 3).astype(np.float32))
000350d3 print("input:\n", workspace.FetchBlob("input"), "\n")
0003510a workspace.FeedBlob("scale", np.array([1.5]).astype(np.float32))
0003514a print("scale: ", workspace.FetchBlob("scale"))
0003517a workspace.FeedBlob("bias", np.array([1.]).astype(np.float32))
000351b8 print("bias: ", workspace.FetchBlob("bias"))
000351e6 workspace.RunOperatorOnce(op)
00035204 print("output:\n", workspace.FetchBlob("output"))
0003523c **Result**
0003524d input:
00035254  [[[[ 0.97856593 -1.1832817  -0.2540021 ]
0003527e    [-1.3315694  -0.7485018   0.3787225 ]
000352a7    [-0.6826597  -1.4637762   0.57116514]]]
000352d4  [[[-0.44948956  0.85544354 -0.9315333 ]
000352fd    [-0.37202677 -0.22266895 -0.27194235]
00035326    [ 0.4948163  -0.7296504   1.3393803 ]]]]
00035353 scale:  [1.5]
00035361 bias:  [1.]
0003536d output:
00035375  [[[[ 3.5017493  -0.3791256   1.2890853 ]
0003539f    [-0.6453266   0.40137637  2.4249308 ]
000353c8    [ 0.5195738  -0.8826599   2.7703972 ]]]
000353f5  [[[ 0.12639964  2.856744   -0.8821926 ]
0003541e    [ 0.28847694  0.60098207  0.49788612]
00035447    [ 2.1021945  -0.45978796  3.869297  ]]]]
00035479 </details>
00035488 The *Gather* op accepts a *DATA* tensor of rank $r >= 1$ and *INDICES* tensor of rank $q$ as inputs. It then gathers entries of the outer-most dimension of *DATA*, indexed by *INDICES*, and concatenate them in an output tensor of rank $q + (r - 1)$.
00035583 Github Links:
00035592 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/gather_op.cc
000355df - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/gather_op.h
0003562d <details>
00035638 <summary> <b>Example</b> </summary>
0003565d **Code**
0003566c workspace.ResetWorkspace()
00035688 op = core.CreateOperator(
000356a2     "Gather",
000356b0     ["DATA", "INDICES"],
000356c9     ["OUTPUT"]
000356da data = np.array([[1., 1.2],[2.3, 3.4],[4.5, 5.7]])
0003570d print("DATA:\n",data)
00035724 inds = np.array([[0, 1],[1, 2]])
00035745 print("INDICES:\n",inds)
0003575f // Feed X into workspace
00035778 workspace.FeedBlob("DATA", data.astype(np.float32))
000357ac workspace.FeedBlob("INDICES", inds.astype(np.int32))
000357e2 workspace.RunOperatorOnce(op)
00035800 print("OUTPUT:\n", workspace.FetchBlob("OUTPUT"))
00035838 **Result**
00035849 DATA:
0003584f  [[1.  1.2]
0003585b  [2.3 3.4]
00035866  [4.5 5.7]]
00035872 INDICES:
0003587b  [[0 1]
00035883  [1 2]]
0003588b OUTPUT:
00035893  [[[1.  1.2]
000358a0   [2.3 3.4]]
000358ae  [[2.3 3.4]
000358ba   [4.5 5.7]]]
000358ce </details>
000358dc Calculates the natural log of the given input tensor ($ln(x)$), element-wise. This
0003592f operation can be done in an in-place fashion too, by providing the same input
0003597d and output blobs.
00035990 Github Link:
0003599d - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/log_op.cc
000359e8 <details>
000359f3 <summary> <b>Example</b> </summary>
00035a18 **Code**
00035a27 workspace.ResetWorkspace()
00035a43 op = core.CreateOperator(
00035a5d     "Log",
00035a68     ["X"],
00035a73     ["X"],
00035a81 workspace.FeedBlob("X", (np.random.rand(3,3)).astype(np.float32))
00035ac3 print("X before running op:", workspace.FetchBlob("X"))
00035afb workspace.RunOperatorOnce(op)
00035b19 print("X after running op:", workspace.FetchBlob("X"))
00035b56 **Result**
00035b67 X before running op:
00035b7c [[0.07341351 0.15404125 0.386613  ]
00035ba0  [0.34090295 0.99727786 0.24141751]
00035bc4  [0.32016268 0.8724168  0.93515724]]
00035be9 X after running op:
00035bfd [[-2.6116474  -1.8705349  -0.9503311 ]
00035c24  [-1.0761575  -0.00272586 -1.4212275 ]
00035c4b  [-1.138926   -0.13648799 -0.06704059]]
00035c79 </details>
00035c87 Fill the output tensor with float samples from uniform distribution [`min`, `max`].
00035cdc - The range can be defined either by arguments or input blobs. `min` and `max` are inclusive.
00035d3a     - If the range is given by input blobs, you also need to give the shape as input.
00035d90     - When the range is given as arguments, this operator enforces min <= max. When the range is given as inputs, the constraint is not enforced.
00035e22     - When the range is given as inputs and max < min, the first dimension of the output is set to 0. This behavior is allowed so that dynamically sampling indices into a dynamically sized tensor is possible.
00035ef3 - The shape of the output can be given as argument or input.
00035f31 Github Links:
00035f3f - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/filler_op.h
00035f8b - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/filler_op.cc
00035fd9 <details>
00035fe4 <summary> <b>Example</b> </summary>
00036009 **Code**
00036018 workspace.ResetWorkspace()
00036034 op_1 = core.CreateOperator(
00036050     "UniformFill",
00036063     [],
0003606b     ["output"],
0003607b     min=5.5,
00036088     max=10.5,
00036096     shape=(3,3)
000360a9 op_2 = core.CreateOperator(
000360c5     "UniformFill",
000360d8     ["shape", "min", "max"],
000360f5     ["output"],
00036105     input_as_shape=1
0003611d // Test arg-based op
00036132 workspace.RunOperatorOnce(op_1)
00036152 print("output (op_1):\n", workspace.FetchBlob("output"))
0003618c // Test input-based op
000361a3 workspace.ResetWorkspace()
000361be workspace.FeedBlob("shape", np.array([5,5]))
000361eb workspace.FeedBlob("min", np.array(13.8, dtype=np.float32))
00036227 workspace.FeedBlob("max", np.array(19.3, dtype=np.float32))
00036263 workspace.RunOperatorOnce(op_2)
00036283 print("output (op_2):\n", workspace.FetchBlob("output"))
000362c2 **Result**
000362d3 output (op_1):
000362e2  [[8.894862  8.225005  6.7890406]
00036304  [9.588293  7.1072135 7.7234955]
00036325  [8.210596  6.0202913 9.665462 ]]
00036347 output (op_2):
00036356  [[18.965155 15.603871 15.038921 17.14872  18.134571]
0003638c  [18.84237  17.845276 19.214737 16.970337 15.494069]
000363c1  [18.754795 16.724329 15.311974 16.962536 18.60965 ]
000363f6  [15.186268 15.264773 18.73341  19.077969 14.237255]
0003642b  [15.917589 15.844325 16.248466 17.006554 17.502048]]
00036467 </details>
00036475 Produces a slice of the input tensor.
0003649c - Currently, only slicing in a single dimension is supported.
000364db - Start and end indices are either passed as two 1D input tensors or using the `starts` and `ends` arguments.
0003654a - If a negative value is passed for any of the start or end indices, it represents |value| - 1 elements before the end of that dimension. End indices are non-inclusive unless negative (end index -1 means up to and including the last element).
0003663e Github Links:
0003664c - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/slice_op.cc
00036699 <details>
000366a4 <summary> <b>Example</b> </summary>
000366c9 **Code**
000366d8 workspace.ResetWorkspace()
000366f4 op = core.CreateOperator(
0003670e     "Slice",
0003671b     ["X"],
00036726     ["Y"],
00036731     starts=(0,1),
00036743     ends=(-1,3)
00036756 workspace.FeedBlob("X", np.array([[1,2,3,4],[5,6,7,8]]))
0003678f print("X:", workspace.FetchBlob("X"))
000367b5 workspace.RunOperatorOnce(op)
000367d3 print("Y:", workspace.FetchBlob("Y"))
000367ff **Result**
00036813 [[1 2 3 4]
0003681e  [5 6 7 8]]
0003682d [[2 3]
00036834  [6 7]]
00036842 </details>
00036850 Element-wise max of an arbitrary number of input tensors. This operation can be
000368a0 performed in-place, by using the first input blob as the output blob. All inputs
000368f1 must have the same shape and data type, and the output will have the same shape
00036941 as the inputs.
00036951 Github Link:
0003695e - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/minmax_ops.cc
000369ad <details>
000369b8 <summary> <b>Example</b> </summary>
000369dd **Code**
000369ec workspace.ResetWorkspace()
00036a08 op = core.CreateOperator(
00036a22     "Max",
00036a2d     ["X", "Y", "Z"],
00036a42     ["X"],
00036a50 workspace.FeedBlob("X", (np.random.rand(3,3)).astype(np.float32))
00036a92 workspace.FeedBlob("Y", (np.random.rand(3,3)).astype(np.float32))
00036ad4 workspace.FeedBlob("Z", (np.random.rand(3,3)).astype(np.float32))
00036b16 print("X:", workspace.FetchBlob("X"))
00036b3c print("Y:", workspace.FetchBlob("Y"))
00036b62 print("Z:", workspace.FetchBlob("Z"))
00036b88 workspace.RunOperatorOnce(op)
00036ba6 print("Max:", workspace.FetchBlob("X"))
00036bd4 **Result**
00036be8 [[0.4496477  0.07061381 0.7139333 ]
00036c0c  [0.83203    0.05970785 0.72786295]
00036c30  [0.75988126 0.04601283 0.32820013]]
00036c58 [[0.05683139 0.16872478 0.671098  ]
00036c7c  [0.70739156 0.09878621 0.03416285]
00036ca0  [0.34087983 0.94986707 0.67263436]]
00036cc8 [[0.48051122 0.07141234 0.85264146]
00036cec  [0.77086854 0.22082241 0.13154659]
00036d10  [0.42401117 0.995431   0.4263775 ]]
00036d35 Max:
00036d3a [[0.48051122 0.16872478 0.85264146]
00036d5e  [0.83203    0.22082241 0.72786295]
00036d82  [0.75988126 0.995431   0.67263436]]
00036dad </details>
00036dbb The FC operator computes an output $(Y)$ as a linear combination of the input data blob $(X)$ with a weight blob $(W)$ and bias blob $(b)$. More formally,
00036e57 $$Y = XW^T+b$$
00036e67 Here, $X$ is a matrix of shape $(M,K)$, $W$ is a matrix of shape $(N,K)$, $b$ is a vector of length $N$, and $Y$ is a matrix of shape $(M,N)$. $N$ can be thought of as the number of nodes in the layer, $M$ is the batch size, and $K$ is the number of features in an input observation.
00036f84 *NOTE: $X$ does not need to explicitly be a 2-dimensional matrix, however, if it is not it will be coerced into one. For an arbitrary $n$-dimensional tensor $X$, e.g. $[a_0, a_1, \ldots ,a_{k-1}, a_k, \ldots , a_{n-1}]$, where $a_i$ in $N$, and $k$ is the $axis$ arg provided, then $X$ will be coerced into a 2-dimensional tensor with dimensions $[a_0 * \ldots * a_{k-1}, a_k * \ldots * a_{n-1}]$. For the default case where axis=1, this means the $X$ tensor will be coerced into a 2D tensor of dimensions $[a_0, a_1 * \ldots * a_{n-1}]$, where $a_0$ is often the batch size. In this situation, we must have $a_0 = M$ and $a_1 * \ldots * a_{n-1} = K$. Lastly, even though $b$ is a vector of length $N$, it is copied and resized to shape $(M x N)$ implicitly, then added to each vector in the batch.*
000372a5 Github Links:
000372b3 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/fully_connected_op.h
00037308 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/fully_connected_op.cc
0003735f <details>
0003736a <summary> <b>Example</b> </summary>
0003738f **Code**
0003739e // In this example, our batch size is 1 (M=1), the input observation will have
000373ed //   6 features (K=6), and the layer will have one hidden node (N=1). The
00037437 //   expected output is Y=7.
00037454 workspace.ResetWorkspace()
00037470 op = core.CreateOperator(
0003748a     "FC",
00037494     ["X", "W", "b"],
000374a9     ["Y"]
000374b6 // Create X: MxK
000374c7 data = np.array([1,2,3,4,5,6]).astype(np.float32)
000374f9 data = data[np.newaxis,:]
00037514 // Create W: NxK
00037525 weights = np.array(np.array([1,1/2.,1/3.,1/4.,1/5.,1/6.])).astype(np.float32)
00037573 weights = weights[np.newaxis,:]
00037594 // Create b: N
000375a3 bias = np.array([1.]).astype(np.float32)
000375cd // Put the inputs into the workspace
000375f2 workspace.FeedBlob("X", data)
00037610 workspace.FeedBlob("W", weights)
00037631 workspace.FeedBlob("b", bias)
00037650 // Run the operator
00037664 workspace.RunOperatorOnce(op)
00037682 print("Y:\n", workspace.FetchBlob("Y"))
000376b0 **Result**
000376c4  [[7.]]
000376d2 </details>
000376e0 Element-wise sum of each of the input tensors. The first input tensor can be used
00037732 in-place as the output tensor, in which case the sum will be done in place and
00037781 results will be accumulated the first input tensor. All inputs and outputs must
000377d1 have the same shape and data type.
000377f5 Github Links:
00037804 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/elementwise_sum_op.cc
0003785c <details>
00037867 <summary> <b>Example</b> </summary>
0003788c **Code**
0003789b workspace.ResetWorkspace()
000378b7 op = core.CreateOperator(
000378d1     "Sum",
000378dc     ["A",  "B"],
000378ed     ["C"],
000378fb workspace.FeedBlob("A", np.array([[1,2],[3,4]]).astype(np.float32))
0003793f workspace.FeedBlob("B", np.array([[5,6],[7,8]]).astype(np.float32))
00037983 print("A:", workspace.FetchBlob("A"))
000379a9 print("B:", workspace.FetchBlob("B"))
000379cf workspace.RunOperatorOnce(op)
000379ed print("C:", workspace.FetchBlob("A"))
00037a19 **Result**
00037a2a A: [[1. 2.]
00037a36  [3. 4.]]
00037a40 B: [[5. 6.]
00037a4c  [7. 8.]]
00037a56 C: [[1. 2.]
00037a62  [3. 4.]]
00037a72 </details>
00037a7e <details>
00037a89 <summary> <b>Example 2</b> </summary>
00037ab0 **Code**
00037abf workspace.ResetWorkspace()
00037adb op = core.CreateOperator(
00037af5     "Sum",
00037b00     ["A",  "B"],
00037b11     ["A"],  // inplace
00037b2b workspace.FeedBlob("A", np.array([[1,2,5],[8,3,4]]).astype(np.float32))
00037b73 workspace.FeedBlob("B", np.array([[9,5,6],[6,7,8]]).astype(np.float32))
00037bbb print("A:", workspace.FetchBlob("A"))
00037be1 print("B:", workspace.FetchBlob("B"))
00037c07 workspace.RunOperatorOnce(op)
00037c25 print("A after Sum:", workspace.FetchBlob("A"))
00037c5b **Result**
00037c6c A: [[1. 2. 5.]
00037c7b  [8. 3. 4.]]
00037c88 B: [[9. 5. 6.]
00037c97  [6. 7. 8.]]
00037ca4 A after Sum: [[10.  7. 11.]
00037cc0  [14. 10. 12.]]
00037cd6 </details>
00037ce4 Calculates the hyperbolic tangent of the given input tensor element-wise. This
00037d33 operation can be done in an in-place fashion too, by providing the same input
00037d81 and output blobs.
00037d94 Github Links:
00037da3 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/tanh_op.cc
00037df0 <details>
00037dfb <summary> <b>Example</b> </summary>
00037e20 **Code**
00037e2f workspace.ResetWorkspace()
00037e4b op = core.CreateOperator(
00037e65     "Tanh",
00037e71     ["X"],
00037e7c     ["X"],
00037e8a workspace.FeedBlob("X", np.random.randn(3, 3).astype(np.float32))
00037ecc print("X:\n", workspace.FetchBlob("X"), "\n")
00037efb workspace.RunOperatorOnce(op)
00037f19 print("X:\n", workspace.FetchBlob("X"))
00037f47 **Result**
00037f5b  [[ 2.032603   -2.3556721  -0.14955314]
00037f83  [ 0.39309832 -1.1020128  -0.92951244]
00037faa  [-0.62815386  0.21342885  1.4002231 ]]
00037fd6  [[ 0.9662601  -0.982175   -0.14844811]
00037ffe  [ 0.3740282  -0.8012209  -0.73036647]
00038025  [-0.55677974  0.21024609  0.8853999 ]]
00038053 </details>
00038061 This op fills an output tensor with samples drawn from a normal distribution specified by the mean and standard deviation arguments. The output tensor shape is specified by the *shape* argument. However, if *input_as_shape* is set to *true*, then the *input* should be a 1D tensor containing the desired output shape (the dimensions specified in *extra_shape* will also be appended). In this case, the *shape* argument should **not** be set.
0003821c *Note: cannot set the shape argument and pass in an input at the same time.*
0003826a Github Links:
00038278 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/filler_op.h
000382c4 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/filler_op.cc
00038312 <details>
0003831d <summary> <b>Example</b> </summary>
00038342 **Code**
00038351 workspace.ResetWorkspace()
0003836d op = core.CreateOperator(
00038387     "GaussianFill",
0003839b     [],
000383a3     ["out"],
000383b0     shape=[3,3],
000383c1     mean=2.0,
000383cf     std=1.1
000383de workspace.RunOperatorOnce(op)
000383fc print("Out:\n", workspace.FetchBlob("out"))
0003842e **Result**
0003843f Out:
00038444  [[1.2084167  2.3336504  2.827349  ]
00038469  [2.7108908  0.9374752  1.7173369 ]
0003848d  [0.03320992 2.1775863  1.0894578 ]]
000384b8 </details>
000384c6 Element-wise min of an arbitrary number of input tensors. This operation can be performed in-place, by using the first input blob as the output blob. All inputs must have the same shape and data type, and the output will have the same shape as the inputs.
000385c7 Github Link:
000385d4 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/minmax_ops.cc
00038623 <details>
0003862e <summary> <b>Example</b> </summary>
00038653 **Code**
00038662 workspace.ResetWorkspace()
0003867e op = core.CreateOperator(
00038698     "Min",
000386a3     ["X", "Y", "Z"],
000386b8     ["X"],
000386c6 workspace.FeedBlob("X", (np.random.rand(2,2)).astype(np.float32))
00038708 workspace.FeedBlob("Y", (np.random.rand(2,2)).astype(np.float32))
0003874a workspace.FeedBlob("Z", (np.random.rand(2,2)).astype(np.float32))
0003878c print("X:", workspace.FetchBlob("X"))
000387b2 print("Y:", workspace.FetchBlob("Y"))
000387d8 print("Z:", workspace.FetchBlob("Z"))
000387fe workspace.RunOperatorOnce(op)
0003881c print("Min:", workspace.FetchBlob("X"))
0003884a **Result**
0003885e [[0.32731926 0.4939747 ]
00038877  [0.29242373 0.43460014]]
00038894 [[0.40928316 0.916115  ]
000388ad  [0.77526504 0.29339448]]
000388ca [[0.7899794  0.90335774]
000388e3  [0.82599413 0.2843068 ]]
000388fd Min:
00038902 [[0.32731926 0.4939747 ]
0003891b  [0.29242373 0.2843068 ]]
0003893b </details>
00038949 This op fills an output tensor with values sampled from a uniform distribution with the range determined by the desired shape of the output. Rather, than specifying the range of values manually, the novelty of Xavier Fill is that it automatically scales the range of the distribution it draws from based on the size of the desired output tensor. For more information check out the paper [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf). The output tensor shape is specified by the *shape* argument. However, if *input_as_shape* is set to *true*, then the *input* should be a 1D tensor containing the desired output shape (the dimensions specified in *extra_shape* will also be appended). In this case, the *shape* argument should **not** be set.
00038c88 *Note: Do not set the shape argument and pass in an input at the same time.*
00038cd6 Github Links:
00038ce4 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/filler_op.h
00038d30 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/filler_op.cc
00038d7e <details>
00038d89 <summary> <b>Example</b> </summary>
00038dae **Code**
00038dbd workspace.ResetWorkspace()
00038dd9 op = core.CreateOperator(
00038df3     "XavierFill",
00038e05     [],
00038e0d     ["out"],
00038e1a     shape=[3,3],
00038e2e workspace.RunOperatorOnce(op)
00038e4c print("Out:\n", workspace.FetchBlob("out"))
00038e7e **Result**
00038e8f Out:
00038e94  [[-0.8412168   0.33207083 -0.88418937]
00038ebc  [ 0.43059897 -0.8340702   0.07781601]
00038ee3  [ 0.93261135 -0.24542928 -0.3980782 ]]
00038f11 </details>
00038f20 This op implements the exponential linear unit (ELU) activation function as described in [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)](https://arxiv.org/abs/1511.07289). The op takes an input tensor $X$ of arbitrary shape, computes the elementwise elu operation, and returns a vector $Y$ of the same shape as output. The alpha parameter may be passed as an argument, but defaults to 1. The elu operation is defined as
000390e2 $$y=f(x) =\begin{cases}\alpha(e^x-1) & x < 0 \\ x & otherwise\end{cases}$$
0003912e Github Links:
0003913c - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/elu_op.h
00039185 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/elu_op.cc
000391d0 <details>
000391db <summary> <b>Example</b> </summary>
00039200 **Code**
0003920e workspace.ResetWorkspace()
0003922a op = core.CreateOperator(
00039244     "Elu",
0003924f     ["X"],
0003925a     ["Y"],
00039265     alpha=1.1
00039276 workspace.FeedBlob("X", np.random.randn(3, 3).astype(np.float32))
000392b8 print("X:\n", workspace.FetchBlob("X"), "\n")
000392e7 workspace.RunOperatorOnce(op)
00039305 print("Y:\n", workspace.FetchBlob("Y"))
00039333 **Result**
00039347  [[ 0.35339102  1.1860217  -0.10710736]
0003936f  [-3.1173866  -0.1889988  -0.20330353]
00039396  [ 1.8525308  -0.368949    0.506277  ]]
000393c2  [[ 0.35339102  1.1860217  -0.11172786]
000393ea  [-1.0513     -0.18943374 -0.20236646]
00039411  [ 1.8525308  -0.33939326  0.506277  ]]
0003943f </details>
0003944d Split a tensor into a list of tensors, given a lengths input, along the specified
0003949f 'axis'. If `K` outputs are provided, the op assumes `len(lengths) % K == 0`.
000394ec The `input` will be split into `K` parts. Each part of length
0003952a `sum(lengths[i*k:i*k+k))`
00039545 <details>
00039550 <summary> <b>Example 1</b> </summary>
00039577 **Code**
00039586 workspace.ResetWorkspace()
000395a2 op = core.CreateOperator(
000395bc     "SplitByLengths",
000395d2     ["input", "lengths"],
000395ec     ["output_0","output_1","output_2"],
00039614     axis=0
00039622 workspace.FeedBlob("input", np.random.randint(10, size=(9)))
0003965f workspace.FeedBlob("lengths", np.array([3,2,4], dtype=np.int32))
000396a0 print("input:", workspace.FetchBlob("input"))
000396ce print("lengths:", workspace.FetchBlob("lengths"))
00039700 workspace.RunOperatorOnce(op)
0003971e print("output_0:", workspace.FetchBlob("output_0"))
00039752 print("output_1:", workspace.FetchBlob("output_1"))
00039786 print("output_2:", workspace.FetchBlob("output_2"))
000397c0 **Result**
000397d1 input: [2 2 6 6 6 0 5 7 4]
000397ec lengths: [3 2 4]
000397fd output_0: [2 2 6]
0003980f output_1: [6 6]
0003981f output_2: [0 5 7 4]
00039839 <summary> <b>Example 2</b> </summary>
00039860 **Code**
0003986f workspace.ResetWorkspace()
0003988b op = core.CreateOperator(
000398a5     "SplitByLengths",
000398bb     ["input", "lengths"],
000398d5     ["output_0","output_1","output_2"],
000398fd     axis=0,
00039909     use_scaling_lengths=true,
0003992a workspace.FeedBlob("input", np.random.randint(10, size=(9)))
00039967 workspace.FeedBlob("lengths", np.array([1,1,1], dtype=np.int32))
000399a8 print("input:", workspace.FetchBlob("input"))
000399d6 print("lengths:", workspace.FetchBlob("lengths"))
00039a08 print("output_0:", workspace.FetchBlob("output_0"))
00039a3c print("output_1:", workspace.FetchBlob("output_1"))
00039a70 print("output_2:", workspace.FetchBlob("output_2"))
00039aaa **Result**
00039abb input: [2 2 6 6 6 0 5 7 4]
00039ad6 lengths: [1 1 1]
00039ae7 output_0: [2 2 6]
00039af9 output_1: [6 6 6]
00039b0b output_2: [5 7 4]
00039b23 </details>
00039b31 Split an `input` tensor into a list of tensors, along the axis specified by the `axis` dimension. The lengths of the split can be specified using argument `split` or optional second input blob to the operator. Otherwise, the tensor is split to equal sized parts.
00039c39 Github Links:
00039c47 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/concat_split_op.cc
00039c9b <details>
00039ca6 <summary> <b>Example</b> </summary>
00039ccb **Code**
00039cda workspace.ResetWorkspace()
00039cf6 op = core.CreateOperator(
00039d10     "Split",
00039d1d     ["input"],
00039d2c     ["output_0","output_1","output_2"],
00039d54     split=(3,2,4),
00039d67     axis=0
00039d75 workspace.FeedBlob("input", np.random.randint(10, size=(9)))
00039db2 print("input:", workspace.FetchBlob("input"))
00039de0 workspace.RunOperatorOnce(op)
00039dfe print("output_0:", workspace.FetchBlob("output_0"))
00039e32 print("output_1:", workspace.FetchBlob("output_1"))
00039e66 print("output_2:", workspace.FetchBlob("output_2"))
00039ea0 **Result**
00039eb1 input: [2 2 6 6 6 0 5 7 4]
00039ecc output_0: [2 2 6]
00039ede output_1: [6 6]
00039eee output_2: [0 5 7 4]
00039f08 </details>
00039f16 This op fills a uint8 output tensor with the data specified by the *value* argument. The data must previously be serialized as a byte string. The output tensor shape is specified by the *shape* argument. Beware, when using this argument *value* should have a value for every element of the *output*, as missing values will not be initialized automatically. If *input_as_shape* is set to *true*, then the *input* should be a 1D tensor containing the desired output shape (the dimensions specified in *extra_shape* will also be appended). In this case, the *shape* argument should **not** be set.
0003a16a This op allows us to write uint8 tensors to Protobuf as byte strings and read them back as uint8 tensors in order to avoid the Protobuf uint32_t varint encoding size penalty.
0003a21a <details>
0003a225 <summary> <b>Example</b> </summary>
0003a24a **Code**
0003a259 workspace.ResetWorkspace()
0003a275 val = np.array([1, 2, 3], dtype=np.uint8)
0003a29f op = core.CreateOperator(
0003a2b9     "GivenTensorByteStringToUInt8Fill",
0003a2e1     [],
0003a2e9     ["out"],
0003a2f6     values=[val.tobytes()],
0003a312     shape=val.shape,
0003a32a workspace.RunOperatorOnce(op)
0003a348 print("Out:\n", workspace.FetchBlob("out"))
0003a37a **Result**
0003a38b Out:
0003a390  [1 2 3]
0003a39f </details>
0003a3ad The *LengthsRangeFill* op takes a single input *lengths* and outputs a single tensor *range_sequence*. For each element of *lengths*, the op appends the range(0,lengths) vector to the end of *range_sequence*. For example, if input=[2,4,1], the output would be [0,1,0,1,2,3,0].
0003a4c3 Github Links:
0003a4d1 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/filler_op.h
0003a51d - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/filler_op.cc
0003a56b <details>
0003a576 <summary> <b>Example</b> </summary>
0003a59b **Code**
0003a5aa workspace.ResetWorkspace()
0003a5c6 op = core.CreateOperator(
0003a5e0     "LengthsRangeFill",
0003a5f8     ["lengths"],
0003a609     ["range_sequence"],
0003a624 workspace.FeedBlob("lengths", np.array([2,4,1]).astype(np.int32))
0003a666 print("lengths:\n", workspace.FetchBlob("lengths"))
0003a69b workspace.RunOperatorOnce(op)
0003a6b9 print("range_sequence: \n", workspace.FetchBlob("range_sequence"))
0003a702 **Result**
0003a713 lengths:
0003a71c  [2 4 1]
0003a725 range_sequence:
0003a735  [0 1 0 1 2 3 0]
0003a74c </details>
0003a75a This op fills an output tensor with the data specified by the *value* and *dtype* arguments.  The output tensor shape is specified by the *shape* argument. Beware, when using this argument *value* should have a value for every element of the *output*, as missing values will not be initialized automatically. If *input_as_shape* is set to *true*, then the *input* should be a 1D tensor containing the desired output shape (the dimensions specified in *extra_shape* will also be appended). In this case, the *shape* argument should **not** be set.
0003a97e *Note: Do not set the shape argument and pass in an input at the same time.*
0003a9cc Github Links:
0003a9da - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/given_tensor_fill_op.h
0003aa31 - https://github.com/caffe2/caffe2/blob/master/caffe2/operators/given_tensor_fill_op.cc
0003aa8a <details>
0003aa95 <summary> <b>Example</b> </summary>
0003aaba **Code**
0003aac9 workspace.ResetWorkspace()
0003aae5 op = core.CreateOperator(
0003aaff     "GivenTensorFill",
0003ab16     [],
0003ab1e     ["out"],
0003ab2b     values=[1., 2., 3.],
0003ab44     shape=[3],
0003ab56 workspace.RunOperatorOnce(op)
0003ab74 print("Out:\n", workspace.FetchBlob("out"))
0003aba6 **Result**
0003abb7 Out:
0003abbc  [1. 2. 3.]
0003abce </details>
0003abdc Input `data` is a N * D matrix. Apply box-cox transform for each column.
0003ac25 `lambda1` and `lambda2` is of size D that defines the hyper-parameters for
0003ac70 the transform of each column `x` of the input `data`:
0003aca7     ln(x + lambda2), if lambda1 == 0
0003accc     ((x + lambda2)^lambda1 - 1)/lambda1, if lambda1 != 0
0003ad09 PReluGradient takes both Y and dY and uses this to update dX and dW according
0003ad57 to the chain rule and derivatives of the rectified linear function.
0003ad9e Applies rectified linear unit operation to the input data element-wise. The Relu operation takes one input $X$, produces one output $Y$, and is defined as:
0003ae3b $$Y = max(0,X)$$
0003ae4d Github Links:
0003ae5b - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/relu_op.h
0003aea5 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/relu_op.cc
0003aef1 <details>
0003aefc <summary> <b>Example</b> </summary>
0003af21 **Code**
0003af2f workspace.ResetWorkspace()
0003af4b op = core.CreateOperator(
0003af65   "Relu",
0003af6f   ["X"],
0003af78   ["Y"]
0003af85 workspace.FeedBlob("X", np.random.randn(4, 4).astype(np.float32)) // NCHW
0003afcf print("X:\n", workspace.FetchBlob("X"), "\n")
0003affe workspace.RunOperatorOnce(op)
0003b01c print("Y:\n", workspace.FetchBlob("Y"))
0003b04a **Result**
0003b05e  [[-1.4655551   0.64575136  0.7921748   0.4150579 ]
0003b092  [ 0.41085166 -0.2837964   0.9881425  -1.9300346 ]
0003b0c5  [ 0.39705405  0.44639114  0.9940703   0.2926532 ]
0003b0f8  [-0.6726489   0.01330667  1.101319    0.33858967]]
0003b130  [[0.         0.64575136 0.7921748  0.4150579 ]
0003b160  [0.41085166 0.         0.9881425  0.        ]
0003b18f  [0.39705405 0.44639114 0.9940703  0.2926532 ]
0003b1be  [0.         0.01330667 1.101319   0.33858967]]
0003b1f4 </details>
0003b204 The *PRelu* op takes input data tensor $X$, an input slope tensor $slope$, and produces one output tensor $Y$ of the same shape as $X.$ The op performs the element wise *PRelu* operation, defined as
0003b2cc $$y=prelu(x) =\begin{cases}slope * x & x < 0\\x & otherwise\end{cases}$$
0003b316 Note, is slope is size 1, the value is shared across the channels, otherwise $X$ and $slope$ must be the same shape. See [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852) for more information.
0003b426 Github Links:
0003b435 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/prelu_op.h
0003b480 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/prelu_op.cc
0003b4ce <details>
0003b4d9 <summary> <b>Example</b> </summary>
0003b4fe **Code**
0003b50d workspace.ResetWorkspace()
0003b529 op = core.CreateOperator(
0003b543     "PRelu",
0003b550     ["X","Slope"],
0003b563     ["Y"],
0003b571 workspace.FeedBlob("X", np.random.randn(3, 3).astype(np.float32))
0003b5b3 print("X:\n", workspace.FetchBlob("X"), "\n")
0003b5e2 workspace.FeedBlob("Slope", np.array([0.1]).astype(np.float32))
0003b622 print("Slope:\n", workspace.FetchBlob("Slope"), "\n")
0003b659 workspace.RunOperatorOnce(op)
0003b677 print("Y:\n", workspace.FetchBlob("Y"))
0003b6a5 **Result**
0003b6b9  [[ 0.3957382  -0.19725518 -0.26991343]
0003b6e1  [ 1.5513182  -0.27427664 -0.14584002]
0003b708  [-0.4121164   0.9292345   0.96426094]]
0003b731 Slope:
0003b738  [0.1]
0003b743  [[ 0.3957382  -0.01972552 -0.02699134]
0003b76b  [ 1.5513182  -0.02742766 -0.014584  ]
0003b792  [-0.04121164  0.9292345   0.96426094]]
0003b7c0 </details>
0003b7cf The *LeakyRelu* op takes one input tensor $X$ and an argument $alpha$, and produces one output tensor $Y$ of the same shape as $X.$ The op performs the element wise leaky relu operation, defined as
0003b896 $$y=LeakyRelu(x) =\begin{cases}\alpha x & x < 0\\x & otherwise\end{cases}$$
0003b8e3 The default value of *alpha* is 0.01.
0003b90a Github Links:
0003b919 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/leaky_relu_op.h
0003b969 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/leaky_relu_op.cc
0003b9bc <details>
0003b9c7 <summary> <b>Example</b> </summary>
0003b9ec **Code**
0003b9fb workspace.ResetWorkspace()
0003ba17 op = core.CreateOperator(
0003ba31     "LeakyRelu",
0003ba42     ["X"],
0003ba4d     ["Y"],
0003ba58     alpha=0.01
0003ba6a workspace.FeedBlob("X", np.random.randn(3, 3).astype(np.float32))
0003baac print("X:\n", workspace.FetchBlob("X"), "\n")
0003badb workspace.RunOperatorOnce(op)
0003baf9 print("Y:\n", workspace.FetchBlob("Y"))
0003bb27 **Result**
0003bb3b  [[-0.91060215  0.09374836  2.1429708 ]
0003bb63  [-0.748983    0.19164062 -1.5130422 ]
0003bb8a  [-0.29539835 -0.8530696   0.7673204 ]]
0003bbb6  [[-0.00910602  0.09374836  2.1429708 ]
0003bbde  [-0.00748983  0.19164062 -0.01513042]
0003bc05  [-0.00295398 -0.0085307   0.7673204 ]]
0003bc33 </details>
0003bc42 *Softsign* takes one input data tensor $X$ and produces one output data $Y,$ where the softsign function, $y = \frac{x}{1+ |x|}$, is applied to $X$ elementwise. This operation can be done in an in-place fashion too, by providing the same input and output blobs.
0003bd49 Github Links:
0003bd58 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/softsign_op.cc
0003bda9 <details>
0003bdb4 <summary> <b>Example</b> </summary>
0003bdd9 **Code**
0003bde8 workspace.ResetWorkspace()
0003be04 op = core.CreateOperator(
0003be1e     "Softsign",
0003be2e     ["X"],
0003be39     ["Y"],
0003be47 workspace.FeedBlob("X", np.random.randn(3, 3).astype(np.float32))
0003be89 print("X:\n", workspace.FetchBlob("X"), "\n")
0003beb8 workspace.RunOperatorOnce(op)
0003bed6 print("Y:\n", workspace.FetchBlob("Y"))
0003bf04 **Result**
0003bf18  [[-1.3060539   0.7242748  -1.9907674 ]
0003bf40  [-0.64802396 -0.03244735  0.7455406 ]
0003bf67  [-0.298492   -0.5774271   2.8364444 ]]
0003bf93  [[-0.5663588   0.420046   -0.6656376 ]
0003bfbb  [-0.39321268 -0.03142761  0.4271116 ]
0003bfe2  [-0.2298759  -0.36605626  0.739342  ]]
0003c010 </details>
0003c01f Apply the Sigmoid function element-wise to the input tensor. This is often used
0003c06f as a non-linear activation function in a neural network. The sigmoid function is
0003c0c0 defined as:
0003c0cd $$Sigmoid(x) = \frac{1}{1+\exp(-x)}$$
0003c0f4 Github Links:
0003c103 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/sigmoid_op.cc
0003c153 <details>
0003c15e <summary> <b>Example</b> </summary>
0003c183 **Code**
0003c192 workspace.ResetWorkspace()
0003c1ae op = core.CreateOperator(
0003c1c8     "Sigmoid",
0003c1d7     ["X"],
0003c1e2     ["Y"]
0003c1ef workspace.FeedBlob("X", np.random.randn(5).astype(np.float32))
0003c22e print("input:", workspace.FetchBlob("X"))
0003c258 workspace.RunOperatorOnce(op)
0003c276 print("sigmoid:", workspace.FetchBlob("Y"))
0003c2a8 **Result**
0003c2b9 input: [ 1.5744036   0.31632107  1.7842269   1.4450722  -2.1726978 ]
0003c2fe sigmoid: [0.8284105  0.57842743 0.85621804 0.80923885 0.10222916]
0003c346 </details>
0003c356 Applies the Softmax function to an n-dimensional input Tensor rescaling them so
0003c3a6 that the elements of the n-dimensional output Tensor lie in the range (0,1) and
0003c3f6 sum to 1. The softmax operator is typically the last layer in a classifier network,
0003c44a as its output can be interpreted as confidence probabilities of an input belonging
0003c49d to each class. The input is a 2-D tensor (Tensor) of size (batch_size x
0003c4e5 input_feature_dimensions). The output tensor has the same shape and contains the
0003c536 softmax normalized values of the corresponding input. The softmax function is
0003c584 defined as follows:
0003c599 $$softmax(x_i) = \frac{\exp(x_i)}{\sum_{j} \exp(x_j)}$$
0003c5d2 The input does not need to explicitly be a 2D vector; rather, it will be coerced
0003c623 into one. For an arbitrary n-dimensional tensor `X` in
0003c65a $[a_0, a_1, ..., a_{k-1}, a_k, ..., a_{n-1}]$, where k is the `axis` provided,
0003c6a9 then `X` will be coerced into a 2-dimensional tensor with dimensions
0003c6ee $[(a_0 * ... * a_{k-1}), (a_k * ... * a_{n-1})]$. For the default case where
0003c73b `axis`=1, the `X` tensor will be coerced into a 2D tensor of dimensions
0003c783 $[a_0, (a_1 * ... * a_{n-1})]$, where $a_0$ is often the batch size. In this
0003c7d0 situation, we must have $a_0 = N$ and $a_1 * ... * a_{n-1} = D$. Each of these
0003c81f dimensions must be matched correctly, or else the operator will throw errors.
0003c86e Github Links:
0003c87d - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/softmax_op.h
0003c8ca - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/softmax_op.cc
0003c91a <details>
0003c925 <summary> <b>Example</b> </summary>
0003c94a **Code**
0003c958 workspace.ResetWorkspace()
0003c974 op = core.CreateOperator(
0003c98e     "Softmax",
0003c99d     ["X"],
0003c9a8     ["Y"]
0003c9b5 workspace.FeedBlob("X", np.random.randn(1, 5).astype(np.float32))
0003c9f7 print("input:", workspace.FetchBlob("X"))
0003ca21 workspace.RunOperatorOnce(op)
0003ca3f print("softmax:", workspace.FetchBlob("Y"))
0003ca71 **Result**
0003ca81 input: [[ 0.0417839   0.61960053 -0.23150268 -0.64389366 -3.0000346 ]]
0003cac8 softmax: [[0.24422921 0.43525138 0.18582782 0.12303016 0.01166145]]
0003cb12 </details>
0003cb21 N6caffe213BatchBoxCoxOpINS_10CPUContextEEE
0003cb4c N6caffe28OperatorINS_10CPUContextEEE
0003cba0 NSt6__ndk110__function6__funcIPFNS_10unique_ptrIN6caffe212OperatorBaseENS_14default_deleteIS4_EEEERKNS3_11OperatorDefEPNS3_9WorkspaceEENS_9allocatorISE_EESD_EE
0003cc40 NSt6__ndk110__function6__baseIFNS_10unique_ptrIN6caffe212OperatorBaseENS_14default_deleteIS4_EEEERKNS3_11OperatorDefEPNS3_9WorkspaceEEEE
0003ccca PFNSt6__ndk110unique_ptrIN6caffe212OperatorBaseENS_14default_deleteIS2_EEEERKNS1_11OperatorDefEPNS1_9WorkspaceEE
0003cd3b FNSt6__ndk110unique_ptrIN6caffe212OperatorBaseENS_14default_deleteIS2_EEEERKNS1_11OperatorDefEPNS1_9WorkspaceEE
0003cdab N6caffe225GradientNotImplementedYetE
0003cdd0 N6caffe217GradientMakerBaseE
0003cded NSt6__ndk110__function6__funcIPFNS_10unique_ptrIN6caffe217GradientMakerBaseENS_14default_deleteIS4_EEEERKNS3_11OperatorDefERKNS_6vectorINS3_15GradientWrapperENS_9allocatorISC_EEEEENSD_ISJ_EESI_EE
0003ceb1 NSt6__ndk110__function6__baseIFNS_10unique_ptrIN6caffe217GradientMakerBaseENS_14default_deleteIS4_EEEERKNS3_11OperatorDefERKNS_6vectorINS3_15GradientWrapperENS_9allocatorISC_EEEEEEE
0003cf67 PFNSt6__ndk110unique_ptrIN6caffe217GradientMakerBaseENS_14default_deleteIS2_EEEERKNS1_11OperatorDefERKNS_6vectorINS1_15GradientWrapperENS_9allocatorISA_EEEEE
0003d005 FNSt6__ndk110unique_ptrIN6caffe217GradientMakerBaseENS_14default_deleteIS2_EEEERKNS1_11OperatorDefERKNS_6vectorINS1_15GradientWrapperENS_9allocatorISA_EEEEE
0003d1f4  (08@HPX`hpx
0003d280 N6caffe215BBoxTransformOpIfNS_10CPUContextEEE
0003d2ae N6caffe233ThrowInTheTowelIfGradientIsCalledE
0003d2e3 d<:0vf2L( n\~N6caffe217BoxWithNMSLimitOpINS_10CPUContextEEE
0003d31f N3c1011StorageImplE
0003d333 N3c1020intrusive_ptr_targetE
0003d442 N6caffe219ByteWeightDequantOpINS_10CPUContextEEE
0003d473 N6caffe216ChannelShuffleOpIfNS_10CPUContextEEE
0003d4a2 N6caffe224ChannelShuffleGradientOpIfNS_10CPUContextEEE
0003d4d9 N6caffe212_GLOBAL__N_125GetChannelShuffleGradientE
0003d50c N6caffe26ClipOpIfNS_10CPUContextEEE
0003d530 N6caffe214ClipGradientOpIfNS_10CPUContextEEE
0003d55d N6caffe215GetClipGradientE
0003d578 N6caffe27SplitOpINS_10CPUContextEEE
0003d59c N6caffe216SplitByLengthsOpINS_10CPUContextEEE
0003d5ca NSt6__ndk110__function6__funcIPFNS_6vectorIN6caffe211TensorShapeENS_9allocatorIS4_EEEERKNS3_11OperatorDefERKS7_ENS5_ISE_EESD_EE
0003d64a NSt6__ndk110__function6__baseIFNS_6vectorIN6caffe211TensorShapeENS_9allocatorIS4_EEEERKNS3_11OperatorDefERKS7_EEE
0003d6bc PFNSt6__ndk16vectorIN6caffe211TensorShapeENS_9allocatorIS2_EEEERKNS1_11OperatorDefERKS5_E
0003d716 FNSt6__ndk16vectorIN6caffe211TensorShapeENS_9allocatorIS2_EEEERKNS1_11OperatorDefERKS5_E
0003d76f NSt6__ndk110__function6__funcIPFN6caffe28OpSchema4CostERKNS2_11OperatorDefERKNS_6vectorINS2_11TensorShapeENS_9allocatorIS9_EEEEENSA_ISG_EESF_EE
0003d7ff NSt6__ndk110__function6__baseIFN6caffe28OpSchema4CostERKNS2_11OperatorDefERKNS_6vectorINS2_11TensorShapeENS_9allocatorIS9_EEEEEEE
0003d881 PFN6caffe28OpSchema4CostERKNS_11OperatorDefERKNSt6__ndk16vectorINS_11TensorShapeENS5_9allocatorIS7_EEEEE
0003d8ea FN6caffe28OpSchema4CostERKNS_11OperatorDefERKNSt6__ndk16vectorINS_11TensorShapeENS5_9allocatorIS7_EEEEE
0003d952 NSt6__ndk110__function6__funcIPFNS_4pairINS_6vectorIN6caffe212DeviceOptionENS_9allocatorIS5_EEEES8_EERKNS4_11OperatorDefEENS6_ISE_EESD_EE
0003d9dc NSt6__ndk110__function6__baseIFNS_4pairINS_6vectorIN6caffe212DeviceOptionENS_9allocatorIS5_EEEES8_EERKNS4_11OperatorDefEEEE
0003da58 PFNSt6__ndk14pairINS_6vectorIN6caffe212DeviceOptionENS_9allocatorIS3_EEEES6_EERKNS2_11OperatorDefEE
0003dabc FNSt6__ndk14pairINS_6vectorIN6caffe212DeviceOptionENS_9allocatorIS3_EEEES6_EERKNS2_11OperatorDefEE
0003db1f NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFNS_4pairINS_6vectorINS2_12DeviceOptionENS4_IS8_EEEESA_EERKNS2_11OperatorDefEEEE
0003dbae N6caffe23$_0E
0003dbbc N6caffe28ConcatOpINS_10CPUContextEEE
0003dbe1 N6caffe216GetSplitGradientE
0003dbfd N6caffe217GetConcatGradientE
0003dc1a NSt6__ndk110__function6__funcIZN6caffe216ConvDocGeneratorEPKcE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
0003dc84 NSt6__ndk110__function6__baseIFvRN6caffe28OpSchemaEEEE
0003dcbc The Conv2D operator computes a 2D convolution operation over an input blob $(X)$, with a filter blob $(filter)$ and a bias blob $(bias)$, and outputs a single output blob $(Y)$. Although there are several options for order, the convention is that the input $(X)$ is a blob of shape $(N,C_{in},H_{in},W_{in})$ and the output $(Y)$ is a blob of shape $(N,C_{out},H_{out},W_{out})$. Here, $N$ is the batch size, $C$ is the number of channels, $H$ is the spatial height, and $W$ is the spatial width. For example, if your input data was a batch of five, 100x120pixel RGB images, $X$ would have shape $(5,3,120,100)$.
0003df22 The $filter$ input blob may contain multiple filters and has shape $(M, C_{in}, K_H, K_W)$. Here, $M$ is the number of individual filters contained in the blob, $C_{in}$ is the number of channels of each filter (by convention in 2D convolution it is the same as the number of channels in the input), $K_H$ is the spatial height of the kernel, and $K_W$ is the spatial width of the kernel. The $bias$ blob is a vector of length $M$, where there is one bias for each filter in the $filter$ blob.
0003e111 Given the shape of the input blob and the filter blob, we can calculate the shape of the output blob as follows. The number of items in the batch $N$ will stay the same. The number of channels in the output will equal the number of kernels in the filter blob, so $C_{out} = M.$ With stride and pad defined below, the spatial height and width of the output ($H_{out}$ and $W_{out}$) are calculated as
0003e2a2 $$H_{out} = \left \lfloor{\frac{H_{in} - K_H + 2*pad}{stride}+1}\right \rfloor$$
0003e2f5 $$W_{out} = \left \lfloor{\frac{W_{in} - K_W + 2*pad}{stride}+1}\right \rfloor$$
0003e348 Github Links:
0003e357 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/conv_op.h
0003e3a1 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/conv_op.cc
0003e3ec - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/conv_pool_op_base.h
0003e441 <details>
0003e44c <summary> <b>Example</b> </summary>
0003e471 **Code**
0003e480 workspace.ResetWorkspace()
0003e49c op = core.CreateOperator(
0003e4b6     "Conv",
0003e4c2     ["X", "filter", "bias"],
0003e4df     ["Y"],
0003e4ea     kernel=5,
0003e4f8     pad=1,
0003e503     stride=2
0003e513 // Create X: (N,C,H,W)
0003e52a data = np.random.randn(1,1,8,8).astype(np.float32)
0003e55d print("Data shape: ",data.shape)
0003e57f // Create W: (M,C,Kh,Kw)
0003e598 filters = np.random.randn(3,1,5,5).astype(np.float32)
0003e5ce print("Filter shape: ",filters.shape)
0003e5f5 // Create b: M
0003e604 bias = np.array([1.,1.,1.]).astype(np.float32)
0003e633 print("Bias shape: ",bias.shape)
0003e655 // Put the inputs into the workspace
0003e67a workspace.FeedBlob("X", data)
0003e698 workspace.FeedBlob("filter", filters)
0003e6be workspace.FeedBlob("bias", bias)
0003e6e0 // Run the operator
0003e6f4 workspace.RunOperatorOnce(op)
0003e712 print("Y:\n", workspace.FetchBlob("Y"))
0003e740 **Result**
0003e751 Data shape:  (1, 1, 8, 8)
0003e76b Filter shape:  (3, 1, 5, 5)
0003e787 Bias shape:  (3,)
0003e79c  [[[[  0.6406407    0.8620521    0.56461596]
0003e7c9    [ -1.5042953   -0.79549205 -10.683343  ]
0003e7f5    [ -0.5240259    3.4538248   -3.9564204 ]]
0003e823   [[  0.6876496    4.8328524   -1.9525816 ]
0003e84f    [  1.2995434   -2.3895378    7.2670045 ]
0003e87b    [  3.9929862    1.8126237    5.4699917 ]]
0003e8a9   [[  3.55949      4.7934155    0.76086235]
0003e8d5    [  3.9588015   -1.3251319    4.413117  ]
0003e901    [ -1.5296054   -1.4924102   -3.2552304 ]]]]
0003e936 </details>
0003e944 ZN6caffe216ConvDocGeneratorEPKcE3$_0
0003e969 N6caffe26ConvOpIfNS_10CPUContextEEE
0003e98d N6caffe214ConvPoolOpBaseINS_10CPUContextEEE
0003e9b9 NSt6__ndk110__function6__funcIZN6caffe26ConvOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNHWCEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
0003ea45 NSt6__ndk110__function6__baseIFvPN6caffe26TensorEEEE
0003ea7a ZN6caffe26ConvOpIfNS_10CPUContextEE24RunOnDeviceWithOrderNHWCEvEUlPNS_6TensorEE_
0003eacb NSt6__ndk110__function6__funcIZN6caffe26ConvOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNCHWEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
0003eb57 ZN6caffe26ConvOpIfNS_10CPUContextEE24RunOnDeviceWithOrderNCHWEvEUlPNS_6TensorEE_
0003eba8 N6caffe215ConvTransposeOpIfNS_10CPUContextEEE
0003ebd6 N6caffe223ConvTransposeUnpoolBaseINS_10CPUContextEEE
0003ec0b NSt6__ndk110__function6__funcIZN6caffe215ConvTransposeOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNCHWEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
0003eca1 ZN6caffe215ConvTransposeOpIfNS_10CPUContextEE24RunOnDeviceWithOrderNCHWEvEUlPNS_6TensorEE_
0003ecfc NSt6__ndk110__function6__funcIZN6caffe215ConvTransposeOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNHWCEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
0003ed92 ZN6caffe215ConvTransposeOpIfNS_10CPUContextEE24RunOnDeviceWithOrderNHWCEvEUlPNS_6TensorEE_
0003eded N6caffe221ConvTransposeMobileOpIfNS_10CPUContextEEE
0003ee21 N6caffe226UnsupportedOperatorFeatureE
0003ee47 NSt6__ndk110__function6__funcIZN6caffe221ConvTransposeMobileOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNCHWEvEUlPNS2_6TensorEE_NS_9allocatorIS8_EEFvS7_EEE
0003eee3 ZN6caffe221ConvTransposeMobileOpIfNS_10CPUContextEE24RunOnDeviceWithOrderNCHWEvEUlPNS_6TensorEE_
0003ef44 NSt6__ndk110__function6__funcIZZN6caffe221ConvTransposeMobileOpIfNS2_10CPUContextEE24RunOnDeviceWithOrderNCHWEvENKUlPNS2_6TensorEE_clES7_EUliiE_NS_9allocatorIS9_EEFvimEEE
0003efef NSt6__ndk110__function6__baseIFvimEEE
0003f015 ZZN6caffe221ConvTransposeMobileOpIfNS_10CPUContextEE24RunOnDeviceWithOrderNCHWEvENKUlPNS_6TensorEE_clES4_EUliiE_
0003f086 NSt6__ndk110__function6__funcIZN6caffe225reinterleaveMultithreadedILi1EfNS2_10CPUContextEEEvPKT0_S7_PS5_iiiiiiiPNS2_10ThreadPoolEEUlimE_NS_9allocatorISB_EEFvimEEE
0003f129 ZN6caffe225reinterleaveMultithreadedILi1EfNS_10CPUContextEEEvPKT0_S4_PS2_iiiiiiiPNS_10ThreadPoolEEUlimE_
0003f192 NSt6__ndk110__function6__funcIZN6caffe225reinterleaveMultithreadedILi2EfNS2_10CPUContextEEEvPKT0_S7_PS5_iiiiiiiPNS2_10ThreadPoolEEUlimE_NS_9allocatorISB_EEFvimEEE
0003f235 ZN6caffe225reinterleaveMultithreadedILi2EfNS_10CPUContextEEEvPKT0_S4_PS2_iiiiiiiPNS_10ThreadPoolEEUlimE_
0003f29e NSt6__ndk110__function6__funcIZN6caffe225reinterleaveMultithreadedILi3EfNS2_10CPUContextEEEvPKT0_S7_PS5_iiiiiiiPNS2_10ThreadPoolEEUlimE_NS_9allocatorISB_EEFvimEEE
0003f341 ZN6caffe225reinterleaveMultithreadedILi3EfNS_10CPUContextEEEvPKT0_S4_PS2_iiiiiiiPNS_10ThreadPoolEEUlimE_
0003f3aa NSt6__ndk110__function6__funcIZN6caffe225reinterleaveMultithreadedILi4EfNS2_10CPUContextEEEvPKT0_S7_PS5_iiiiiiiPNS2_10ThreadPoolEEUlimE_NS_9allocatorISB_EEFvimEEE
0003f44d ZN6caffe225reinterleaveMultithreadedILi4EfNS_10CPUContextEEEvPKT0_S4_PS2_iiiiiiiPNS_10ThreadPoolEEUlimE_
0003f4b6 N6caffe29DropoutOpIfNS_10CPUContextEEE
0003f4dd N6caffe217DropoutGradientOpIfNS_10CPUContextEEE
0003f50d NSt6__ndk110__function6__funcIN6caffe23$_1ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
0003f592 N6caffe23$_1E
0003f5a0 N6caffe218GetDropoutGradientE
0003f5be N6caffe227BinaryElementwiseWithArgsOpINS_11TensorTypesIJilfdEEENS_10CPUContextENS_28BinaryFunctorWithDefaultCtorINS_10AddFunctorIS3_EEEENS_15SameTypeAsInputEEE
0003f65e N6caffe227BinaryElementwiseWithArgsOpINS_11TensorTypesIJilfdEEENS_10CPUContextENS_28BinaryFunctorWithDefaultCtorINS_10DivFunctorIS3_EEEENS_15SameTypeAsInputEEE
0003f6fe N6caffe227BinaryElementwiseWithArgsOpINS_11TensorTypesIJilfdEEENS_10CPUContextENS_28BinaryFunctorWithDefaultCtorINS_10MulFunctorIS3_EEEENS_15SameTypeAsInputEEE
0003f79e N6caffe227BinaryElementwiseWithArgsOpINS_11TensorTypesIJilfdEEENS_10CPUContextENS_28BinaryFunctorWithDefaultCtorINS_10SubFunctorIS3_EEEENS_15SameTypeAsInputEEE
0003f83e N6caffe25SumOpINS_10CPUContextEEE
0003f860 N6caffe226UnaryElementwiseWithArgsOpINS_11TensorTypesIJfEEENS_10CPUContextENS_10EluFunctorIS3_EENS_15SameTypeAsInputEEE
0003f8d8 N6caffe227BinaryElementwiseWithArgsOpINS_11TensorTypesIJfEEENS_10CPUContextENS_18EluGradientFunctorIS3_EENS_15SameTypeAsInputEEE
0003f959 N6caffe212_GLOBAL__N_114GetEluGradientE
0003f981 N6caffe213UniformFillOpIfNS_10CPUContextEEE
0003f9ad N6caffe28FillerOpINS_10CPUContextEEE
0003f9d2 N6caffe213UniformFillOpIiNS_10CPUContextEEE
0003f9fe N6caffe219UniqueUniformFillOpINS_10CPUContextEEE
0003fa2f N6caffe214ConstantFillOpINS_10CPUContextEEE
0003fa5b N6caffe214DiagonalFillOpINS_10CPUContextEEE
0003fa87 N6caffe214GaussianFillOpIfNS_10CPUContextEEE
0003fab4 N6caffe212XavierFillOpIfNS_10CPUContextEEE
0003fadf N6caffe210MSRAFillOpIfNS_10CPUContextEEE
0003fb08 N6caffe211RangeFillOpIfNS_10CPUContextEEE
0003fb32 N6caffe218LengthsRangeFillOpINS_10CPUContextEEE
0003fb62 N6caffe210NoGradientE
0003fb78 N6caffe29FlattenOpINS_10CPUContextEEE
0003fb9e N6caffe218GetFlattenGradientE
0003fbbc N6caffe216FullyConnectedOpINS_10CPUContextENS_13DefaultEngineELb1EEE
0003fc01 N6caffe224FullyConnectedGradientOpINS_10CPUContextENS_13DefaultEngineELb1EEE
0003fc4e N6caffe216FullyConnectedOpINS_10CPUContextENS_13DefaultEngineELb0EEE
0003fc93 N6caffe224FullyConnectedGradientOpINS_10CPUContextENS_13DefaultEngineELb0EEE
0003fce0 NSt6__ndk110__function6__funcINS_6__bindIRFNS_6vectorIN6caffe211TensorShapeENS_9allocatorIS5_EEEERKNS4_11OperatorDefERKS8_bEJRKNS_12placeholders4__phILi1EEERKNSH_ILi2EEEbEEENS6_ISO_EEFS8_SB_SD_EEE
0003fda5 NSt6__ndk16__bindIRFNS_6vectorIN6caffe211TensorShapeENS_9allocatorIS3_EEEERKNS2_11OperatorDefERKS6_bEJRKNS_12placeholders4__phILi1EEERKNSF_ILi2EEEbEEE
0003fe3c NSt6__ndk118__weak_result_typeIPFNS_6vectorIN6caffe211TensorShapeENS_9allocatorIS3_EEEERKNS2_11OperatorDefERKS6_bEEE
0003feb1 NSt6__ndk110__function6__funcINS_6__bindIRFN6caffe28OpSchema4CostERKNS3_11OperatorDefERKNS_6vectorINS3_11TensorShapeENS_9allocatorISA_EEEEbEJRKNS_12placeholders4__phILi1EEERKNSJ_ILi2EEEbEEENSB_ISQ_EEFS5_S8_SF_EEE
0003ff86 NSt6__ndk16__bindIRFN6caffe28OpSchema4CostERKNS1_11OperatorDefERKNS_6vectorINS1_11TensorShapeENS_9allocatorIS8_EEEEbEJRKNS_12placeholders4__phILi1EEERKNSH_ILi2EEEbEEE
0004002d NSt6__ndk118__weak_result_typeIPFN6caffe28OpSchema4CostERKNS1_11OperatorDefERKNS_6vectorINS1_11TensorShapeENS_9allocatorIS8_EEEEbEEE
000400b2 N6caffe212_GLOBAL__N_113GetFCGradientE
000400d9 N6caffe28GatherOpINS_10CPUContextEEE
000400fe NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
00040183 N6caffe23$_0E
00040191 N6caffe217GetGatherGradientE
000401ae N6caffe219GenerateProposalsOpINS_10CPUContextEEE
000401df N6caffe217GivenTensorFillOpIfNS_10CPUContextEEE
0004020f N6caffe217GivenTensorFillOpIdNS_10CPUContextEEE
0004023f N6caffe217GivenTensorFillOpIbNS_10CPUContextEEE
0004026f N6caffe217GivenTensorFillOpIsNS_10CPUContextEEE
0004029f N6caffe217GivenTensorFillOpIiNS_10CPUContextEEE
000402cf N6caffe217GivenTensorFillOpIlNS_10CPUContextEEE
000402ff N6caffe217GivenTensorFillOpINSt6__ndk112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS_10CPUContextEEE
00040371 N6caffe234GivenTensorByteStringToUInt8FillOpINS_10CPUContextEEE
000403b1 N6caffe220HeatmapMaxKeypointOpIfNS_10CPUContextEEE
000403e4 N6caffe24IfOpINS_10CPUContextEEE
00040405 NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFbiiEEE
0004044b NSt6__ndk110__function6__baseIFbiiEEE
00040471 N6caffe23$_0E
0004047f N6caffe214InstanceNormOpIfNS_10CPUContextEEE
000404ac N6caffe29IsEmptyOpINS_10CPUContextEEE
000404d2 N6caffe211LeakyReluOpIfNS_10CPUContextEEE
000404fc N6caffe219LeakyReluGradientOpIfNS_10CPUContextEEE
0004052e N6caffe220GetLeakyReluGradientE
0004054e N6caffe226UnaryElementwiseWithArgsOpINS_11TensorTypesIJfEEENS_10CPUContextENS_27UnaryFunctorWithDefaultCtorINS_10LogFunctorIS3_EEEENS_15SameTypeAsInputEEE
000405e9 N6caffe212_GLOBAL__N_114GetLogGradientE
00040611 N6caffe28MatMulOpIfNS_10CPUContextENS_13DefaultEngineEEE
0004064a NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
000406cf N6caffe23$_0E
000406dd N6caffe217GetMatMulGradientE
000406fa N6caffe25MinOpIfNS_10CPUContextEEE
0004071d N6caffe25MaxOpIfNS_10CPUContextEEE
00040740 N6caffe211NormalizeOpIfNS_10CPUContextEEE
0004076a N6caffe219NormalizeGradientOpIfNS_10CPUContextEEE
0004079c N6caffe220GetNormalizeGradientE
000407bc N6caffe212_GLOBAL__N_120NormalizePlanarYUVOpE
000407ea N6caffe211NHWC2NCHWOpIfNS_10CPUContextEEE
00040814 N6caffe211NCHW2NHWCOpIfNS_10CPUContextEEE
0004083e NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
000408c3 N6caffe23$_0E
000408d1 NSt6__ndk110__function6__funcIN6caffe23$_1ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
00040956 N6caffe23$_1E
00040964 N6caffe212_GLOBAL__N_120GetNHWC2NCHWGradientE
00040992 N6caffe212_GLOBAL__N_120GetNCHW2NHWCGradientE
000409c0 N6caffe210PadImageOpIfNS_10CPUContextEEE
000409e9 N6caffe218PadImageGradientOpIfNS_10CPUContextEEE
00040a1a N6caffe219GetPadImageGradientE
00040a39 NSt6__ndk110__function6__funcIZN6caffe223AveragePoolDocGeneratorEPKcE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00040aab consumes an input blob and applies average pooling across the blob according
00040af8 to kernel sizes, stride sizes, pad lengths and dilation. Average pooling consists
00040b4a of taking the average value of a subset of the input tensor according to the kernel
00040b9e size and downsampling the data into the output blob for further processing. The
00040bee `brew` module has a wrapper for this operator for use in a `ModelHelper` object.
00040c40 Pooling layers reduce the spatial dimensionality of the input blob. Each of the
00040c90 output blob's dimensions will reduce according to:
00040cc4 $$dim_{out}=\frac{dim_{in}-kernel+2*pad}{stride}+1$$
00040cfa Github Links:
00040d09 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/pool_op.h
00040d53 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/pool_op.cc
00040d9e - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/conv_pool_op_base.h
00040df4 <details>
00040dff <summary> <b>Example</b> </summary>
00040e24 **Code**
00040e32 workspace.ResetWorkspace()
00040e4e op = core.CreateOperator(
00040e68     "AveragePool",
00040e7b     ["X"],
00040e86     ["Y"],
00040e91     kernel=2,
00040e9f     stride=2,
00040eb0 workspace.FeedBlob("X", np.random.randn(1, 1, 6, 6).astype(np.float32)) // NCHW
00040f00 print("X:\n", workspace.FetchBlob("X"), "\n")
00040f2e workspace.RunOperatorOnce(op)
00040f4c print("Y:\n", workspace.FetchBlob("Y"))
00040f79 **Result**
00040f8c  [[[[-0.2883434   0.43498734  0.05417408  1.912558    0.09390241
00040fcd     -0.33173105]
00040fde    [ 1.633709    1.2047161   0.36964908  0.99961185  0.4184147
0004101d      0.9989975 ]
0004102e    [ 1.7644193   0.1789665   1.5812988  -0.6038542  -0.36090398
0004106e      0.33195344]
0004107f    [ 0.9457722  -0.95174325 -0.78124577  1.2062047   1.1903144
000410be      0.2586746 ]
000410cf    [ 1.252104    0.32645547  1.8073524  -0.78397465  0.9978303
0004110e     -0.97614396]
0004111f    [ 0.5440196   1.5778259  -0.76750124  0.5051756   0.8838398
0004115e     -0.37085298]]]]
00041176  [[[[0.7462672  0.83399826 0.2948959 ]
0004119d    [0.4843537  0.3506009  0.35500962]
000411c3    [0.9251013  0.19026303 0.13366827]]]]
000411f1 </details>
000411fe ZN6caffe223AveragePoolDocGeneratorEPKcE3$_0
0004122a NSt6__ndk110__function6__funcIZN6caffe219MaxPoolDocGeneratorEPKcE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00041298 consumes an input blob and applies max pooling across the blob according to
000412e4 kernel sizes, stride sizes, pad lengths and dilation. Max pooling consists of
00041332 taking the maximum value of a subset of the input tensor according to the kernel
00041383 size and downsampling the data into the output blob for further processing. The
000413d3 `brew` module has a wrapper for this operator for use in a `ModelHelper` object.
00041425 Pooling layers reduce the spatial dimensionality of the input blob. Each of the
00041475 output blob's dimensions will reduce according to:
000414a9 $$dim_{out}=\frac{dim_{in}-kernel+2*pad}{stride}+1$$
000414df Github Links:
000414ee - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/pool_op.h
00041538 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/pool_op.cc
00041583 - https://github.com/pytorch/pytorch/blob/main/caffe2/operators/conv_pool_op_base.h
000415d8 <details>
000415e3 <summary> <b>Example</b> </summary>
00041608 **Code**
00041616 workspace.ResetWorkspace()
00041632 op = core.CreateOperator(
0004164c     "MaxPool",
0004165b     ["X"],
00041666     ["Y"],
00041671     kernel=2,
0004167f     stride=2,
00041690 workspace.FeedBlob("X", np.random.randn(1, 1, 6, 6).astype(np.float32)) // NCHW
000416e0 print("X:\n", workspace.FetchBlob("X"), "\n")
0004170e workspace.RunOperatorOnce(op)
0004172c print("Y:\n", workspace.FetchBlob("Y"))
00041759 **Result**
0004176c  [[[[-2.8534958e-01 -1.7719941e+00 -8.2277227e-04  1.1088650e+00
000417ad     -2.1476576e+00 -3.5070452e-01]
000417d0    [-9.0058845e-01 -3.0070004e-01 -1.7907504e+00 -7.1746534e-01
00041810      1.2798511e+00 -3.2214901e-01]
00041833    [ 1.5806322e+00  1.6845188e+00 -2.6633200e-01 -3.8576153e-01
00041873     -9.6424848e-02 -3.9696163e-01]
00041896    [ 1.2572408e-01  6.3612902e-01 -3.9554062e-01 -6.9735396e-01
000418d6     -9.1898698e-01 -1.9609968e-01]
000418f9    [-1.1587460e+00  2.4605224e+00 -1.5497679e+00  1.3020347e-01
00041939     -8.1293899e-01 -7.8803545e-01]
0004195c    [ 1.4323474e+00  1.3618395e+00  9.8975077e-02 -1.1307785e-01
0004199c      7.2035044e-01  2.7642491e-01]]]]
000419c6  [[[[-0.28534958  1.108865    1.2798511 ]
000419f0    [ 1.6845188  -0.266332   -0.09642485]
00041a19    [ 2.4605224   0.13020347  0.72035044]]]]
00041a4b </details>
00041a58 ZN6caffe219MaxPoolDocGeneratorEPKcE3$_0
00041a80 N6caffe26PoolOpIfNS_10CPUContextENS_18AveragePoolFunctorIS1_EEEE
00041ac1 N6caffe26PoolOpIfNS_10CPUContextENS_14MaxPoolFunctorIS1_EEEE
00041afe N6caffe27PReluOpIfNS_10CPUContextEEE
00041b23 N6caffe215PReluGradientOpIfNS_10CPUContextEEE
00041b51 N6caffe216GetPReluGradientE
00041b6d N6caffe213QuantDecodeOpILNS_16QuantDecodeRunTyE0EEE
00041ba1 NSt6__ndk110__function6__funcIZN6caffe212_GLOBAL__N_113DecodeGeneralERKNS2_6TensorES6_PS5_PS4_bEUlS6_S6_S7_S8_bE_NS_9allocatorIS9_EEFvS6_S6_S7_S8_bEEE
00041c38 NSt6__ndk110__function6__baseIFvRKN6caffe26TensorES5_PS4_PS3_bEEE
00041c7a ZN6caffe212_GLOBAL__N_113DecodeGeneralERKNS_6TensorES3_PS2_PS1_bEUlS3_S3_S4_S5_bE_
00041ccd NSt6__ndk110__function6__funcIZN6caffe212_GLOBAL__N_113DecodeGeneralERKNS2_6TensorES6_PS5_PS4_bEUlS6_S6_S7_S8_bE0_NS_9allocatorIS9_EEFvS6_S6_S7_S8_bEEE
00041d65 ZN6caffe212_GLOBAL__N_113DecodeGeneralERKNS_6TensorES3_PS2_PS1_bEUlS3_S3_S4_S5_bE0_
00041db9 NSt6__ndk110__function6__funcIZN6caffe212_GLOBAL__N_113DecodeGeneralERKNS2_6TensorES6_PS5_PS4_bEUlS6_S6_S7_S8_bE1_NS_9allocatorIS9_EEFvS6_S6_S7_S8_bEEE
00041e51 ZN6caffe212_GLOBAL__N_113DecodeGeneralERKNS_6TensorES3_PS2_PS1_bEUlS3_S3_S4_S5_bE1_
00041ea5 N6caffe221QuantDecodeGradientOpE
00041ec6 NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFbiiEEE
00041f0c N6caffe23$_0E
00041f1a NSt6__ndk110__function6__funcIN6caffe23$_1ENS_9allocatorIS3_EEFbiEEE
00041f5f NSt6__ndk110__function6__baseIFbiEEE
00041f84 N6caffe23$_1E
00041f92 N6caffe222GetQuantDecodeGradientE
00041fb4 N6caffe226UnaryElementwiseWithArgsOpINS_11TensorTypesIJfEEENS_10CPUContextENS_27UnaryFunctorWithDefaultCtorINS_11ReluFunctorIS3_EEEENS_15SameTypeAsInputEEE
00042050 N6caffe227BinaryElementwiseWithArgsOpINS_11TensorTypesIJfEEENS_10CPUContextENS_28BinaryFunctorWithDefaultCtorINS_19ReluGradientFunctorIS3_EEEENS_15SameTypeAsInputEEE
000420f6 N6caffe212_GLOBAL__N_115GetReluGradientE
0004211f N6caffe212ReplaceNaNOpINS_10CPUContextEEE
00042149 N6caffe29ReshapeOpIfNS_10CPUContextEEE
00042170 NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
000421f5 N6caffe23$_0E
00042203 N6caffe218GetReshapeGradientE
00042221 N6caffe215ResizeNearestOpIfNS_10CPUContextEEE
0004224f N6caffe223ResizeNearestGradientOpIfNS_10CPUContextEEE
00042285 N6caffe224GetResizeNearestGradientE
000422a9 N6caffe210RoIAlignOpIfNS_10CPUContextEEE
000422d2 N6caffe27ScaleOpINS_10CPUContextEEE
000422f6 N6caffe216GetScaleGradientE
00042312 N6caffe27ShapeOpINS_10CPUContextEEE
00042336 NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
000423bb N6caffe23$_0E
000423c9 N6caffe226UnaryElementwiseWithArgsOpINS_11TensorTypesIJfEEENS_10CPUContextENS_27UnaryFunctorWithDefaultCtorINS_14SigmoidFunctorIS3_EEEENS_15SameTypeAsInputEEE
00042468 N6caffe27SliceOpINS_10CPUContextEEE
0004248c N6caffe215SliceGradientOpINS_10CPUContextEEE
000424b9 NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
0004253e N6caffe23$_0E
0004254c NSt6__ndk110__function6__funcIN6caffe23$_1ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
000425d1 N6caffe23$_1E
000425df N6caffe212_GLOBAL__N_116GetSliceGradientE
00042609 N6caffe29SoftmaxOpIfNS_10CPUContextEEE
00042630 N6caffe217SoftmaxGradientOpIfNS_10CPUContextEEE
00042660 N6caffe218GetSoftmaxGradientE
0004267e N6caffe226UnaryElementwiseWithArgsOpINS_11TensorTypesIJfEEENS_10CPUContextENS_27UnaryFunctorWithDefaultCtorINS_15SoftsignFunctorIS3_EEEENS_15SameTypeAsInputEEE
0004271e N6caffe227BinaryElementwiseWithArgsOpINS_11TensorTypesIJfEEENS_10CPUContextENS_28BinaryFunctorWithDefaultCtorINS_23SoftsignGradientFunctorIS3_EEEENS_15SameTypeAsInputEEE
000427c8 N6caffe212_GLOBAL__N_119GetSoftsignGradientE
000427f5 N6caffe211SpatialBNOpINS_10CPUContextEEE
0004281e NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
000428a3 N6caffe23$_0E
000428b1 N6caffe211StumpFuncOpIffNS_10CPUContextEEE
000428dc NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
00042961 N6caffe23$_0E
0004296f N6caffe216StumpFuncIndexOpIflNS_10CPUContextEEE
0004299f N6caffe245PackedInt8BGRANHWCToNCHWCStylizerPreprocessOpE
000429d8 N6caffe243BRGNCHWCToPackedInt8BGRAStylizerDeprocessOpE
00042a0f N6caffe226UnaryElementwiseWithArgsOpINS_11TensorTypesIJfEEENS_10CPUContextENS_27UnaryFunctorWithDefaultCtorINS_11TanhFunctorIS3_EEEENS_15SameTypeAsInputEEE
00042aab N6caffe211TransposeOpINS_10CPUContextEEE
00042ad4 NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
00042b59 N6caffe23$_0E
00042b67 N6caffe220GetTransposeGradientE
00042b87 N6caffe217QuantDecompZstdOpE
00042ba4 NSt6__ndk110__function6__funcIZN6caffe212_GLOBAL__N_114GetMutableDataEiPNS2_6TensorEE3$_0NS_9allocatorIS6_EEFPhS5_EEE
00042c1a NSt6__ndk110__function6__baseIFPhPN6caffe26TensorEEEE
00042c50 ZN6caffe212_GLOBAL__N_114GetMutableDataEiPNS_6TensorEE3$_0
00042c8b NSt6__ndk110__function6__funcIZN6caffe212_GLOBAL__N_114GetMutableDataEiPNS2_6TensorEE3$_1NS_9allocatorIS6_EEFPhS5_EEE
00042d01 ZN6caffe212_GLOBAL__N_114GetMutableDataEiPNS_6TensorEE3$_1
00042d3c NSt6__ndk110__function6__funcIZN6caffe212_GLOBAL__N_114GetMutableDataEiPNS2_6TensorEE3$_2NS_9allocatorIS6_EEFPhS5_EEE
00042db2 ZN6caffe212_GLOBAL__N_114GetMutableDataEiPNS_6TensorEE3$_2
00042ded NSt6__ndk110__function6__funcIZN6caffe212_GLOBAL__N_114GetMutableDataEiPNS2_6TensorEE3$_3NS_9allocatorIS6_EEFPhS5_EEE
00042e63 ZN6caffe212_GLOBAL__N_114GetMutableDataEiPNS_6TensorEE3$_3
00042e9e N6caffe214ImplodeBatchOpIfNS_10CPUContextEEE
00042ecb N6caffe214ExplodeBatchOpIfNS_10CPUContextEEE
00042ef8 N6caffe28BBoxIDOpIfNS_10CPUContextEEE
00042fe0 N6caffe220HeatmapPCAKeypointOpIfNS_10CPUContextEEE
00043013 N6caffe236MergeProbAndBboxWithConceptMappingOpINS_10CPUContextEEE
00043055 N6caffe29RoIWarpOpIfNS_10CPUContextEEE
0004307c N6caffe223BBoxConcatBatchSplitsOpINS_10CPUContextEEE
000430b1 N6caffe234ConvSequencePredictionRebatchingOpE
000430df N6caffe229ConvSequencePredictionSplitOpE
00043108 N6caffe245BatchSequenceSubConversionPositiveMeanPoolingINS_10CPUContextEEE
00043153 N6caffe226BatchSequenceSubConversionINS_10CPUContextEEE
0004318b N6caffe245BatchSequenceSubConversionNegativeMeanPoolingINS_10CPUContextEEE
000431d6 N6caffe238BatchSequenceSubConversionLastPositiveINS_10CPUContextEEE
0004321a N6caffe239BatchSequenceSubConversionCTRStatisticsINS_10CPUContextEEE
0004325f N6caffe230BatchSequenceSubConversionCopyINS_10CPUContextEEE
0004329b N6caffe224ConvSequenceRebatchingOpINS_10CPUContextEEE
000432d1 N6caffe225BatchSequenceConversionOpINS_10CPUContextEEE
00043308 N6caffe212_GLOBAL__N_112MedianBlurOpE
0004344e  !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
0004362f N6caffe212_GLOBAL__N_118StyleButNotColorOpE
00043751 	2	E	X	k	~	
000438d9 	?	d	
00043a12 # I o 
00043a1f !*!P!v!
00043a2d "1"W"|"
00043a3b #8#^#
00043a49 $?$e$
00043a55 $!%F%l%
000440ed 	 	@	`	
0004487f 	w	a	K	5	
00044af1 	v	I	
00044e59 7C8N6caffe24int89Int8AddOpILNS0_10ActivationE0EEE
00044e8b N6caffe24int89Int8AddOpILNS0_10ActivationE1EEE
00044eba N6caffe24int817Int8AveragePoolOpILNS0_10ActivationE0EEE
00044ef2 N6caffe24int817Int8AveragePoolOpILNS0_10ActivationE1EEE
00044f2a NSt6__ndk110__function6__funcIZN6caffe223AveragePoolDocGeneratorEPKcbE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00044f9d consumes an input blob X and applies average pooling across the
00044fdd the blob according to kernel sizes, stride sizes, and pad lengths defined by the
0004502e ConvPoolOpBase operator. Average pooling consisting of averaging all values of a
0004507f subset of the input tensor according to the kernel size and downsampling the
000450cc data into the output blob Y for further processing.
00045101 ZN6caffe223AveragePoolDocGeneratorEPKcbE3$_0
0004512e N6caffe24int820Int8ChannelShuffleOpE
00045153 N6caffe24int812Int8ConcatOpE
00045170 N6caffe24int810Int8ConvOpILNS0_10ActivationE0EEE
000451a1 NSt6__ndk110__function6__funcIZN6caffe24int810Int8ConvOpILNS3_10ActivationE0EE24RunOnDeviceWithOrderNHWCEvEUlPNS2_6TensorEE_NS_9allocatorIS9_EEFvS8_EEE
00045239 ZN6caffe24int810Int8ConvOpILNS0_10ActivationE0EE24RunOnDeviceWithOrderNHWCEvEUlPNS_6TensorEE_
00045297 NSt6__ndk110__function6__funcIZN6caffe216ConvDocGeneratorEPKcbE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00045303 [Only NHWC order is supported now]Note that other parameters, such as the stride and
00045358 kernel size, or the pads' sizes in each direction are not necessary for input
000453a6 because they are provided by the ConvPoolOpBase operator. Various dimension
000453f2 checks are done implicitly, and the sizes are specified in the Input docs for
00045440 this operator. As is expected, the filter is convolved with a subset of the
0004548c image and the bias is added; this is done throughout the image data and the
000454d8 output is computed. As a side note on the implementation layout:
00045519 conv_op_impl.h is the templated implementation of the conv_op.h file, which is
00045568 why they are separate files.
00045586 ZN6caffe216ConvDocGeneratorEPKcbE3$_0
000455ac N6caffe24int810Int8ConvOpILNS0_10ActivationE1EEE
000455dd NSt6__ndk110__function6__funcIZN6caffe24int810Int8ConvOpILNS3_10ActivationE1EE24RunOnDeviceWithOrderNHWCEvEUlPNS2_6TensorEE_NS_9allocatorIS9_EEFvS8_EEE
00045675 ZN6caffe24int810Int8ConvOpILNS0_10ActivationE1EE24RunOnDeviceWithOrderNHWCEvEUlPNS_6TensorEE_
000456d3 N6caffe24int819Int8ConvTransposeOpE
000456f7 NSt6__ndk110__function6__funcIZN6caffe24int819Int8ConvTransposeOp24RunOnDeviceWithOrderNHWCEvEUlPNS2_6TensorEE_NS_9allocatorIS7_EEFvS6_EEE
00045782 ZN6caffe24int819Int8ConvTransposeOp24RunOnDeviceWithOrderNHWCEvEUlPNS_6TensorEE_
000457d3 N6caffe24int816Int8DequantizeOpE
000457f4 N6caffe24int88Int8FCOpE
0004580c NSt6__ndk110__function6__funcIZN6caffe24int88Int8FCOp11RunOnDeviceEvEUlPNS2_6TensorEE_NS_9allocatorIS7_EEFvS6_EEE
0004587e ZN6caffe24int88Int8FCOp11RunOnDeviceEvEUlPNS_6TensorEE_
000458b6 N6caffe24int813Int8FlattenOpE
000458d4 N6caffe24int821Int8GivenTensorFillOpE
000458fa N6caffe24int824Int8GivenIntTensorFillOpE
00045923 N6caffe24int815Int8LeakyReluOpE
00045943 N6caffe24int813Int8MaxPoolOpILNS0_10ActivationE0EEE
00045977 N6caffe24int813Int8MaxPoolOpILNS0_10ActivationE1EEE
000459ab NSt6__ndk110__function6__funcIZN6caffe219MaxPoolDocGeneratorEPKcbE3$_0NS_9allocatorIS5_EEFvRNS2_8OpSchemaEEEE
00045a1a consumes an input blob X and applies max pooling across the
00045a56 the blob according to kernel sizes, stride sizes, and pad lengths defined by the
00045aa7 ConvPoolOpBase operator. Max pooling consisting of taking the maximum value of a
00045af8 subset of the input tensor according to the kernel size and downsampling the
00045b45 data into the output blob Y for further processing.
00045b7a ZN6caffe219MaxPoolDocGeneratorEPKcbE3$_0
00045ba3 N6caffe24int814Int8QuantizeOpE
00045bc2 NSt6__ndk110__function6__funcIN6caffe23$_0ENS_9allocatorIS3_EEFNS_6vectorINS2_11TensorShapeENS4_IS7_EEEERKNS2_11OperatorDefERKS9_EEE
00045c47 N6caffe23$_0E
00045c55 N6caffe24int810Int8ReluOpE
00045c70 N6caffe24int813Int8ReshapeOpE
00045c8e N6caffe29ReshapeOpIhNS_10CPUContextEEE
00045cb5 N6caffe24int819Int8ResizeNearestOpE
00045cd9 N6caffe24int814Int8RoIAlignOpE
00045cf8 N6caffe24int811Int8SliceOpE
00045d14 N6caffe24int813Int8SigmoidOpE
00045d32 N6caffe24int813Int8SoftmaxOpE
00045d50 N6caffe24int815Int8TransposeOpE
00045d70 N6caffe212NNPACKConvOpE
00045d88 NSt6__ndk110__function6__funcIPFNS_10unique_ptrIN3c1013C10FlagParserENS_14default_deleteIS4_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEENSB_ISH_EESG_EE
00045e35 NSt6__ndk110__function6__baseIFNS_10unique_ptrIN3c1013C10FlagParserENS_14default_deleteIS4_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEE
00045ed4 PFNSt6__ndk110unique_ptrIN3c1013C10FlagParserENS_14default_deleteIS2_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE
00045f5b FNSt6__ndk110unique_ptrIN3c1013C10FlagParserENS_14default_deleteIS2_EEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE
00045fe1 NSt6__ndk110__function6__funcIZN6caffe212NNPACKConvOp24RunOnDeviceWithOrderNCHWEvE3$_0NS_9allocatorIS4_EEFvPNS2_6TensorEEEE
0004605d ZN6caffe212NNPACKConvOp24RunOnDeviceWithOrderNCHWEvE3$_0
000528b5 zPLR
0006223b 7h&A
00062379 #@9h
00062641 #@9h
000627fc (@@9
0006280b 9(8@
00062b8f 6`.@
00063c8b T yh
00063f62 X7a"@
0006401e @y	 @y9
000641e0 	 @y
000642b2 @yh"
000642da @y		
000644ee X7`"@
00064502 X7u"@
00064516 X7a"@
0006458a X7t"@
000645bb R*y(
00064636 X7`"@
0006464a X7u"@
0006465e X7w"@
00064b96 `7	 @
00065046 X7t"@
00065242 @ytN@
0006525b 0(ih8
0006527e @yhR
000652b3 TiRAy
000652c7 T(ki8
00065313 ohRAyzR@
0006532b T(kh8
000653bc hRAyuR@
000653cb T(kh8
00065408 hRAyuR@
00065417 T(kh8
0006543d P@yi
000654de @y		
00065516 @y		
0006554e @y		
00065566 @y		
0006557e @y		
000656a6 @y		
000656de @y		
000661fa @y		
0006636d !@y)
0006646f 7		@
000664f7 7		@
000665cc 	@A9
000665db 6`2@
00066604 h"@9h
000669b5 `@9H
00066deb ThFA9
00066ecc hBA9
00067496 @9	ii8
000674a2 _8I!	
000679bf 7		@
00067b69 80.	
00067c6f ThB@9
00067f9f 7		@
00068145 80.	
0006873b 7		@
000688e5 80.	
00068c37 T*!@
00068d60 I(@)
00068dec (a@9
00068df3 7(	@
000694d7 6`"@
000694e0 hb@9h
00069989 `@9H
000699e7 7		@
00069a13 7		@
0006a153 ThFA9
0006a234 hBA9
0006a7cf 7		@
0006a975 80.	
0006b21c 	eX7
0006b296 JxhdX7
0006b2f2 JxHzX7
0006b3d6 Jxh`X7
0006b4b6 Jxh_X7
0006b58a Jx	\X7	!@
0006b64e Jx	WX7	!@
0006b866 Jx(LX7
0006b8f6 JxhHX7
0006b946 JxhFX7
0006b9f2 E9)}
0006bdc4 hRAy
0006cefd #@9h
0006cf69 #@9h
0006d80c ,-@-h
0006d81c *%A-
0006db37 Th.@
0006dc3f Th&@
0006dd53 Ti.@
0006e114 L-@-
0006e11c J%A-
0006e24f R)M@
0006e357 Tc("
0006e367 Tc8"
0006edeb Rl*@
0006f77b Th&@
0006f877 Th&@
0006f973 Tj&@
0006fc87 Th&@
0006fd7f Th&@
0006fe77 Tj&@
0007015f Th	@
000701bb Tj	@
000703f5 c@9h
0007059d c@9h
0007068d c@9h
000707f1 c@9H
0007081d c@9h
00070ba6 F9hz
000712be JxHyX7
00071442 @yh#@y
000714cc H#@y
000714f6 B9	h
000716f7 <`RA
00071767 q</	
00071784 jrE9
000717d4 f2F9
000718a0 d2F9
00071943 ThrE9
0007195f <iZA
00071ac3 R s@
00071b62 F9*_
00072060 hRAy
0007232f 6 C@
00072866 @yh#@y
000728f4 H#@y
00072b2f <`RA
00072b9f q+k	
00072bbc jrE9
00072c0c f2F9
00072cd8 d2F9
00072d7b ThrE9
00072d97 <iZA
00072fa2 F9*_
000734a4 hRAy
0007376f 6 C@
000748c7 T*yk
00074b38 Lii8k	
00074b90  yhx
00075380 h0@y
00075568 (`@9
000759bf =h'@
00075bd7 7i"@
00076b2f 7i"@
000782f3 ~   
0007830f ~   
000783ef Npin
0007843f 60yh
00078496 #.%ih
0007851a #.%ih
000786ff *LM,
000789ed c@9h
00078b4d c@9h
00078d2d c@9h
00078e8d c@9h
00079049 c@9(
00079bae @-  #
00079c52 @-` !
0007a268 -)@)N
0007a4a7 THD@
0007d073 )K	@
0007d08b Qi:@)
0007d208 /1A)m	@
0007d220 ,E@)1~@
0007d339 6@)		@
0007d5b0 J3@)
0007d801 A@)*	@
0007d910 L(@)
0007d915 4@)		@
0007dab7 Ti(@
0007dabc M0@)H	@
0007dcac ,,@)H	@
0007e6b6 !^   
0007f165 c@9h
0007f389 c@9h
0007f479 c@9h
0007f5dd c@9H
0007f609 c@9h
0007f945 PAyH
0007f9a9 PAyH
0007fd15 PAyH
0007fdc8 	PAy
0007ff69 c@9h
00080182 X7	!@
000805c6 X7	!@
00080697 T?@;
000809e6 X7	!@
00080cea X7	!@
00080dbb T?@;
000811ed #@9h
000812ed #@9h
000816e5 #@9h
000817e5 #@9h
00081bc5 c@9h
00081ce3 T+|@
00081ceb Ri1)
00081d1b T*	@
00081d68 *a@9
00081e6f T7|@
00081e84 	a@9
00082805 c@9h
000828d1 c@9h
00082a89 c@9h
000837f8 	a@9i
000839f1 c@9h
00083adb T)!@
00083aef 7*	@
00083be5 C@9h
00083cb1 C@9h
00083f6d C@9h
0008434b T($@
000844a1 cA9h
00084512 	kk%
00084a81 cA9h
00084ca7 TH7@
00084e0d @@9?!
00085131 c@9h
00085247 RHkj
00085383 0(ih8	}
00085899 #B9h
000861b9 #B9h	
000863b1 @@9?!
00086aa7 Th*@
0008799e @9hR
000879b1 #@9h
00088281 QAysV
000882e1 is8	
000891bf 6hRAy
000891e2 X7`R@
000891ec hRAy
000891ff 0(ih8iN@
00089260 hRAy		
000893aa @9hR
000893bd #@9h
0008969d !@y)
00089792 Jx(.X7
00089956 Jxh$X7
0008999e Jxh#X7
00089a5c h#@y
0008aa40 )@@9
0008b226 @9hR
0008b239 #@9h
0008b442 B9h8
0008b5fe JxH-X7
0008b632 Jxh,X7
0008b68b ThVA
0008b837 )t"A
0008b907 *hVA
0008ba2d PAy?
0008ba55 QAy~H
0008ba99 QAy?
0008cc74 Ka@9J
0008cedc 	a@9i
0008cfed c@9h
0008d161 c@9h
0008d324 (a@9*
0008d548 	a@9i
0008d785 c@9h
0008dc69 CA9h
0008e228 @/r0
0008eebd CA9h
0008f105 #A9h
0008f1ab TU	@
0008fb2d #@9h
000901f3 6hRA
000902ab 6hRA
0009070b Ti"Z
00090750 hRE9
0009129e JxHDX7
000912f8 	BX7
00091301 BX7	!@
00091366 6)*@X7
00091418 )=X7	!@
00091619 #wi)}(
00091655 .X7	 @
00091667 TH.X7
00091702 Jx)}
0009171c (*X7
000917be JxH'X7
000918d3 6hRAy
00091edc I?X7
00091fe0 )9X7
000921ea JxH*X7
000921f5 #wi)}(
0009222e JxH)X7	 @
000922fa JxI$X7
0009235e JxH#X7
00092483 6hRAy
0009395a X7	 @
000939a6 X7	 @
00093c9b T		@
000942bb *h*E
0009432f Th:@
00094482 X79!@
0009448a X7(!@
00094abf T(+@
00094adf Tk6@
00094b17 *#y{
00094eff K*}I
00095e65 	@)(
00095e70 g)@)l-A)
00097b39 CA9h
00097d6d CA9h
00097ecd CA9h
00097f4d CA9h
00098179 CA9h
00098981 #@9h
00099047 6hRA
000990ff 6hRA
00099db6 Jx(?X7
00099e50 i;X7
00099ea8 )9X7
0009a068 )-X7
0009a0ee Jxh)X7
0009a1be Jxh#X7
0009a1dc *%@))}
0009a1e6 Jx(}
0009a1f1 #0)J$X7
0009a246 Jx("X7
0009a802 Jx(=X7
0009a95e 4)I4X7
0009aa12 Jx(/X7
0009abe4 *%@))}
0009abee Jx(}
0009ae5b <(}@
0009c64d 1A).%@)H
0009d19b Th&B
0009d292 Jxi	X7
0009d379 1A)O)@)h
0009d641 c@9h
0009d7f1 c@9h
0009d901 c@9H
0009d92d c@9h
0009df08 	 @9
0009dfe2 JxI8X7	!@
0009e03c )6X7
0009e15a Jx(1X7
0009e2ca 	ka*
0009e2cf Th"A
0009e3b2 Jxh$X7
0009e3c6 JxH$X7
0009e9bc 	 @9
0009e9ed  @9	
0009eee2 Jxi2X7
0009f09a Jx('X7
0009f0f2 Jxh&X7
0009ff78 6\@)
0009ff90 Xd@)
000a01db T F@
000a0296 	k!!
000a077b N1}@
000a080b T1}@
000a086b kJI.
000a0b8a $N#h
000a0be7 T1}~
000a0c8b kJI/
000a0fa2 $N#h
000a1003 N1}~
000a109b kJI.
000a125d c@9h
000a1349 c@9h
000a13e4 hRE9
000a158f T`BA
000a16bd j38aM*
000a17d8 hRE9
000a1cb7 RJ=	
000a1e82 !^   
000a2096 !^   
000a222b R	Y@
000a2888 	a@9i
000a2b19 c@9h
000a34a9 C@9h
000a34e9 C@9h
000a34f8 hBE9
000a3503 ThVA
000a350f ThbE9i
000a3554 hbE9i
000a35a2 E9jbE9i
000a377c hbE9h
000a3a08 hbE9h
000a3a48 hbE9h
000a41c8 hBE9
000a427e JxH"X7
000a431e X7	 @
000a4362 X7	 @
000a4f24 hBE9
000a4fda Jxh"X7
000a507a X7	 @
000a50be X7	 @
000a5794 hBE9
000a584a Jxh"X7
000a58ea X7	 @
000a592e X7	 @
000a5fcc hBE9
000a6082 JxH"X7
000a6122 X7	 @
000a6166 X7	 @
000a68d9 c@9h
000a69c5 c@9h
000a6b29 C@9h
000a6b69 C@9h
000a6b78 hBE9
000a6b83 ThVA
000a6b8f ThbE9i
000a6bd4 hbE9i
000a6c22 E9jbE9i
000a6dfc hbE9h
000a7128 hBE9
000a71de JxH"X7
000a727e X7	 @
000a72c2 X7	 @
000a795c hBE9
000a7a12 Jxh"X7
000a7ab2 X7	 @
000a7af6 X7	 @
000a8194 hBE9
000a824a Jxh"X7
000a82ea X7	 @
000a832e X7	 @
000a89cc hBE9
000a8a82 JxH"X7
000a8b22 X7	 @
000a8b66 X7	 @
000a92d9 c@9h
000a93c5 c@9h
000a9529 C@9h
000a9569 C@9h
000a9578 hBE9
000a9583 ThVA
000a958f ThbE9i
000a95d4 hbE9i
000a9622 E9jbE9i
000a97fc hbE9h
000a9b28 hBE9
000a9bde JxH"X7
000a9c7e X7	 @
000a9cc2 X7	 @
000aa35c hBE9
000aa412 Jxh"X7
000aa4b2 X7	 @
000aa4f6 X7	 @
000aab94 hBE9
000aac4a Jxh"X7
000aacea X7	 @
000aad2e X7	 @
000ab3cc hBE9
000ab482 JxH"X7
000ab522 X7	 @
000ab566 X7	 @
000abcd9 c@9h
000abdc5 c@9h
000abf29 C@9h
000abf69 C@9h
000abf78 hBE9
000abf83 ThVA
000abf8f ThbE9i
000abfd4 hbE9i
000ac022 E9jbE9i
000ac1fc hbE9h
000ac528 hBE9
000ac5de JxH"X7
000ac67e X7	 @
000ac6c2 X7	 @
000acd5c hBE9
000ace12 Jxh"X7
000aceb2 X7	 @
000acef6 X7	 @
000ad594 hBE9
000ad64a Jxh"X7
000ad6ea X7	 @
000ad72e X7	 @
000addcc hBE9
000ade82 JxH"X7
000adf22 X7	 @
000adf66 X7	 @
000ae6d9 c@9h
000ae7c5 c@9h
000aea43 0(ih8	}
000aeb69 PAy	
000aefc0 	QAy?! k
000aefff T yj
000af2dd PAy	
000af6fd PAy	
000afb1d PAy	
000b003d cA9h
000b01b9 cA9h
000b0331 cA9h
000b08cd C@9h
000b090d C@9h
000b0928 hBE9
000b0933 ThVA
000b093f ThbE9i
000b0984 hbE9i
000b09d2 E9jbE9i
000b0bb0 hbE9h
000b1032 X7	 @
000b1076 X7	 @
000b129f T+E@
000b18f0 	a@9i
000b1ae9 #@9h
000b1d14  f`0
000b319f 4i"U
000b31d3 7i"U
000b3560 	!@y?
000b35e2 Jx( X7
000b360e Jx( X7
000b37a6 X7	 @
000b3cd0 hRAy
000b4c0c hRAy
000b52ca X76S@
000b52db 6(SAy
000b55f2 X76S@
000b5603 6(SAy
000b7081 #@9h
000b9506 X7	!@
000b9692 X7	!@
000ba01c `P\P
000ba280 `=\0
000bc85f RMyi
000bcc89 QAy	
000bd14c 	a@9i
000bd345 c@9h
000bd443 7*	@
000bdef6 JxH-X7
000bdf7c j*X7
000bdfda JxI(X7
000be107 *	y7
000be14e JxH)X7
000be697 6hRAy
000be759 c@9h
000be7ba Jx)	X7
000bf0cc *.X7
000bf1fa Jx6}@
000bf236 JxH*X7
000bf296 Jx	(X7
000bf4b7 6(SAy
000bf5ab 6(SAy
000bf9f2 Jx)	X7
000c0062 JxH0X7
000c0090 j/X7
000c0160 	+X7
000c01d2 Jx	(X7
000c02ff *	y7
000c0346 JxH)X7
000c088f 6hRAy
000c0951 c@9h
000c0cae JxH+X7
000c0d56 Jx6}@
000c0d5c J'X7
000c0d92 JxH*X7
000c0df2 Jx	(X7
000c100f 6(SAy
000c1107 6(SAy
000c1bd9 #A9h
000c1ca5 #A9h
000c1d71 #A9h
000c1e24  kXp
000c1e3d #A9h
000c1fcd #A9h
000c2159 c@9h
000c21d1 #A9h
000c22dd #A9h
000c23d9 #A9h
000c2475 #A9h
000c2529 #A9h
000c292d c@9h
000c29a5 #A9h
000c2d47 0:iu8
000c2db6 Jx(6X7
000c2e56 Jx(2X7
000c2ff6 Jxh(X7
000c37eb 0:iu8
000c380a JxI.X7
000c387e JxH5X7
000c3982 Jxh/X7
000c3a46 JxH*X7
000c3a9a Jx((X7
000c515f T7|@
000c5361 c@9h
000c56a9 #@9h
000c594d #@9h
000c6307 R,E@
000c6317 Ta}@
000c6593 TL}@
000c7246 Jxh:X7
000c7687 6@i<
000c769f 6@i;
000c76af 6@i9
000c806b T-9@i
000c809f Tl}@
000c80db T/A@i
000c8527 TL}@
000c8683 T*E@
000c8897 T	E@
000c8f42 LKk	@
000c95ef Th/@
000c96f7 Th'@
000c980b Ti/@
000c9be5 -@-@
000c9bed %A-h"
000c9d4b R)M@
000c9e87 Tc("
000c9e97 Tc8"
000cc01f =LI@
000cc2cf 6fzh
000cc349 Z .	
000cc3c5 Z .	
000cc53b T`Yh
000cc55f R`yh
000cca09 CC9h
000ccb69 CC9h
000ccd49 CC9h
000ccea9 CC9h
000ce6a1 c@9h
000ce700  +R0
000ce755 c@9h
000ce941 c@9h
000cea9d c@9h
000ceb51 c@9h
000ceda5 c@9h
000d0425 c@9h
000d06ff Rc(x
000d077d h)8)
000d0914 Jyix
000d0919 x)x)
000d0e4f 7		@
000d29bb Rc(x
000d2a39 h)8)
000d2ee8 Jyix
000d2eed x)x)
000d3d6b 7		@
000d42e4 `MOP
000d4548 `:O0
000d46ec @-Op
000d4854  "O0
000d4d11 CA9h
000d5c11 CA9(
000d5ebf 7		@
000d5f1c hRAy
000d5f8c kii8
000d5f91 h)8)
000d62b5 cA9h
000d638d cA9h
000d64dd #@9h
000d6509 cA9h
000d66c1 #@9h
000d66ed cA9h
000d6b52 X7	!@
000d6cb6 X7	!@
000d6d62 Jx(|X7
000d6edf Ta|"
000d6efc JAE9
000d7737 T@ .
000d773f T  "
000d81da <N8W7O
000d9ddb 6*!@
000da19f RTT@
000da2e3 TM0@
000da8db OQA	
000daa23 TtU@
000daddb OqKB
000dae2f OqKD
000dae57 OtGE
000dae83 OrSF
000db90c ROh-TWi-1
000db930 SGj-
000db938 TWk-
000db950 SSl-P
000db958 VKm-!
000db96c TWn-$
000db974 QKo-
000db990 UGp-ROq-
000db9ac UKr-SSs-%
000db9c4 UOt-0
000db9cc VGu-A
000db9e0 TWv-D
000db9e8 QKw-9
000dc137 ="D@
000dc33e 3N2O@
000dc34a 5N4WA
000dc3cb Tv\@
000dc44f Tv\@
000dc4c7 Tv\@
000dc527 Tv`@
000dc57b Tv`@
000dceff 6*!@
000dd26b TI	@
000dd957 TL,@
000ddf83 Tj.@
000de097 Tl*@
000de483 6k&@
000df2c7 RI		
000df953 TI		
000dfcc1 c@9h
000dfe05 c@9h
000e0445 !@y)
000e0a29 #@9h
000e0b89 #@9h
000e1543 T F@
000e17e5 #@9h
000e1966 !^   
000e1e7f 6HSAy
000e2aa9 c@9h
000e2b65 c@9h
000e2c75 c@9H
000e2ca1 c@9h
000e2df3 =`RA
000e2faf 6(SAy
000e34c3 0(ih8	}
000e3bf4 	a@9i
000e3ded c@9h
000e4028 @oG0
000e4a84 	a@9i
000e4c7d c@9h
000e556a Jx) X7
000e572d +=)!
000e5733 T)}@
000e57b9 _~)U
000e6a91 cT9h
000e6ad9 #B9h
000e6af9 #C9h
000e6b49 #^9h
000e7085 cG9h
000e70fd cA9h
000e711d #B9h
000e7171 #C9h
000e71a1 #^9h
000e7619 cG9h
000e76e5 #B9h
000e7739 #C9h
000e7769 #^9h
000e7c59 #B9h
000e7cad #C9h
000e7cdd #^9h
000e7d25 #E9h
000e814d cA9h
000e816d #B9h
000e81c5 #C9h
000e821d #^9h
000e8265 #E9h
000e832e A9( 
000e83fd #B9h
000e8455 #C9h
000e84ad #^9h
000e84f5 #E9h
000e85c9 #B9h
000e8621 #C9h
000e8679 #^9h
000e86c1 #E9h
000e877d cT9h
000e87c5 #B9h
000e87e5 #C9h
000e8839 #^9h
000e8881 #E9h
000eb266 Jx)	X7
000eb427 Ti|@
000eb632 X7	!@
000ebb18 	a@9i
000ebdad c@9h
000ebe4d c@9h
000ebf31 c@9h
000ec08d c@9h
000ec2a1 c@9h
000ec6a6 !nbk
000ec6bb Ta{i
000ec889 C@9h
000edd99 c@9h
000ee9c9 #@9h
000eea72 B9HS
000eeaba JxHQX7
000eedcd 1@)-
000eee9b QI}~
000eef33 *	!@)g
000eefac L)@),
000ef02f T(}@
000ef050 l-@)
000ef0c7 TI}@
000ef14c l-@),
000ef2c1 1@).
000ef36f QH}~
000ef419 1@)-
000ef62a B9ie
000ef802 JxhTX7
000ef995 5@)M
000efa10 		X7	!@
000efa7a X7	!@
000efd04 		X7	!@
000efd6e X7	!@
000f0003 NOI.
000f00b6 X7	!@
000f0116 X7	!@
000f0416 JxH>X7
000f048a Jx(;X7
000f0525 6X7	!@
000f062c H0X7
000f0841 1@)-
000f08ef QH}~
000f099d 1@)-
000f0b1f K@yk
000f0cf6 Jx(hX7
000f0eba Jx	\X7	!@
000f0f72 JxhWX7
000f0fca JxHUX7
000f11e1 5@)M
000f1264 )	X7	!@
000f12ce X7	!@
000f1568 )	X7	!@
000f15d2 X7	!@
000f1840 )	X7	!@
000f18aa X7	!@
000f1e91 #@9h
000f1f07 Ti"Z
000f2375 #@9h
000f23ab Ti"Z
000f2781 c@9h
000f29bc  1@0
000f31f0 K1@)M)A).%@)
000f3265 A@)15@)B
000f329a @9m9@)
000f32c3 Kj	@
000f35bd '[))
000f3649 A@)1
000f373b qKK)
000f394a @90}
000f3c50 MM@)
000f3c7c 0E@)
000f3d1d +E)	
000f3dff KI}	
000f4190 /A@)	
000f41ac k)@)
000f467b *J}@
000f471a !N`j
000f47d3 *h$@
000f4930 K1@)M)A).%@)
000f4965 Y@i 
000f49cd 1@)+|
000f4b7d #a)?
000f4c89 'Z))
000f4d18 ka@)
000f4d25 A@))!@)
000f4fc6 	K1~@
000f5241 E@)n
000f52e5 /E)	
000f5714 a-@)
000f5734 )-@)
000f58db Ni		
000f667b ThRE9
000f66a3 T-ik
000f69e2 X7	!@
000f6ac3 6(SAy
000f6b03 4hRE9
000f6ee3 6(SAy
000f6f23 4hRE9
000f6f5f *	}@
000f6f6d '<))
000f71f3 ThRE9
000f721b T-ik
000f7456 X7	!@
000f7537 6(SAy
000f7577 4hRE9
000f7953 6(SAy
000f7993 4hRE9
000f79cf *	}@
000f79dd '<))
000f7cb1 CA9h
000f7e7d CA9h
000f8059 CA9h
000f8239 CA9h
000f8435 CA9h
000f85f9 CA9h
000f87dd CA9h
000f89bd CA9h
000f919b Ri|@
000f91af Nj||
000f9256 "N"@
000f930a &N0@
000f9316 &NE@
000f932e !.e@
000f933e $.!8
000f9a17 *!D@
000f9a4b K!xk
000f9aa7 Tj}@
000f9b12 xna	
000f9bf2 Jxh0X7
000f9c2e JxI/X7
000f9c76 Jx	/X7
000f9d57 6hSAy
000f9f4b /(  
000f9f73 /H  
000f9f7b TAim
000fa0df /(  
000fa10b /H  
000fa163 /H  
000fa52d #@9h
000fa5b1 #@9h
000fa65d #@9h
000fa6e1 #@9h
000fa8f0 	a@9i
000fa928 	!A9i
000fabec  '<0
000fb761 QAy;
000fb778 :QAy
000fc234 i&@x
000fc287 Th&@x
000fc9f3 T+0B
000fcb0f Ti4B
000fcc83 T`*@
000fd7fd c@9h
000fe347 0(ih8	}
000fe5f2 CK+|@
000fe78d C@9h
000fe7cd C@9h
000fe7dc hBE9
000fe7e7 ThVA
000fe7f3 ThbE9i
000fe838 hbE9i
000fe886 E9jbE9i
000fea60 hbE9h
000feee2 X7	 @
000fef26 X7	 @
000ff14f T+E@
000ff16f /(  
000ff7a0 	a@9i
00101012 @y	!@y?
00101032 B9	E
0010105a Jxh;X7
001011b6 Jxh3X7
0010127b T	yw
001013f1 "@y?
001014d6 X7	 @
00102926 @y	!@y?
0010294e B9h-
00102a56 Jx(6X7
00102b8b T	yw
00102cf9 "@y?
00102dde X7	 @
00103e07 R	Y@
0010460c 	a@9i
00104639 #@9h
00104664 	a@9i
00104725 #@9h
001048cd c@9h
00104a8d CA9h
00104c21 CA9h
00104d01 CA9h
00104edd CA9h
00104f47 *k}~
001052df 6(SAy
00105327 TaVA
0010536f Q)}@
001055ba JxH X7
001058af Qi}~
00105c32 Jx('X7
00105fcb Qo{@
00105fd7 *k}~
001062e6 Jx	'X7
0010630e Jxh(X7
00106362 JxH&X7
001063b6 Jx($X7
001066a7 QP{@
001066b7 Q!x@
00106c75 #@9h
00106ece !^   
00106f8a !^   
001070b1 #@9h
0010726d #@9H
001072aa !^   
00107366 !^   
0010753d #A9h
00107675 #A9h
001076a0 	a@9i
00107745 #A9(
0010795d c@9h
001081ed 	@mH
00108207 T(  
0010822f ^JcA
0010834a B-Cyf
001083a7 TP[A
001086d6 !na	
00108851 	@m(
00108856 E97Y
00108873 T(  
00108b16 D-G|
00108b1e E-w|
00108f5d #@9h
00109189 #@9H
00109715 c@9h
00109841 c@9h
00109951 c@9H
0010997d c@9h
0010a7e6 X7	!@
0010b6f2 <N8W7O
0010c0bf 6i"U
0010c467 6i"U
0010c8ba JxHCX7
0010c95a Jxi@X7
0010c9be B9h>
0010ca02 JxH=X7
0010cbe7 KHy;
0010cc12 JxH-X7
0010ccd6 JxH(X7	 @
0010cd2a Jx('X7	 @
0010cd3f Th'X7
0010cd9f Tyku8z~@
0010cde6 JxH$X7
0010cdfe Jxh$X7
0010cf45 QAy`
0010cf8f Tvks8
0010d095 QAy 
0010dbca JxiDX7
0010dc5e JxiAX7
0010dc96 JxH@X7
0010dcaa Jx)@X7
0010dd0e B9(>
0010e029 (X7	 @
0010e03b Th(X7
0010e07d &X7	 @
0010e08f T('X7
0010e14e Jx($X7
0010e291 QAy`
0010e3dd QAy 
0010f177 6i"U
0010f52f 6i"U
0010fad7 TJyh
0010fe3b T`"@
001100e1 #@9h
00110134 	!A9i
001102d5 #@9h
00110328 	a@9i
00110345 CA9h
001103d1 #@9h
001105c5 CA9h
00110750 @_10
00110901 #@9h
00110ce5 #@9h
00111130 *#X7
00111b80 	a@9i
00111d89 c@9h
00111e55 c@9h
00111f2d c@9h
00112089 c@9h
0011213d c@9h
001123a9 c@9h
0011240f T;|@
00112573 T@E@
00112a5e CK+|@
00112c15 C@9h
00112c55 C@9h
00112c64 hBE9
00112c6f ThVA
00112c7b ThbE9i
00112cc0 hbE9i
00112d0e E9jbE9i
00112ee8 hbE9h
00113214 hBE9
001132ca Jx("X7
0011336a X7	 @
001133ae X7	 @
00113d4c 	a@9i
0011490f 0(ih8	}
00114abd #@9h
00114b30 hBE9
00114efe !^   
00114fba !^   
0011529e JxI^X7
001153e3 TIVX7
00115453 T*E@
001154a6 JxHQX7
0011569c hBE9
001156de Jx(FX7
0011591e Jx(3X7
00115a2e Jx(+X7
00115be7 4hjA
0011674f T`xj
00116e61 c@9h
001170c1 c@9h
0011732f =!-@
001175b1 c@9h
001177d5 c@9h
00117f33 T`"@
00118a99 "@yZ
00118d83 6HSAy
00118deb *7y@
00119297 /UaA
001192d7 oEEB
0011932e 'NGEE
001197b3 *3y@
00119973 NlH)
00119a16 VN"*!
00119a73 T(  
00119a91 i181
00119bcd c@9h
00119d05 c@9h
0011a251 C@9h
0011c9d6 	kA0
0011ca36 Jx(3X7
0011ca68 	QAy
0011ca7e JxI.X7
0011cb72 @yjA
0011cb9c 	#@y
0011d437 6hRAy
0011d547 6hRAy
0011d65f 6hRAy
0011d777 6hRAy
0011d95f Tl!@
0011da07 Tl @
0011dbf1 #@9h
0011dc5d #@9h
0011e081 c@9h
0011e181 c@9h
0011e271 c@9h
0011e3d5 c@9H
0011e401 c@9h
0011e5b2 JxhKX7
0011e662 JxhGX7
0011e6ea Jx(DX7
0011e9e2 Jxh'X7
0011ea36 JxH%X7
0011ea8a Jx(#X7
0011eb6f *ty@
0011f086 JxHDX7
0011f11e Jx(LX7
0011f186 JxhIX7
0011f20e Jx(FX7
0011f293 T(aA
0011f29f T(UA
0011f2a7 7(YA
0011f2b6 Jx(9X7
0011f384 	PAy?
0011f442 JxH=X7
0011f4d2 JxH9X7
0011f6b3 TI]A
0011f76f THaA
0011f787 TI]A
0011f7c7 THaA
0011f84f THaA
0011f863 TI]A
0011fd91 #@9h
0011ff65 #@9H
00120001 #@9h
001201d5 #@9H
001202d9 c@9h
001203a5 c@9h
001204d1 c@9h
00120615 c@9h
00120705 c@9h
00120764 `q)0
001207b9 c@9h
00120a21 c@9h
0012159a Jx	1X7
001215ce Jx(KX7
0012164a Jxh1X7
0012165e Jx(AX7
001216d9 -X7	!@
00121786 B9H)
001217b9 7X7	!@
00121881 2X7	!@
00121d4b 6hRAy
00121e1b 6hz(
00122192 !^   
0012224e !^   
00122c8d 	@-A
001233e4 	i{8?
00123674 	i{8i
0012404e X7	!@
001241aa X7	!@
00124716 Jx(yX7
00124b36 'NDT7OC
00124b46 &NbT7OB
00124ee4 bSE9
001251cf T	9-
00126077 Rayi
00126083 T @ 
001260cf T @ 
0012624b R#AA
001262bb ^@  
001262db - A 
00126707 T	A 
00126897 T	@ 
001268d7 *Y%(
001268ee @-/;C-
00126f41 `@9H
00127d5f nR*$
00127d83 o#@!
00127ef3 Th	@
00127f53 Tj	@
0012813e #NQx
0012815e 7Nw{
0012822e <nZ[
0012827a  n$X
001294e7 ^@  
00129507 - A 
00129933 T	A 
00129ac3 T	@ 
00129b03 *Y%(
00129b1a @-/;C-
0012adf9 c@9h
0012af41 c@9h
0012b1be JxH*X7
0012b387 6hSAy
0012b403 6hRAy
0012bb99 c@9h
0012bc95 c@9h
0012bd85 c@9h
0012bee9 c@9H
0012bf15 c@9h
0012bfaa JxHEX7
0012bfbe 9)!E
0012c07b ThRA
0012c19e Jx)<X7	!@
0012c2c5 4X7	!@
0012c346 Jx(1X7
0012c426 Jx(+X7
0012c451 *X7	!@
0012c4a8 h(X7
0012c500 (&X7
0012c572 Jx	#X7	!@
0012c7d4 hRAy
0012cc1d 	@- 
0012cf0f Td|@
0012d0c6 C-k}
0012d49d #@9h
0012d675 #@9H
0012d771 c@9h
0012d8b5 c@9h
0012d9c5 c@9H
0012d9f1 c@9h
0012db0a Jx(!X7
0012e521 c@9h
0012e5f1 c@9h
0012e701 c@9H
0012e72d c@9h
0012e7c2 Jx)"X7	!@
0012ea2a **K}~
0012ed4e Jxi*X7	!@
0012eda8 H(X7
0012ee6c (#X7
0012f093 4hRA
0012f0e7 Ti}~
0012f1bb TI}~
0012f441 %X7	!@
0012f4e0 H!X7
0012f6ef 6(SAy
0012f9cc l-@ik
0012fdac 	!@)
0012fe12 X7	!@
0012ff60 wc@)
001301de X7	!@
00130328 wc@)
001304ea X7	!@
0013063c wc@)
001307de X7	!@
001308f1 "@)@
00130ab6 X7	!@
00130e06 B9)1
00130e52 JxH+X7
00130ea6 Jx()X7
00132019 c@9h
001320fd c@9h
001321e1 c@9h
001322dd c@9h
001323c1 c@9h
001324bd c@9h
001325a1 c@9h
00132655 c@9h
00132745 c@9h
00132a4d c@9h
00132b55 "@ys
00132dab QM}@
00132e5d iw8[
00132e64 @iw8
00132e71 iw8W
00133007 K(h68
00133091 l!n d n
0013309b <Gl#nqk
001330a5 l%nad"n
001330bd d1nEf3nrn2nTl n
001330cd d"nul!n
001330d5 l$n!d#n
001330ed f4nbd"n#n'n
001330f9 l nAl!nbd%n#l n
00133109 d!nad"n l n
001331c7 Q)}@
0013323b kJU-
00133305 ij80
0013330d i`80
00133315 il80
00133d68 hj 8
00133e1c $l n
00133e35 d%nBl$nVn'n
00133e45 n1nff#n0f0ncl3n
00133e55 d!n l n
00133e71 l%ned"nBl#n
00133e7d d2nGn'n
00133e89 l3n0n0n
00133e91 f4n8d n
00133ec0 :f2nAn1n
00133ec9 g9nrf$n
00133ed5 d"n`d n6o8n
00133ee1 o=npg:n
00133ee9 l!n!d%nEn4nWo;n
00133f0d l!n d nAl'nun5nMo;n
00133f21 e?nzg:n8n$n
00133f35 l#ncd%n
00133f49 g<n6o8n0n n
00133f5d l"nRd%nsl&n
00133fa9 l9n9g&nmo:nZg;n
00133fd1 n>nwm7n
00133fdd d4nGn0nNo8n
00133fe9 f2npn1n>g/n
00133ffd g-n1f3n
00134011 g:n+m>n
00134025 g/nsm(n
0013402d e+n+g7n
0013403d d*nlg5n@m nze(n
00134051 f7n)g=n
00134065 g6nMo<n
00134071 d%n8e?n
0013407d o)n*g7n
00134095 m n	o6n
001340a1 d(n|m*nXe+n
001340bd o)n;e;nIo6n
001340e5 e7n=o5n
001340ed f9n~g*n
001340fd l)n e nHo6n
00134109 f:n%n>n
00134125 l ndn?nSm;n
00134131 n(n!d%n%n6n
0013413d l#nCn<nBd$n$g'n
00134151 n3n!l%n
00134159 d#nBl$n
00134161 d'n d nal"n
0013416d d!n`j
00134231 jc8b
00134245 Jd8B
00134251 ja8!
00134339 js8v
00134357 K8kx87Kw8
001343bd jf8u
001348dd c@9h
00134d0d zjx,zix*{jx)xix-{hxHxhx
00134d3c ixlx
00134d99 F@8J
00134fc1 C@9h
001358f8 h"@y
00135948 h"@y
00135ecf RBA 
001363f5 #A9h
001364c1 #A9h
00136575 #A9h
00136629 #A9h
00136765 #A9h
001368b1 #A9h
001369f5 #A9h
00136b19 #A9h
00136e19 #A9h
0013715a Jxh/X7
001371f7 5		@
0013722a Jxh2X7
001373da Jxh'X7
00137453 6(SAy
001375ff 6HSAy
00137c0e Jxh1X7
00137cab 5		@
00137cde Jxh4X7
00137eae Jxh(X7
00137f27 6(SAy
001380f3 6HSAy
00138549 B@9i
001386dd c@9h
001387a9 c@9h
0013891d c@9h
00138a41 c@9h
00138c55 c@9h
0013955d c@9h
00139e27 Tt"A
00139ea6 Jx(%X7
0013a01b Ri"A
0013a043 0Jyk
0013a081 PAy?
0013a0b0 hSAy
0013a95d c@9h
0013aa01 #A9h
0013ab4d c@9h
0013abf9 #A9h
0013afd2 X7	!@
0013b544 ,5A)J
0013b54d 76),%@)
0013b55d '5)i
0013b56c -%@)
0013b576 2)Iq@)
0013b63b 6hRAy
0013b6fb 6hRAy
0013b7e3 6hRAy
0013b893 6HSAy
0013b957 6hRAy
0013bc1d B@9I
0013bf81 c@9h
0013c0ed c@9h
0013c2d1 c@9h
0013c6aa X7	!@
0013cb74 ,5A)J
0013cb7d 76),%@)
0013cb8d '5)i
0013cb9c -%@)
0013cba5 73)IU@)
0013cbeb /!A 
0013cc8b 6hRAy
0013cd4b 6hRAy
0013ce33 6hRAy
0013cee3 6HSAy
0013cfa7 6hRAy
0013d21d c@9h
0013d309 c@9h
0013dab8 +%@)
0013dac1 /4)I
0013dacd '3)h
0013dba7 6hRAy
0013dc3f 6hRAy
0013dd27 6hRAy
0013ddd7 6HSAy
0013de9b 6hRAy
0013e0d1 c@9h
0013e1e9 c@9h
0013e2f9 c@9H
0013e325 c@9h
0013e615 c@9h
0013f003 6(SAy
0013f2a5 CA9h
0013f965 QAy	
0014041c hRAy
0014048c kii8
00140491 h)8)
001404a1 #@9	
00140964 hRAy
00140d29 #@9h
00140e7d #@9h
00141b85 cA9h
00141d1d cA9h
00141e95 cA9h
001423e7 6HSAy
00142ad7 6HSAy
00143001 c@9h
001430cd c@9h
00143241 c@9h
00143365 c@9h
00143579 c@9h
001437b3 NdHaN
00143af1 c@9h
00143c19 c@9h
00143d5d c@9h
00144379 CA9h
0014450d c@9h
00144555 CA9h
00144699 c@9h
001446e9 CA9h
00144de6 @y	!@y?
00144e06 B9	E
00144e2e Jxh;X7
00144f8a Jxh3X7
0014504f T	yw
001451c5 "@y?
001452aa X7	 @
00145c5e @y	!@y?
00145c86 B9h-
00145d8e Jx(6X7
00145ec3 T	yw
00146031 "@y?
00146116 X7	 @
0014747e !^   
0014753a !^   
00147fc5 c@9h
001480f1 c@9h
00148201 c@9H
0014822d c@9h
00148365 #@9h
001485bd #@9H
001486aa Jx([X7
00148702 JxhYX7
0014875e Jxh]X7
001487ba Jx(TX7
00148822 JxiQX7
00148892 JxhNX7
001488b9 MX7	!@
001489da JxiFX7	!@
00148a6a JxHDX7
00148adb 6hRAy
00148c77 ^(  
00148f7f =*N@9/J@90F@91B@9
00148fb4 ai`8
00149082 )*,}
00149129 /X)J
0014972d c@9h
00149889 c@9h
00149999 c@9H
001499c5 c@9h
00149ccb 6i"U
00149e07 9hb@
0014a21b 6i"U
0014a35b 9hb@
0014a7cf Th*@
0014b309 c@9h
0014b3f1 c@9h
0014b501 c@9H
0014b52d c@9h
0014b81a Jxi	X7
0014bb61 c@9h
0014bc61 c@9h
0014bd71 c@9H
0014bd9d c@9h
0014c6bd c@9h
0014c7b9 c@9h
0014c8c9 c@9H
0014c8f5 c@9h
0014cb55 #@9h
0014cded #@9h
0014cf29 #@9h
0014d111 "@y9
0014d13a B9iR
0014d254 I6X7
0014d38e 	ka2
0014d39a JxH3X7
0014d596 Jx(,X7
0014dfbf ThFA9
0014e0a0 hBA9
0014e63b 7		@
0014e7e1 80.	
0014ec13 oL)@
0014ed4e B9	n
0014ef7b Tt*@
0014f33b Th*A
0014fa81 +O)J
0015011d c@9h
001501f5 c@9h
001502ed c@9h
001504c2 `Q)}
001504cf T(  
001504ea `Q)}
001504f7 TH  
00150512 `Q)}
001507a0 	an9)
00150819 an9H
00150896 `Q)}
001508a3 T(  
001508be `Q)}
00150ab2 A9	(
00150bb4 	,A)
00150ca6 l9h}
00150df4 	an9	
00150f34 	an9	
00150fad an9(
00150fee `Qk}
00150ffb T(  
00151016 `Qk}
00151023 TH  
0015103e `Qk}
0015104b TI@ 
0015112d CB9-}
00151414  	Az
0015141d 	Az@
001515b3 Rif@
00151621 	@9i
00151691 cE)	}	
0015181a B9?0
00151b19 CA9n
001521e6 j9(|
001523b3 T(  
001523db TH  
001524da ;)}-
0015256d s{)(!
001525c9 #E)\e
001525d9 #F)L5
001525e9 #G)U
001525f9 #y)_9
00152609 #H)I!
00152945 an9H
00152959 4A)	0B)K
001529a9 ,F)O
001529ca j9J}
00152ad6 `Q)}
00152ae3 T(  
00152afe `Q)}
00152b0b TH  
00152b26 `Q)}
00152b6a ?)A0
00152d70 	an9i
00152e0e `Q)}
00152e1b T(  
00152e36 `Q)}
00152e53 R@ #
00152f0b *	@ 
00152fb4 	an9i
00152fcd 	Z-	iC9
001531ca F)1|
00153729 TE)P|
001541f5 an9h
0015421a `Q)}
001542d6 `Q)}
001542e3 TH  
001542fe `Q)}
0015450b NZ{a
00154513 N{{a
0015461c 	an9	
0015468d an9h
00154950 )Am9
00154aa3 k	0@
00154d90 +E@9
00154d98 (I@9
00154e04 )A@9
00155006 F)L}
001550e1 dC9+
00155b75 an9h
00155b9a `Q)}
00155ba7 T(  
00155bc2 `Q)}
00155e47 n @ 
00155e63 n @ 
00155e9f n @ 
00155ebb n @ 
00155eff n @ 
00155f17 n @ 
00155f53 n @ 
00155fbe !.cxa
00156006 !.!xa
00156042 !.Bxa
001560f0 	an9	
00156182 `Q)}
0015618f T(  
001561aa `Q)}
001563e8 	an9	
001564ce 	Kk}`
001564fa @8Mxm
00156554 Hhh8Ihi8!
00156560 Jhj8h
00156567 9Hhk8i
0015658c Hhh8h
00156644 {#9.
00156690 i#@Oj#A
00156698 k#AOl#B
001566a0 m#BOn#C
001566a8 o#CO
001566ad #9.p#D
001566b4 q#DOr#E
001566bc s#EOt#F
001566c4 u#FOv#G
001566cc w#GO
001566f1 #SO{#9.
00156720 i#`Oj#a
00156728 k#aOl#b
00156730 m#bOn#c
00156738 o#cO
0015673d #9.p#d
00156744 q#dOr#e
0015674c s#eOt#f
00156754 u#fOv#g
0015675c w#gO
00156781 #sO{#9.
001567b0 i+@Oj+A
001567b8 k+AOl+B
001567c0 m+BOn+C
001567c8 o+CO
001567cd #9.p+D
001567d4 q+DOr+E
001567dc s+EOt+F
001567e4 u+FOv+G
001567ec w+GO
00156811 +SO{#9.
00156840 i+`Oj+a
00156848 k+aOl+b
00156850 m+bOn+c
00156858 o+cO
0015685d #9.p+d
00156864 q+dOr+e
0015686c s+eOt+f
00156874 u+fOv+g
0015687c w+gO1"
00156960 {#9.h#@
00156968 i#@Oj#A
00156970 k#AOl#B
00156978 m#BOn#C
00156980 o#COp#D
00156988 q#DOr#E
00156990 s#EOt#F
00156998 u#FOv#G
001569a0 w#GO?
001569f1 #WOi
001569fc {#9.h#`
00156a04 i#`Oj#a
00156a0c k#aOl#b
00156a14 m#bOn#c
00156a1c o#cOp#d
00156a24 q#dOr#e
00156a2c s#eOt#f
00156a34 u#fOv#g
00156a3c w#gO?
00156a98 {#9.h+@
00156aa0 i+@Oj+A
00156aa8 k+AOl+B
00156ab0 m+BOn+C
00156ab8 o+COp+D
00156ac0 q+DOr+E
00156ac8 s+EOt+F
00156ad0 u+FOv+G
00156ad8 w+GO?B
00156b34 {#9.h+`
00156b3c i+`Oj+a
00156b44 k+aOl+b
00156b4c m+bOn+c
00156b54 o+cOp+d
00156b5c q+dOr+e
00156b64 s+eOt+f
00156b6c u+fOv+g
00156b74 w+gO
00156cbc (IaNjIaN
00156cc9 IaN0JaNrJaN
00156d09 *!.H)!n
00156d11 )!nP*!n
00156f44 {#9.`p
00156f90 i#@Oj#A
00156f98 k#AOl#B
00156fa0 m#BOn#C
00156fa8 o#CO
00156fad #9.p#D
00156fb4 q#DOr#E
00156fbc s#EOt#F
00156fc4 u#FOv#G
00156fcc w#GO
00156ff1 #SO{#9.
00157020 i#`Oj#a
00157028 k#aOl#b
00157030 m#bOn#c
00157038 o#cO
0015703d #9.p#d
00157044 q#dOr#e
0015704c s#eOt#f
00157054 u#fOv#g
0015705c w#gO
00157081 #sO{#9.
001570b0 i+@Oj+A
001570b8 k+AOl+B
001570c0 m+BOn+C
001570c8 o+CO
001570cd #9.p+D
001570d4 q+DOr+E
001570dc s+EOt+F
001570e4 u+FOv+G
001570ec w+GO
00157111 +SO{#9.
00157140 i+`Oj+a
00157148 k+aOl+b
00157150 m+bOn+c
00157158 o+cO
0015715d #9.p+d
00157164 q+dOr+e
0015716c s+eOt+f
00157174 u+fOv+g
0015717c w+gOB 
00157260 {#9.h#@
00157268 i#@Oj#A
00157270 k#AOl#B
00157278 m#BOn#C
00157280 o#COp#D
00157288 q#DOr#E
00157290 s#EOt#F
00157298 u#FOv#G
001572a0 w#GO_
001572f1 #WOi
001572fc {#9.h#`
00157304 i#`Oj#a
0015730c k#aOl#b
00157314 m#bOn#c
0015731c o#cOp#d
00157324 q#dOr#e
0015732c s#eOt#f
00157334 u#fOv#g
0015733c w#gO_
00157398 {#9.h+@
001573a0 i+@Oj+A
001573a8 k+AOl+B
001573b0 m+BOn+C
001573b8 o+COp+D
001573c0 q+DOr+E
001573c8 s+EOt+F
001573d0 u+FOv+G
001573d8 w+GO_@
00157434 {#9.h+`
0015743c i+`Oj+a
00157444 k+aOl+b
0015744c m+bOn+c
00157454 o+cOp+d
0015745c q+dOr+e
00157464 s+eOt+f
0015746c u+fOv+g
00157474 w+gO
001575b4 (IaNjIaN
001575c1 IaN0JaNrJaN
00157601 *!.H)!n
00157609 )!nP*!n
0015777e @M%A
00157806 &.'ju
00157826 '.giu
0015782e '.Giu
0015798e &.'ht
001579be '.'B
00157aa2 &.'hu
00157ac2 '.'ju
00157c12 '.'B@
00157d86 '.Gis
00157d8e '.'is
00157d96 '.gis
00157e86 &.gjj
00157e92 1.qji
00157e9e '.gjk
00157eaa 1.qjm
00157eb6 '.gjl
00157ec2 1.qjn
001581cb TTL@
00158211  #.s"$.
0015821d "#.'
00158226 rN1jv
0015822d UCm1"#.g
0015823a tNR"$.
00158245 "$.s"#.G
00158259 UDm1"#.
00158266 sNR"$.
00158271 "$.s"#.G
00158285 UEm1"#.
00158292 sNR"$.
0015829d "$.s"#.G
001582aa qNqiv
001582b8 1"#.
001582c2 sNR"$.3iv
001582d4 s"#.G
001582e6 sNGA
00158350 2"$.
0015835f ~4ju
0015836d "#.Q
0015837d QCmR"#.
0015838a vNs"$.
001583ba uNs"$.R"#.
001583ee tNs"$.R"#.
001583fb ~viu
00158401 "$.7iu
0015842a tNs"$.R"#.
00158439  #.q
0015844a gNQA
00158495 "#.1"$.R"#.
001584a1 "#.g
001584ad MAm'
001584c0 r"$.
001584c8 1"#.s"#.
001584d9 UBmG
001584ed "$.1"#.
00158501 UCms"#.G
00158519 "$.1"#.
00158526 sNsiv
00158534 s"#.G
00158541 "$.Qiv
00158550 1"#.
00158562 qN1I@
001585d4 1"$.
001585f0 R"$.
001585f5 "#.s"#.
001585fd "#.0
0015860d "$.P
00158620 R"#.sF
00158635 YBms"#.
0015865e sNR"#.
00158675 "$.s"#.
0015867f ~viu
00158685 "$.Wiu
00158692 sNR"#.
001586b1 "$.s"#.
001586ce gN'I@
001586e7 NN0K
00158705 A@m)!
00158721 "$.1"#.R"$.s"#.
0015873d EAmT
00158745 "$.P
0015874a sN1"$.
00158760 s"$.
0015876d "#.4
00158776 rNQI
001587a6 gN1V
001587af N1Ja
001587b9 JaN0
00158829 aAmR"$.
00158831 "$.yiq
00158849 "#.s"#.
00158851 "#.U
00158871 #$.R"#.
0015887c 1"#.
00158892 rNRM@
001588cf N0Ja
001589bf TGD@
001589e8 PMBm
00158a07 /s"$.GA@
00158a1e rNVECmg
00158a29 "$.p
00158a34 1"$.
00158a4a uNVIDm'
00158a55 "$.0
00158a60 Q"$.
00158a76 tNVQEm'
00158a81 "$.vis
00158a8d "$.T1@
00158a97 /6is
00158b58 QUBm
00158b70 2"$.
00158b87 /PE@
00158b9a sNWICm
00158bb4 R"$.
00158bca vNWMDm
00158be8 r"$.
00158bf3 ~xis
00158bfe uNWUEm
00158c13 ~8is
00158c1d "$.U1@
00158d34 7"$.
00158da0 I#$.
00158db2 ~N;j{
00158dc1 !Dm1
00158de1 #$.2
00158e45 !$.9#$.
00158e72 vNvi{
00158e81 #$.1
00158f0e eN1V
00158f27 N1Ja
00158f41 JaNSJaN
00158f49 HaN'
00158f59 (!.1*!.
00158f65 d!.1f!.
00158f71 l".1n".
00159063 N|j{
0015909d !CmS
0015911a zN=E
00159162 |N<E
00159172 yN~i{
0015922a eN1V
00159243 N1Ja
0015925b NQJaN
00159265 HaN'
00159275 (!.1*!.
00159281 d!.2f!.
0015928d l".Pn".gn".
00159352 ".eic
00159682 %.'jp
0015976b ~1hm
00159797 ~&QA
00159803 NBHa
00159808 "HaN@
001598f6 &.'ih
001599d3 ~3jm
001599eb ~5ji
00159a6c dHaN
00159c5e  O  
00159c7f N!Ha
00159c91 HaN@
00159d5b ns"0.
00159d95 "0.i
00159d9c *#'.
00159e73 NZKa
00159e95 JaN4Ka
00159ea9 JaNU
00159eae dNtJaN
00159ec1 *!.v*!n
00159ed1 f2nsn1n
00159ed9 n1nsP
00159f04 s"0.
00159f09 "'.u
00159f4f NtJaN
00159f56 dNs*!.sf1.sn2.s
00159f93 ~0"0.qF
00159fa0 '"'.
00159fe4 EHaN
00159fea dNB(!.Ad!. l .
0015a060 BX .
0015a0af nRJa
0015a0bb nR*!.Rn .Rf!.r
0015a10c cd"n
0015a119 d"ncl!n
0015a129 l!nC
0015a160 cl!.cd".C
0015a184 Al!. d . i"
0015a1a4 Bl!.Bd .B
0015a1df Ti(@
0015a25c Bd#nci
0015a275 d#nBd&n
0015a281 f1ncd$nBd%nbd"nBl nBd!n
0015a2fb <Bd#ncj
0015a315 d'nBd&n
0015a31d f1ncd$nBd%nbd"nBl nBd!nB
0015a357 T,)@
0015a3c8 Bd#n
0015a3e1 d#nBd&n
0015a3ed f1ncd$nBd%nbd"nBl nBd!n
0015a463 =Bd#ncj
0015a47d d'nBd&n
0015a485 f1ncd$nBd%nbd"nBl nBd!nB
0015a500 Bd#nk
0015a57b nBd$na
0015a583 TBl nCd!nb@
0015a5ac Bd#nk
0015a607 nBd$na
0015a60f TBl n
0015a618 Cd!nb@
0015a628 Bl .Bd!.
0015a657 nBd#nA
0015a683 nBd$n
0015a68b TBl nj
0015a698 Cd!nb@
0015a6ac Bl .
0015a6b4 Bd!.
0015a6e8 Bd#n!
0015a6ef TBl .j
0015a6fc Bd!."
0015a749 d!nh
0015a816 @9*h`8
0015a8ae @9+h`8)
0015a8b8 ,hh8!
0015a97a @9,h`8
0015a984 -hi8.hj8!
0015ab53 7 @`
0015adee `QJ}
0015ae03 R$)@z
0015af17 TCI@
0015af1f 4AQ@
0015aff3 4Ai@
0015b07f TC9@
0015b087 4AA@
0015b09f 4Aa@
0015b6ce (*I!
0015b997 T	}`
0015bdab T,}`
0015bdee (*L 
0015be77 T,}`
0015c363 T	}`
0015c40f T*}`
0015c4b7 TK}`
0015cd9e Cm"#@
0015d1e5 dA9H
0015d4ca A9Q}
0015d521 DB9O%
0016a68d .init_array
0016a699 .fini_array
0016a6a5 .text
0016a6ab .got
0016a6b0 .note.android.ident
0016a6c4 .got.plt
0016a6cd .rela.plt
0016a6d7 .bss
0016a6dc .dynstr
0016a6e4 .eh_frame_hdr
0016a6f2 .gnu.version_r
0016a701 .data.rel.ro
0016a70e .relr.dyn
0016a718 .rela.dyn
0016a722 .gnu.version
0016a72f .dynsym
0016a737 .gnu.hash
0016a741 .relro_padding
0016a750 .eh_frame
0016a75a .gcc_except_table
0016a76c .note.gnu.build-id
0016a77f .dynamic
0016a788 .shstrtab
0016a792 .rodata
0016a79a .data
